<?xml version="1.0" standalone="no"?><!DOCTYPE svg PUBLIC "-//W3C//DTD SVG 1.1//EN" "http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd"><svg version="1.1" width="1200" height="970" onload="init(evt)" viewBox="0 0 1200 970" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:fg="http://github.com/jonhoo/inferno"><!--Flame graph stack visualization. See https://github.com/brendangregg/FlameGraph for latest version, and http://www.brendangregg.com/flamegraphs.html for examples.--><!--NOTES: --><defs><linearGradient id="background" y1="0" y2="1" x1="0" x2="0"><stop stop-color="#eeeeee" offset="5%"/><stop stop-color="#eeeeb0" offset="95%"/></linearGradient></defs><style type="text/css">
text { font-family:monospace; font-size:12px }
#title { text-anchor:middle; font-size:17px; }
#matched { text-anchor:end; }
#search { text-anchor:end; opacity:0.1; cursor:pointer; }
#search:hover, #search.show { opacity:1; }
#subtitle { text-anchor:middle; font-color:rgb(160,160,160); }
#unzoom { cursor:pointer; }
#frames > *:hover { stroke:black; stroke-width:0.5; cursor:pointer; }
.hide { display:none; }
.parent { opacity:0.5; }
</style><script type="text/ecmascript"><![CDATA[
        var nametype = 'Function:';
        var fontsize = 12;
        var fontwidth = 0.59;
        var xpad = 10;
        var inverted = true;
        var searchcolor = 'rgb(230,0,230)';
        var fluiddrawing = true;
        var truncate_text_right = false;
    ]]><![CDATA["use strict";
var details, searchbtn, unzoombtn, matchedtxt, svg, searching, frames, known_font_width;
function init(evt) {
    details = document.getElementById("details").firstChild;
    searchbtn = document.getElementById("search");
    unzoombtn = document.getElementById("unzoom");
    matchedtxt = document.getElementById("matched");
    svg = document.getElementsByTagName("svg")[0];
    frames = document.getElementById("frames");
    known_font_width = get_monospace_width(frames);
    total_samples = parseInt(frames.attributes.total_samples.value);
    searching = 0;

    // Use GET parameters to restore a flamegraph's state.
    var restore_state = function() {
        var params = get_params();
        if (params.x && params.y)
            zoom(find_group(document.querySelector('[*|x="' + params.x + '"][y="' + params.y + '"]')));
        if (params.s)
            search(params.s);
    };

    if (fluiddrawing) {
        // Make width dynamic so the SVG fits its parent's width.
        svg.removeAttribute("width");
        // Edge requires us to have a viewBox that gets updated with size changes.
        var isEdge = /Edge\/\d./i.test(navigator.userAgent);
        if (!isEdge) {
            svg.removeAttribute("viewBox");
        }
        var update_for_width_change = function() {
            if (isEdge) {
                svg.attributes.viewBox.value = "0 0 " + svg.width.baseVal.value + " " + svg.height.baseVal.value;
            }

            // Keep consistent padding on left and right of frames container.
            frames.attributes.width.value = svg.width.baseVal.value - xpad * 2;

            // Text truncation needs to be adjusted for the current width.
            update_text_for_elements(frames.children);

            // Keep search elements at a fixed distance from right edge.
            var svgWidth = svg.width.baseVal.value;
            searchbtn.attributes.x.value = svgWidth - xpad;
            matchedtxt.attributes.x.value = svgWidth - xpad;
        };
        window.addEventListener('resize', function() {
            update_for_width_change();
        });
        // This needs to be done asynchronously for Safari to work.
        setTimeout(function() {
            unzoom();
            update_for_width_change();
            restore_state();
        }, 0);
    } else {
        restore_state();
    }
}
// event listeners
window.addEventListener("click", function(e) {
    var target = find_group(e.target);
    if (target) {
        if (target.nodeName == "a") {
            if (e.ctrlKey === false) return;
            e.preventDefault();
        }
        if (target.classList.contains("parent")) unzoom();
        zoom(target);

        // set parameters for zoom state
        var el = target.querySelector("rect");
        if (el && el.attributes && el.attributes.y && el.attributes["fg:x"]) {
            var params = get_params()
            params.x = el.attributes["fg:x"].value;
            params.y = el.attributes.y.value;
            history.replaceState(null, null, parse_params(params));
        }
    }
    else if (e.target.id == "unzoom") {
        unzoom();

        // remove zoom state
        var params = get_params();
        if (params.x) delete params.x;
        if (params.y) delete params.y;
        history.replaceState(null, null, parse_params(params));
    }
    else if (e.target.id == "search") search_prompt();
}, false)
// mouse-over for info
// show
window.addEventListener("mouseover", function(e) {
    var target = find_group(e.target);
    if (target) details.nodeValue = nametype + " " + g_to_text(target);
}, false)
// clear
window.addEventListener("mouseout", function(e) {
    var target = find_group(e.target);
    if (target) details.nodeValue = ' ';
}, false)
// ctrl-F for search
window.addEventListener("keydown",function (e) {
    if (e.keyCode === 114 || (e.ctrlKey && e.keyCode === 70)) {
        e.preventDefault();
        search_prompt();
    }
}, false)
// functions
function get_params() {
    var params = {};
    var paramsarr = window.location.search.substr(1).split('&');
    for (var i = 0; i < paramsarr.length; ++i) {
        var tmp = paramsarr[i].split("=");
        if (!tmp[0] || !tmp[1]) continue;
        params[tmp[0]]  = decodeURIComponent(tmp[1]);
    }
    return params;
}
function parse_params(params) {
    var uri = "?";
    for (var key in params) {
        uri += key + '=' + encodeURIComponent(params[key]) + '&';
    }
    if (uri.slice(-1) == "&")
        uri = uri.substring(0, uri.length - 1);
    if (uri == '?')
        uri = window.location.href.split('?')[0];
    return uri;
}
function find_child(node, selector) {
    var children = node.querySelectorAll(selector);
    if (children.length) return children[0];
    return;
}
function find_group(node) {
    var parent = node.parentElement;
    if (!parent) return;
    if (parent.id == "frames") return node;
    return find_group(parent);
}
function orig_save(e, attr, val) {
    if (e.attributes["fg:orig_" + attr] != undefined) return;
    if (e.attributes[attr] == undefined) return;
    if (val == undefined) val = e.attributes[attr].value;
    e.setAttribute("fg:orig_" + attr, val);
}
function orig_load(e, attr) {
    if (e.attributes["fg:orig_"+attr] == undefined) return;
    e.attributes[attr].value = e.attributes["fg:orig_" + attr].value;
    e.removeAttribute("fg:orig_" + attr);
}
function g_to_text(e) {
    var text = find_child(e, "title").firstChild.nodeValue;
    return (text)
}
function g_to_func(e) {
    var func = g_to_text(e);
    // if there's any manipulation we want to do to the function
    // name before it's searched, do it here before returning.
    return (func);
}
function get_monospace_width(frames) {
    // Given the id="frames" element, return the width of text characters if
    // this is a monospace font, otherwise return 0.
    text = find_child(frames.children[0], "text");
    originalContent = text.textContent;
    text.textContent = "!";
    bangWidth = text.getComputedTextLength();
    text.textContent = "W";
    wWidth = text.getComputedTextLength();
    text.textContent = originalContent;
    if (bangWidth === wWidth) {
        return bangWidth;
    } else {
        return 0;
    }
}
function update_text_for_elements(elements) {
    // In order to render quickly in the browser, you want to do one pass of
    // reading attributes, and one pass of mutating attributes. See
    // https://web.dev/avoid-large-complex-layouts-and-layout-thrashing/ for details.

    // Fall back to inefficient calculation, if we're variable-width font.
    // TODO This should be optimized somehow too.
    if (known_font_width === 0) {
        for (var i = 0; i < elements.length; i++) {
            update_text(elements[i]);
        }
        return;
    }

    var textElemNewAttributes = [];
    for (var i = 0; i < elements.length; i++) {
        var e = elements[i];
        var r = find_child(e, "rect");
        var t = find_child(e, "text");
        var w = parseFloat(r.attributes.width.value) * frames.attributes.width.value / 100 - 3;
        var txt = find_child(e, "title").textContent.replace(/\([^(]*\)$/,"");
        var newX = format_percent((parseFloat(r.attributes.x.value) + (100 * 3 / frames.attributes.width.value)));

        // Smaller than this size won't fit anything
        if (w < 2 * known_font_width) {
            textElemNewAttributes.push([newX, ""]);
            continue;
        }

        // Fit in full text width
        if (txt.length * known_font_width < w) {
            textElemNewAttributes.push([newX, txt]);
            continue;
        }

        var substringLength = Math.floor(w / known_font_width) - 2;
        if (truncate_text_right) {
            // Truncate the right side of the text.
            textElemNewAttributes.push([newX, txt.substring(0, substringLength) + ".."]);
            continue;
        } else {
            // Truncate the left side of the text.
            textElemNewAttributes.push([newX, ".." + txt.substring(txt.length - substringLength, txt.length)]);
            continue;
        }
    }

    console.assert(textElemNewAttributes.length === elements.length, "Resize failed, please file a bug at https://github.com/jonhoo/inferno/");

    // Now that we know new textContent, set it all in one go so we don't refresh a bazillion times.
    for (var i = 0; i < elements.length; i++) {
        var e = elements[i];
        var values = textElemNewAttributes[i];
        var t = find_child(e, "text");
        t.attributes.x.value = values[0];
        t.textContent = values[1];
    }
}

function update_text(e) {
    var r = find_child(e, "rect");
    var t = find_child(e, "text");
    var w = parseFloat(r.attributes.width.value) * frames.attributes.width.value / 100 - 3;
    var txt = find_child(e, "title").textContent.replace(/\([^(]*\)$/,"");
    t.attributes.x.value = format_percent((parseFloat(r.attributes.x.value) + (100 * 3 / frames.attributes.width.value)));

    // Smaller than this size won't fit anything
    if (w < 2 * fontsize * fontwidth) {
        t.textContent = "";
        return;
    }
    t.textContent = txt;
    // Fit in full text width
    if (t.getComputedTextLength() < w)
        return;
    if (truncate_text_right) {
        // Truncate the right side of the text.
        for (var x = txt.length - 2; x > 0; x--) {
            if (t.getSubStringLength(0, x + 2) <= w) {
                t.textContent = txt.substring(0, x) + "..";
                return;
            }
        }
    } else {
        // Truncate the left side of the text.
        for (var x = 2; x < txt.length; x++) {
            if (t.getSubStringLength(x - 2, txt.length) <= w) {
                t.textContent = ".." + txt.substring(x, txt.length);
                return;
            }
        }
    }
    t.textContent = "";
}
// zoom
function zoom_reset(e) {
    if (e.tagName == "rect") {
        e.attributes.x.value = format_percent(100 * parseInt(e.attributes["fg:x"].value) / total_samples);
        e.attributes.width.value = format_percent(100 * parseInt(e.attributes["fg:w"].value) / total_samples);
    }
    if (e.childNodes == undefined) return;
    for(var i = 0, c = e.childNodes; i < c.length; i++) {
        zoom_reset(c[i]);
    }
}
function zoom_child(e, x, zoomed_width_samples) {
    if (e.tagName == "text") {
        var parent_x = parseFloat(find_child(e.parentNode, "rect[x]").attributes.x.value);
        e.attributes.x.value = format_percent(parent_x + (100 * 3 / frames.attributes.width.value));
    } else if (e.tagName == "rect") {
        e.attributes.x.value = format_percent(100 * (parseInt(e.attributes["fg:x"].value) - x) / zoomed_width_samples);
        e.attributes.width.value = format_percent(100 * parseInt(e.attributes["fg:w"].value) / zoomed_width_samples);
    }
    if (e.childNodes == undefined) return;
    for(var i = 0, c = e.childNodes; i < c.length; i++) {
        zoom_child(c[i], x, zoomed_width_samples);
    }
}
function zoom_parent(e) {
    if (e.attributes) {
        if (e.attributes.x != undefined) {
            e.attributes.x.value = "0.0%";
        }
        if (e.attributes.width != undefined) {
            e.attributes.width.value = "100.0%";
        }
    }
    if (e.childNodes == undefined) return;
    for(var i = 0, c = e.childNodes; i < c.length; i++) {
        zoom_parent(c[i]);
    }
}
function zoom(node) {
    var attr = find_child(node, "rect").attributes;
    var width = parseInt(attr["fg:w"].value);
    var xmin = parseInt(attr["fg:x"].value);
    var xmax = xmin + width;
    var ymin = parseFloat(attr.y.value);
    unzoombtn.classList.remove("hide");
    var el = frames.children;
    var to_update_text = [];
    for (var i = 0; i < el.length; i++) {
        var e = el[i];
        var a = find_child(e, "rect").attributes;
        var ex = parseInt(a["fg:x"].value);
        var ew = parseInt(a["fg:w"].value);
        // Is it an ancestor
        if (!inverted) {
            var upstack = parseFloat(a.y.value) > ymin;
        } else {
            var upstack = parseFloat(a.y.value) < ymin;
        }
        if (upstack) {
            // Direct ancestor
            if (ex <= xmin && (ex+ew) >= xmax) {
                e.classList.add("parent");
                zoom_parent(e);
                to_update_text.push(e);
            }
            // not in current path
            else
                e.classList.add("hide");
        }
        // Children maybe
        else {
            // no common path
            if (ex < xmin || ex >= xmax) {
                e.classList.add("hide");
            }
            else {
                zoom_child(e, xmin, width);
                to_update_text.push(e);
            }
        }
    }
    update_text_for_elements(to_update_text);
}
function unzoom() {
    unzoombtn.classList.add("hide");
    var el = frames.children;
    for(var i = 0; i < el.length; i++) {
        el[i].classList.remove("parent");
        el[i].classList.remove("hide");
        zoom_reset(el[i]);
    }
    update_text_for_elements(el);
}
// search
function reset_search() {
    var el = document.querySelectorAll("#frames rect");
    for (var i = 0; i < el.length; i++) {
        orig_load(el[i], "fill")
    }
    var params = get_params();
    delete params.s;
    history.replaceState(null, null, parse_params(params));
}
function search_prompt() {
    if (!searching) {
        var term = prompt("Enter a search term (regexp " +
            "allowed, eg: ^ext4_)", "");
        if (term != null) {
            search(term)
        }
    } else {
        reset_search();
        searching = 0;
        searchbtn.classList.remove("show");
        searchbtn.firstChild.nodeValue = "Search"
        matchedtxt.classList.add("hide");
        matchedtxt.firstChild.nodeValue = ""
    }
}
function search(term) {
    var re = new RegExp(term);
    var el = frames.children;
    var matches = new Object();
    var maxwidth = 0;
    for (var i = 0; i < el.length; i++) {
        var e = el[i];
        // Skip over frames which are either not visible, or below the zoomed-to frame
        if (e.classList.contains("hide") || e.classList.contains("parent")) {
            continue;
        }
        var func = g_to_func(e);
        var rect = find_child(e, "rect");
        if (func == null || rect == null)
            continue;
        // Save max width. Only works as we have a root frame
        var w = parseInt(rect.attributes["fg:w"].value);
        if (w > maxwidth)
            maxwidth = w;
        if (func.match(re)) {
            // highlight
            var x = parseInt(rect.attributes["fg:x"].value);
            orig_save(rect, "fill");
            rect.attributes.fill.value = searchcolor;
            // remember matches
            if (matches[x] == undefined) {
                matches[x] = w;
            } else {
                if (w > matches[x]) {
                    // overwrite with parent
                    matches[x] = w;
                }
            }
            searching = 1;
        }
    }
    if (!searching)
        return;
    var params = get_params();
    params.s = term;
    history.replaceState(null, null, parse_params(params));

    searchbtn.classList.add("show");
    searchbtn.firstChild.nodeValue = "Reset Search";
    // calculate percent matched, excluding vertical overlap
    var count = 0;
    var lastx = -1;
    var lastw = 0;
    var keys = Array();
    for (k in matches) {
        if (matches.hasOwnProperty(k))
            keys.push(k);
    }
    // sort the matched frames by their x location
    // ascending, then width descending
    keys.sort(function(a, b){
        return a - b;
    });
    // Step through frames saving only the biggest bottom-up frames
    // thanks to the sort order. This relies on the tree property
    // where children are always smaller than their parents.
    for (var k in keys) {
        var x = parseInt(keys[k]);
        var w = matches[keys[k]];
        if (x >= lastx + lastw) {
            count += w;
            lastx = x;
            lastw = w;
        }
    }
    // display matched percent
    matchedtxt.classList.remove("hide");
    var pct = 100 * count / maxwidth;
    if (pct != 100) pct = pct.toFixed(1);
    matchedtxt.firstChild.nodeValue = "Matched: " + pct + "%";
}
function format_percent(n) {
    return n.toFixed(4) + "%";
}
]]></script><rect x="0" y="0" width="100%" height="970" fill="url(#background)"/><text id="title" fill="rgb(0,0,0)" x="50.0000%" y="24.00">py-spy record -o profile.svg -r 20 --native -- python self_play.py</text><text id="details" fill="rgb(0,0,0)" x="10" y="40.00"> </text><text id="unzoom" class="hide" fill="rgb(0,0,0)" x="10" y="24.00">Reset Zoom</text><text id="search" fill="rgb(0,0,0)" x="1190" y="24.00">Search</text><text id="matched" fill="rgb(0,0,0)" x="1190" y="959.00"> </text><svg id="frames" x="10" width="1180" total_samples="25642"><g><title>&lt;module&gt; (torch/_dynamo/symbolic_convert.py:52) (35 samples, 0.14%)</title><rect x="0.2652%" y="484" width="0.1365%" height="15" fill="rgb(227,0,7)" fg:x="68" fg:w="35"/><text x="0.5152%" y="494.50"></text></g><g><title>_find_and_load (&lt;frozen importlib._bootstrap&gt;:1360) (35 samples, 0.14%)</title><rect x="0.2652%" y="500" width="0.1365%" height="15" fill="rgb(217,0,24)" fg:x="68" fg:w="35"/><text x="0.5152%" y="510.50"></text></g><g><title>_find_and_load_unlocked (&lt;frozen importlib._bootstrap&gt;:1331) (35 samples, 0.14%)</title><rect x="0.2652%" y="516" width="0.1365%" height="15" fill="rgb(221,193,54)" fg:x="68" fg:w="35"/><text x="0.5152%" y="526.50"></text></g><g><title>_load_unlocked (&lt;frozen importlib._bootstrap&gt;:935) (35 samples, 0.14%)</title><rect x="0.2652%" y="532" width="0.1365%" height="15" fill="rgb(248,212,6)" fg:x="68" fg:w="35"/><text x="0.5152%" y="542.50"></text></g><g><title>exec_module (&lt;frozen importlib._bootstrap_external&gt;:999) (35 samples, 0.14%)</title><rect x="0.2652%" y="548" width="0.1365%" height="15" fill="rgb(208,68,35)" fg:x="68" fg:w="35"/><text x="0.5152%" y="558.50"></text></g><g><title>_call_with_frames_removed (&lt;frozen importlib._bootstrap&gt;:488) (35 samples, 0.14%)</title><rect x="0.2652%" y="564" width="0.1365%" height="15" fill="rgb(232,128,0)" fg:x="68" fg:w="35"/><text x="0.5152%" y="574.50"></text></g><g><title>&lt;module&gt; (torch/_dynamo/exc.py:41) (35 samples, 0.14%)</title><rect x="0.2652%" y="580" width="0.1365%" height="15" fill="rgb(207,160,47)" fg:x="68" fg:w="35"/><text x="0.5152%" y="590.50"></text></g><g><title>_find_and_load (&lt;frozen importlib._bootstrap&gt;:1360) (35 samples, 0.14%)</title><rect x="0.2652%" y="596" width="0.1365%" height="15" fill="rgb(228,23,34)" fg:x="68" fg:w="35"/><text x="0.5152%" y="606.50"></text></g><g><title>_find_and_load_unlocked (&lt;frozen importlib._bootstrap&gt;:1331) (35 samples, 0.14%)</title><rect x="0.2652%" y="612" width="0.1365%" height="15" fill="rgb(218,30,26)" fg:x="68" fg:w="35"/><text x="0.5152%" y="622.50"></text></g><g><title>_load_unlocked (&lt;frozen importlib._bootstrap&gt;:935) (35 samples, 0.14%)</title><rect x="0.2652%" y="628" width="0.1365%" height="15" fill="rgb(220,122,19)" fg:x="68" fg:w="35"/><text x="0.5152%" y="638.50"></text></g><g><title>exec_module (&lt;frozen importlib._bootstrap_external&gt;:999) (35 samples, 0.14%)</title><rect x="0.2652%" y="644" width="0.1365%" height="15" fill="rgb(250,228,42)" fg:x="68" fg:w="35"/><text x="0.5152%" y="654.50"></text></g><g><title>_call_with_frames_removed (&lt;frozen importlib._bootstrap&gt;:488) (35 samples, 0.14%)</title><rect x="0.2652%" y="660" width="0.1365%" height="15" fill="rgb(240,193,28)" fg:x="68" fg:w="35"/><text x="0.5152%" y="670.50"></text></g><g><title>&lt;module&gt; (torch/_dynamo/__init__.py:13) (40 samples, 0.16%)</title><rect x="0.2652%" y="260" width="0.1560%" height="15" fill="rgb(216,20,37)" fg:x="68" fg:w="40"/><text x="0.5152%" y="270.50"></text></g><g><title>_handle_fromlist (&lt;frozen importlib._bootstrap&gt;:1415) (40 samples, 0.16%)</title><rect x="0.2652%" y="276" width="0.1560%" height="15" fill="rgb(206,188,39)" fg:x="68" fg:w="40"/><text x="0.5152%" y="286.50"></text></g><g><title>_call_with_frames_removed (&lt;frozen importlib._bootstrap&gt;:488) (40 samples, 0.16%)</title><rect x="0.2652%" y="292" width="0.1560%" height="15" fill="rgb(217,207,13)" fg:x="68" fg:w="40"/><text x="0.5152%" y="302.50"></text></g><g><title>_find_and_load (&lt;frozen importlib._bootstrap&gt;:1360) (40 samples, 0.16%)</title><rect x="0.2652%" y="308" width="0.1560%" height="15" fill="rgb(231,73,38)" fg:x="68" fg:w="40"/><text x="0.5152%" y="318.50"></text></g><g><title>_find_and_load_unlocked (&lt;frozen importlib._bootstrap&gt;:1331) (40 samples, 0.16%)</title><rect x="0.2652%" y="324" width="0.1560%" height="15" fill="rgb(225,20,46)" fg:x="68" fg:w="40"/><text x="0.5152%" y="334.50"></text></g><g><title>_load_unlocked (&lt;frozen importlib._bootstrap&gt;:935) (40 samples, 0.16%)</title><rect x="0.2652%" y="340" width="0.1560%" height="15" fill="rgb(210,31,41)" fg:x="68" fg:w="40"/><text x="0.5152%" y="350.50"></text></g><g><title>exec_module (&lt;frozen importlib._bootstrap_external&gt;:999) (40 samples, 0.16%)</title><rect x="0.2652%" y="356" width="0.1560%" height="15" fill="rgb(221,200,47)" fg:x="68" fg:w="40"/><text x="0.5152%" y="366.50"></text></g><g><title>_call_with_frames_removed (&lt;frozen importlib._bootstrap&gt;:488) (40 samples, 0.16%)</title><rect x="0.2652%" y="372" width="0.1560%" height="15" fill="rgb(226,26,5)" fg:x="68" fg:w="40"/><text x="0.5152%" y="382.50"></text></g><g><title>&lt;module&gt; (torch/_dynamo/convert_frame.py:53) (40 samples, 0.16%)</title><rect x="0.2652%" y="388" width="0.1560%" height="15" fill="rgb(249,33,26)" fg:x="68" fg:w="40"/><text x="0.5152%" y="398.50"></text></g><g><title>_find_and_load (&lt;frozen importlib._bootstrap&gt;:1360) (40 samples, 0.16%)</title><rect x="0.2652%" y="404" width="0.1560%" height="15" fill="rgb(235,183,28)" fg:x="68" fg:w="40"/><text x="0.5152%" y="414.50"></text></g><g><title>_find_and_load_unlocked (&lt;frozen importlib._bootstrap&gt;:1331) (40 samples, 0.16%)</title><rect x="0.2652%" y="420" width="0.1560%" height="15" fill="rgb(221,5,38)" fg:x="68" fg:w="40"/><text x="0.5152%" y="430.50"></text></g><g><title>_load_unlocked (&lt;frozen importlib._bootstrap&gt;:935) (40 samples, 0.16%)</title><rect x="0.2652%" y="436" width="0.1560%" height="15" fill="rgb(247,18,42)" fg:x="68" fg:w="40"/><text x="0.5152%" y="446.50"></text></g><g><title>exec_module (&lt;frozen importlib._bootstrap_external&gt;:999) (40 samples, 0.16%)</title><rect x="0.2652%" y="452" width="0.1560%" height="15" fill="rgb(241,131,45)" fg:x="68" fg:w="40"/><text x="0.5152%" y="462.50"></text></g><g><title>_call_with_frames_removed (&lt;frozen importlib._bootstrap&gt;:488) (40 samples, 0.16%)</title><rect x="0.2652%" y="468" width="0.1560%" height="15" fill="rgb(249,31,29)" fg:x="68" fg:w="40"/><text x="0.5152%" y="478.50"></text></g><g><title>main (self_play.py:367) (46 samples, 0.18%)</title><rect x="0.2652%" y="100" width="0.1794%" height="15" fill="rgb(225,111,53)" fg:x="68" fg:w="46"/><text x="0.5152%" y="110.50"></text></g><g><title>__init__ (torch/optim/adamw.py:37) (46 samples, 0.18%)</title><rect x="0.2652%" y="116" width="0.1794%" height="15" fill="rgb(238,160,17)" fg:x="68" fg:w="46"/><text x="0.5152%" y="126.50"></text></g><g><title>__init__ (torch/optim/adam.py:101) (46 samples, 0.18%)</title><rect x="0.2652%" y="132" width="0.1794%" height="15" fill="rgb(214,148,48)" fg:x="68" fg:w="46"/><text x="0.5152%" y="142.50"></text></g><g><title>__init__ (torch/optim/optimizer.py:400) (46 samples, 0.18%)</title><rect x="0.2652%" y="148" width="0.1794%" height="15" fill="rgb(232,36,49)" fg:x="68" fg:w="46"/><text x="0.5152%" y="158.50"></text></g><g><title>inner (torch/_compile.py:46) (46 samples, 0.18%)</title><rect x="0.2652%" y="164" width="0.1794%" height="15" fill="rgb(209,103,24)" fg:x="68" fg:w="46"/><text x="0.5152%" y="174.50"></text></g><g><title>_find_and_load (&lt;frozen importlib._bootstrap&gt;:1360) (46 samples, 0.18%)</title><rect x="0.2652%" y="180" width="0.1794%" height="15" fill="rgb(229,88,8)" fg:x="68" fg:w="46"/><text x="0.5152%" y="190.50"></text></g><g><title>_find_and_load_unlocked (&lt;frozen importlib._bootstrap&gt;:1331) (46 samples, 0.18%)</title><rect x="0.2652%" y="196" width="0.1794%" height="15" fill="rgb(213,181,19)" fg:x="68" fg:w="46"/><text x="0.5152%" y="206.50"></text></g><g><title>_load_unlocked (&lt;frozen importlib._bootstrap&gt;:935) (46 samples, 0.18%)</title><rect x="0.2652%" y="212" width="0.1794%" height="15" fill="rgb(254,191,54)" fg:x="68" fg:w="46"/><text x="0.5152%" y="222.50"></text></g><g><title>exec_module (&lt;frozen importlib._bootstrap_external&gt;:999) (46 samples, 0.18%)</title><rect x="0.2652%" y="228" width="0.1794%" height="15" fill="rgb(241,83,37)" fg:x="68" fg:w="46"/><text x="0.5152%" y="238.50"></text></g><g><title>_call_with_frames_removed (&lt;frozen importlib._bootstrap&gt;:488) (46 samples, 0.18%)</title><rect x="0.2652%" y="244" width="0.1794%" height="15" fill="rgb(233,36,39)" fg:x="68" fg:w="46"/><text x="0.5152%" y="254.50"></text></g><g><title>main (self_play.py:370) (31 samples, 0.12%)</title><rect x="0.4446%" y="100" width="0.1209%" height="15" fill="rgb(226,3,54)" fg:x="114" fg:w="31"/><text x="0.6946%" y="110.50"></text></g><g><title>pre_compile_jit_geometry (jit_geometry.py:17) (31 samples, 0.12%)</title><rect x="0.4446%" y="116" width="0.1209%" height="15" fill="rgb(245,192,40)" fg:x="114" fg:w="31"/><text x="0.6946%" y="126.50"></text></g><g><title>rollout (armada.pyx:84) (31 samples, 0.12%)</title><rect x="0.4446%" y="132" width="0.1209%" height="15" fill="rgb(238,167,29)" fg:x="114" fg:w="31"/><text x="0.6946%" y="142.50"></text></g><g><title>MCTS__select (para_mcts.pyx:322) (31 samples, 0.12%)</title><rect x="0.7488%" y="196" width="0.1209%" height="15" fill="rgb(232,182,51)" fg:x="192" fg:w="31"/><text x="0.9988%" y="206.50"></text></g><g><title>roll_dice (dice.py:39) (245 samples, 0.96%)</title><rect x="0.8892%" y="212" width="0.9555%" height="15" fill="rgb(231,60,39)" fg:x="228" fg:w="245"/><text x="1.1392%" y="222.50"></text></g><g><title>roll_dice (dice.py:43) (56 samples, 0.22%)</title><rect x="1.8446%" y="212" width="0.2184%" height="15" fill="rgb(208,69,12)" fg:x="473" fg:w="56"/><text x="2.0946%" y="222.50"></text></g><g><title>multinomial (numpy/random/_generator.cpython-312-x86_64-linux-gnu.so) (35 samples, 0.14%)</title><rect x="1.9265%" y="228" width="0.1365%" height="15" fill="rgb(235,93,37)" fg:x="494" fg:w="35"/><text x="2.1765%" y="238.50"></text></g><g><title>MCTS__select (para_mcts.pyx:328) (342 samples, 1.33%)</title><rect x="0.8697%" y="196" width="1.3337%" height="15" fill="rgb(213,116,39)" fg:x="223" fg:w="342"/><text x="1.1197%" y="206.50"></text></g><g><title>MCTS__select (para_mcts.pyx:341) (37 samples, 0.14%)</title><rect x="2.2463%" y="196" width="0.1443%" height="15" fill="rgb(222,207,29)" fg:x="576" fg:w="37"/><text x="2.4963%" y="206.50"></text></g><g><title>Py_XDECREF (object.h:798) (37 samples, 0.14%)</title><rect x="2.2463%" y="212" width="0.1443%" height="15" fill="rgb(206,96,30)" fg:x="576" fg:w="37"/><text x="2.4963%" y="222.50"></text></g><g><title>Py_DECREF (object.h:700) (37 samples, 0.14%)</title><rect x="2.2463%" y="228" width="0.1443%" height="15" fill="rgb(218,138,4)" fg:x="576" fg:w="37"/><text x="2.4963%" y="238.50"></text></g><g><title>choice (random.py:341) (95 samples, 0.37%)</title><rect x="2.6402%" y="228" width="0.3705%" height="15" fill="rgb(250,191,14)" fg:x="677" fg:w="95"/><text x="2.8902%" y="238.50"></text></g><g><title>Node_select_child (para_mcts.pyx:87) (99 samples, 0.39%)</title><rect x="2.6363%" y="212" width="0.3861%" height="15" fill="rgb(239,60,40)" fg:x="676" fg:w="99"/><text x="2.8863%" y="222.50"></text></g><g><title>MCTS__select (para_mcts.pyx:353) (101 samples, 0.39%)</title><rect x="2.6324%" y="196" width="0.3939%" height="15" fill="rgb(206,27,48)" fg:x="675" fg:w="101"/><text x="2.8824%" y="206.50"></text></g><g><title>Node_select_child (para_mcts.pyx:89) (35 samples, 0.14%)</title><rect x="3.0302%" y="212" width="0.1365%" height="15" fill="rgb(225,35,8)" fg:x="777" fg:w="35"/><text x="3.2802%" y="222.50"></text></g><g><title>Py_INCREF (object.h:643) (35 samples, 0.14%)</title><rect x="3.0302%" y="228" width="0.1365%" height="15" fill="rgb(250,213,24)" fg:x="777" fg:w="35"/><text x="3.2802%" y="238.50"></text></g><g><title>MCTS__select (para_mcts.pyx:356) (89 samples, 0.35%)</title><rect x="3.0263%" y="196" width="0.3471%" height="15" fill="rgb(247,123,22)" fg:x="776" fg:w="89"/><text x="3.2763%" y="206.50"></text></g><g><title>Node_select_child (para_mcts.pyx:93) (53 samples, 0.21%)</title><rect x="3.1667%" y="212" width="0.2067%" height="15" fill="rgb(231,138,38)" fg:x="812" fg:w="53"/><text x="3.4167%" y="222.50"></text></g><g><title>Node__get_pucb (para_mcts.pyx:129) (48 samples, 0.19%)</title><rect x="3.1862%" y="228" width="0.1872%" height="15" fill="rgb(231,145,46)" fg:x="817" fg:w="48"/><text x="3.4362%" y="238.50"></text></g><g><title>MCTS_para_search (para_mcts.pyx:182) (710 samples, 2.77%)</title><rect x="0.6240%" y="180" width="2.7689%" height="15" fill="rgb(251,118,11)" fg:x="160" fg:w="710"/><text x="0.8740%" y="190.50">MC..</text></g><g><title>Armada_revert_snapshot (armada.pyx:1062) (51 samples, 0.20%)</title><rect x="3.5060%" y="196" width="0.1989%" height="15" fill="rgb(217,147,25)" fg:x="899" fg:w="51"/><text x="3.7560%" y="206.50"></text></g><g><title>Armada_revert_snapshot (armada.pyx:1064) (29 samples, 0.11%)</title><rect x="3.7361%" y="196" width="0.1131%" height="15" fill="rgb(247,81,37)" fg:x="958" fg:w="29"/><text x="3.9861%" y="206.50"></text></g><g><title>MCTS_para_search (para_mcts.pyx:186) (115 samples, 0.45%)</title><rect x="3.4046%" y="180" width="0.4485%" height="15" fill="rgb(209,12,38)" fg:x="873" fg:w="115"/><text x="3.6546%" y="190.50"></text></g><g><title>MCTS_para_search (para_mcts.pyx:193) (35 samples, 0.14%)</title><rect x="3.8804%" y="180" width="0.1365%" height="15" fill="rgb(227,1,9)" fg:x="995" fg:w="35"/><text x="4.1304%" y="190.50"></text></g><g><title>MCTS__get_value_policy (para_mcts.pyx:360) (91 samples, 0.35%)</title><rect x="4.0246%" y="196" width="0.3549%" height="15" fill="rgb(248,47,43)" fg:x="1032" fg:w="91"/><text x="4.2746%" y="206.50"></text></g><g><title>Py_XDECREF (object.h:798) (27 samples, 0.11%)</title><rect x="4.2742%" y="212" width="0.1053%" height="15" fill="rgb(221,10,30)" fg:x="1096" fg:w="27"/><text x="4.5242%" y="222.50"></text></g><g><title>Py_DECREF (object.h:705) (27 samples, 0.11%)</title><rect x="4.2742%" y="228" width="0.1053%" height="15" fill="rgb(210,229,1)" fg:x="1096" fg:w="27"/><text x="4.5242%" y="238.50"></text></g><g><title>MCTS__get_value_policy (para_mcts.pyx:368) (34 samples, 0.13%)</title><rect x="4.3795%" y="196" width="0.1326%" height="15" fill="rgb(222,148,37)" fg:x="1123" fg:w="34"/><text x="4.6295%" y="206.50"></text></g><g><title>dispatcher_vectorcall (numpy/_core/_multiarray_umath.cpython-312-x86_64-linux-gnu.so) (27 samples, 0.11%)</title><rect x="4.4068%" y="212" width="0.1053%" height="15" fill="rgb(234,67,33)" fg:x="1130" fg:w="27"/><text x="4.6568%" y="222.50"></text></g><g><title>MCTS__get_value_policy (para_mcts.pyx:371) (28 samples, 0.11%)</title><rect x="4.6213%" y="196" width="0.1092%" height="15" fill="rgb(247,98,35)" fg:x="1185" fg:w="28"/><text x="4.8713%" y="206.50"></text></g><g><title>at::_ops::copy_::call (libtorch_cpu.so) (40 samples, 0.16%)</title><rect x="4.8826%" y="436" width="0.1560%" height="15" fill="rgb(247,138,52)" fg:x="1252" fg:w="40"/><text x="5.1326%" y="446.50"></text></g><g><title>at::native::copy_ (libtorch_cpu.so) (40 samples, 0.16%)</title><rect x="4.8826%" y="452" width="0.1560%" height="15" fill="rgb(213,79,30)" fg:x="1252" fg:w="40"/><text x="5.1326%" y="462.50"></text></g><g><title>at::native::copy_impl (libtorch_cpu.so) (37 samples, 0.14%)</title><rect x="4.8943%" y="468" width="0.1443%" height="15" fill="rgb(246,177,23)" fg:x="1255" fg:w="37"/><text x="5.1443%" y="478.50"></text></g><g><title>at::_ops::_to_copy::call (libtorch_cpu.so) (52 samples, 0.20%)</title><rect x="4.8709%" y="308" width="0.2028%" height="15" fill="rgb(230,62,27)" fg:x="1249" fg:w="52"/><text x="5.1209%" y="318.50"></text></g><g><title>c10::impl::wrap_kernel_functor_unboxed_&lt;c10::impl::detail::WrapFunctionIntoFunctor_&lt;c10::CompileTimeFunctionPointer&lt;at::Tensor(c10::DispatchKeySet, at::Tensor const&amp;, std::optional&lt;c10::ScalarType&gt;, std::optional&lt;c10::Layout&gt;, std::optional&lt;c10::Device&gt;, std::optional&lt;bool&gt;, bool, std::optional&lt;c10::MemoryFormat&gt;), &amp;torch::autograd::VariableType::(anonymous namespace)::_to_copy(c10::DispatchKeySet, at::Tensor const&amp;, std::optional&lt;c10::ScalarType&gt;, std::optional&lt;c10::Layout&gt;, std::optional&lt;c10::Device&gt;, std::optional&lt;bool&gt;, bool, std::optional&lt;c10::MemoryFormat&gt;)&gt;, at::Tensor, c10::guts::typelist::typelist&lt;c10::DispatchKeySet, at::Tensor const&amp;, std::optional&lt;c10::ScalarType&gt;, std::optional&lt;c10::Layout&gt;, std::optional&lt;c10::Device&gt;, std::optional&lt;bool&gt;, bool, std::optional&lt;c10::MemoryFormat&gt; &gt; &gt;, at::Tensor(c10::DispatchKeySet, at::Tensor const&amp;, std::optional&lt;c10::ScalarType&gt;, std::optional&lt;c10::Layout&gt;, std::optional&lt;c10::Device&gt;, std::optional&lt;bool&gt;, bool, std::optional&lt;c10::MemoryFormat&gt;)&gt;::call (libtorch_cpu.so) (51 samples, 0.20%)</title><rect x="4.8748%" y="324" width="0.1989%" height="15" fill="rgb(216,154,8)" fg:x="1250" fg:w="51"/><text x="5.1248%" y="334.50"></text></g><g><title>torch::autograd::VariableType::(anonymous namespace)::_to_copy (libtorch_cpu.so) (51 samples, 0.20%)</title><rect x="4.8748%" y="340" width="0.1989%" height="15" fill="rgb(244,35,45)" fg:x="1250" fg:w="51"/><text x="5.1248%" y="350.50"></text></g><g><title>at::_ops::_to_copy::redispatch (libtorch_cpu.so) (50 samples, 0.19%)</title><rect x="4.8787%" y="356" width="0.1950%" height="15" fill="rgb(251,115,12)" fg:x="1251" fg:w="50"/><text x="5.1287%" y="366.50"></text></g><g><title>c10::impl::wrap_kernel_functor_unboxed_&lt;c10::impl::detail::WrapFunctionIntoFunctor_&lt;c10::CompileTimeFunctionPointer&lt;at::Tensor(at::Tensor const&amp;, std::optional&lt;c10::ScalarType&gt;, std::optional&lt;c10::Layout&gt;, std::optional&lt;c10::Device&gt;, std::optional&lt;bool&gt;, bool, std::optional&lt;c10::MemoryFormat&gt;), &amp;at::(anonymous namespace)::_to_copy(at::Tensor const&amp;, std::optional&lt;c10::ScalarType&gt;, std::optional&lt;c10::Layout&gt;, std::optional&lt;c10::Device&gt;, std::optional&lt;bool&gt;, bool, std::optional&lt;c10::MemoryFormat&gt;)&gt;, at::Tensor, c10::guts::typelist::typelist&lt;at::Tensor const&amp;, std::optional&lt;c10::ScalarType&gt;, std::optional&lt;c10::Layout&gt;, std::optional&lt;c10::Device&gt;, std::optional&lt;bool&gt;, bool, std::optional&lt;c10::MemoryFormat&gt; &gt; &gt;, at::Tensor(at::Tensor const&amp;, std::optional&lt;c10::ScalarType&gt;, std::optional&lt;c10::Layout&gt;, std::optional&lt;c10::Device&gt;, std::optional&lt;bool&gt;, bool, std::optional&lt;c10::MemoryFormat&gt;)&gt;::call (libtorch_cpu.so) (49 samples, 0.19%)</title><rect x="4.8826%" y="372" width="0.1911%" height="15" fill="rgb(240,54,50)" fg:x="1252" fg:w="49"/><text x="5.1326%" y="382.50"></text></g><g><title>at::_ops::_to_copy::redispatch (libtorch_cpu.so) (49 samples, 0.19%)</title><rect x="4.8826%" y="388" width="0.1911%" height="15" fill="rgb(233,84,52)" fg:x="1252" fg:w="49"/><text x="5.1326%" y="398.50"></text></g><g><title>c10::impl::wrap_kernel_functor_unboxed_&lt;c10::impl::detail::WrapFunctionIntoFunctor_&lt;c10::CompileTimeFunctionPointer&lt;at::Tensor(at::Tensor const&amp;, std::optional&lt;c10::ScalarType&gt;, std::optional&lt;c10::Layout&gt;, std::optional&lt;c10::Device&gt;, std::optional&lt;bool&gt;, bool, std::optional&lt;c10::MemoryFormat&gt;), &amp;at::(anonymous namespace)::(anonymous namespace)::wrapper_CompositeExplicitAutograd___to_copy(at::Tensor const&amp;, std::optional&lt;c10::ScalarType&gt;, std::optional&lt;c10::Layout&gt;, std::optional&lt;c10::Device&gt;, std::optional&lt;bool&gt;, bool, std::optional&lt;c10::MemoryFormat&gt;)&gt;, at::Tensor, c10::guts::typelist::typelist&lt;at::Tensor const&amp;, std::optional&lt;c10::ScalarType&gt;, std::optional&lt;c10::Layout&gt;, std::optional&lt;c10::Device&gt;, std::optional&lt;bool&gt;, bool, std::optional&lt;c10::MemoryFormat&gt; &gt; &gt;, at::Tensor(at::Tensor const&amp;, std::optional&lt;c10::ScalarType&gt;, std::optional&lt;c10::Layout&gt;, std::optional&lt;c10::Device&gt;, std::optional&lt;bool&gt;, bool, std::optional&lt;c10::MemoryFormat&gt;)&gt;::call (libtorch_cpu.so) (49 samples, 0.19%)</title><rect x="4.8826%" y="404" width="0.1911%" height="15" fill="rgb(207,117,47)" fg:x="1252" fg:w="49"/><text x="5.1326%" y="414.50"></text></g><g><title>at::native::_to_copy (libtorch_cpu.so) (49 samples, 0.19%)</title><rect x="4.8826%" y="420" width="0.1911%" height="15" fill="rgb(249,43,39)" fg:x="1252" fg:w="49"/><text x="5.1326%" y="430.50"></text></g><g><title>torch::autograd::dispatch_to (libtorch_python.so) (57 samples, 0.22%)</title><rect x="4.8670%" y="228" width="0.2223%" height="15" fill="rgb(209,38,44)" fg:x="1248" fg:w="57"/><text x="5.1170%" y="238.50"></text></g><g><title>at::Tensor::to (libtorch_python.so) (57 samples, 0.22%)</title><rect x="4.8670%" y="244" width="0.2223%" height="15" fill="rgb(236,212,23)" fg:x="1248" fg:w="57"/><text x="5.1170%" y="254.50"></text></g><g><title>at::_ops::to_dtype_layout::call (libtorch_cpu.so) (57 samples, 0.22%)</title><rect x="4.8670%" y="260" width="0.2223%" height="15" fill="rgb(242,79,21)" fg:x="1248" fg:w="57"/><text x="5.1170%" y="270.50"></text></g><g><title>c10::impl::wrap_kernel_functor_unboxed_&lt;c10::impl::detail::WrapFunctionIntoFunctor_&lt;c10::CompileTimeFunctionPointer&lt;at::Tensor(at::Tensor const&amp;, std::optional&lt;c10::ScalarType&gt;, std::optional&lt;c10::Layout&gt;, std::optional&lt;c10::Device&gt;, std::optional&lt;bool&gt;, bool, bool, std::optional&lt;c10::MemoryFormat&gt;), &amp;at::(anonymous namespace)::(anonymous namespace)::wrapper_CompositeImplicitAutograd_dtype_layout_to(at::Tensor const&amp;, std::optional&lt;c10::ScalarType&gt;, std::optional&lt;c10::Layout&gt;, std::optional&lt;c10::Device&gt;, std::optional&lt;bool&gt;, bool, bool, std::optional&lt;c10::MemoryFormat&gt;)&gt;, at::Tensor, c10::guts::typelist::typelist&lt;at::Tensor const&amp;, std::optional&lt;c10::ScalarType&gt;, std::optional&lt;c10::Layout&gt;, std::optional&lt;c10::Device&gt;, std::optional&lt;bool&gt;, bool, bool, std::optional&lt;c10::MemoryFormat&gt; &gt; &gt;, at::Tensor(at::Tensor const&amp;, std::optional&lt;c10::ScalarType&gt;, std::optional&lt;c10::Layout&gt;, std::optional&lt;c10::Device&gt;, std::optional&lt;bool&gt;, bool, bool, std::optional&lt;c10::MemoryFormat&gt;)&gt;::call (libtorch_cpu.so) (56 samples, 0.22%)</title><rect x="4.8709%" y="276" width="0.2184%" height="15" fill="rgb(211,96,35)" fg:x="1249" fg:w="56"/><text x="5.1209%" y="286.50"></text></g><g><title>at::native::to (libtorch_cpu.so) (56 samples, 0.22%)</title><rect x="4.8709%" y="292" width="0.2184%" height="15" fill="rgb(253,215,40)" fg:x="1249" fg:w="56"/><text x="5.1209%" y="302.50"></text></g><g><title>MCTS__get_value_policy (para_mcts.pyx:375) (82 samples, 0.32%)</title><rect x="4.7929%" y="196" width="0.3198%" height="15" fill="rgb(211,81,21)" fg:x="1229" fg:w="82"/><text x="5.0429%" y="206.50"></text></g><g><title>torch::autograd::THPVariable_to (libtorch_python.so) (63 samples, 0.25%)</title><rect x="4.8670%" y="212" width="0.2457%" height="15" fill="rgb(208,190,38)" fg:x="1248" fg:w="63"/><text x="5.1170%" y="222.50"></text></g><g><title>MCTS__get_value_policy (para_mcts.pyx:376) (30 samples, 0.12%)</title><rect x="5.1127%" y="196" width="0.1170%" height="15" fill="rgb(235,213,38)" fg:x="1311" fg:w="30"/><text x="5.3627%" y="206.50"></text></g><g><title>MCTS__get_value_policy (para_mcts.pyx:377) (36 samples, 0.14%)</title><rect x="5.2297%" y="196" width="0.1404%" height="15" fill="rgb(237,122,38)" fg:x="1341" fg:w="36"/><text x="5.4797%" y="206.50"></text></g><g><title>torch::autograd::THPVariable_to (libtorch_python.so) (26 samples, 0.10%)</title><rect x="5.2687%" y="212" width="0.1014%" height="15" fill="rgb(244,218,35)" fg:x="1351" fg:w="26"/><text x="5.5187%" y="222.50"></text></g><g><title>0x7ac4dff3ec60 (libcuda.so.550.54.15) (27 samples, 0.11%)</title><rect x="5.4013%" y="580" width="0.1053%" height="15" fill="rgb(240,68,47)" fg:x="1385" fg:w="27"/><text x="5.6513%" y="590.50"></text></g><g><title>0x7ac4dff3e746 (libcuda.so.550.54.15) (26 samples, 0.10%)</title><rect x="5.4052%" y="596" width="0.1014%" height="15" fill="rgb(210,16,53)" fg:x="1386" fg:w="26"/><text x="5.6552%" y="606.50"></text></g><g><title>0x7ac4dff3f5f7 (libcuda.so.550.54.15) (28 samples, 0.11%)</title><rect x="5.4013%" y="564" width="0.1092%" height="15" fill="rgb(235,124,12)" fg:x="1385" fg:w="28"/><text x="5.6513%" y="574.50"></text></g><g><title>cudaMemcpyAsync (nvidia/cuda_runtime/lib/libcudart.so.12) (30 samples, 0.12%)</title><rect x="5.4013%" y="500" width="0.1170%" height="15" fill="rgb(224,169,11)" fg:x="1385" fg:w="30"/><text x="5.6513%" y="510.50"></text></g><g><title>0x7ac5be418cb2 (nvidia/cuda_runtime/lib/libcudart.so.12) (30 samples, 0.12%)</title><rect x="5.4013%" y="516" width="0.1170%" height="15" fill="rgb(250,166,2)" fg:x="1385" fg:w="30"/><text x="5.6513%" y="526.50"></text></g><g><title>0x7ac5be448c59 (nvidia/cuda_runtime/lib/libcudart.so.12) (30 samples, 0.12%)</title><rect x="5.4013%" y="532" width="0.1170%" height="15" fill="rgb(242,216,29)" fg:x="1385" fg:w="30"/><text x="5.6513%" y="542.50"></text></g><g><title>0x7ac4e00e8cc9 (libcuda.so.550.54.15) (30 samples, 0.12%)</title><rect x="5.4013%" y="548" width="0.1170%" height="15" fill="rgb(230,116,27)" fg:x="1385" fg:w="30"/><text x="5.6513%" y="558.50"></text></g><g><title>at::_ops::copy_::call (libtorch_cpu.so) (46 samples, 0.18%)</title><rect x="5.3896%" y="436" width="0.1794%" height="15" fill="rgb(228,99,48)" fg:x="1382" fg:w="46"/><text x="5.6396%" y="446.50"></text></g><g><title>at::native::copy_ (libtorch_cpu.so) (46 samples, 0.18%)</title><rect x="5.3896%" y="452" width="0.1794%" height="15" fill="rgb(253,11,6)" fg:x="1382" fg:w="46"/><text x="5.6396%" y="462.50"></text></g><g><title>at::native::copy_impl (libtorch_cpu.so) (46 samples, 0.18%)</title><rect x="5.3896%" y="468" width="0.1794%" height="15" fill="rgb(247,143,39)" fg:x="1382" fg:w="46"/><text x="5.6396%" y="478.50"></text></g><g><title>at::native::copy_kernel_cuda (libtorch_cuda.so) (43 samples, 0.17%)</title><rect x="5.4013%" y="484" width="0.1677%" height="15" fill="rgb(236,97,10)" fg:x="1385" fg:w="43"/><text x="5.6513%" y="494.50"></text></g><g><title>torch::autograd::dispatch_to (libtorch_python.so) (48 samples, 0.19%)</title><rect x="5.3857%" y="228" width="0.1872%" height="15" fill="rgb(233,208,19)" fg:x="1381" fg:w="48"/><text x="5.6357%" y="238.50"></text></g><g><title>at::Tensor::to (libtorch_python.so) (48 samples, 0.19%)</title><rect x="5.3857%" y="244" width="0.1872%" height="15" fill="rgb(216,164,2)" fg:x="1381" fg:w="48"/><text x="5.6357%" y="254.50"></text></g><g><title>at::_ops::to_dtype_layout::call (libtorch_cpu.so) (48 samples, 0.19%)</title><rect x="5.3857%" y="260" width="0.1872%" height="15" fill="rgb(220,129,5)" fg:x="1381" fg:w="48"/><text x="5.6357%" y="270.50"></text></g><g><title>c10::impl::wrap_kernel_functor_unboxed_&lt;c10::impl::detail::WrapFunctionIntoFunctor_&lt;c10::CompileTimeFunctionPointer&lt;at::Tensor(at::Tensor const&amp;, std::optional&lt;c10::ScalarType&gt;, std::optional&lt;c10::Layout&gt;, std::optional&lt;c10::Device&gt;, std::optional&lt;bool&gt;, bool, bool, std::optional&lt;c10::MemoryFormat&gt;), &amp;at::(anonymous namespace)::(anonymous namespace)::wrapper_CompositeImplicitAutograd_dtype_layout_to(at::Tensor const&amp;, std::optional&lt;c10::ScalarType&gt;, std::optional&lt;c10::Layout&gt;, std::optional&lt;c10::Device&gt;, std::optional&lt;bool&gt;, bool, bool, std::optional&lt;c10::MemoryFormat&gt;)&gt;, at::Tensor, c10::guts::typelist::typelist&lt;at::Tensor const&amp;, std::optional&lt;c10::ScalarType&gt;, std::optional&lt;c10::Layout&gt;, std::optional&lt;c10::Device&gt;, std::optional&lt;bool&gt;, bool, bool, std::optional&lt;c10::MemoryFormat&gt; &gt; &gt;, at::Tensor(at::Tensor const&amp;, std::optional&lt;c10::ScalarType&gt;, std::optional&lt;c10::Layout&gt;, std::optional&lt;c10::Device&gt;, std::optional&lt;bool&gt;, bool, bool, std::optional&lt;c10::MemoryFormat&gt;)&gt;::call (libtorch_cpu.so) (48 samples, 0.19%)</title><rect x="5.3857%" y="276" width="0.1872%" height="15" fill="rgb(242,17,10)" fg:x="1381" fg:w="48"/><text x="5.6357%" y="286.50"></text></g><g><title>at::native::to (libtorch_cpu.so) (47 samples, 0.18%)</title><rect x="5.3896%" y="292" width="0.1833%" height="15" fill="rgb(242,107,0)" fg:x="1382" fg:w="47"/><text x="5.6396%" y="302.50"></text></g><g><title>at::_ops::_to_copy::call (libtorch_cpu.so) (47 samples, 0.18%)</title><rect x="5.3896%" y="308" width="0.1833%" height="15" fill="rgb(251,28,31)" fg:x="1382" fg:w="47"/><text x="5.6396%" y="318.50"></text></g><g><title>c10::impl::wrap_kernel_functor_unboxed_&lt;c10::impl::detail::WrapFunctionIntoFunctor_&lt;c10::CompileTimeFunctionPointer&lt;at::Tensor(c10::DispatchKeySet, at::Tensor const&amp;, std::optional&lt;c10::ScalarType&gt;, std::optional&lt;c10::Layout&gt;, std::optional&lt;c10::Device&gt;, std::optional&lt;bool&gt;, bool, std::optional&lt;c10::MemoryFormat&gt;), &amp;torch::autograd::VariableType::(anonymous namespace)::_to_copy(c10::DispatchKeySet, at::Tensor const&amp;, std::optional&lt;c10::ScalarType&gt;, std::optional&lt;c10::Layout&gt;, std::optional&lt;c10::Device&gt;, std::optional&lt;bool&gt;, bool, std::optional&lt;c10::MemoryFormat&gt;)&gt;, at::Tensor, c10::guts::typelist::typelist&lt;c10::DispatchKeySet, at::Tensor const&amp;, std::optional&lt;c10::ScalarType&gt;, std::optional&lt;c10::Layout&gt;, std::optional&lt;c10::Device&gt;, std::optional&lt;bool&gt;, bool, std::optional&lt;c10::MemoryFormat&gt; &gt; &gt;, at::Tensor(c10::DispatchKeySet, at::Tensor const&amp;, std::optional&lt;c10::ScalarType&gt;, std::optional&lt;c10::Layout&gt;, std::optional&lt;c10::Device&gt;, std::optional&lt;bool&gt;, bool, std::optional&lt;c10::MemoryFormat&gt;)&gt;::call (libtorch_cpu.so) (47 samples, 0.18%)</title><rect x="5.3896%" y="324" width="0.1833%" height="15" fill="rgb(233,223,10)" fg:x="1382" fg:w="47"/><text x="5.6396%" y="334.50"></text></g><g><title>torch::autograd::VariableType::(anonymous namespace)::_to_copy (libtorch_cpu.so) (47 samples, 0.18%)</title><rect x="5.3896%" y="340" width="0.1833%" height="15" fill="rgb(215,21,27)" fg:x="1382" fg:w="47"/><text x="5.6396%" y="350.50"></text></g><g><title>at::_ops::_to_copy::redispatch (libtorch_cpu.so) (47 samples, 0.18%)</title><rect x="5.3896%" y="356" width="0.1833%" height="15" fill="rgb(232,23,21)" fg:x="1382" fg:w="47"/><text x="5.6396%" y="366.50"></text></g><g><title>c10::impl::wrap_kernel_functor_unboxed_&lt;c10::impl::detail::WrapFunctionIntoFunctor_&lt;c10::CompileTimeFunctionPointer&lt;at::Tensor(at::Tensor const&amp;, std::optional&lt;c10::ScalarType&gt;, std::optional&lt;c10::Layout&gt;, std::optional&lt;c10::Device&gt;, std::optional&lt;bool&gt;, bool, std::optional&lt;c10::MemoryFormat&gt;), &amp;at::(anonymous namespace)::_to_copy(at::Tensor const&amp;, std::optional&lt;c10::ScalarType&gt;, std::optional&lt;c10::Layout&gt;, std::optional&lt;c10::Device&gt;, std::optional&lt;bool&gt;, bool, std::optional&lt;c10::MemoryFormat&gt;)&gt;, at::Tensor, c10::guts::typelist::typelist&lt;at::Tensor const&amp;, std::optional&lt;c10::ScalarType&gt;, std::optional&lt;c10::Layout&gt;, std::optional&lt;c10::Device&gt;, std::optional&lt;bool&gt;, bool, std::optional&lt;c10::MemoryFormat&gt; &gt; &gt;, at::Tensor(at::Tensor const&amp;, std::optional&lt;c10::ScalarType&gt;, std::optional&lt;c10::Layout&gt;, std::optional&lt;c10::Device&gt;, std::optional&lt;bool&gt;, bool, std::optional&lt;c10::MemoryFormat&gt;)&gt;::call (libtorch_cpu.so) (47 samples, 0.18%)</title><rect x="5.3896%" y="372" width="0.1833%" height="15" fill="rgb(244,5,23)" fg:x="1382" fg:w="47"/><text x="5.6396%" y="382.50"></text></g><g><title>at::_ops::_to_copy::redispatch (libtorch_cpu.so) (47 samples, 0.18%)</title><rect x="5.3896%" y="388" width="0.1833%" height="15" fill="rgb(226,81,46)" fg:x="1382" fg:w="47"/><text x="5.6396%" y="398.50"></text></g><g><title>c10::impl::wrap_kernel_functor_unboxed_&lt;c10::impl::detail::WrapFunctionIntoFunctor_&lt;c10::CompileTimeFunctionPointer&lt;at::Tensor(at::Tensor const&amp;, std::optional&lt;c10::ScalarType&gt;, std::optional&lt;c10::Layout&gt;, std::optional&lt;c10::Device&gt;, std::optional&lt;bool&gt;, bool, std::optional&lt;c10::MemoryFormat&gt;), &amp;at::(anonymous namespace)::(anonymous namespace)::wrapper_CompositeExplicitAutograd___to_copy(at::Tensor const&amp;, std::optional&lt;c10::ScalarType&gt;, std::optional&lt;c10::Layout&gt;, std::optional&lt;c10::Device&gt;, std::optional&lt;bool&gt;, bool, std::optional&lt;c10::MemoryFormat&gt;)&gt;, at::Tensor, c10::guts::typelist::typelist&lt;at::Tensor const&amp;, std::optional&lt;c10::ScalarType&gt;, std::optional&lt;c10::Layout&gt;, std::optional&lt;c10::Device&gt;, std::optional&lt;bool&gt;, bool, std::optional&lt;c10::MemoryFormat&gt; &gt; &gt;, at::Tensor(at::Tensor const&amp;, std::optional&lt;c10::ScalarType&gt;, std::optional&lt;c10::Layout&gt;, std::optional&lt;c10::Device&gt;, std::optional&lt;bool&gt;, bool, std::optional&lt;c10::MemoryFormat&gt;)&gt;::call (libtorch_cpu.so) (47 samples, 0.18%)</title><rect x="5.3896%" y="404" width="0.1833%" height="15" fill="rgb(247,70,30)" fg:x="1382" fg:w="47"/><text x="5.6396%" y="414.50"></text></g><g><title>at::native::_to_copy (libtorch_cpu.so) (47 samples, 0.18%)</title><rect x="5.3896%" y="420" width="0.1833%" height="15" fill="rgb(212,68,19)" fg:x="1382" fg:w="47"/><text x="5.6396%" y="430.50"></text></g><g><title>MCTS__get_value_policy (para_mcts.pyx:378) (54 samples, 0.21%)</title><rect x="5.3701%" y="196" width="0.2106%" height="15" fill="rgb(240,187,13)" fg:x="1377" fg:w="54"/><text x="5.6201%" y="206.50"></text></g><g><title>torch::autograd::THPVariable_to (libtorch_python.so) (52 samples, 0.20%)</title><rect x="5.3779%" y="212" width="0.2028%" height="15" fill="rgb(223,113,26)" fg:x="1379" fg:w="52"/><text x="5.6279%" y="222.50"></text></g><g><title>MCTS__get_value_policy (para_mcts.pyx:379) (31 samples, 0.12%)</title><rect x="5.5807%" y="196" width="0.1209%" height="15" fill="rgb(206,192,2)" fg:x="1431" fg:w="31"/><text x="5.8307%" y="206.50"></text></g><g><title>MCTS__get_value_policy (para_mcts.pyx:381) (27 samples, 0.11%)</title><rect x="5.7016%" y="196" width="0.1053%" height="15" fill="rgb(241,108,4)" fg:x="1462" fg:w="27"/><text x="5.9516%" y="206.50"></text></g><g><title>at::_ops::relu::call (libtorch_cpu.so) (28 samples, 0.11%)</title><rect x="6.5518%" y="388" width="0.1092%" height="15" fill="rgb(247,173,49)" fg:x="1680" fg:w="28"/><text x="6.8018%" y="398.50"></text></g><g><title>c10::impl::wrap_kernel_functor_unboxed_&lt;c10::impl::detail::WrapFunctionIntoFunctor_&lt;c10::CompileTimeFunctionPointer&lt;at::Tensor(c10::DispatchKeySet, at::Tensor const&amp;), &amp;torch::autograd::VariableType::(anonymous namespace)::relu(c10::DispatchKeySet, at::Tensor const&amp;)&gt;, at::Tensor, c10::guts::typelist::typelist&lt;c10::DispatchKeySet, at::Tensor const&amp;&gt; &gt;, at::Tensor(c10::DispatchKeySet, at::Tensor const&amp;)&gt;::call (libtorch_cpu.so) (27 samples, 0.11%)</title><rect x="6.5557%" y="404" width="0.1053%" height="15" fill="rgb(224,114,35)" fg:x="1681" fg:w="27"/><text x="6.8057%" y="414.50"></text></g><g><title>torch::autograd::VariableType::(anonymous namespace)::relu (libtorch_cpu.so) (27 samples, 0.11%)</title><rect x="6.5557%" y="420" width="0.1053%" height="15" fill="rgb(245,159,27)" fg:x="1681" fg:w="27"/><text x="6.8057%" y="430.50"></text></g><g><title>forward (torch/nn/modules/activation.py:135) (31 samples, 0.12%)</title><rect x="6.5440%" y="340" width="0.1209%" height="15" fill="rgb(245,172,44)" fg:x="1678" fg:w="31"/><text x="6.7940%" y="350.50"></text></g><g><title>relu (torch/nn/functional.py:1701) (30 samples, 0.12%)</title><rect x="6.5479%" y="356" width="0.1170%" height="15" fill="rgb(236,23,11)" fg:x="1679" fg:w="30"/><text x="6.7979%" y="366.50"></text></g><g><title>torch::autograd::THPVariable_relu (libtorch_python.so) (29 samples, 0.11%)</title><rect x="6.5518%" y="372" width="0.1131%" height="15" fill="rgb(205,117,38)" fg:x="1680" fg:w="29"/><text x="6.8018%" y="382.50"></text></g><g><title>at::cuda::blas::gemm_and_bias&lt;float, float&gt; (libtorch_cuda.so) (52 samples, 0.20%)</title><rect x="6.7740%" y="548" width="0.2028%" height="15" fill="rgb(237,72,25)" fg:x="1737" fg:w="52"/><text x="7.0240%" y="558.50"></text></g><g><title>at::native::structured_addmm_out_cuda::impl (libtorch_cuda.so) (61 samples, 0.24%)</title><rect x="6.7545%" y="516" width="0.2379%" height="15" fill="rgb(244,70,9)" fg:x="1732" fg:w="61"/><text x="7.0045%" y="526.50"></text></g><g><title>at::native::(anonymous namespace)::addmm_out_cuda_impl (libtorch_cuda.so) (59 samples, 0.23%)</title><rect x="6.7623%" y="532" width="0.2301%" height="15" fill="rgb(217,125,39)" fg:x="1734" fg:w="59"/><text x="7.0123%" y="542.50"></text></g><g><title>at::_ops::addmm::redispatch (libtorch_cpu.so) (73 samples, 0.28%)</title><rect x="6.7194%" y="468" width="0.2847%" height="15" fill="rgb(235,36,10)" fg:x="1723" fg:w="73"/><text x="6.9694%" y="478.50"></text></g><g><title>c10::impl::wrap_kernel_functor_unboxed_&lt;c10::impl::detail::WrapFunctionIntoFunctor_&lt;c10::CompileTimeFunctionPointer&lt;at::Tensor(at::Tensor const&amp;, at::Tensor const&amp;, at::Tensor const&amp;, c10::Scalar const&amp;, c10::Scalar const&amp;), &amp;at::(anonymous namespace)::wrapper_CUDA_addmm(at::Tensor const&amp;, at::Tensor const&amp;, at::Tensor const&amp;, c10::Scalar const&amp;, c10::Scalar const&amp;)&gt;, at::Tensor, c10::guts::typelist::typelist&lt;at::Tensor const&amp;, at::Tensor const&amp;, at::Tensor const&amp;, c10::Scalar const&amp;, c10::Scalar const&amp;&gt; &gt;, at::Tensor(at::Tensor const&amp;, at::Tensor const&amp;, at::Tensor const&amp;, c10::Scalar const&amp;, c10::Scalar const&amp;)&gt;::call (libtorch_cuda.so) (73 samples, 0.28%)</title><rect x="6.7194%" y="484" width="0.2847%" height="15" fill="rgb(251,123,47)" fg:x="1723" fg:w="73"/><text x="6.9694%" y="494.50"></text></g><g><title>at::(anonymous namespace)::wrapper_CUDA_addmm (libtorch_cuda.so) (73 samples, 0.28%)</title><rect x="6.7194%" y="500" width="0.2847%" height="15" fill="rgb(221,13,13)" fg:x="1723" fg:w="73"/><text x="6.9694%" y="510.50"></text></g><g><title>at::_ops::addmm::call (libtorch_cpu.so) (76 samples, 0.30%)</title><rect x="6.7116%" y="420" width="0.2964%" height="15" fill="rgb(238,131,9)" fg:x="1721" fg:w="76"/><text x="6.9616%" y="430.50"></text></g><g><title>c10::impl::wrap_kernel_functor_unboxed_&lt;c10::impl::detail::WrapFunctionIntoFunctor_&lt;c10::CompileTimeFunctionPointer&lt;at::Tensor(c10::DispatchKeySet, at::Tensor const&amp;, at::Tensor const&amp;, at::Tensor const&amp;, c10::Scalar const&amp;, c10::Scalar const&amp;), &amp;torch::autograd::VariableType::(anonymous namespace)::addmm(c10::DispatchKeySet, at::Tensor const&amp;, at::Tensor const&amp;, at::Tensor const&amp;, c10::Scalar const&amp;, c10::Scalar const&amp;)&gt;, at::Tensor, c10::guts::typelist::typelist&lt;c10::DispatchKeySet, at::Tensor const&amp;, at::Tensor const&amp;, at::Tensor const&amp;, c10::Scalar const&amp;, c10::Scalar const&amp;&gt; &gt;, at::Tensor(c10::DispatchKeySet, at::Tensor const&amp;, at::Tensor const&amp;, at::Tensor const&amp;, c10::Scalar const&amp;, c10::Scalar const&amp;)&gt;::call (libtorch_cpu.so) (74 samples, 0.29%)</title><rect x="6.7194%" y="436" width="0.2886%" height="15" fill="rgb(211,50,8)" fg:x="1723" fg:w="74"/><text x="6.9694%" y="446.50"></text></g><g><title>torch::autograd::VariableType::(anonymous namespace)::addmm (libtorch_cpu.so) (74 samples, 0.29%)</title><rect x="6.7194%" y="452" width="0.2886%" height="15" fill="rgb(245,182,24)" fg:x="1723" fg:w="74"/><text x="6.9694%" y="462.50"></text></g><g><title>at::_ops::linear::call (libtorch_cpu.so) (91 samples, 0.35%)</title><rect x="6.6999%" y="372" width="0.3549%" height="15" fill="rgb(242,14,37)" fg:x="1718" fg:w="91"/><text x="6.9499%" y="382.50"></text></g><g><title>c10::impl::wrap_kernel_functor_unboxed_&lt;c10::impl::detail::WrapFunctionIntoFunctor_&lt;c10::CompileTimeFunctionPointer&lt;at::Tensor(at::Tensor const&amp;, at::Tensor const&amp;, std::optional&lt;at::Tensor&gt; const&amp;), &amp;at::(anonymous namespace)::(anonymous namespace)::wrapper_CompositeImplicitAutograd__linear(at::Tensor const&amp;, at::Tensor const&amp;, std::optional&lt;at::Tensor&gt; const&amp;)&gt;, at::Tensor, c10::guts::typelist::typelist&lt;at::Tensor const&amp;, at::Tensor const&amp;, std::optional&lt;at::Tensor&gt; const&amp;&gt; &gt;, at::Tensor(at::Tensor const&amp;, at::Tensor const&amp;, std::optional&lt;at::Tensor&gt; const&amp;)&gt;::call (libtorch_cpu.so) (90 samples, 0.35%)</title><rect x="6.7038%" y="388" width="0.3510%" height="15" fill="rgb(246,228,12)" fg:x="1719" fg:w="90"/><text x="6.9538%" y="398.50"></text></g><g><title>at::native::linear (libtorch_cpu.so) (89 samples, 0.35%)</title><rect x="6.7077%" y="404" width="0.3471%" height="15" fill="rgb(213,55,15)" fg:x="1720" fg:w="89"/><text x="6.9577%" y="414.50"></text></g><g><title>forward (armada_net.py:153) (168 samples, 0.66%)</title><rect x="6.4036%" y="244" width="0.6552%" height="15" fill="rgb(209,9,3)" fg:x="1642" fg:w="168"/><text x="6.6536%" y="254.50"></text></g><g><title>_wrapped_call_impl (torch/nn/modules/module.py:1773) (164 samples, 0.64%)</title><rect x="6.4192%" y="260" width="0.6396%" height="15" fill="rgb(230,59,30)" fg:x="1646" fg:w="164"/><text x="6.6692%" y="270.50"></text></g><g><title>_call_impl (torch/nn/modules/module.py:1784) (160 samples, 0.62%)</title><rect x="6.4348%" y="276" width="0.6240%" height="15" fill="rgb(209,121,21)" fg:x="1650" fg:w="160"/><text x="6.6848%" y="286.50"></text></g><g><title>forward (torch/nn/modules/container.py:244) (155 samples, 0.60%)</title><rect x="6.4543%" y="292" width="0.6045%" height="15" fill="rgb(220,109,13)" fg:x="1655" fg:w="155"/><text x="6.7043%" y="302.50"></text></g><g><title>_wrapped_call_impl (torch/nn/modules/module.py:1773) (144 samples, 0.56%)</title><rect x="6.4972%" y="308" width="0.5616%" height="15" fill="rgb(232,18,1)" fg:x="1666" fg:w="144"/><text x="6.7472%" y="318.50"></text></g><g><title>_call_impl (torch/nn/modules/module.py:1784) (133 samples, 0.52%)</title><rect x="6.5401%" y="324" width="0.5187%" height="15" fill="rgb(215,41,42)" fg:x="1677" fg:w="133"/><text x="6.7901%" y="334.50"></text></g><g><title>forward (torch/nn/modules/linear.py:125) (99 samples, 0.39%)</title><rect x="6.6726%" y="340" width="0.3861%" height="15" fill="rgb(224,123,36)" fg:x="1711" fg:w="99"/><text x="6.9226%" y="350.50"></text></g><g><title>torch::autograd::THPVariable_linear (libtorch_python.so) (94 samples, 0.37%)</title><rect x="6.6921%" y="356" width="0.3666%" height="15" fill="rgb(240,125,3)" fg:x="1716" fg:w="94"/><text x="6.9421%" y="366.50"></text></g><g><title>forward (torch/nn/modules/transformer.py:853) (76 samples, 0.30%)</title><rect x="7.4331%" y="340" width="0.2964%" height="15" fill="rgb(205,98,50)" fg:x="1906" fg:w="76"/><text x="7.6831%" y="350.50"></text></g><g><title>&lt;genexpr&gt; (torch/nn/modules/transformer.py:856) (58 samples, 0.23%)</title><rect x="7.5033%" y="356" width="0.2262%" height="15" fill="rgb(205,185,37)" fg:x="1924" fg:w="58"/><text x="7.7533%" y="366.50"></text></g><g><title>modules (torch/nn/modules/module.py:2815) (55 samples, 0.21%)</title><rect x="7.5150%" y="372" width="0.2145%" height="15" fill="rgb(238,207,15)" fg:x="1927" fg:w="55"/><text x="7.7650%" y="382.50"></text></g><g><title>named_modules (torch/nn/modules/module.py:2863) (34 samples, 0.13%)</title><rect x="7.5969%" y="388" width="0.1326%" height="15" fill="rgb(213,199,42)" fg:x="1948" fg:w="34"/><text x="7.8469%" y="398.50"></text></g><g><title>forward (torch/nn/modules/transformer.py:885) (40 samples, 0.16%)</title><rect x="7.9245%" y="340" width="0.1560%" height="15" fill="rgb(235,201,11)" fg:x="2032" fg:w="40"/><text x="8.1745%" y="350.50"></text></g><g><title>&lt;genexpr&gt; (torch/nn/modules/transformer.py:886) (33 samples, 0.13%)</title><rect x="7.9518%" y="356" width="0.1287%" height="15" fill="rgb(207,46,11)" fg:x="2039" fg:w="33"/><text x="8.2018%" y="366.50"></text></g><g><title>at::Tensor::narrow (libtorch_cpu.so) (27 samples, 0.11%)</title><rect x="8.4471%" y="612" width="0.1053%" height="15" fill="rgb(241,35,35)" fg:x="2166" fg:w="27"/><text x="8.6971%" y="622.50"></text></g><g><title>at::_ops::narrow::call (libtorch_cpu.so) (26 samples, 0.10%)</title><rect x="8.4510%" y="628" width="0.1014%" height="15" fill="rgb(243,32,47)" fg:x="2167" fg:w="26"/><text x="8.7010%" y="638.50"></text></g><g><title>c10::impl::wrap_kernel_functor_unboxed_&lt;c10::impl::detail::WrapFunctionIntoFunctor_&lt;c10::CompileTimeFunctionPointer&lt;at::Tensor(at::Tensor const&amp;, long, c10::SymInt, c10::SymInt), &amp;at::(anonymous namespace)::(anonymous namespace)::wrapper_CompositeImplicitAutograd__narrow(at::Tensor const&amp;, long, c10::SymInt, c10::SymInt)&gt;, at::Tensor, c10::guts::typelist::typelist&lt;at::Tensor const&amp;, long, c10::SymInt, c10::SymInt&gt; &gt;, at::Tensor(at::Tensor const&amp;, long, c10::SymInt, c10::SymInt)&gt;::call (libtorch_cpu.so) (26 samples, 0.10%)</title><rect x="8.4510%" y="644" width="0.1014%" height="15" fill="rgb(247,202,23)" fg:x="2167" fg:w="26"/><text x="8.7010%" y="654.50"></text></g><g><title>at::(anonymous namespace)::(anonymous namespace)::wrapper_CompositeImplicitAutograd__narrow (libtorch_cpu.so) (26 samples, 0.10%)</title><rect x="8.4510%" y="660" width="0.1014%" height="15" fill="rgb(219,102,11)" fg:x="2167" fg:w="26"/><text x="8.7010%" y="670.50"></text></g><g><title>at::native::narrow_symint (libtorch_cpu.so) (26 samples, 0.10%)</title><rect x="8.4510%" y="676" width="0.1014%" height="15" fill="rgb(243,110,44)" fg:x="2167" fg:w="26"/><text x="8.7010%" y="686.50"></text></g><g><title>at::native::split (libtorch_cpu.so) (28 samples, 0.11%)</title><rect x="8.4471%" y="596" width="0.1092%" height="15" fill="rgb(222,74,54)" fg:x="2166" fg:w="28"/><text x="8.6971%" y="606.50"></text></g><g><title>at::native::transform_bias_rescale_qkv_cuda (libtorch_cuda.so) (74 samples, 0.29%)</title><rect x="8.3691%" y="580" width="0.2886%" height="15" fill="rgb(216,99,12)" fg:x="2146" fg:w="74"/><text x="8.6191%" y="590.50"></text></g><g><title>at::_ops::_transform_bias_rescale_qkv::call (libtorch_cpu.so) (78 samples, 0.30%)</title><rect x="8.3613%" y="532" width="0.3042%" height="15" fill="rgb(226,22,26)" fg:x="2144" fg:w="78"/><text x="8.6113%" y="542.50"></text></g><g><title>c10::impl::wrap_kernel_functor_unboxed_&lt;c10::impl::detail::WrapFunctionIntoFunctor_&lt;c10::CompileTimeFunctionPointer&lt;std::tuple&lt;at::Tensor, at::Tensor, at::Tensor&gt; (at::Tensor const&amp;, at::Tensor const&amp;, long), &amp;at::(anonymous namespace)::(anonymous namespace)::wrapper_CUDA___transform_bias_rescale_qkv(at::Tensor const&amp;, at::Tensor const&amp;, long)&gt;, std::tuple&lt;at::Tensor, at::Tensor, at::Tensor&gt;, c10::guts::typelist::typelist&lt;at::Tensor const&amp;, at::Tensor const&amp;, long&gt; &gt;, std::tuple&lt;at::Tensor, at::Tensor, at::Tensor&gt; (at::Tensor const&amp;, at::Tensor const&amp;, long)&gt;::call (libtorch_cuda.so) (77 samples, 0.30%)</title><rect x="8.3652%" y="548" width="0.3003%" height="15" fill="rgb(217,163,10)" fg:x="2145" fg:w="77"/><text x="8.6152%" y="558.50"></text></g><g><title>at::(anonymous namespace)::(anonymous namespace)::wrapper_CUDA___transform_bias_rescale_qkv (libtorch_cuda.so) (77 samples, 0.30%)</title><rect x="8.3652%" y="564" width="0.3003%" height="15" fill="rgb(213,25,53)" fg:x="2145" fg:w="77"/><text x="8.6152%" y="574.50"></text></g><g><title>0x7ac5037f1c92 (nvidia/cublas/lib/libcublas.so.12) (29 samples, 0.11%)</title><rect x="8.6967%" y="660" width="0.1131%" height="15" fill="rgb(252,105,26)" fg:x="2230" fg:w="29"/><text x="8.9467%" y="670.50"></text></g><g><title>0x7ac5036ab0e6 (nvidia/cublas/lib/libcublas.so.12) (29 samples, 0.11%)</title><rect x="8.6967%" y="676" width="0.1131%" height="15" fill="rgb(220,39,43)" fg:x="2230" fg:w="29"/><text x="8.9467%" y="686.50"></text></g><g><title>at::cuda::blas::bgemm_internal_cublas&lt;float, float&gt; (libtorch_cuda.so) (33 samples, 0.13%)</title><rect x="8.6850%" y="612" width="0.1287%" height="15" fill="rgb(229,68,48)" fg:x="2227" fg:w="33"/><text x="8.9350%" y="622.50"></text></g><g><title>cublasSgemmStridedBatched (nvidia/cublas/lib/libcublas.so.12) (30 samples, 0.12%)</title><rect x="8.6967%" y="628" width="0.1170%" height="15" fill="rgb(252,8,32)" fg:x="2230" fg:w="30"/><text x="8.9467%" y="638.50"></text></g><g><title>0x7ac5037f25eb (nvidia/cublas/lib/libcublas.so.12) (30 samples, 0.12%)</title><rect x="8.6967%" y="644" width="0.1170%" height="15" fill="rgb(223,20,43)" fg:x="2230" fg:w="30"/><text x="8.9467%" y="654.50"></text></g><g><title>at::(anonymous namespace)::wrapper_CUDA_bmm_out_out (libtorch_cuda.so) (37 samples, 0.14%)</title><rect x="8.6733%" y="564" width="0.1443%" height="15" fill="rgb(229,81,49)" fg:x="2224" fg:w="37"/><text x="8.9233%" y="574.50"></text></g><g><title>at::native::structured_bmm_out_cuda::impl (libtorch_cuda.so) (34 samples, 0.13%)</title><rect x="8.6850%" y="580" width="0.1326%" height="15" fill="rgb(236,28,36)" fg:x="2227" fg:w="34"/><text x="8.9350%" y="590.50"></text></g><g><title>at::native::(anonymous namespace)::baddbmm_out_cuda_impl (libtorch_cuda.so) (34 samples, 0.13%)</title><rect x="8.6850%" y="596" width="0.1326%" height="15" fill="rgb(249,185,26)" fg:x="2227" fg:w="34"/><text x="8.9350%" y="606.50"></text></g><g><title>at::_ops::bmm_out::call (libtorch_cpu.so) (38 samples, 0.15%)</title><rect x="8.6733%" y="548" width="0.1482%" height="15" fill="rgb(249,174,33)" fg:x="2224" fg:w="38"/><text x="8.9233%" y="558.50"></text></g><g><title>at::native::bmm_nn (libtorch_cpu.so) (59 samples, 0.23%)</title><rect x="8.6655%" y="532" width="0.2301%" height="15" fill="rgb(233,201,37)" fg:x="2222" fg:w="59"/><text x="8.9155%" y="542.50"></text></g><g><title>0x7ac4e246b6ab (nvidia/cublas/lib/libcublasLt.so.12) (27 samples, 0.11%)</title><rect x="9.0633%" y="740" width="0.1053%" height="15" fill="rgb(221,78,26)" fg:x="2324" fg:w="27"/><text x="9.3133%" y="750.50"></text></g><g><title>0x7ac5036ab0e6 (nvidia/cublas/lib/libcublas.so.12) (42 samples, 0.16%)</title><rect x="9.0087%" y="692" width="0.1638%" height="15" fill="rgb(250,127,30)" fg:x="2310" fg:w="42"/><text x="9.2587%" y="702.50"></text></g><g><title>0x7ac5036a8f8d (nvidia/cublas/lib/libcublas.so.12) (29 samples, 0.11%)</title><rect x="9.0594%" y="708" width="0.1131%" height="15" fill="rgb(230,49,44)" fg:x="2323" fg:w="29"/><text x="9.3094%" y="718.50"></text></g><g><title>cublasLtSSSMatmul (nvidia/cublas/lib/libcublasLt.so.12) (29 samples, 0.11%)</title><rect x="9.0594%" y="724" width="0.1131%" height="15" fill="rgb(229,67,23)" fg:x="2323" fg:w="29"/><text x="9.3094%" y="734.50"></text></g><g><title>at::cuda::blas::bgemm_internal_cublas&lt;float, float&gt; (libtorch_cuda.so) (57 samples, 0.22%)</title><rect x="8.9541%" y="628" width="0.2223%" height="15" fill="rgb(249,83,47)" fg:x="2296" fg:w="57"/><text x="9.2041%" y="638.50"></text></g><g><title>cublasSgemmStridedBatched (nvidia/cublas/lib/libcublas.so.12) (46 samples, 0.18%)</title><rect x="8.9970%" y="644" width="0.1794%" height="15" fill="rgb(215,43,3)" fg:x="2307" fg:w="46"/><text x="9.2470%" y="654.50"></text></g><g><title>0x7ac5037f25eb (nvidia/cublas/lib/libcublas.so.12) (44 samples, 0.17%)</title><rect x="9.0048%" y="660" width="0.1716%" height="15" fill="rgb(238,154,13)" fg:x="2309" fg:w="44"/><text x="9.2548%" y="670.50"></text></g><g><title>0x7ac5037f1c92 (nvidia/cublas/lib/libcublas.so.12) (43 samples, 0.17%)</title><rect x="9.0087%" y="676" width="0.1677%" height="15" fill="rgb(219,56,2)" fg:x="2310" fg:w="43"/><text x="9.2587%" y="686.50"></text></g><g><title>at::native::structured_bmm_out_cuda::impl (libtorch_cuda.so) (59 samples, 0.23%)</title><rect x="8.9502%" y="596" width="0.2301%" height="15" fill="rgb(233,0,4)" fg:x="2295" fg:w="59"/><text x="9.2002%" y="606.50"></text></g><g><title>at::native::(anonymous namespace)::baddbmm_out_cuda_impl (libtorch_cuda.so) (59 samples, 0.23%)</title><rect x="8.9502%" y="612" width="0.2301%" height="15" fill="rgb(235,30,7)" fg:x="2295" fg:w="59"/><text x="9.2002%" y="622.50"></text></g><g><title>at::_ops::bmm::call (libtorch_cpu.so) (74 samples, 0.29%)</title><rect x="8.8956%" y="548" width="0.2886%" height="15" fill="rgb(250,79,13)" fg:x="2281" fg:w="74"/><text x="9.1456%" y="558.50"></text></g><g><title>c10::impl::wrap_kernel_functor_unboxed_&lt;c10::impl::detail::WrapFunctionIntoFunctor_&lt;c10::CompileTimeFunctionPointer&lt;at::Tensor(at::Tensor const&amp;, at::Tensor const&amp;), &amp;at::(anonymous namespace)::wrapper_CUDA_bmm(at::Tensor const&amp;, at::Tensor const&amp;)&gt;, at::Tensor, c10::guts::typelist::typelist&lt;at::Tensor const&amp;, at::Tensor const&amp;&gt; &gt;, at::Tensor(at::Tensor const&amp;, at::Tensor const&amp;)&gt;::call (libtorch_cuda.so) (74 samples, 0.29%)</title><rect x="8.8956%" y="564" width="0.2886%" height="15" fill="rgb(211,146,34)" fg:x="2281" fg:w="74"/><text x="9.1456%" y="574.50"></text></g><g><title>at::(anonymous namespace)::wrapper_CUDA_bmm (libtorch_cuda.so) (74 samples, 0.29%)</title><rect x="8.8956%" y="580" width="0.2886%" height="15" fill="rgb(228,22,38)" fg:x="2281" fg:w="74"/><text x="9.1456%" y="590.50"></text></g><g><title>at::native::bmm_nt (libtorch_cpu.so) (93 samples, 0.36%)</title><rect x="8.8956%" y="532" width="0.3627%" height="15" fill="rgb(235,168,5)" fg:x="2281" fg:w="93"/><text x="9.1456%" y="542.50"></text></g><g><title>0x7ac4e2b9a5ac (nvidia/cublas/lib/libcublasLt.so.12) (31 samples, 0.12%)</title><rect x="9.6989%" y="804" width="0.1209%" height="15" fill="rgb(221,155,16)" fg:x="2487" fg:w="31"/><text x="9.9489%" y="814.50"></text></g><g><title>0x7ac4e2b98fb7 (nvidia/cublas/lib/libcublasLt.so.12) (30 samples, 0.12%)</title><rect x="9.7028%" y="820" width="0.1170%" height="15" fill="rgb(215,215,53)" fg:x="2488" fg:w="30"/><text x="9.9528%" y="830.50"></text></g><g><title>0x7ac4e54731fd (nvidia/cublas/lib/libcublasLt.so.12) (28 samples, 0.11%)</title><rect x="9.7106%" y="836" width="0.1092%" height="15" fill="rgb(223,4,10)" fg:x="2490" fg:w="28"/><text x="9.9606%" y="846.50"></text></g><g><title>0x7ac4e54731dd (nvidia/cublas/lib/libcublasLt.so.12) (28 samples, 0.11%)</title><rect x="9.7106%" y="852" width="0.1092%" height="15" fill="rgb(234,103,6)" fg:x="2490" fg:w="28"/><text x="9.9606%" y="862.50"></text></g><g><title>0x7ac4e54fd49b (nvidia/cublas/lib/libcublasLt.so.12) (28 samples, 0.11%)</title><rect x="9.7106%" y="868" width="0.1092%" height="15" fill="rgb(227,97,0)" fg:x="2490" fg:w="28"/><text x="9.9606%" y="878.50"></text></g><g><title>0x7ac4e549a7ce (nvidia/cublas/lib/libcublasLt.so.12) (27 samples, 0.11%)</title><rect x="9.7145%" y="884" width="0.1053%" height="15" fill="rgb(234,150,53)" fg:x="2491" fg:w="27"/><text x="9.9645%" y="894.50"></text></g><g><title>0x7ac4e00ef270 (libcuda.so.550.54.15) (27 samples, 0.11%)</title><rect x="9.7145%" y="900" width="0.1053%" height="15" fill="rgb(228,201,54)" fg:x="2491" fg:w="27"/><text x="9.9645%" y="910.50"></text></g><g><title>at::cuda::blas::gemm_internal_cublas&lt;float, float&gt; (libtorch_cuda.so) (72 samples, 0.28%)</title><rect x="9.5624%" y="676" width="0.2808%" height="15" fill="rgb(222,22,37)" fg:x="2452" fg:w="72"/><text x="9.8124%" y="686.50"></text></g><g><title>cublasSgemm_v2 (nvidia/cublas/lib/libcublas.so.12) (63 samples, 0.25%)</title><rect x="9.5975%" y="692" width="0.2457%" height="15" fill="rgb(237,53,32)" fg:x="2461" fg:w="63"/><text x="9.8475%" y="702.50"></text></g><g><title>0x7ac5037cda1d (nvidia/cublas/lib/libcublas.so.12) (63 samples, 0.25%)</title><rect x="9.5975%" y="708" width="0.2457%" height="15" fill="rgb(233,25,53)" fg:x="2461" fg:w="63"/><text x="9.8475%" y="718.50"></text></g><g><title>0x7ac5036ab0e6 (nvidia/cublas/lib/libcublas.so.12) (62 samples, 0.24%)</title><rect x="9.6014%" y="724" width="0.2418%" height="15" fill="rgb(210,40,34)" fg:x="2462" fg:w="62"/><text x="9.8514%" y="734.50"></text></g><g><title>0x7ac5036a8f8d (nvidia/cublas/lib/libcublas.so.12) (51 samples, 0.20%)</title><rect x="9.6443%" y="740" width="0.1989%" height="15" fill="rgb(241,220,44)" fg:x="2473" fg:w="51"/><text x="9.8943%" y="750.50"></text></g><g><title>cublasLtSSSMatmul (nvidia/cublas/lib/libcublasLt.so.12) (51 samples, 0.20%)</title><rect x="9.6443%" y="756" width="0.1989%" height="15" fill="rgb(235,28,35)" fg:x="2473" fg:w="51"/><text x="9.8943%" y="766.50"></text></g><g><title>0x7ac4e246b6ab (nvidia/cublas/lib/libcublasLt.so.12) (48 samples, 0.19%)</title><rect x="9.6560%" y="772" width="0.1872%" height="15" fill="rgb(210,56,17)" fg:x="2476" fg:w="48"/><text x="9.9060%" y="782.50"></text></g><g><title>0x7ac4e2394df1 (nvidia/cublas/lib/libcublasLt.so.12) (39 samples, 0.15%)</title><rect x="9.6911%" y="788" width="0.1521%" height="15" fill="rgb(224,130,29)" fg:x="2485" fg:w="39"/><text x="9.9411%" y="798.50"></text></g><g><title>at::native::structured_mm_out_cuda::impl (libtorch_cuda.so) (78 samples, 0.30%)</title><rect x="9.5468%" y="644" width="0.3042%" height="15" fill="rgb(235,212,8)" fg:x="2448" fg:w="78"/><text x="9.7968%" y="654.50"></text></g><g><title>at::native::(anonymous namespace)::addmm_out_cuda_impl (libtorch_cuda.so) (78 samples, 0.30%)</title><rect x="9.5468%" y="660" width="0.3042%" height="15" fill="rgb(223,33,50)" fg:x="2448" fg:w="78"/><text x="9.7968%" y="670.50"></text></g><g><title>at::_ops::mm::call (libtorch_cpu.so) (98 samples, 0.38%)</title><rect x="9.4727%" y="596" width="0.3822%" height="15" fill="rgb(219,149,13)" fg:x="2429" fg:w="98"/><text x="9.7227%" y="606.50"></text></g><g><title>c10::impl::wrap_kernel_functor_unboxed_&lt;c10::impl::detail::WrapFunctionIntoFunctor_&lt;c10::CompileTimeFunctionPointer&lt;at::Tensor(at::Tensor const&amp;, at::Tensor const&amp;), &amp;at::(anonymous namespace)::wrapper_CUDA_mm(at::Tensor const&amp;, at::Tensor const&amp;)&gt;, at::Tensor, c10::guts::typelist::typelist&lt;at::Tensor const&amp;, at::Tensor const&amp;&gt; &gt;, at::Tensor(at::Tensor const&amp;, at::Tensor const&amp;)&gt;::call (libtorch_cuda.so) (97 samples, 0.38%)</title><rect x="9.4766%" y="612" width="0.3783%" height="15" fill="rgb(250,156,29)" fg:x="2430" fg:w="97"/><text x="9.7266%" y="622.50"></text></g><g><title>at::(anonymous namespace)::wrapper_CUDA_mm (libtorch_cuda.so) (97 samples, 0.38%)</title><rect x="9.4766%" y="628" width="0.3783%" height="15" fill="rgb(216,193,19)" fg:x="2430" fg:w="97"/><text x="9.7266%" y="638.50"></text></g><g><title>at::native::qkv_projection (libtorch_cpu.so) (142 samples, 0.55%)</title><rect x="9.3401%" y="532" width="0.5538%" height="15" fill="rgb(216,135,14)" fg:x="2395" fg:w="142"/><text x="9.5901%" y="542.50"></text></g><g><title>at::native::(anonymous namespace)::gemm_nt (libtorch_cpu.so) (142 samples, 0.55%)</title><rect x="9.3401%" y="548" width="0.5538%" height="15" fill="rgb(241,47,5)" fg:x="2395" fg:w="142"/><text x="9.5901%" y="558.50"></text></g><g><title>at::native::matmul (libtorch_cpu.so) (122 samples, 0.48%)</title><rect x="9.4181%" y="564" width="0.4758%" height="15" fill="rgb(233,42,35)" fg:x="2415" fg:w="122"/><text x="9.6681%" y="574.50"></text></g><g><title>at::native::_matmul_impl (libtorch_cpu.so) (119 samples, 0.46%)</title><rect x="9.4298%" y="580" width="0.4641%" height="15" fill="rgb(231,13,6)" fg:x="2418" fg:w="119"/><text x="9.6798%" y="590.50"></text></g><g><title>cudaLaunchKernel (nvidia/cuda_runtime/lib/libcudart.so.12) (33 samples, 0.13%)</title><rect x="10.0343%" y="740" width="0.1287%" height="15" fill="rgb(207,181,40)" fg:x="2573" fg:w="33"/><text x="10.2843%" y="750.50"></text></g><g><title>at::native::gpu_kernel_impl&lt;__nv_hdl_wrapper_t&lt;false, true, false, __nv_dl_tag&lt;void (*)(at::TensorIteratorBase&amp;), &amp;at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&amp;), (unsigned int)15&gt;, float (float), &gt; &gt; (libtorch_cuda.so) (39 samples, 0.15%)</title><rect x="10.0187%" y="724" width="0.1521%" height="15" fill="rgb(254,173,49)" fg:x="2569" fg:w="39"/><text x="10.2687%" y="734.50"></text></g><g><title>at::_ops::copy_::call (libtorch_cpu.so) (66 samples, 0.26%)</title><rect x="9.9251%" y="660" width="0.2574%" height="15" fill="rgb(221,1,38)" fg:x="2545" fg:w="66"/><text x="10.1751%" y="670.50"></text></g><g><title>at::native::copy_ (libtorch_cpu.so) (65 samples, 0.25%)</title><rect x="9.9290%" y="676" width="0.2535%" height="15" fill="rgb(206,124,46)" fg:x="2546" fg:w="65"/><text x="10.1790%" y="686.50"></text></g><g><title>at::native::copy_impl (libtorch_cpu.so) (64 samples, 0.25%)</title><rect x="9.9329%" y="692" width="0.2496%" height="15" fill="rgb(249,21,11)" fg:x="2547" fg:w="64"/><text x="10.1829%" y="702.50"></text></g><g><title>at::native::copy_device_to_device (libtorch_cuda.so) (46 samples, 0.18%)</title><rect x="10.0031%" y="708" width="0.1794%" height="15" fill="rgb(222,201,40)" fg:x="2565" fg:w="46"/><text x="10.2531%" y="718.50"></text></g><g><title>at::TensorBase::__dispatch_contiguous (libtorch_cpu.so) (84 samples, 0.33%)</title><rect x="9.9017%" y="548" width="0.3276%" height="15" fill="rgb(235,61,29)" fg:x="2539" fg:w="84"/><text x="10.1517%" y="558.50"></text></g><g><title>at::_ops::contiguous::call (libtorch_cpu.so) (84 samples, 0.33%)</title><rect x="9.9017%" y="564" width="0.3276%" height="15" fill="rgb(219,207,3)" fg:x="2539" fg:w="84"/><text x="10.1517%" y="574.50"></text></g><g><title>c10::impl::wrap_kernel_functor_unboxed_&lt;c10::impl::detail::WrapFunctionIntoFunctor_&lt;c10::CompileTimeFunctionPointer&lt;at::Tensor(at::Tensor const&amp;, c10::MemoryFormat), &amp;at::(anonymous namespace)::(anonymous namespace)::wrapper_CompositeImplicitAutograd__contiguous(at::Tensor const&amp;, c10::MemoryFormat)&gt;, at::Tensor, c10::guts::typelist::typelist&lt;at::Tensor const&amp;, c10::MemoryFormat&gt; &gt;, at::Tensor(at::Tensor const&amp;, c10::MemoryFormat)&gt;::call (libtorch_cpu.so) (79 samples, 0.31%)</title><rect x="9.9212%" y="580" width="0.3081%" height="15" fill="rgb(222,56,46)" fg:x="2544" fg:w="79"/><text x="10.1712%" y="590.50"></text></g><g><title>at::native::contiguous (libtorch_cpu.so) (78 samples, 0.30%)</title><rect x="9.9251%" y="596" width="0.3042%" height="15" fill="rgb(239,76,54)" fg:x="2545" fg:w="78"/><text x="10.1751%" y="606.50"></text></g><g><title>at::_ops::clone::call (libtorch_cpu.so) (78 samples, 0.30%)</title><rect x="9.9251%" y="612" width="0.3042%" height="15" fill="rgb(231,124,27)" fg:x="2545" fg:w="78"/><text x="10.1751%" y="622.50"></text></g><g><title>c10::impl::wrap_kernel_functor_unboxed_&lt;c10::impl::detail::WrapFunctionIntoFunctor_&lt;c10::CompileTimeFunctionPointer&lt;at::Tensor(at::Tensor const&amp;, std::optional&lt;c10::MemoryFormat&gt;), &amp;at::(anonymous namespace)::(anonymous namespace)::wrapper_CompositeExplicitAutograd__clone(at::Tensor const&amp;, std::optional&lt;c10::MemoryFormat&gt;)&gt;, at::Tensor, c10::guts::typelist::typelist&lt;at::Tensor const&amp;, std::optional&lt;c10::MemoryFormat&gt; &gt; &gt;, at::Tensor(at::Tensor const&amp;, std::optional&lt;c10::MemoryFormat&gt;)&gt;::call (libtorch_cpu.so) (78 samples, 0.30%)</title><rect x="9.9251%" y="628" width="0.3042%" height="15" fill="rgb(249,195,6)" fg:x="2545" fg:w="78"/><text x="10.1751%" y="638.50"></text></g><g><title>at::native::clone (libtorch_cpu.so) (78 samples, 0.30%)</title><rect x="9.9251%" y="644" width="0.3042%" height="15" fill="rgb(237,174,47)" fg:x="2545" fg:w="78"/><text x="10.1751%" y="654.50"></text></g><g><title>cublasLtMatmul (nvidia/cublas/lib/libcublasLt.so.12) (26 samples, 0.10%)</title><rect x="10.4399%" y="660" width="0.1014%" height="15" fill="rgb(206,201,31)" fg:x="2677" fg:w="26"/><text x="10.6899%" y="670.50"></text></g><g><title>at::cuda::blas::gemm_and_bias&lt;float, float&gt; (libtorch_cuda.so) (64 samples, 0.25%)</title><rect x="10.3424%" y="644" width="0.2496%" height="15" fill="rgb(231,57,52)" fg:x="2652" fg:w="64"/><text x="10.5924%" y="654.50"></text></g><g><title>at::native::structured_addmm_out_cuda::impl (libtorch_cuda.so) (70 samples, 0.27%)</title><rect x="10.3307%" y="612" width="0.2730%" height="15" fill="rgb(248,177,22)" fg:x="2649" fg:w="70"/><text x="10.5807%" y="622.50"></text></g><g><title>at::native::(anonymous namespace)::addmm_out_cuda_impl (libtorch_cuda.so) (70 samples, 0.27%)</title><rect x="10.3307%" y="628" width="0.2730%" height="15" fill="rgb(215,211,37)" fg:x="2649" fg:w="70"/><text x="10.5807%" y="638.50"></text></g><g><title>at::_ops::addmm::call (libtorch_cpu.so) (88 samples, 0.34%)</title><rect x="10.2722%" y="564" width="0.3432%" height="15" fill="rgb(241,128,51)" fg:x="2634" fg:w="88"/><text x="10.5222%" y="574.50"></text></g><g><title>c10::impl::wrap_kernel_functor_unboxed_&lt;c10::impl::detail::WrapFunctionIntoFunctor_&lt;c10::CompileTimeFunctionPointer&lt;at::Tensor(at::Tensor const&amp;, at::Tensor const&amp;, at::Tensor const&amp;, c10::Scalar const&amp;, c10::Scalar const&amp;), &amp;at::(anonymous namespace)::wrapper_CUDA_addmm(at::Tensor const&amp;, at::Tensor const&amp;, at::Tensor const&amp;, c10::Scalar const&amp;, c10::Scalar const&amp;)&gt;, at::Tensor, c10::guts::typelist::typelist&lt;at::Tensor const&amp;, at::Tensor const&amp;, at::Tensor const&amp;, c10::Scalar const&amp;, c10::Scalar const&amp;&gt; &gt;, at::Tensor(at::Tensor const&amp;, at::Tensor const&amp;, at::Tensor const&amp;, c10::Scalar const&amp;, c10::Scalar const&amp;)&gt;::call (libtorch_cuda.so) (86 samples, 0.34%)</title><rect x="10.2800%" y="580" width="0.3354%" height="15" fill="rgb(227,165,31)" fg:x="2636" fg:w="86"/><text x="10.5300%" y="590.50"></text></g><g><title>at::(anonymous namespace)::wrapper_CUDA_addmm (libtorch_cuda.so) (86 samples, 0.34%)</title><rect x="10.2800%" y="596" width="0.3354%" height="15" fill="rgb(228,167,24)" fg:x="2636" fg:w="86"/><text x="10.5300%" y="606.50"></text></g><g><title>at::native::linear (libtorch_cpu.so) (94 samples, 0.37%)</title><rect x="10.2722%" y="548" width="0.3666%" height="15" fill="rgb(228,143,12)" fg:x="2634" fg:w="94"/><text x="10.5222%" y="558.50"></text></g><g><title>at::native::transform0213_gemm_nt_bias (libtorch_cpu.so) (195 samples, 0.76%)</title><rect x="9.8939%" y="532" width="0.7605%" height="15" fill="rgb(249,149,8)" fg:x="2537" fg:w="195"/><text x="10.1439%" y="542.50"></text></g><g><title>at::native::native_multi_head_attention_cuda (libtorch_cuda.so) (604 samples, 2.36%)</title><rect x="8.3457%" y="516" width="2.3555%" height="15" fill="rgb(243,35,44)" fg:x="2140" fg:w="604"/><text x="8.5957%" y="526.50">a..</text></g><g><title>at::_ops::_native_multi_head_attention::call (libtorch_cpu.so) (610 samples, 2.38%)</title><rect x="8.3262%" y="468" width="2.3789%" height="15" fill="rgb(246,89,9)" fg:x="2135" fg:w="610"/><text x="8.5762%" y="478.50">at..</text></g><g><title>c10::impl::wrap_kernel_functor_unboxed_&lt;c10::impl::detail::WrapFunctionIntoFunctor_&lt;c10::CompileTimeFunctionPointer&lt;std::tuple&lt;at::Tensor, at::Tensor&gt; (at::Tensor const&amp;, at::Tensor const&amp;, at::Tensor const&amp;, long, long, at::Tensor const&amp;, at::Tensor const&amp;, at::Tensor const&amp;, at::Tensor const&amp;, std::optional&lt;at::Tensor&gt; const&amp;, bool, bool, std::optional&lt;long&gt;), &amp;at::(anonymous namespace)::(anonymous namespace)::wrapper_CUDA___native_multi_head_attention(at::Tensor const&amp;, at::Tensor const&amp;, at::Tensor const&amp;, long, long, at::Tensor const&amp;, at::Tensor const&amp;, at::Tensor const&amp;, at::Tensor const&amp;, std::optional&lt;at::Tensor&gt; const&amp;, bool, bool, std::optional&lt;long&gt;)&gt;, std::tuple&lt;at::Tensor, at::Tensor&gt;, c10::guts::typelist::typelist&lt;at::Tensor const&amp;, at::Tensor const&amp;, at::Tensor const&amp;, long, long, at::Tensor const&amp;, at::Tensor const&amp;, at::Tensor const&amp;, at::Tensor const&amp;, std::optional&lt;at::Tensor&gt; const&amp;, bool, bool, std::optional&lt;long&gt; &gt; &gt;, std::tuple&lt;at::Tensor, at::Tensor&gt; (at::Tensor const&amp;, at::Tensor const&amp;, at::Tensor const&amp;, long, long, at::Tensor const&amp;, at::Tensor const&amp;, at::Tensor const&amp;, at::Tensor const&amp;, std::optional&lt;at::Tensor&gt; const&amp;, bool, bool, std::optional&lt;long&gt;)&gt;::call (libtorch_cuda.so) (608 samples, 2.37%)</title><rect x="8.3340%" y="484" width="2.3711%" height="15" fill="rgb(233,213,13)" fg:x="2137" fg:w="608"/><text x="8.5840%" y="494.50">c1..</text></g><g><title>at::(anonymous namespace)::(anonymous namespace)::wrapper_CUDA___native_multi_head_attention (libtorch_cuda.so) (608 samples, 2.37%)</title><rect x="8.3340%" y="500" width="2.3711%" height="15" fill="rgb(233,141,41)" fg:x="2137" fg:w="608"/><text x="8.5840%" y="510.50">at..</text></g><g><title>at::native::gpu_kernel_impl_nocast&lt;at::native::CUDAFunctor_add&lt;float&gt; &gt; (libtorch_cuda.so) (26 samples, 0.10%)</title><rect x="10.7987%" y="532" width="0.1014%" height="15" fill="rgb(239,167,4)" fg:x="2769" fg:w="26"/><text x="11.0487%" y="542.50"></text></g><g><title>at::native::add_kernel (libtorch_cuda.so) (31 samples, 0.12%)</title><rect x="10.7831%" y="500" width="0.1209%" height="15" fill="rgb(209,217,16)" fg:x="2765" fg:w="31"/><text x="11.0331%" y="510.50"></text></g><g><title>at::native::add_kernel(at::TensorIteratorBase&amp;, c10::Scalar const&amp;)::{lambda()#1}::operator() const (libtorch_cuda.so) (29 samples, 0.11%)</title><rect x="10.7909%" y="516" width="0.1131%" height="15" fill="rgb(219,88,35)" fg:x="2767" fg:w="29"/><text x="11.0409%" y="526.50"></text></g><g><title>at::(anonymous namespace)::wrapper_CUDA_add__Tensor (libtorch_cuda.so) (55 samples, 0.21%)</title><rect x="10.7129%" y="484" width="0.2145%" height="15" fill="rgb(220,193,23)" fg:x="2747" fg:w="55"/><text x="10.9629%" y="494.50"></text></g><g><title>at::_ops::add__Tensor::call (libtorch_cpu.so) (59 samples, 0.23%)</title><rect x="10.7051%" y="468" width="0.2301%" height="15" fill="rgb(230,90,52)" fg:x="2745" fg:w="59"/><text x="10.9551%" y="478.50"></text></g><g><title>cublasLtMatmul (nvidia/cublas/lib/libcublasLt.so.12) (35 samples, 0.14%)</title><rect x="11.0795%" y="564" width="0.1365%" height="15" fill="rgb(252,106,19)" fg:x="2841" fg:w="35"/><text x="11.3295%" y="574.50"></text></g><g><title>0x7ac4e246b6ab (nvidia/cublas/lib/libcublasLt.so.12) (30 samples, 0.12%)</title><rect x="11.0990%" y="580" width="0.1170%" height="15" fill="rgb(206,74,20)" fg:x="2846" fg:w="30"/><text x="11.3490%" y="590.50"></text></g><g><title>at::cuda::blas::gemm_and_bias&lt;float, float&gt; (libtorch_cuda.so) (69 samples, 0.27%)</title><rect x="10.9898%" y="548" width="0.2691%" height="15" fill="rgb(230,138,44)" fg:x="2818" fg:w="69"/><text x="11.2398%" y="558.50"></text></g><g><title>at::_ops::_addmm_activation::call (libtorch_cpu.so) (82 samples, 0.32%)</title><rect x="10.9430%" y="484" width="0.3198%" height="15" fill="rgb(235,182,43)" fg:x="2806" fg:w="82"/><text x="11.1930%" y="494.50"></text></g><g><title>c10::impl::wrap_kernel_functor_unboxed_&lt;c10::impl::detail::WrapFunctionIntoFunctor_&lt;c10::CompileTimeFunctionPointer&lt;at::Tensor(at::Tensor const&amp;, at::Tensor const&amp;, at::Tensor const&amp;, c10::Scalar const&amp;, c10::Scalar const&amp;, bool), &amp;at::(anonymous namespace)::wrapper_CUDA__addmm_activation(at::Tensor const&amp;, at::Tensor const&amp;, at::Tensor const&amp;, c10::Scalar const&amp;, c10::Scalar const&amp;, bool)&gt;, at::Tensor, c10::guts::typelist::typelist&lt;at::Tensor const&amp;, at::Tensor const&amp;, at::Tensor const&amp;, c10::Scalar const&amp;, c10::Scalar const&amp;, bool&gt; &gt;, at::Tensor(at::Tensor const&amp;, at::Tensor const&amp;, at::Tensor const&amp;, c10::Scalar const&amp;, c10::Scalar const&amp;, bool)&gt;::call (libtorch_cuda.so) (80 samples, 0.31%)</title><rect x="10.9508%" y="500" width="0.3120%" height="15" fill="rgb(242,16,51)" fg:x="2808" fg:w="80"/><text x="11.2008%" y="510.50"></text></g><g><title>at::(anonymous namespace)::wrapper_CUDA__addmm_activation (libtorch_cuda.so) (80 samples, 0.31%)</title><rect x="10.9508%" y="516" width="0.3120%" height="15" fill="rgb(248,9,4)" fg:x="2808" fg:w="80"/><text x="11.2008%" y="526.50"></text></g><g><title>at::native::(anonymous namespace)::addmm_out_cuda_impl (libtorch_cuda.so) (72 samples, 0.28%)</title><rect x="10.9820%" y="532" width="0.2808%" height="15" fill="rgb(210,31,22)" fg:x="2816" fg:w="72"/><text x="11.2320%" y="542.50"></text></g><g><title>at::native::structured_addmm_out_cuda::impl (libtorch_cuda.so) (41 samples, 0.16%)</title><rect x="11.3135%" y="532" width="0.1599%" height="15" fill="rgb(239,54,39)" fg:x="2901" fg:w="41"/><text x="11.5635%" y="542.50"></text></g><g><title>at::native::(anonymous namespace)::addmm_out_cuda_impl (libtorch_cuda.so) (41 samples, 0.16%)</title><rect x="11.3135%" y="548" width="0.1599%" height="15" fill="rgb(230,99,41)" fg:x="2901" fg:w="41"/><text x="11.5635%" y="558.50"></text></g><g><title>at::cuda::blas::gemm_and_bias&lt;float, float&gt; (libtorch_cuda.so) (40 samples, 0.16%)</title><rect x="11.3174%" y="564" width="0.1560%" height="15" fill="rgb(253,106,12)" fg:x="2902" fg:w="40"/><text x="11.5674%" y="574.50"></text></g><g><title>at::_ops::addmm::call (libtorch_cpu.so) (57 samples, 0.22%)</title><rect x="11.2628%" y="484" width="0.2223%" height="15" fill="rgb(213,46,41)" fg:x="2888" fg:w="57"/><text x="11.5128%" y="494.50"></text></g><g><title>c10::impl::wrap_kernel_functor_unboxed_&lt;c10::impl::detail::WrapFunctionIntoFunctor_&lt;c10::CompileTimeFunctionPointer&lt;at::Tensor(at::Tensor const&amp;, at::Tensor const&amp;, at::Tensor const&amp;, c10::Scalar const&amp;, c10::Scalar const&amp;), &amp;at::(anonymous namespace)::wrapper_CUDA_addmm(at::Tensor const&amp;, at::Tensor const&amp;, at::Tensor const&amp;, c10::Scalar const&amp;, c10::Scalar const&amp;)&gt;, at::Tensor, c10::guts::typelist::typelist&lt;at::Tensor const&amp;, at::Tensor const&amp;, at::Tensor const&amp;, c10::Scalar const&amp;, c10::Scalar const&amp;&gt; &gt;, at::Tensor(at::Tensor const&amp;, at::Tensor const&amp;, at::Tensor const&amp;, c10::Scalar const&amp;, c10::Scalar const&amp;)&gt;::call (libtorch_cuda.so) (56 samples, 0.22%)</title><rect x="11.2667%" y="500" width="0.2184%" height="15" fill="rgb(215,133,35)" fg:x="2889" fg:w="56"/><text x="11.5167%" y="510.50"></text></g><g><title>at::(anonymous namespace)::wrapper_CUDA_addmm (libtorch_cuda.so) (56 samples, 0.22%)</title><rect x="11.2667%" y="516" width="0.2184%" height="15" fill="rgb(213,28,5)" fg:x="2889" fg:w="56"/><text x="11.5167%" y="526.50"></text></g><g><title>at::native::(anonymous namespace)::linear_for_ffn (libtorch_cpu.so) (160 samples, 0.62%)</title><rect x="10.9352%" y="468" width="0.6240%" height="15" fill="rgb(215,77,49)" fg:x="2804" fg:w="160"/><text x="11.1852%" y="478.50"></text></g><g><title>0x7ac4dff2b605 (libcuda.so.550.54.15) (37 samples, 0.14%)</title><rect x="11.7464%" y="692" width="0.1443%" height="15" fill="rgb(248,100,22)" fg:x="3012" fg:w="37"/><text x="11.9964%" y="702.50"></text></g><g><title>0x7ac4e00ef270 (libcuda.so.550.54.15) (40 samples, 0.16%)</title><rect x="11.7386%" y="644" width="0.1560%" height="15" fill="rgb(208,67,9)" fg:x="3010" fg:w="40"/><text x="11.9886%" y="654.50"></text></g><g><title>0x7ac4dff32a6f (libcuda.so.550.54.15) (39 samples, 0.15%)</title><rect x="11.7425%" y="660" width="0.1521%" height="15" fill="rgb(219,133,21)" fg:x="3011" fg:w="39"/><text x="11.9925%" y="670.50"></text></g><g><title>0x7ac4dff2be78 (libcuda.so.550.54.15) (38 samples, 0.15%)</title><rect x="11.7464%" y="676" width="0.1482%" height="15" fill="rgb(246,46,29)" fg:x="3012" fg:w="38"/><text x="11.9964%" y="686.50"></text></g><g><title>0x7ac5be415aa8 (nvidia/cuda_runtime/lib/libcudart.so.12) (42 samples, 0.16%)</title><rect x="11.7386%" y="628" width="0.1638%" height="15" fill="rgb(246,185,52)" fg:x="3010" fg:w="42"/><text x="11.9886%" y="638.50"></text></g><g><title>at::native::(anonymous namespace)::LayerNormKernelImplInternal&lt;float, float&gt; (libtorch_cuda.so) (57 samples, 0.22%)</title><rect x="11.6840%" y="596" width="0.2223%" height="15" fill="rgb(252,136,11)" fg:x="2996" fg:w="57"/><text x="11.9340%" y="606.50"></text></g><g><title>cudaLaunchKernel (nvidia/cuda_runtime/lib/libcudart.so.12) (47 samples, 0.18%)</title><rect x="11.7230%" y="612" width="0.1833%" height="15" fill="rgb(219,138,53)" fg:x="3006" fg:w="47"/><text x="11.9730%" y="622.50"></text></g><g><title>at::_ops::empty_memory_format::redispatch (libtorch_cpu.so) (27 samples, 0.11%)</title><rect x="11.9257%" y="660" width="0.1053%" height="15" fill="rgb(211,51,23)" fg:x="3058" fg:w="27"/><text x="12.1757%" y="670.50"></text></g><g><title>c10::impl::wrap_kernel_functor_unboxed_&lt;c10::impl::detail::WrapFunctionIntoFunctor_&lt;c10::CompileTimeFunctionPointer&lt;at::Tensor(c10::ArrayRef&lt;c10::SymInt&gt;, std::optional&lt;c10::ScalarType&gt;, std::optional&lt;c10::Layout&gt;, std::optional&lt;c10::Device&gt;, std::optional&lt;bool&gt;, std::optional&lt;c10::MemoryFormat&gt;), &amp;at::(anonymous namespace)::(anonymous namespace)::wrapper_CUDA_memory_format_empty(c10::ArrayRef&lt;c10::SymInt&gt;, std::optional&lt;c10::ScalarType&gt;, std::optional&lt;c10::Layout&gt;, std::optional&lt;c10::Device&gt;, std::optional&lt;bool&gt;, std::optional&lt;c10::MemoryFormat&gt;)&gt;, at::Tensor, c10::guts::typelist::typelist&lt;c10::ArrayRef&lt;c10::SymInt&gt;, std::optional&lt;c10::ScalarType&gt;, std::optional&lt;c10::Layout&gt;, std::optional&lt;c10::Device&gt;, std::optional&lt;bool&gt;, std::optional&lt;c10::MemoryFormat&gt; &gt; &gt;, at::Tensor(c10::ArrayRef&lt;c10::SymInt&gt;, std::optional&lt;c10::ScalarType&gt;, std::optional&lt;c10::Layout&gt;, std::optional&lt;c10::Device&gt;, std::optional&lt;bool&gt;, std::optional&lt;c10::MemoryFormat&gt;)&gt;::call (libtorch_cuda.so) (26 samples, 0.10%)</title><rect x="11.9296%" y="676" width="0.1014%" height="15" fill="rgb(247,221,28)" fg:x="3059" fg:w="26"/><text x="12.1796%" y="686.50"></text></g><g><title>at::(anonymous namespace)::(anonymous namespace)::wrapper_CUDA_memory_format_empty (libtorch_cuda.so) (26 samples, 0.10%)</title><rect x="11.9296%" y="692" width="0.1014%" height="15" fill="rgb(251,222,45)" fg:x="3059" fg:w="26"/><text x="12.1796%" y="702.50"></text></g><g><title>at::empty_symint (libtorch_cpu.so) (34 samples, 0.13%)</title><rect x="11.9062%" y="612" width="0.1326%" height="15" fill="rgb(217,162,53)" fg:x="3053" fg:w="34"/><text x="12.1562%" y="622.50"></text></g><g><title>at::_ops::empty_memory_format::call (libtorch_cpu.so) (32 samples, 0.12%)</title><rect x="11.9140%" y="628" width="0.1248%" height="15" fill="rgb(229,93,14)" fg:x="3055" fg:w="32"/><text x="12.1640%" y="638.50"></text></g><g><title>c10::impl::wrap_kernel_functor_unboxed_&lt;c10::impl::detail::WrapFunctionIntoFunctor_&lt;c10::CompileTimeFunctionPointer&lt;at::Tensor(c10::ArrayRef&lt;c10::SymInt&gt;, std::optional&lt;c10::ScalarType&gt;, std::optional&lt;c10::Layout&gt;, std::optional&lt;c10::Device&gt;, std::optional&lt;bool&gt;, std::optional&lt;c10::MemoryFormat&gt;), &amp;at::(anonymous namespace)::empty_memory_format(c10::ArrayRef&lt;c10::SymInt&gt;, std::optional&lt;c10::ScalarType&gt;, std::optional&lt;c10::Layout&gt;, std::optional&lt;c10::Device&gt;, std::optional&lt;bool&gt;, std::optional&lt;c10::MemoryFormat&gt;)&gt;, at::Tensor, c10::guts::typelist::typelist&lt;c10::ArrayRef&lt;c10::SymInt&gt;, std::optional&lt;c10::ScalarType&gt;, std::optional&lt;c10::Layout&gt;, std::optional&lt;c10::Device&gt;, std::optional&lt;bool&gt;, std::optional&lt;c10::MemoryFormat&gt; &gt; &gt;, at::Tensor(c10::ArrayRef&lt;c10::SymInt&gt;, std::optional&lt;c10::ScalarType&gt;, std::optional&lt;c10::Layout&gt;, std::optional&lt;c10::Device&gt;, std::optional&lt;bool&gt;, std::optional&lt;c10::MemoryFormat&gt;)&gt;::call (libtorch_cpu.so) (30 samples, 0.12%)</title><rect x="11.9218%" y="644" width="0.1170%" height="15" fill="rgb(209,67,49)" fg:x="3057" fg:w="30"/><text x="12.1718%" y="654.50"></text></g><g><title>at::native::empty_like (libtorch_cpu.so) (36 samples, 0.14%)</title><rect x="11.9062%" y="596" width="0.1404%" height="15" fill="rgb(213,87,29)" fg:x="3053" fg:w="36"/><text x="12.1562%" y="606.50"></text></g><g><title>at::native::layer_norm_cuda (libtorch_cuda.so) (124 samples, 0.48%)</title><rect x="11.5904%" y="580" width="0.4836%" height="15" fill="rgb(205,151,52)" fg:x="2972" fg:w="124"/><text x="11.8404%" y="590.50"></text></g><g><title>at::_ops::native_layer_norm::call (libtorch_cpu.so) (129 samples, 0.50%)</title><rect x="11.5865%" y="532" width="0.5031%" height="15" fill="rgb(253,215,39)" fg:x="2971" fg:w="129"/><text x="11.8365%" y="542.50"></text></g><g><title>c10::impl::wrap_kernel_functor_unboxed_&lt;c10::impl::detail::WrapFunctionIntoFunctor_&lt;c10::CompileTimeFunctionPointer&lt;std::tuple&lt;at::Tensor, at::Tensor, at::Tensor&gt; (at::Tensor const&amp;, c10::ArrayRef&lt;c10::SymInt&gt;, std::optional&lt;at::Tensor&gt; const&amp;, std::optional&lt;at::Tensor&gt; const&amp;, double), &amp;at::(anonymous namespace)::(anonymous namespace)::wrapper_CUDA__native_layer_norm(at::Tensor const&amp;, c10::ArrayRef&lt;c10::SymInt&gt;, std::optional&lt;at::Tensor&gt; const&amp;, std::optional&lt;at::Tensor&gt; const&amp;, double)&gt;, std::tuple&lt;at::Tensor, at::Tensor, at::Tensor&gt;, c10::guts::typelist::typelist&lt;at::Tensor const&amp;, c10::ArrayRef&lt;c10::SymInt&gt;, std::optional&lt;at::Tensor&gt; const&amp;, std::optional&lt;at::Tensor&gt; const&amp;, double&gt; &gt;, std::tuple&lt;at::Tensor, at::Tensor, at::Tensor&gt; (at::Tensor const&amp;, c10::ArrayRef&lt;c10::SymInt&gt;, std::optional&lt;at::Tensor&gt; const&amp;, std::optional&lt;at::Tensor&gt; const&amp;, double)&gt;::call (libtorch_cuda.so) (128 samples, 0.50%)</title><rect x="11.5904%" y="548" width="0.4992%" height="15" fill="rgb(221,220,41)" fg:x="2972" fg:w="128"/><text x="11.8404%" y="558.50"></text></g><g><title>at::(anonymous namespace)::(anonymous namespace)::wrapper_CUDA__native_layer_norm (libtorch_cuda.so) (128 samples, 0.50%)</title><rect x="11.5904%" y="564" width="0.4992%" height="15" fill="rgb(218,133,21)" fg:x="2972" fg:w="128"/><text x="11.8404%" y="574.50"></text></g><g><title>at::native::(anonymous namespace)::norm (libtorch_cpu.so) (146 samples, 0.57%)</title><rect x="11.5592%" y="468" width="0.5694%" height="15" fill="rgb(221,193,43)" fg:x="2964" fg:w="146"/><text x="11.8092%" y="478.50"></text></g><g><title>at::_ops::layer_norm::call (libtorch_cpu.so) (145 samples, 0.57%)</title><rect x="11.5631%" y="484" width="0.5655%" height="15" fill="rgb(240,128,52)" fg:x="2965" fg:w="145"/><text x="11.8131%" y="494.50"></text></g><g><title>c10::impl::wrap_kernel_functor_unboxed_&lt;c10::impl::detail::WrapFunctionIntoFunctor_&lt;c10::CompileTimeFunctionPointer&lt;at::Tensor(at::Tensor const&amp;, c10::ArrayRef&lt;c10::SymInt&gt;, std::optional&lt;at::Tensor&gt; const&amp;, std::optional&lt;at::Tensor&gt; const&amp;, double, bool), &amp;at::(anonymous namespace)::(anonymous namespace)::wrapper_CompositeImplicitAutograd__layer_norm(at::Tensor const&amp;, c10::ArrayRef&lt;c10::SymInt&gt;, std::optional&lt;at::Tensor&gt; const&amp;, std::optional&lt;at::Tensor&gt; const&amp;, double, bool)&gt;, at::Tensor, c10::guts::typelist::typelist&lt;at::Tensor const&amp;, c10::ArrayRef&lt;c10::SymInt&gt;, std::optional&lt;at::Tensor&gt; const&amp;, std::optional&lt;at::Tensor&gt; const&amp;, double, bool&gt; &gt;, at::Tensor(at::Tensor const&amp;, c10::ArrayRef&lt;c10::SymInt&gt;, std::optional&lt;at::Tensor&gt; const&amp;, std::optional&lt;at::Tensor&gt; const&amp;, double, bool)&gt;::call (libtorch_cpu.so) (142 samples, 0.55%)</title><rect x="11.5748%" y="500" width="0.5538%" height="15" fill="rgb(253,114,12)" fg:x="2968" fg:w="142"/><text x="11.8248%" y="510.50"></text></g><g><title>at::native::layer_norm_symint (libtorch_cpu.so) (141 samples, 0.55%)</title><rect x="11.5787%" y="516" width="0.5499%" height="15" fill="rgb(215,223,47)" fg:x="2969" fg:w="141"/><text x="11.8287%" y="526.50"></text></g><g><title>at::native::transformer_encoder_layer_forward (libtorch_cpu.so) (990 samples, 3.86%)</title><rect x="8.3145%" y="452" width="3.8609%" height="15" fill="rgb(248,225,23)" fg:x="2132" fg:w="990"/><text x="8.5645%" y="462.50">at::..</text></g><g><title>at::(anonymous namespace)::(anonymous namespace)::wrapper_CUDA___transformer_encoder_layer_fwd (libtorch_cuda.so) (997 samples, 3.89%)</title><rect x="8.3106%" y="436" width="3.8882%" height="15" fill="rgb(250,108,0)" fg:x="2131" fg:w="997"/><text x="8.5606%" y="446.50">at::..</text></g><g><title>c10::impl::make_boxed_from_unboxed_functor&lt;c10::impl::detail::WrapFunctionIntoFunctor_&lt;c10::CompileTimeFunctionPointer&lt;at::Tensor(at::Tensor const&amp;, long, long, at::Tensor const&amp;, at::Tensor const&amp;, at::Tensor const&amp;, at::Tensor const&amp;, bool, bool, double, at::Tensor const&amp;, at::Tensor const&amp;, at::Tensor const&amp;, at::Tensor const&amp;, at::Tensor const&amp;, at::Tensor const&amp;, at::Tensor const&amp;, at::Tensor const&amp;, std::optional&lt;at::Tensor&gt; const&amp;, std::optional&lt;long&gt;), &amp;at::(anonymous namespace)::(anonymous namespace)::wrapper_CUDA___transformer_encoder_layer_fwd(at::Tensor const&amp;, long, long, at::Tensor const&amp;, at::Tensor const&amp;, at::Tensor const&amp;, at::Tensor const&amp;, bool, bool, double, at::Tensor const&amp;, at::Tensor const&amp;, at::Tensor const&amp;, at::Tensor const&amp;, at::Tensor const&amp;, at::Tensor const&amp;, at::Tensor const&amp;, at::Tensor const&amp;, std::optional&lt;at::Tensor&gt; const&amp;, std::optional&lt;long&gt;)&gt;, at::Tensor, c10::guts::typelist::typelist&lt;at::Tensor const&amp;, long, long, at::Tensor const&amp;, at::Tensor const&amp;, at::Tensor const&amp;, at::Tensor const&amp;, bool, bool, double, at::Tensor const&amp;, at::Tensor const&amp;, at::Tensor const&amp;, at::Tensor const&amp;, at::Tensor const&amp;, at::Tensor const&amp;, at::Tensor const&amp;, at::Tensor const&amp;, std::optional&lt;at::Tensor&gt; const&amp;, std::optional&lt;long&gt; &gt; &gt;, false&gt;::call (libtorch_cuda.so) (1,006 samples, 3.92%)</title><rect x="8.3106%" y="420" width="3.9233%" height="15" fill="rgb(228,208,7)" fg:x="2131" fg:w="1006"/><text x="8.5606%" y="430.50">c10:..</text></g><g><title>at::_ops::_transformer_encoder_layer_fwd::call (libtorch_cpu.so) (1,025 samples, 4.00%)</title><rect x="8.2794%" y="372" width="3.9973%" height="15" fill="rgb(244,45,10)" fg:x="2123" fg:w="1025"/><text x="8.5294%" y="382.50">at::..</text></g><g><title>c10::impl::BoxedKernelWrapper&lt;at::Tensor(at::Tensor const&amp;, long, long, at::Tensor const&amp;, at::Tensor const&amp;, at::Tensor const&amp;, at::Tensor const&amp;, bool, bool, double, at::Tensor const&amp;, at::Tensor const&amp;, at::Tensor const&amp;, at::Tensor const&amp;, at::Tensor const&amp;, at::Tensor const&amp;, at::Tensor const&amp;, at::Tensor const&amp;, std::optional&lt;at::Tensor&gt; const&amp;, std::optional&lt;long&gt;), void&gt;::call (libtorch_cpu.so) (1,025 samples, 4.00%)</title><rect x="8.2794%" y="388" width="3.9973%" height="15" fill="rgb(207,125,25)" fg:x="2123" fg:w="1025"/><text x="8.5294%" y="398.50">c10:..</text></g><g><title>torch::autograd::autogradNotImplementedFallbackImpl (libtorch_cpu.so) (1,025 samples, 4.00%)</title><rect x="8.2794%" y="404" width="3.9973%" height="15" fill="rgb(210,195,18)" fg:x="2123" fg:w="1025"/><text x="8.5294%" y="414.50">torc..</text></g><g><title>forward (torch/nn/modules/transformer.py:524) (1,327 samples, 5.18%)</title><rect x="7.1757%" y="292" width="5.1751%" height="15" fill="rgb(249,80,12)" fg:x="1840" fg:w="1327"/><text x="7.4257%" y="302.50">forwar..</text></g><g><title>_wrapped_call_impl (torch/nn/modules/module.py:1773) (1,315 samples, 5.13%)</title><rect x="7.2225%" y="308" width="5.1283%" height="15" fill="rgb(221,65,9)" fg:x="1852" fg:w="1315"/><text x="7.4725%" y="318.50">_wrapp..</text></g><g><title>_call_impl (torch/nn/modules/module.py:1784) (1,302 samples, 5.08%)</title><rect x="7.2732%" y="324" width="5.0776%" height="15" fill="rgb(235,49,36)" fg:x="1865" fg:w="1302"/><text x="7.5232%" y="334.50">_call_..</text></g><g><title>forward (torch/nn/modules/transformer.py:922) (1,056 samples, 4.12%)</title><rect x="8.2326%" y="340" width="4.1182%" height="15" fill="rgb(225,32,20)" fg:x="2111" fg:w="1056"/><text x="8.4826%" y="350.50">forw..</text></g><g><title>torch::autograd::THPVariable__transformer_encoder_layer_fwd (libtorch_python.so) (1,048 samples, 4.09%)</title><rect x="8.2638%" y="356" width="4.0870%" height="15" fill="rgb(215,141,46)" fg:x="2119" fg:w="1048"/><text x="8.5138%" y="366.50">torc..</text></g><g><title>forward (armada_net.py:156) (1,359 samples, 5.30%)</title><rect x="7.0587%" y="244" width="5.2999%" height="15" fill="rgb(250,160,47)" fg:x="1810" fg:w="1359"/><text x="7.3087%" y="254.50">forwar..</text></g><g><title>_wrapped_call_impl (torch/nn/modules/module.py:1773) (1,354 samples, 5.28%)</title><rect x="7.0782%" y="260" width="5.2804%" height="15" fill="rgb(216,222,40)" fg:x="1815" fg:w="1354"/><text x="7.3282%" y="270.50">_wrapp..</text></g><g><title>_call_impl (torch/nn/modules/module.py:1784) (1,352 samples, 5.27%)</title><rect x="7.0860%" y="276" width="5.2726%" height="15" fill="rgb(234,217,39)" fg:x="1817" fg:w="1352"/><text x="7.3360%" y="286.50">_call_..</text></g><g><title>forward (armada_net.py:158) (29 samples, 0.11%)</title><rect x="12.3586%" y="244" width="0.1131%" height="15" fill="rgb(207,178,40)" fg:x="3169" fg:w="29"/><text x="12.6086%" y="254.50"></text></g><g><title>torch::autograd::THPVariable_mean (libtorch_python.so) (26 samples, 0.10%)</title><rect x="12.3703%" y="260" width="0.1014%" height="15" fill="rgb(221,136,13)" fg:x="3172" fg:w="26"/><text x="12.6203%" y="270.50"></text></g><g><title>at::_ops::addmm::call (libtorch_cpu.so) (30 samples, 0.12%)</title><rect x="12.5848%" y="372" width="0.1170%" height="15" fill="rgb(249,199,10)" fg:x="3227" fg:w="30"/><text x="12.8348%" y="382.50"></text></g><g><title>c10::impl::wrap_kernel_functor_unboxed_&lt;c10::impl::detail::WrapFunctionIntoFunctor_&lt;c10::CompileTimeFunctionPointer&lt;at::Tensor(c10::DispatchKeySet, at::Tensor const&amp;, at::Tensor const&amp;, at::Tensor const&amp;, c10::Scalar const&amp;, c10::Scalar const&amp;), &amp;torch::autograd::VariableType::(anonymous namespace)::addmm(c10::DispatchKeySet, at::Tensor const&amp;, at::Tensor const&amp;, at::Tensor const&amp;, c10::Scalar const&amp;, c10::Scalar const&amp;)&gt;, at::Tensor, c10::guts::typelist::typelist&lt;c10::DispatchKeySet, at::Tensor const&amp;, at::Tensor const&amp;, at::Tensor const&amp;, c10::Scalar const&amp;, c10::Scalar const&amp;&gt; &gt;, at::Tensor(c10::DispatchKeySet, at::Tensor const&amp;, at::Tensor const&amp;, at::Tensor const&amp;, c10::Scalar const&amp;, c10::Scalar const&amp;)&gt;::call (libtorch_cpu.so) (30 samples, 0.12%)</title><rect x="12.5848%" y="388" width="0.1170%" height="15" fill="rgb(249,222,13)" fg:x="3227" fg:w="30"/><text x="12.8348%" y="398.50"></text></g><g><title>torch::autograd::VariableType::(anonymous namespace)::addmm (libtorch_cpu.so) (30 samples, 0.12%)</title><rect x="12.5848%" y="404" width="0.1170%" height="15" fill="rgb(244,185,38)" fg:x="3227" fg:w="30"/><text x="12.8348%" y="414.50"></text></g><g><title>at::_ops::addmm::redispatch (libtorch_cpu.so) (30 samples, 0.12%)</title><rect x="12.5848%" y="420" width="0.1170%" height="15" fill="rgb(236,202,9)" fg:x="3227" fg:w="30"/><text x="12.8348%" y="430.50"></text></g><g><title>c10::impl::wrap_kernel_functor_unboxed_&lt;c10::impl::detail::WrapFunctionIntoFunctor_&lt;c10::CompileTimeFunctionPointer&lt;at::Tensor(at::Tensor const&amp;, at::Tensor const&amp;, at::Tensor const&amp;, c10::Scalar const&amp;, c10::Scalar const&amp;), &amp;at::(anonymous namespace)::wrapper_CUDA_addmm(at::Tensor const&amp;, at::Tensor const&amp;, at::Tensor const&amp;, c10::Scalar const&amp;, c10::Scalar const&amp;)&gt;, at::Tensor, c10::guts::typelist::typelist&lt;at::Tensor const&amp;, at::Tensor const&amp;, at::Tensor const&amp;, c10::Scalar const&amp;, c10::Scalar const&amp;&gt; &gt;, at::Tensor(at::Tensor const&amp;, at::Tensor const&amp;, at::Tensor const&amp;, c10::Scalar const&amp;, c10::Scalar const&amp;)&gt;::call (libtorch_cuda.so) (30 samples, 0.12%)</title><rect x="12.5848%" y="436" width="0.1170%" height="15" fill="rgb(250,229,37)" fg:x="3227" fg:w="30"/><text x="12.8348%" y="446.50"></text></g><g><title>at::(anonymous namespace)::wrapper_CUDA_addmm (libtorch_cuda.so) (30 samples, 0.12%)</title><rect x="12.5848%" y="452" width="0.1170%" height="15" fill="rgb(206,174,23)" fg:x="3227" fg:w="30"/><text x="12.8348%" y="462.50"></text></g><g><title>at::_ops::linear::call (libtorch_cpu.so) (45 samples, 0.18%)</title><rect x="12.5731%" y="324" width="0.1755%" height="15" fill="rgb(211,33,43)" fg:x="3224" fg:w="45"/><text x="12.8231%" y="334.50"></text></g><g><title>c10::impl::wrap_kernel_functor_unboxed_&lt;c10::impl::detail::WrapFunctionIntoFunctor_&lt;c10::CompileTimeFunctionPointer&lt;at::Tensor(at::Tensor const&amp;, at::Tensor const&amp;, std::optional&lt;at::Tensor&gt; const&amp;), &amp;at::(anonymous namespace)::(anonymous namespace)::wrapper_CompositeImplicitAutograd__linear(at::Tensor const&amp;, at::Tensor const&amp;, std::optional&lt;at::Tensor&gt; const&amp;)&gt;, at::Tensor, c10::guts::typelist::typelist&lt;at::Tensor const&amp;, at::Tensor const&amp;, std::optional&lt;at::Tensor&gt; const&amp;&gt; &gt;, at::Tensor(at::Tensor const&amp;, at::Tensor const&amp;, std::optional&lt;at::Tensor&gt; const&amp;)&gt;::call (libtorch_cpu.so) (43 samples, 0.17%)</title><rect x="12.5809%" y="340" width="0.1677%" height="15" fill="rgb(245,58,50)" fg:x="3226" fg:w="43"/><text x="12.8309%" y="350.50"></text></g><g><title>at::native::linear (libtorch_cpu.so) (43 samples, 0.17%)</title><rect x="12.5809%" y="356" width="0.1677%" height="15" fill="rgb(244,68,36)" fg:x="3226" fg:w="43"/><text x="12.8309%" y="366.50"></text></g><g><title>forward (armada_net.py:159) (73 samples, 0.28%)</title><rect x="12.4717%" y="244" width="0.2847%" height="15" fill="rgb(232,229,15)" fg:x="3198" fg:w="73"/><text x="12.7217%" y="254.50"></text></g><g><title>_wrapped_call_impl (torch/nn/modules/module.py:1773) (65 samples, 0.25%)</title><rect x="12.5029%" y="260" width="0.2535%" height="15" fill="rgb(254,30,23)" fg:x="3206" fg:w="65"/><text x="12.7529%" y="270.50"></text></g><g><title>_call_impl (torch/nn/modules/module.py:1784) (57 samples, 0.22%)</title><rect x="12.5341%" y="276" width="0.2223%" height="15" fill="rgb(235,160,14)" fg:x="3214" fg:w="57"/><text x="12.7841%" y="286.50"></text></g><g><title>forward (torch/nn/modules/linear.py:125) (56 samples, 0.22%)</title><rect x="12.5380%" y="292" width="0.2184%" height="15" fill="rgb(212,155,44)" fg:x="3215" fg:w="56"/><text x="12.7880%" y="302.50"></text></g><g><title>torch::autograd::THPVariable_linear (libtorch_python.so) (50 samples, 0.19%)</title><rect x="12.5614%" y="308" width="0.1950%" height="15" fill="rgb(226,2,50)" fg:x="3221" fg:w="50"/><text x="12.8114%" y="318.50"></text></g><g><title>named_modules (torch/nn/modules/module.py:2863) (32 samples, 0.12%)</title><rect x="13.3258%" y="388" width="0.1248%" height="15" fill="rgb(234,177,6)" fg:x="3417" fg:w="32"/><text x="13.5758%" y="398.50"></text></g><g><title>forward (torch/nn/modules/transformer.py:853) (75 samples, 0.29%)</title><rect x="13.1659%" y="340" width="0.2925%" height="15" fill="rgb(217,24,9)" fg:x="3376" fg:w="75"/><text x="13.4159%" y="350.50"></text></g><g><title>&lt;genexpr&gt; (torch/nn/modules/transformer.py:856) (59 samples, 0.23%)</title><rect x="13.2283%" y="356" width="0.2301%" height="15" fill="rgb(220,13,46)" fg:x="3392" fg:w="59"/><text x="13.4783%" y="366.50"></text></g><g><title>modules (torch/nn/modules/module.py:2815) (58 samples, 0.23%)</title><rect x="13.2322%" y="372" width="0.2262%" height="15" fill="rgb(239,221,27)" fg:x="3393" fg:w="58"/><text x="13.4822%" y="382.50"></text></g><g><title>forward (torch/nn/modules/transformer.py:885) (44 samples, 0.17%)</title><rect x="13.7080%" y="340" width="0.1716%" height="15" fill="rgb(222,198,25)" fg:x="3515" fg:w="44"/><text x="13.9580%" y="350.50"></text></g><g><title>&lt;genexpr&gt; (torch/nn/modules/transformer.py:886) (41 samples, 0.16%)</title><rect x="13.7197%" y="356" width="0.1599%" height="15" fill="rgb(211,99,13)" fg:x="3518" fg:w="41"/><text x="13.9697%" y="366.50"></text></g><g><title>at::_ops::chunk::call (libtorch_cpu.so) (28 samples, 0.11%)</title><rect x="14.2501%" y="532" width="0.1092%" height="15" fill="rgb(232,111,31)" fg:x="3654" fg:w="28"/><text x="14.5001%" y="542.50"></text></g><g><title>c10::impl::wrap_kernel_functor_unboxed_&lt;c10::impl::detail::WrapFunctionIntoFunctor_&lt;c10::CompileTimeFunctionPointer&lt;std::vector&lt;at::Tensor, std::allocator&lt;at::Tensor&gt; &gt; (at::Tensor const&amp;, long, long), &amp;at::(anonymous namespace)::(anonymous namespace)::wrapper_CompositeImplicitAutograd__chunk(at::Tensor const&amp;, long, long)&gt;, std::vector&lt;at::Tensor, std::allocator&lt;at::Tensor&gt; &gt;, c10::guts::typelist::typelist&lt;at::Tensor const&amp;, long, long&gt; &gt;, std::vector&lt;at::Tensor, std::allocator&lt;at::Tensor&gt; &gt; (at::Tensor const&amp;, long, long)&gt;::call (libtorch_cpu.so) (26 samples, 0.10%)</title><rect x="14.2579%" y="548" width="0.1014%" height="15" fill="rgb(245,82,37)" fg:x="3656" fg:w="26"/><text x="14.5079%" y="558.50"></text></g><g><title>at::native::chunk (libtorch_cpu.so) (26 samples, 0.10%)</title><rect x="14.2579%" y="564" width="0.1014%" height="15" fill="rgb(227,149,46)" fg:x="3656" fg:w="26"/><text x="14.5079%" y="574.50"></text></g><g><title>at::(anonymous namespace)::structured_addmm_out_cuda_functional::set_output_raw_strided (libtorch_cuda.so) (27 samples, 0.11%)</title><rect x="14.4139%" y="660" width="0.1053%" height="15" fill="rgb(218,36,50)" fg:x="3696" fg:w="27"/><text x="14.6639%" y="670.50"></text></g><g><title>at::meta::structured_addmm::meta (libtorch_cpu.so) (31 samples, 0.12%)</title><rect x="14.4061%" y="644" width="0.1209%" height="15" fill="rgb(226,80,48)" fg:x="3694" fg:w="31"/><text x="14.6561%" y="654.50"></text></g><g><title>0x7ac4dff2b605 (libcuda.so.550.54.15) (32 samples, 0.12%)</title><rect x="14.9091%" y="884" width="0.1248%" height="15" fill="rgb(238,224,15)" fg:x="3823" fg:w="32"/><text x="15.1591%" y="894.50"></text></g><g><title>0x7ac4dff2be78 (libcuda.so.550.54.15) (34 samples, 0.13%)</title><rect x="14.9091%" y="868" width="0.1326%" height="15" fill="rgb(241,136,10)" fg:x="3823" fg:w="34"/><text x="15.1591%" y="878.50"></text></g><g><title>0x7ac4e00ef270 (libcuda.so.550.54.15) (47 samples, 0.18%)</title><rect x="14.8662%" y="836" width="0.1833%" height="15" fill="rgb(208,32,45)" fg:x="3812" fg:w="47"/><text x="15.1162%" y="846.50"></text></g><g><title>0x7ac4dff32a6f (libcuda.so.550.54.15) (43 samples, 0.17%)</title><rect x="14.8818%" y="852" width="0.1677%" height="15" fill="rgb(207,135,9)" fg:x="3816" fg:w="43"/><text x="15.1318%" y="862.50"></text></g><g><title>0x7ac4e2b9a5ac (nvidia/cublas/lib/libcublasLt.so.12) (53 samples, 0.21%)</title><rect x="14.8467%" y="740" width="0.2067%" height="15" fill="rgb(206,86,44)" fg:x="3807" fg:w="53"/><text x="15.0967%" y="750.50"></text></g><g><title>0x7ac4e2b98fb7 (nvidia/cublas/lib/libcublasLt.so.12) (52 samples, 0.20%)</title><rect x="14.8506%" y="756" width="0.2028%" height="15" fill="rgb(245,177,15)" fg:x="3808" fg:w="52"/><text x="15.1006%" y="766.50"></text></g><g><title>0x7ac4e54731fd (nvidia/cublas/lib/libcublasLt.so.12) (51 samples, 0.20%)</title><rect x="14.8545%" y="772" width="0.1989%" height="15" fill="rgb(206,64,50)" fg:x="3809" fg:w="51"/><text x="15.1045%" y="782.50"></text></g><g><title>0x7ac4e54731dd (nvidia/cublas/lib/libcublasLt.so.12) (51 samples, 0.20%)</title><rect x="14.8545%" y="788" width="0.1989%" height="15" fill="rgb(234,36,40)" fg:x="3809" fg:w="51"/><text x="15.1045%" y="798.50"></text></g><g><title>0x7ac4e54fd49b (nvidia/cublas/lib/libcublasLt.so.12) (50 samples, 0.19%)</title><rect x="14.8584%" y="804" width="0.1950%" height="15" fill="rgb(213,64,8)" fg:x="3810" fg:w="50"/><text x="15.1084%" y="814.50"></text></g><g><title>0x7ac4e549a7ce (nvidia/cublas/lib/libcublasLt.so.12) (49 samples, 0.19%)</title><rect x="14.8623%" y="820" width="0.1911%" height="15" fill="rgb(210,75,36)" fg:x="3811" fg:w="49"/><text x="15.1123%" y="830.50"></text></g><g><title>cublasLtMatmul (nvidia/cublas/lib/libcublasLt.so.12) (88 samples, 0.34%)</title><rect x="14.7492%" y="692" width="0.3432%" height="15" fill="rgb(229,88,21)" fg:x="3782" fg:w="88"/><text x="14.9992%" y="702.50"></text></g><g><title>0x7ac4e246b6ab (nvidia/cublas/lib/libcublasLt.so.12) (82 samples, 0.32%)</title><rect x="14.7726%" y="708" width="0.3198%" height="15" fill="rgb(252,204,47)" fg:x="3788" fg:w="82"/><text x="15.0226%" y="718.50"></text></g><g><title>0x7ac4e2394df1 (nvidia/cublas/lib/libcublasLt.so.12) (68 samples, 0.27%)</title><rect x="14.8272%" y="724" width="0.2652%" height="15" fill="rgb(208,77,27)" fg:x="3802" fg:w="68"/><text x="15.0772%" y="734.50"></text></g><g><title>at::cuda::blas::gemm_and_bias&lt;float, float&gt; (libtorch_cuda.so) (156 samples, 0.61%)</title><rect x="14.5581%" y="676" width="0.6084%" height="15" fill="rgb(221,76,26)" fg:x="3733" fg:w="156"/><text x="14.8081%" y="686.50"></text></g><g><title>at::native::structured_addmm_out_cuda::impl (libtorch_cuda.so) (172 samples, 0.67%)</title><rect x="14.5269%" y="644" width="0.6708%" height="15" fill="rgb(225,139,18)" fg:x="3725" fg:w="172"/><text x="14.7769%" y="654.50"></text></g><g><title>at::native::(anonymous namespace)::addmm_out_cuda_impl (libtorch_cuda.so) (172 samples, 0.67%)</title><rect x="14.5269%" y="660" width="0.6708%" height="15" fill="rgb(230,137,11)" fg:x="3725" fg:w="172"/><text x="14.7769%" y="670.50"></text></g><g><title>at::_ops::addmm::call (libtorch_cpu.so) (212 samples, 0.83%)</title><rect x="14.3788%" y="596" width="0.8268%" height="15" fill="rgb(212,28,1)" fg:x="3687" fg:w="212"/><text x="14.6288%" y="606.50"></text></g><g><title>c10::impl::wrap_kernel_functor_unboxed_&lt;c10::impl::detail::WrapFunctionIntoFunctor_&lt;c10::CompileTimeFunctionPointer&lt;at::Tensor(at::Tensor const&amp;, at::Tensor const&amp;, at::Tensor const&amp;, c10::Scalar const&amp;, c10::Scalar const&amp;), &amp;at::(anonymous namespace)::wrapper_CUDA_addmm(at::Tensor const&amp;, at::Tensor const&amp;, at::Tensor const&amp;, c10::Scalar const&amp;, c10::Scalar const&amp;)&gt;, at::Tensor, c10::guts::typelist::typelist&lt;at::Tensor const&amp;, at::Tensor const&amp;, at::Tensor const&amp;, c10::Scalar const&amp;, c10::Scalar const&amp;&gt; &gt;, at::Tensor(at::Tensor const&amp;, at::Tensor const&amp;, at::Tensor const&amp;, c10::Scalar const&amp;, c10::Scalar const&amp;)&gt;::call (libtorch_cuda.so) (210 samples, 0.82%)</title><rect x="14.3866%" y="612" width="0.8190%" height="15" fill="rgb(248,164,17)" fg:x="3689" fg:w="210"/><text x="14.6366%" y="622.50"></text></g><g><title>at::(anonymous namespace)::wrapper_CUDA_addmm (libtorch_cuda.so) (209 samples, 0.82%)</title><rect x="14.3905%" y="628" width="0.8151%" height="15" fill="rgb(222,171,42)" fg:x="3690" fg:w="209"/><text x="14.6405%" y="638.50"></text></g><g><title>at::native::_flatten_nd_linear (libtorch_cpu.so) (246 samples, 0.96%)</title><rect x="14.3710%" y="580" width="0.9594%" height="15" fill="rgb(243,84,45)" fg:x="3685" fg:w="246"/><text x="14.6210%" y="590.50"></text></g><g><title>at::_ops::linear::call (libtorch_cpu.so) (251 samples, 0.98%)</title><rect x="14.3593%" y="532" width="0.9789%" height="15" fill="rgb(252,49,23)" fg:x="3682" fg:w="251"/><text x="14.6093%" y="542.50"></text></g><g><title>c10::impl::wrap_kernel_functor_unboxed_&lt;c10::impl::detail::WrapFunctionIntoFunctor_&lt;c10::CompileTimeFunctionPointer&lt;at::Tensor(at::Tensor const&amp;, at::Tensor const&amp;, std::optional&lt;at::Tensor&gt; const&amp;), &amp;at::(anonymous namespace)::(anonymous namespace)::wrapper_CompositeImplicitAutograd__linear(at::Tensor const&amp;, at::Tensor const&amp;, std::optional&lt;at::Tensor&gt; const&amp;)&gt;, at::Tensor, c10::guts::typelist::typelist&lt;at::Tensor const&amp;, at::Tensor const&amp;, std::optional&lt;at::Tensor&gt; const&amp;&gt; &gt;, at::Tensor(at::Tensor const&amp;, at::Tensor const&amp;, std::optional&lt;at::Tensor&gt; const&amp;)&gt;::call (libtorch_cpu.so) (249 samples, 0.97%)</title><rect x="14.3671%" y="548" width="0.9711%" height="15" fill="rgb(215,19,7)" fg:x="3684" fg:w="249"/><text x="14.6171%" y="558.50"></text></g><g><title>at::native::linear (libtorch_cpu.so) (249 samples, 0.97%)</title><rect x="14.3671%" y="564" width="0.9711%" height="15" fill="rgb(238,81,41)" fg:x="3684" fg:w="249"/><text x="14.6171%" y="574.50"></text></g><g><title>at::empty (libtorch_cuda.so) (28 samples, 0.11%)</title><rect x="15.4551%" y="724" width="0.1092%" height="15" fill="rgb(210,199,37)" fg:x="3963" fg:w="28"/><text x="15.7051%" y="734.50"></text></g><g><title>at::_ops::empty_memory_format::call (libtorch_cpu.so) (28 samples, 0.11%)</title><rect x="15.4551%" y="740" width="0.1092%" height="15" fill="rgb(244,192,49)" fg:x="3963" fg:w="28"/><text x="15.7051%" y="750.50"></text></g><g><title>c10::impl::wrap_kernel_functor_unboxed_&lt;c10::impl::detail::WrapFunctionIntoFunctor_&lt;c10::CompileTimeFunctionPointer&lt;at::Tensor(c10::ArrayRef&lt;c10::SymInt&gt;, std::optional&lt;c10::ScalarType&gt;, std::optional&lt;c10::Layout&gt;, std::optional&lt;c10::Device&gt;, std::optional&lt;bool&gt;, std::optional&lt;c10::MemoryFormat&gt;), &amp;at::(anonymous namespace)::empty_memory_format(c10::ArrayRef&lt;c10::SymInt&gt;, std::optional&lt;c10::ScalarType&gt;, std::optional&lt;c10::Layout&gt;, std::optional&lt;c10::Device&gt;, std::optional&lt;bool&gt;, std::optional&lt;c10::MemoryFormat&gt;)&gt;, at::Tensor, c10::guts::typelist::typelist&lt;c10::ArrayRef&lt;c10::SymInt&gt;, std::optional&lt;c10::ScalarType&gt;, std::optional&lt;c10::Layout&gt;, std::optional&lt;c10::Device&gt;, std::optional&lt;bool&gt;, std::optional&lt;c10::MemoryFormat&gt; &gt; &gt;, at::Tensor(c10::ArrayRef&lt;c10::SymInt&gt;, std::optional&lt;c10::ScalarType&gt;, std::optional&lt;c10::Layout&gt;, std::optional&lt;c10::Device&gt;, std::optional&lt;bool&gt;, std::optional&lt;c10::MemoryFormat&gt;)&gt;::call (libtorch_cpu.so) (27 samples, 0.11%)</title><rect x="15.4590%" y="756" width="0.1053%" height="15" fill="rgb(226,211,11)" fg:x="3964" fg:w="27"/><text x="15.7090%" y="766.50"></text></g><g><title>at::native::_efficient_attention_forward(at::Tensor const&amp;, at::Tensor const&amp;, at::Tensor const&amp;, std::optional&lt;at::Tensor&gt; const&amp;, std::optional&lt;at::Tensor&gt; const&amp;, std::optional&lt;at::Tensor&gt; const&amp;, std::optional&lt;long&gt;, std::optional&lt;long&gt;, double, long, bool, std::optional&lt;double&gt;, std::optional&lt;at::Tensor&gt; const&amp;, std::optional&lt;long&gt;)::{lambda(auto:1, auto:2)#1}::operator()&lt;PyTorchMemEffAttention::AttentionKernel&lt;float, cutlass::arch::Sm75, true, 64, 64, 64, true, true&gt;, void (*)(PyTorchMemEffAttention::AttentionKernel&lt;float, cutlass::arch::Sm75, true, 64, 64, 64, true, true&gt;::Params)&gt; const (libtorch_cuda.so) (54 samples, 0.21%)</title><rect x="15.5643%" y="724" width="0.2106%" height="15" fill="rgb(236,162,54)" fg:x="3991" fg:w="54"/><text x="15.8143%" y="734.50"></text></g><g><title>at::native::_efficient_attention_forward (libtorch_cuda.so) (96 samples, 0.37%)</title><rect x="15.4239%" y="708" width="0.3744%" height="15" fill="rgb(220,229,9)" fg:x="3955" fg:w="96"/><text x="15.6739%" y="718.50"></text></g><g><title>at::_ops::_efficient_attention_forward::call (libtorch_cpu.so) (104 samples, 0.41%)</title><rect x="15.4005%" y="660" width="0.4056%" height="15" fill="rgb(250,87,22)" fg:x="3949" fg:w="104"/><text x="15.6505%" y="670.50"></text></g><g><title>c10::impl::wrap_kernel_functor_unboxed_&lt;c10::impl::detail::WrapFunctionIntoFunctor_&lt;c10::CompileTimeFunctionPointer&lt;std::tuple&lt;at::Tensor, at::Tensor, at::Tensor, at::Tensor, c10::SymInt, c10::SymInt&gt; (at::Tensor const&amp;, at::Tensor const&amp;, at::Tensor const&amp;, std::optional&lt;at::Tensor&gt; const&amp;, std::optional&lt;at::Tensor&gt; const&amp;, std::optional&lt;at::Tensor&gt; const&amp;, std::optional&lt;c10::SymInt&gt;, std::optional&lt;c10::SymInt&gt;, double, long, bool, std::optional&lt;double&gt;, std::optional&lt;at::Tensor&gt; const&amp;, std::optional&lt;long&gt;), &amp;at::(anonymous namespace)::(anonymous namespace)::wrapper_CUDA___efficient_attention_forward(at::Tensor const&amp;, at::Tensor const&amp;, at::Tensor const&amp;, std::optional&lt;at::Tensor&gt; const&amp;, std::optional&lt;at::Tensor&gt; const&amp;, std::optional&lt;at::Tensor&gt; const&amp;, std::optional&lt;c10::SymInt&gt;, std::optional&lt;c10::SymInt&gt;, double, long, bool, std::optional&lt;double&gt;, std::optional&lt;at::Tensor&gt; const&amp;, std::optional&lt;long&gt;)&gt;, std::tuple&lt;at::Tensor, at::Tensor, at::Tensor, at::Tensor, c10::SymInt, c10::SymInt&gt;, c10::guts::typelist::typelist&lt;at::Tensor const&amp;, at::Tensor const&amp;, at::Tensor const&amp;, std::optional&lt;at::Tensor&gt; const&amp;, std::optional&lt;at::Tensor&gt; const&amp;, std::optional&lt;at::Tensor&gt; const&amp;, std::optional&lt;c10::SymInt&gt;, std::optional&lt;c10::SymInt&gt;, double, long, bool, std::optional&lt;double&gt;, std::optional&lt;at::Tensor&gt; const&amp;, std::optional&lt;long&gt; &gt; &gt;, std::tuple&lt;at::Tensor, at::Tensor, at::Tensor, at::Tensor, c10::SymInt, c10::SymInt&gt; (at::Tensor const&amp;, at::Tensor const&amp;, at::Tensor const&amp;, std::optional&lt;at::Tensor&gt; const&amp;, std::optional&lt;at::Tensor&gt; const&amp;, std::optional&lt;at::Tensor&gt; const&amp;, std::optional&lt;c10::SymInt&gt;, std::optional&lt;c10::SymInt&gt;, double, long, bool, std::optional&lt;double&gt;, std::optional&lt;at::Tensor&gt; const&amp;, std::optional&lt;long&gt;)&gt;::call (libtorch_cuda.so) (100 samples, 0.39%)</title><rect x="15.4161%" y="676" width="0.3900%" height="15" fill="rgb(239,43,17)" fg:x="3953" fg:w="100"/><text x="15.6661%" y="686.50"></text></g><g><title>at::(anonymous namespace)::(anonymous namespace)::wrapper_CUDA___efficient_attention_forward (libtorch_cuda.so) (100 samples, 0.39%)</title><rect x="15.4161%" y="692" width="0.3900%" height="15" fill="rgb(231,177,25)" fg:x="3953" fg:w="100"/><text x="15.6661%" y="702.50"></text></g><g><title>at::native::_scaled_dot_product_efficient_attention_cuda (libtorch_cuda.so) (120 samples, 0.47%)</title><rect x="15.3966%" y="628" width="0.4680%" height="15" fill="rgb(219,179,1)" fg:x="3948" fg:w="120"/><text x="15.6466%" y="638.50"></text></g><g><title>at::native::_scaled_dot_product_efficient_attention_cuda(at::Tensor const&amp;, at::Tensor const&amp;, at::Tensor const&amp;, std::optional&lt;at::Tensor&gt; const&amp;, bool, double, bool, std::optional&lt;double&gt;)::{lambda(at::Tensor const&amp;, at::Tensor const&amp;, at::Tensor const&amp;, std::optional&lt;at::Tensor&gt; const&amp;)#1}::operator() const (libtorch_cuda.so) (119 samples, 0.46%)</title><rect x="15.4005%" y="644" width="0.4641%" height="15" fill="rgb(238,219,53)" fg:x="3949" fg:w="119"/><text x="15.6505%" y="654.50"></text></g><g><title>at::_ops::_scaled_dot_product_efficient_attention::call (libtorch_cpu.so) (125 samples, 0.49%)</title><rect x="15.3849%" y="580" width="0.4875%" height="15" fill="rgb(232,167,36)" fg:x="3945" fg:w="125"/><text x="15.6349%" y="590.50"></text></g><g><title>c10::impl::wrap_kernel_functor_unboxed_&lt;c10::impl::detail::WrapFunctionIntoFunctor_&lt;c10::CompileTimeFunctionPointer&lt;std::tuple&lt;at::Tensor, at::Tensor, at::Tensor, at::Tensor&gt; (at::Tensor const&amp;, at::Tensor const&amp;, at::Tensor const&amp;, std::optional&lt;at::Tensor&gt; const&amp;, bool, double, bool, std::optional&lt;double&gt;), &amp;at::(anonymous namespace)::(anonymous namespace)::wrapper_CUDA___scaled_dot_product_efficient_attention(at::Tensor const&amp;, at::Tensor const&amp;, at::Tensor const&amp;, std::optional&lt;at::Tensor&gt; const&amp;, bool, double, bool, std::optional&lt;double&gt;)&gt;, std::tuple&lt;at::Tensor, at::Tensor, at::Tensor, at::Tensor&gt;, c10::guts::typelist::typelist&lt;at::Tensor const&amp;, at::Tensor const&amp;, at::Tensor const&amp;, std::optional&lt;at::Tensor&gt; const&amp;, bool, double, bool, std::optional&lt;double&gt; &gt; &gt;, std::tuple&lt;at::Tensor, at::Tensor, at::Tensor, at::Tensor&gt; (at::Tensor const&amp;, at::Tensor const&amp;, at::Tensor const&amp;, std::optional&lt;at::Tensor&gt; const&amp;, bool, double, bool, std::optional&lt;double&gt;)&gt;::call (libtorch_cuda.so) (125 samples, 0.49%)</title><rect x="15.3849%" y="596" width="0.4875%" height="15" fill="rgb(244,19,51)" fg:x="3945" fg:w="125"/><text x="15.6349%" y="606.50"></text></g><g><title>at::(anonymous namespace)::(anonymous namespace)::wrapper_CUDA___scaled_dot_product_efficient_attention (libtorch_cuda.so) (125 samples, 0.49%)</title><rect x="15.3849%" y="612" width="0.4875%" height="15" fill="rgb(224,6,22)" fg:x="3945" fg:w="125"/><text x="15.6349%" y="622.50"></text></g><g><title>at::_ops::scaled_dot_product_attention::call (libtorch_cpu.so) (148 samples, 0.58%)</title><rect x="15.3615%" y="532" width="0.5772%" height="15" fill="rgb(224,145,5)" fg:x="3939" fg:w="148"/><text x="15.6115%" y="542.50"></text></g><g><title>c10::impl::wrap_kernel_functor_unboxed_&lt;c10::impl::detail::WrapFunctionIntoFunctor_&lt;c10::CompileTimeFunctionPointer&lt;at::Tensor(at::Tensor const&amp;, at::Tensor const&amp;, at::Tensor const&amp;, std::optional&lt;at::Tensor&gt; const&amp;, double, bool, std::optional&lt;double&gt;, bool), &amp;at::(anonymous namespace)::(anonymous namespace)::wrapper_CompositeImplicitAutograd__scaled_dot_product_attention(at::Tensor const&amp;, at::Tensor const&amp;, at::Tensor const&amp;, std::optional&lt;at::Tensor&gt; const&amp;, double, bool, std::optional&lt;double&gt;, bool)&gt;, at::Tensor, c10::guts::typelist::typelist&lt;at::Tensor const&amp;, at::Tensor const&amp;, at::Tensor const&amp;, std::optional&lt;at::Tensor&gt; const&amp;, double, bool, std::optional&lt;double&gt;, bool&gt; &gt;, at::Tensor(at::Tensor const&amp;, at::Tensor const&amp;, at::Tensor const&amp;, std::optional&lt;at::Tensor&gt; const&amp;, double, bool, std::optional&lt;double&gt;, bool)&gt;::call (libtorch_cpu.so) (146 samples, 0.57%)</title><rect x="15.3693%" y="548" width="0.5694%" height="15" fill="rgb(234,130,49)" fg:x="3941" fg:w="146"/><text x="15.6193%" y="558.50"></text></g><g><title>at::native::scaled_dot_product_attention (libtorch_cpu.so) (146 samples, 0.57%)</title><rect x="15.3693%" y="564" width="0.5694%" height="15" fill="rgb(254,6,2)" fg:x="3941" fg:w="146"/><text x="15.6193%" y="574.50"></text></g><g><title>at::_ops::transpose_int::call (libtorch_cpu.so) (26 samples, 0.10%)</title><rect x="15.9387%" y="532" width="0.1014%" height="15" fill="rgb(208,96,46)" fg:x="4087" fg:w="26"/><text x="16.1887%" y="542.50"></text></g><g><title>at::native::native_multi_head_attention_cuda (libtorch_cuda.so) (503 samples, 1.96%)</title><rect x="14.2384%" y="516" width="1.9616%" height="15" fill="rgb(239,3,39)" fg:x="3651" fg:w="503"/><text x="14.4884%" y="526.50">a..</text></g><g><title>at::_ops::_native_multi_head_attention::call (libtorch_cpu.so) (504 samples, 1.97%)</title><rect x="14.2384%" y="468" width="1.9655%" height="15" fill="rgb(233,210,1)" fg:x="3651" fg:w="504"/><text x="14.4884%" y="478.50">a..</text></g><g><title>c10::impl::wrap_kernel_functor_unboxed_&lt;c10::impl::detail::WrapFunctionIntoFunctor_&lt;c10::CompileTimeFunctionPointer&lt;std::tuple&lt;at::Tensor, at::Tensor&gt; (at::Tensor const&amp;, at::Tensor const&amp;, at::Tensor const&amp;, long, long, at::Tensor const&amp;, at::Tensor const&amp;, at::Tensor const&amp;, at::Tensor const&amp;, std::optional&lt;at::Tensor&gt; const&amp;, bool, bool, std::optional&lt;long&gt;), &amp;at::(anonymous namespace)::(anonymous namespace)::wrapper_CUDA___native_multi_head_attention(at::Tensor const&amp;, at::Tensor const&amp;, at::Tensor const&amp;, long, long, at::Tensor const&amp;, at::Tensor const&amp;, at::Tensor const&amp;, at::Tensor const&amp;, std::optional&lt;at::Tensor&gt; const&amp;, bool, bool, std::optional&lt;long&gt;)&gt;, std::tuple&lt;at::Tensor, at::Tensor&gt;, c10::guts::typelist::typelist&lt;at::Tensor const&amp;, at::Tensor const&amp;, at::Tensor const&amp;, long, long, at::Tensor const&amp;, at::Tensor const&amp;, at::Tensor const&amp;, at::Tensor const&amp;, std::optional&lt;at::Tensor&gt; const&amp;, bool, bool, std::optional&lt;long&gt; &gt; &gt;, std::tuple&lt;at::Tensor, at::Tensor&gt; (at::Tensor const&amp;, at::Tensor const&amp;, at::Tensor const&amp;, long, long, at::Tensor const&amp;, at::Tensor const&amp;, at::Tensor const&amp;, at::Tensor const&amp;, std::optional&lt;at::Tensor&gt; const&amp;, bool, bool, std::optional&lt;long&gt;)&gt;::call (libtorch_cuda.so) (504 samples, 1.97%)</title><rect x="14.2384%" y="484" width="1.9655%" height="15" fill="rgb(244,137,37)" fg:x="3651" fg:w="504"/><text x="14.4884%" y="494.50">c..</text></g><g><title>at::(anonymous namespace)::(anonymous namespace)::wrapper_CUDA___native_multi_head_attention (libtorch_cuda.so) (504 samples, 1.97%)</title><rect x="14.2384%" y="500" width="1.9655%" height="15" fill="rgb(240,136,2)" fg:x="3651" fg:w="504"/><text x="14.4884%" y="510.50">a..</text></g><g><title>at::meta::structured_add_Tensor::meta (libtorch_cpu.so) (28 samples, 0.11%)</title><rect x="16.2195%" y="500" width="0.1092%" height="15" fill="rgb(239,18,37)" fg:x="4159" fg:w="28"/><text x="16.4695%" y="510.50"></text></g><g><title>at::TensorIteratorBase::build_borrowing_binary_op (libtorch_cpu.so) (27 samples, 0.11%)</title><rect x="16.2234%" y="516" width="0.1053%" height="15" fill="rgb(218,185,22)" fg:x="4160" fg:w="27"/><text x="16.4734%" y="526.50"></text></g><g><title>at::TensorIteratorBase::build (libtorch_cpu.so) (27 samples, 0.11%)</title><rect x="16.2234%" y="532" width="0.1053%" height="15" fill="rgb(225,218,4)" fg:x="4160" fg:w="27"/><text x="16.4734%" y="542.50"></text></g><g><title>0x7ac5be415aa8 (nvidia/cuda_runtime/lib/libcudart.so.12) (26 samples, 0.10%)</title><rect x="16.4262%" y="564" width="0.1014%" height="15" fill="rgb(230,182,32)" fg:x="4212" fg:w="26"/><text x="16.6762%" y="574.50"></text></g><g><title>0x7ac4e00ef270 (libcuda.so.550.54.15) (26 samples, 0.10%)</title><rect x="16.4262%" y="580" width="0.1014%" height="15" fill="rgb(242,56,43)" fg:x="4212" fg:w="26"/><text x="16.6762%" y="590.50"></text></g><g><title>at::native::add_kernel (libtorch_cuda.so) (52 samples, 0.20%)</title><rect x="16.3287%" y="500" width="0.2028%" height="15" fill="rgb(233,99,24)" fg:x="4187" fg:w="52"/><text x="16.5787%" y="510.50"></text></g><g><title>at::native::add_kernel(at::TensorIteratorBase&amp;, c10::Scalar const&amp;)::{lambda()#1}::operator() const (libtorch_cuda.so) (51 samples, 0.20%)</title><rect x="16.3326%" y="516" width="0.1989%" height="15" fill="rgb(234,209,42)" fg:x="4188" fg:w="51"/><text x="16.5826%" y="526.50"></text></g><g><title>at::native::gpu_kernel_impl_nocast&lt;at::native::CUDAFunctor_add&lt;float&gt; &gt; (libtorch_cuda.so) (44 samples, 0.17%)</title><rect x="16.3599%" y="532" width="0.1716%" height="15" fill="rgb(227,7,12)" fg:x="4195" fg:w="44"/><text x="16.6099%" y="542.50"></text></g><g><title>cudaLaunchKernel (nvidia/cuda_runtime/lib/libcudart.so.12) (37 samples, 0.14%)</title><rect x="16.3872%" y="548" width="0.1443%" height="15" fill="rgb(245,203,43)" fg:x="4202" fg:w="37"/><text x="16.6372%" y="558.50"></text></g><g><title>at::_ops::add__Tensor::call (libtorch_cpu.so) (85 samples, 0.33%)</title><rect x="16.2039%" y="468" width="0.3315%" height="15" fill="rgb(238,205,33)" fg:x="4155" fg:w="85"/><text x="16.4539%" y="478.50"></text></g><g><title>at::(anonymous namespace)::wrapper_CUDA_add__Tensor (libtorch_cuda.so) (84 samples, 0.33%)</title><rect x="16.2078%" y="484" width="0.3276%" height="15" fill="rgb(231,56,7)" fg:x="4156" fg:w="84"/><text x="16.4578%" y="494.50"></text></g><g><title>cublasLtMatmul (nvidia/cublas/lib/libcublasLt.so.12) (43 samples, 0.17%)</title><rect x="16.6602%" y="564" width="0.1677%" height="15" fill="rgb(244,186,29)" fg:x="4272" fg:w="43"/><text x="16.9102%" y="574.50"></text></g><g><title>0x7ac4e246b6ab (nvidia/cublas/lib/libcublasLt.so.12) (41 samples, 0.16%)</title><rect x="16.6680%" y="580" width="0.1599%" height="15" fill="rgb(234,111,31)" fg:x="4274" fg:w="41"/><text x="16.9180%" y="590.50"></text></g><g><title>0x7ac4e2394df1 (nvidia/cublas/lib/libcublasLt.so.12) (37 samples, 0.14%)</title><rect x="16.6836%" y="596" width="0.1443%" height="15" fill="rgb(241,149,10)" fg:x="4278" fg:w="37"/><text x="16.9336%" y="606.50"></text></g><g><title>at::cuda::blas::gemm_and_bias&lt;float, float&gt; (libtorch_cuda.so) (69 samples, 0.27%)</title><rect x="16.6095%" y="548" width="0.2691%" height="15" fill="rgb(249,206,44)" fg:x="4259" fg:w="69"/><text x="16.8595%" y="558.50"></text></g><g><title>at::native::(anonymous namespace)::addmm_out_cuda_impl (libtorch_cuda.so) (74 samples, 0.29%)</title><rect x="16.5978%" y="532" width="0.2886%" height="15" fill="rgb(251,153,30)" fg:x="4256" fg:w="74"/><text x="16.8478%" y="542.50"></text></g><g><title>at::_ops::_addmm_activation::call (libtorch_cpu.so) (90 samples, 0.35%)</title><rect x="16.5471%" y="484" width="0.3510%" height="15" fill="rgb(239,152,38)" fg:x="4243" fg:w="90"/><text x="16.7971%" y="494.50"></text></g><g><title>c10::impl::wrap_kernel_functor_unboxed_&lt;c10::impl::detail::WrapFunctionIntoFunctor_&lt;c10::CompileTimeFunctionPointer&lt;at::Tensor(at::Tensor const&amp;, at::Tensor const&amp;, at::Tensor const&amp;, c10::Scalar const&amp;, c10::Scalar const&amp;, bool), &amp;at::(anonymous namespace)::wrapper_CUDA__addmm_activation(at::Tensor const&amp;, at::Tensor const&amp;, at::Tensor const&amp;, c10::Scalar const&amp;, c10::Scalar const&amp;, bool)&gt;, at::Tensor, c10::guts::typelist::typelist&lt;at::Tensor const&amp;, at::Tensor const&amp;, at::Tensor const&amp;, c10::Scalar const&amp;, c10::Scalar const&amp;, bool&gt; &gt;, at::Tensor(at::Tensor const&amp;, at::Tensor const&amp;, at::Tensor const&amp;, c10::Scalar const&amp;, c10::Scalar const&amp;, bool)&gt;::call (libtorch_cuda.so) (88 samples, 0.34%)</title><rect x="16.5549%" y="500" width="0.3432%" height="15" fill="rgb(249,139,47)" fg:x="4245" fg:w="88"/><text x="16.8049%" y="510.50"></text></g><g><title>at::(anonymous namespace)::wrapper_CUDA__addmm_activation (libtorch_cuda.so) (86 samples, 0.34%)</title><rect x="16.5627%" y="516" width="0.3354%" height="15" fill="rgb(244,64,35)" fg:x="4247" fg:w="86"/><text x="16.8127%" y="526.50"></text></g><g><title>cublasLtMatmul (nvidia/cublas/lib/libcublasLt.so.12) (36 samples, 0.14%)</title><rect x="17.0346%" y="580" width="0.1404%" height="15" fill="rgb(216,46,15)" fg:x="4368" fg:w="36"/><text x="17.2846%" y="590.50"></text></g><g><title>0x7ac4e246b6ab (nvidia/cublas/lib/libcublasLt.so.12) (36 samples, 0.14%)</title><rect x="17.0346%" y="596" width="0.1404%" height="15" fill="rgb(250,74,19)" fg:x="4368" fg:w="36"/><text x="17.2846%" y="606.50"></text></g><g><title>0x7ac4e2394df1 (nvidia/cublas/lib/libcublasLt.so.12) (34 samples, 0.13%)</title><rect x="17.0424%" y="612" width="0.1326%" height="15" fill="rgb(249,42,33)" fg:x="4370" fg:w="34"/><text x="17.2924%" y="622.50"></text></g><g><title>at::native::structured_addmm_out_cuda::impl (libtorch_cuda.so) (67 samples, 0.26%)</title><rect x="16.9449%" y="532" width="0.2613%" height="15" fill="rgb(242,149,17)" fg:x="4345" fg:w="67"/><text x="17.1949%" y="542.50"></text></g><g><title>at::native::(anonymous namespace)::addmm_out_cuda_impl (libtorch_cuda.so) (67 samples, 0.26%)</title><rect x="16.9449%" y="548" width="0.2613%" height="15" fill="rgb(244,29,21)" fg:x="4345" fg:w="67"/><text x="17.1949%" y="558.50"></text></g><g><title>at::cuda::blas::gemm_and_bias&lt;float, float&gt; (libtorch_cuda.so) (65 samples, 0.25%)</title><rect x="16.9527%" y="564" width="0.2535%" height="15" fill="rgb(220,130,37)" fg:x="4347" fg:w="65"/><text x="17.2027%" y="574.50"></text></g><g><title>at::_ops::addmm::call (libtorch_cpu.so) (80 samples, 0.31%)</title><rect x="16.8981%" y="484" width="0.3120%" height="15" fill="rgb(211,67,2)" fg:x="4333" fg:w="80"/><text x="17.1481%" y="494.50"></text></g><g><title>c10::impl::wrap_kernel_functor_unboxed_&lt;c10::impl::detail::WrapFunctionIntoFunctor_&lt;c10::CompileTimeFunctionPointer&lt;at::Tensor(at::Tensor const&amp;, at::Tensor const&amp;, at::Tensor const&amp;, c10::Scalar const&amp;, c10::Scalar const&amp;), &amp;at::(anonymous namespace)::wrapper_CUDA_addmm(at::Tensor const&amp;, at::Tensor const&amp;, at::Tensor const&amp;, c10::Scalar const&amp;, c10::Scalar const&amp;)&gt;, at::Tensor, c10::guts::typelist::typelist&lt;at::Tensor const&amp;, at::Tensor const&amp;, at::Tensor const&amp;, c10::Scalar const&amp;, c10::Scalar const&amp;&gt; &gt;, at::Tensor(at::Tensor const&amp;, at::Tensor const&amp;, at::Tensor const&amp;, c10::Scalar const&amp;, c10::Scalar const&amp;)&gt;::call (libtorch_cuda.so) (78 samples, 0.30%)</title><rect x="16.9059%" y="500" width="0.3042%" height="15" fill="rgb(235,68,52)" fg:x="4335" fg:w="78"/><text x="17.1559%" y="510.50"></text></g><g><title>at::(anonymous namespace)::wrapper_CUDA_addmm (libtorch_cuda.so) (78 samples, 0.30%)</title><rect x="16.9059%" y="516" width="0.3042%" height="15" fill="rgb(246,142,3)" fg:x="4335" fg:w="78"/><text x="17.1559%" y="526.50"></text></g><g><title>at::native::(anonymous namespace)::linear_for_ffn (libtorch_cpu.so) (206 samples, 0.80%)</title><rect x="16.5354%" y="468" width="0.8034%" height="15" fill="rgb(241,25,7)" fg:x="4240" fg:w="206"/><text x="16.7854%" y="478.50"></text></g><g><title>at::empty (libtorch_cuda.so) (28 samples, 0.11%)</title><rect x="17.4362%" y="596" width="0.1092%" height="15" fill="rgb(242,119,39)" fg:x="4471" fg:w="28"/><text x="17.6862%" y="606.50"></text></g><g><title>at::_ops::empty_memory_format::call (libtorch_cpu.so) (26 samples, 0.10%)</title><rect x="17.4440%" y="612" width="0.1014%" height="15" fill="rgb(241,98,45)" fg:x="4473" fg:w="26"/><text x="17.6940%" y="622.50"></text></g><g><title>c10::impl::wrap_kernel_functor_unboxed_&lt;c10::impl::detail::WrapFunctionIntoFunctor_&lt;c10::CompileTimeFunctionPointer&lt;at::Tensor(c10::ArrayRef&lt;c10::SymInt&gt;, std::optional&lt;c10::ScalarType&gt;, std::optional&lt;c10::Layout&gt;, std::optional&lt;c10::Device&gt;, std::optional&lt;bool&gt;, std::optional&lt;c10::MemoryFormat&gt;), &amp;at::(anonymous namespace)::empty_memory_format(c10::ArrayRef&lt;c10::SymInt&gt;, std::optional&lt;c10::ScalarType&gt;, std::optional&lt;c10::Layout&gt;, std::optional&lt;c10::Device&gt;, std::optional&lt;bool&gt;, std::optional&lt;c10::MemoryFormat&gt;)&gt;, at::Tensor, c10::guts::typelist::typelist&lt;c10::ArrayRef&lt;c10::SymInt&gt;, std::optional&lt;c10::ScalarType&gt;, std::optional&lt;c10::Layout&gt;, std::optional&lt;c10::Device&gt;, std::optional&lt;bool&gt;, std::optional&lt;c10::MemoryFormat&gt; &gt; &gt;, at::Tensor(c10::ArrayRef&lt;c10::SymInt&gt;, std::optional&lt;c10::ScalarType&gt;, std::optional&lt;c10::Layout&gt;, std::optional&lt;c10::Device&gt;, std::optional&lt;bool&gt;, std::optional&lt;c10::MemoryFormat&gt;)&gt;::call (libtorch_cpu.so) (26 samples, 0.10%)</title><rect x="17.4440%" y="628" width="0.1014%" height="15" fill="rgb(254,28,30)" fg:x="4473" fg:w="26"/><text x="17.6940%" y="638.50"></text></g><g><title>at::native::(anonymous namespace)::LayerNormKernelImplInternal&lt;float, float&gt; (libtorch_cuda.so) (36 samples, 0.14%)</title><rect x="17.5454%" y="596" width="0.1404%" height="15" fill="rgb(241,142,54)" fg:x="4499" fg:w="36"/><text x="17.7954%" y="606.50"></text></g><g><title>cudaLaunchKernel (nvidia/cuda_runtime/lib/libcudart.so.12) (30 samples, 0.12%)</title><rect x="17.5688%" y="612" width="0.1170%" height="15" fill="rgb(222,85,15)" fg:x="4505" fg:w="30"/><text x="17.8188%" y="622.50"></text></g><g><title>at::empty_symint (libtorch_cpu.so) (31 samples, 0.12%)</title><rect x="17.7014%" y="612" width="0.1209%" height="15" fill="rgb(210,85,47)" fg:x="4539" fg:w="31"/><text x="17.9514%" y="622.50"></text></g><g><title>at::_ops::empty_memory_format::call (libtorch_cpu.so) (31 samples, 0.12%)</title><rect x="17.7014%" y="628" width="0.1209%" height="15" fill="rgb(224,206,25)" fg:x="4539" fg:w="31"/><text x="17.9514%" y="638.50"></text></g><g><title>c10::impl::wrap_kernel_functor_unboxed_&lt;c10::impl::detail::WrapFunctionIntoFunctor_&lt;c10::CompileTimeFunctionPointer&lt;at::Tensor(c10::ArrayRef&lt;c10::SymInt&gt;, std::optional&lt;c10::ScalarType&gt;, std::optional&lt;c10::Layout&gt;, std::optional&lt;c10::Device&gt;, std::optional&lt;bool&gt;, std::optional&lt;c10::MemoryFormat&gt;), &amp;at::(anonymous namespace)::empty_memory_format(c10::ArrayRef&lt;c10::SymInt&gt;, std::optional&lt;c10::ScalarType&gt;, std::optional&lt;c10::Layout&gt;, std::optional&lt;c10::Device&gt;, std::optional&lt;bool&gt;, std::optional&lt;c10::MemoryFormat&gt;)&gt;, at::Tensor, c10::guts::typelist::typelist&lt;c10::ArrayRef&lt;c10::SymInt&gt;, std::optional&lt;c10::ScalarType&gt;, std::optional&lt;c10::Layout&gt;, std::optional&lt;c10::Device&gt;, std::optional&lt;bool&gt;, std::optional&lt;c10::MemoryFormat&gt; &gt; &gt;, at::Tensor(c10::ArrayRef&lt;c10::SymInt&gt;, std::optional&lt;c10::ScalarType&gt;, std::optional&lt;c10::Layout&gt;, std::optional&lt;c10::Device&gt;, std::optional&lt;bool&gt;, std::optional&lt;c10::MemoryFormat&gt;)&gt;::call (libtorch_cpu.so) (29 samples, 0.11%)</title><rect x="17.7092%" y="644" width="0.1131%" height="15" fill="rgb(243,201,19)" fg:x="4541" fg:w="29"/><text x="17.9592%" y="654.50"></text></g><g><title>at::native::empty_like (libtorch_cpu.so) (38 samples, 0.15%)</title><rect x="17.6858%" y="596" width="0.1482%" height="15" fill="rgb(236,59,4)" fg:x="4535" fg:w="38"/><text x="17.9358%" y="606.50"></text></g><g><title>at::native::layer_norm_cuda (libtorch_cuda.so) (122 samples, 0.48%)</title><rect x="17.3855%" y="580" width="0.4758%" height="15" fill="rgb(254,179,45)" fg:x="4458" fg:w="122"/><text x="17.6355%" y="590.50"></text></g><g><title>at::_ops::native_layer_norm::call (libtorch_cpu.so) (127 samples, 0.50%)</title><rect x="17.3738%" y="532" width="0.4953%" height="15" fill="rgb(226,14,10)" fg:x="4455" fg:w="127"/><text x="17.6238%" y="542.50"></text></g><g><title>c10::impl::wrap_kernel_functor_unboxed_&lt;c10::impl::detail::WrapFunctionIntoFunctor_&lt;c10::CompileTimeFunctionPointer&lt;std::tuple&lt;at::Tensor, at::Tensor, at::Tensor&gt; (at::Tensor const&amp;, c10::ArrayRef&lt;c10::SymInt&gt;, std::optional&lt;at::Tensor&gt; const&amp;, std::optional&lt;at::Tensor&gt; const&amp;, double), &amp;at::(anonymous namespace)::(anonymous namespace)::wrapper_CUDA__native_layer_norm(at::Tensor const&amp;, c10::ArrayRef&lt;c10::SymInt&gt;, std::optional&lt;at::Tensor&gt; const&amp;, std::optional&lt;at::Tensor&gt; const&amp;, double)&gt;, std::tuple&lt;at::Tensor, at::Tensor, at::Tensor&gt;, c10::guts::typelist::typelist&lt;at::Tensor const&amp;, c10::ArrayRef&lt;c10::SymInt&gt;, std::optional&lt;at::Tensor&gt; const&amp;, std::optional&lt;at::Tensor&gt; const&amp;, double&gt; &gt;, std::tuple&lt;at::Tensor, at::Tensor, at::Tensor&gt; (at::Tensor const&amp;, c10::ArrayRef&lt;c10::SymInt&gt;, std::optional&lt;at::Tensor&gt; const&amp;, std::optional&lt;at::Tensor&gt; const&amp;, double)&gt;::call (libtorch_cuda.so) (126 samples, 0.49%)</title><rect x="17.3777%" y="548" width="0.4914%" height="15" fill="rgb(244,27,41)" fg:x="4456" fg:w="126"/><text x="17.6277%" y="558.50"></text></g><g><title>at::(anonymous namespace)::(anonymous namespace)::wrapper_CUDA__native_layer_norm (libtorch_cuda.so) (125 samples, 0.49%)</title><rect x="17.3816%" y="564" width="0.4875%" height="15" fill="rgb(235,35,32)" fg:x="4457" fg:w="125"/><text x="17.6316%" y="574.50"></text></g><g><title>at::native::(anonymous namespace)::norm (libtorch_cpu.so) (144 samples, 0.56%)</title><rect x="17.3387%" y="468" width="0.5616%" height="15" fill="rgb(218,68,31)" fg:x="4446" fg:w="144"/><text x="17.5887%" y="478.50"></text></g><g><title>at::_ops::layer_norm::call (libtorch_cpu.so) (141 samples, 0.55%)</title><rect x="17.3504%" y="484" width="0.5499%" height="15" fill="rgb(207,120,37)" fg:x="4449" fg:w="141"/><text x="17.6004%" y="494.50"></text></g><g><title>c10::impl::wrap_kernel_functor_unboxed_&lt;c10::impl::detail::WrapFunctionIntoFunctor_&lt;c10::CompileTimeFunctionPointer&lt;at::Tensor(at::Tensor const&amp;, c10::ArrayRef&lt;c10::SymInt&gt;, std::optional&lt;at::Tensor&gt; const&amp;, std::optional&lt;at::Tensor&gt; const&amp;, double, bool), &amp;at::(anonymous namespace)::(anonymous namespace)::wrapper_CompositeImplicitAutograd__layer_norm(at::Tensor const&amp;, c10::ArrayRef&lt;c10::SymInt&gt;, std::optional&lt;at::Tensor&gt; const&amp;, std::optional&lt;at::Tensor&gt; const&amp;, double, bool)&gt;, at::Tensor, c10::guts::typelist::typelist&lt;at::Tensor const&amp;, c10::ArrayRef&lt;c10::SymInt&gt;, std::optional&lt;at::Tensor&gt; const&amp;, std::optional&lt;at::Tensor&gt; const&amp;, double, bool&gt; &gt;, at::Tensor(at::Tensor const&amp;, c10::ArrayRef&lt;c10::SymInt&gt;, std::optional&lt;at::Tensor&gt; const&amp;, std::optional&lt;at::Tensor&gt; const&amp;, double, bool)&gt;::call (libtorch_cpu.so) (138 samples, 0.54%)</title><rect x="17.3621%" y="500" width="0.5382%" height="15" fill="rgb(227,98,0)" fg:x="4452" fg:w="138"/><text x="17.6121%" y="510.50"></text></g><g><title>at::native::layer_norm_symint (libtorch_cpu.so) (136 samples, 0.53%)</title><rect x="17.3699%" y="516" width="0.5304%" height="15" fill="rgb(207,7,3)" fg:x="4454" fg:w="136"/><text x="17.6199%" y="526.50"></text></g><g><title>at::native::transformer_encoder_layer_forward (libtorch_cpu.so) (951 samples, 3.71%)</title><rect x="14.2267%" y="452" width="3.7088%" height="15" fill="rgb(206,98,19)" fg:x="3648" fg:w="951"/><text x="14.4767%" y="462.50">at::..</text></g><g><title>at::(anonymous namespace)::(anonymous namespace)::wrapper_CUDA___transformer_encoder_layer_fwd (libtorch_cuda.so) (955 samples, 3.72%)</title><rect x="14.2267%" y="436" width="3.7244%" height="15" fill="rgb(217,5,26)" fg:x="3648" fg:w="955"/><text x="14.4767%" y="446.50">at::..</text></g><g><title>c10::impl::make_boxed_from_unboxed_functor&lt;c10::impl::detail::WrapFunctionIntoFunctor_&lt;c10::CompileTimeFunctionPointer&lt;at::Tensor(at::Tensor const&amp;, long, long, at::Tensor const&amp;, at::Tensor const&amp;, at::Tensor const&amp;, at::Tensor const&amp;, bool, bool, double, at::Tensor const&amp;, at::Tensor const&amp;, at::Tensor const&amp;, at::Tensor const&amp;, at::Tensor const&amp;, at::Tensor const&amp;, at::Tensor const&amp;, at::Tensor const&amp;, std::optional&lt;at::Tensor&gt; const&amp;, std::optional&lt;long&gt;), &amp;at::(anonymous namespace)::(anonymous namespace)::wrapper_CUDA___transformer_encoder_layer_fwd(at::Tensor const&amp;, long, long, at::Tensor const&amp;, at::Tensor const&amp;, at::Tensor const&amp;, at::Tensor const&amp;, bool, bool, double, at::Tensor const&amp;, at::Tensor const&amp;, at::Tensor const&amp;, at::Tensor const&amp;, at::Tensor const&amp;, at::Tensor const&amp;, at::Tensor const&amp;, at::Tensor const&amp;, std::optional&lt;at::Tensor&gt; const&amp;, std::optional&lt;long&gt;)&gt;, at::Tensor, c10::guts::typelist::typelist&lt;at::Tensor const&amp;, long, long, at::Tensor const&amp;, at::Tensor const&amp;, at::Tensor const&amp;, at::Tensor const&amp;, bool, bool, double, at::Tensor const&amp;, at::Tensor const&amp;, at::Tensor const&amp;, at::Tensor const&amp;, at::Tensor const&amp;, at::Tensor const&amp;, at::Tensor const&amp;, at::Tensor const&amp;, std::optional&lt;at::Tensor&gt; const&amp;, std::optional&lt;long&gt; &gt; &gt;, false&gt;::call (libtorch_cuda.so) (960 samples, 3.74%)</title><rect x="14.2228%" y="420" width="3.7439%" height="15" fill="rgb(235,190,38)" fg:x="3647" fg:w="960"/><text x="14.4728%" y="430.50">c10:..</text></g><g><title>c10::impl::BoxedKernelWrapper&lt;at::Tensor(at::Tensor const&amp;, long, long, at::Tensor const&amp;, at::Tensor const&amp;, at::Tensor const&amp;, at::Tensor const&amp;, bool, bool, double, at::Tensor const&amp;, at::Tensor const&amp;, at::Tensor const&amp;, at::Tensor const&amp;, at::Tensor const&amp;, at::Tensor const&amp;, at::Tensor const&amp;, at::Tensor const&amp;, std::optional&lt;at::Tensor&gt; const&amp;, std::optional&lt;long&gt;), void&gt;::call (libtorch_cpu.so) (978 samples, 3.81%)</title><rect x="14.1877%" y="388" width="3.8141%" height="15" fill="rgb(247,86,24)" fg:x="3638" fg:w="978"/><text x="14.4377%" y="398.50">c10:..</text></g><g><title>torch::autograd::autogradNotImplementedFallbackImpl (libtorch_cpu.so) (977 samples, 3.81%)</title><rect x="14.1916%" y="404" width="3.8102%" height="15" fill="rgb(205,101,16)" fg:x="3639" fg:w="977"/><text x="14.4416%" y="414.50">torc..</text></g><g><title>at::_ops::_transformer_encoder_layer_fwd::call (libtorch_cpu.so) (980 samples, 3.82%)</title><rect x="14.1838%" y="372" width="3.8219%" height="15" fill="rgb(246,168,33)" fg:x="3637" fg:w="980"/><text x="14.4338%" y="382.50">at::..</text></g><g><title>forward (armada_net.py:161) (1,361 samples, 5.31%)</title><rect x="12.7564%" y="244" width="5.3077%" height="15" fill="rgb(231,114,1)" fg:x="3271" fg:w="1361"/><text x="13.0064%" y="254.50">forwar..</text></g><g><title>_wrapped_call_impl (torch/nn/modules/module.py:1773) (1,359 samples, 5.30%)</title><rect x="12.7642%" y="260" width="5.2999%" height="15" fill="rgb(207,184,53)" fg:x="3273" fg:w="1359"/><text x="13.0142%" y="270.50">_wrapp..</text></g><g><title>_call_impl (torch/nn/modules/module.py:1784) (1,355 samples, 5.28%)</title><rect x="12.7798%" y="276" width="5.2843%" height="15" fill="rgb(224,95,51)" fg:x="3277" fg:w="1355"/><text x="13.0298%" y="286.50">_call_..</text></g><g><title>forward (torch/nn/modules/transformer.py:524) (1,329 samples, 5.18%)</title><rect x="12.8812%" y="292" width="5.1829%" height="15" fill="rgb(212,188,45)" fg:x="3303" fg:w="1329"/><text x="13.1312%" y="302.50">forwar..</text></g><g><title>_wrapped_call_impl (torch/nn/modules/module.py:1773) (1,315 samples, 5.13%)</title><rect x="12.9358%" y="308" width="5.1283%" height="15" fill="rgb(223,154,38)" fg:x="3317" fg:w="1315"/><text x="13.1858%" y="318.50">_wrapp..</text></g><g><title>_call_impl (torch/nn/modules/module.py:1784) (1,300 samples, 5.07%)</title><rect x="12.9943%" y="324" width="5.0698%" height="15" fill="rgb(251,22,52)" fg:x="3332" fg:w="1300"/><text x="13.2443%" y="334.50">_call_..</text></g><g><title>forward (torch/nn/modules/transformer.py:922) (1,016 samples, 3.96%)</title><rect x="14.1019%" y="340" width="3.9622%" height="15" fill="rgb(229,209,22)" fg:x="3616" fg:w="1016"/><text x="14.3519%" y="350.50">forw..</text></g><g><title>torch::autograd::THPVariable__transformer_encoder_layer_fwd (libtorch_python.so) (1,008 samples, 3.93%)</title><rect x="14.1331%" y="356" width="3.9311%" height="15" fill="rgb(234,138,34)" fg:x="3624" fg:w="1008"/><text x="14.3831%" y="366.50">torc..</text></g><g><title>at::_ops::mean_dim::call (libtorch_cpu.so) (43 samples, 0.17%)</title><rect x="18.0758%" y="276" width="0.1677%" height="15" fill="rgb(212,95,11)" fg:x="4635" fg:w="43"/><text x="18.3258%" y="286.50"></text></g><g><title>c10::impl::wrap_kernel_functor_unboxed_&lt;c10::impl::detail::WrapFunctionIntoFunctor_&lt;c10::CompileTimeFunctionPointer&lt;at::Tensor(c10::DispatchKeySet, at::Tensor const&amp;, c10::OptionalArrayRef&lt;long&gt;, bool, std::optional&lt;c10::ScalarType&gt;), &amp;torch::autograd::VariableType::(anonymous namespace)::mean_dim(c10::DispatchKeySet, at::Tensor const&amp;, c10::OptionalArrayRef&lt;long&gt;, bool, std::optional&lt;c10::ScalarType&gt;)&gt;, at::Tensor, c10::guts::typelist::typelist&lt;c10::DispatchKeySet, at::Tensor const&amp;, c10::OptionalArrayRef&lt;long&gt;, bool, std::optional&lt;c10::ScalarType&gt; &gt; &gt;, at::Tensor(c10::DispatchKeySet, at::Tensor const&amp;, c10::OptionalArrayRef&lt;long&gt;, bool, std::optional&lt;c10::ScalarType&gt;)&gt;::call (libtorch_cpu.so) (43 samples, 0.17%)</title><rect x="18.0758%" y="292" width="0.1677%" height="15" fill="rgb(240,179,47)" fg:x="4635" fg:w="43"/><text x="18.3258%" y="302.50"></text></g><g><title>torch::autograd::VariableType::(anonymous namespace)::mean_dim (libtorch_cpu.so) (43 samples, 0.17%)</title><rect x="18.0758%" y="308" width="0.1677%" height="15" fill="rgb(240,163,11)" fg:x="4635" fg:w="43"/><text x="18.3258%" y="318.50"></text></g><g><title>at::_ops::mean_dim::redispatch (libtorch_cpu.so) (43 samples, 0.17%)</title><rect x="18.0758%" y="324" width="0.1677%" height="15" fill="rgb(236,37,12)" fg:x="4635" fg:w="43"/><text x="18.3258%" y="334.50"></text></g><g><title>c10::impl::wrap_kernel_functor_unboxed_&lt;c10::impl::detail::WrapFunctionIntoFunctor_&lt;c10::CompileTimeFunctionPointer&lt;at::Tensor(at::Tensor const&amp;, c10::OptionalArrayRef&lt;long&gt;, bool, std::optional&lt;c10::ScalarType&gt;), &amp;at::(anonymous namespace)::wrapper_CUDA_mean_dim(at::Tensor const&amp;, c10::OptionalArrayRef&lt;long&gt;, bool, std::optional&lt;c10::ScalarType&gt;)&gt;, at::Tensor, c10::guts::typelist::typelist&lt;at::Tensor const&amp;, c10::OptionalArrayRef&lt;long&gt;, bool, std::optional&lt;c10::ScalarType&gt; &gt; &gt;, at::Tensor(at::Tensor const&amp;, c10::OptionalArrayRef&lt;long&gt;, bool, std::optional&lt;c10::ScalarType&gt;)&gt;::call (libtorch_cuda.so) (42 samples, 0.16%)</title><rect x="18.0797%" y="340" width="0.1638%" height="15" fill="rgb(232,164,16)" fg:x="4636" fg:w="42"/><text x="18.3297%" y="350.50"></text></g><g><title>at::(anonymous namespace)::wrapper_CUDA_mean_dim (libtorch_cuda.so) (42 samples, 0.16%)</title><rect x="18.0797%" y="356" width="0.1638%" height="15" fill="rgb(244,205,15)" fg:x="4636" fg:w="42"/><text x="18.3297%" y="366.50"></text></g><g><title>at::native::structured_mean_out::impl (libtorch_cpu.so) (37 samples, 0.14%)</title><rect x="18.0992%" y="372" width="0.1443%" height="15" fill="rgb(223,117,47)" fg:x="4641" fg:w="37"/><text x="18.3492%" y="382.50"></text></g><g><title>forward (armada_net.py:163) (55 samples, 0.21%)</title><rect x="18.0641%" y="244" width="0.2145%" height="15" fill="rgb(244,107,35)" fg:x="4632" fg:w="55"/><text x="18.3141%" y="254.50"></text></g><g><title>torch::autograd::THPVariable_mean (libtorch_python.so) (53 samples, 0.21%)</title><rect x="18.0719%" y="260" width="0.2067%" height="15" fill="rgb(205,140,8)" fg:x="4634" fg:w="53"/><text x="18.3219%" y="270.50"></text></g><g><title>at::_ops::addmm::redispatch (libtorch_cpu.so) (29 samples, 0.11%)</title><rect x="18.3566%" y="420" width="0.1131%" height="15" fill="rgb(228,84,46)" fg:x="4707" fg:w="29"/><text x="18.6066%" y="430.50"></text></g><g><title>c10::impl::wrap_kernel_functor_unboxed_&lt;c10::impl::detail::WrapFunctionIntoFunctor_&lt;c10::CompileTimeFunctionPointer&lt;at::Tensor(at::Tensor const&amp;, at::Tensor const&amp;, at::Tensor const&amp;, c10::Scalar const&amp;, c10::Scalar const&amp;), &amp;at::(anonymous namespace)::wrapper_CUDA_addmm(at::Tensor const&amp;, at::Tensor const&amp;, at::Tensor const&amp;, c10::Scalar const&amp;, c10::Scalar const&amp;)&gt;, at::Tensor, c10::guts::typelist::typelist&lt;at::Tensor const&amp;, at::Tensor const&amp;, at::Tensor const&amp;, c10::Scalar const&amp;, c10::Scalar const&amp;&gt; &gt;, at::Tensor(at::Tensor const&amp;, at::Tensor const&amp;, at::Tensor const&amp;, c10::Scalar const&amp;, c10::Scalar const&amp;)&gt;::call (libtorch_cuda.so) (29 samples, 0.11%)</title><rect x="18.3566%" y="436" width="0.1131%" height="15" fill="rgb(254,188,9)" fg:x="4707" fg:w="29"/><text x="18.6066%" y="446.50"></text></g><g><title>at::(anonymous namespace)::wrapper_CUDA_addmm (libtorch_cuda.so) (29 samples, 0.11%)</title><rect x="18.3566%" y="452" width="0.1131%" height="15" fill="rgb(206,112,54)" fg:x="4707" fg:w="29"/><text x="18.6066%" y="462.50"></text></g><g><title>at::_ops::addmm::call (libtorch_cpu.so) (33 samples, 0.13%)</title><rect x="18.3449%" y="372" width="0.1287%" height="15" fill="rgb(216,84,49)" fg:x="4704" fg:w="33"/><text x="18.5949%" y="382.50"></text></g><g><title>c10::impl::wrap_kernel_functor_unboxed_&lt;c10::impl::detail::WrapFunctionIntoFunctor_&lt;c10::CompileTimeFunctionPointer&lt;at::Tensor(c10::DispatchKeySet, at::Tensor const&amp;, at::Tensor const&amp;, at::Tensor const&amp;, c10::Scalar const&amp;, c10::Scalar const&amp;), &amp;torch::autograd::VariableType::(anonymous namespace)::addmm(c10::DispatchKeySet, at::Tensor const&amp;, at::Tensor const&amp;, at::Tensor const&amp;, c10::Scalar const&amp;, c10::Scalar const&amp;)&gt;, at::Tensor, c10::guts::typelist::typelist&lt;c10::DispatchKeySet, at::Tensor const&amp;, at::Tensor const&amp;, at::Tensor const&amp;, c10::Scalar const&amp;, c10::Scalar const&amp;&gt; &gt;, at::Tensor(c10::DispatchKeySet, at::Tensor const&amp;, at::Tensor const&amp;, at::Tensor const&amp;, c10::Scalar const&amp;, c10::Scalar const&amp;)&gt;::call (libtorch_cpu.so) (32 samples, 0.12%)</title><rect x="18.3488%" y="388" width="0.1248%" height="15" fill="rgb(214,194,35)" fg:x="4705" fg:w="32"/><text x="18.5988%" y="398.50"></text></g><g><title>torch::autograd::VariableType::(anonymous namespace)::addmm (libtorch_cpu.so) (32 samples, 0.12%)</title><rect x="18.3488%" y="404" width="0.1248%" height="15" fill="rgb(249,28,3)" fg:x="4705" fg:w="32"/><text x="18.5988%" y="414.50"></text></g><g><title>at::_ops::linear::call (libtorch_cpu.so) (42 samples, 0.16%)</title><rect x="18.3449%" y="324" width="0.1638%" height="15" fill="rgb(222,56,52)" fg:x="4704" fg:w="42"/><text x="18.5949%" y="334.50"></text></g><g><title>c10::impl::wrap_kernel_functor_unboxed_&lt;c10::impl::detail::WrapFunctionIntoFunctor_&lt;c10::CompileTimeFunctionPointer&lt;at::Tensor(at::Tensor const&amp;, at::Tensor const&amp;, std::optional&lt;at::Tensor&gt; const&amp;), &amp;at::(anonymous namespace)::(anonymous namespace)::wrapper_CompositeImplicitAutograd__linear(at::Tensor const&amp;, at::Tensor const&amp;, std::optional&lt;at::Tensor&gt; const&amp;)&gt;, at::Tensor, c10::guts::typelist::typelist&lt;at::Tensor const&amp;, at::Tensor const&amp;, std::optional&lt;at::Tensor&gt; const&amp;&gt; &gt;, at::Tensor(at::Tensor const&amp;, at::Tensor const&amp;, std::optional&lt;at::Tensor&gt; const&amp;)&gt;::call (libtorch_cpu.so) (42 samples, 0.16%)</title><rect x="18.3449%" y="340" width="0.1638%" height="15" fill="rgb(245,217,50)" fg:x="4704" fg:w="42"/><text x="18.5949%" y="350.50"></text></g><g><title>at::native::linear (libtorch_cpu.so) (42 samples, 0.16%)</title><rect x="18.3449%" y="356" width="0.1638%" height="15" fill="rgb(213,201,24)" fg:x="4704" fg:w="42"/><text x="18.5949%" y="366.50"></text></g><g><title>forward (armada_net.py:164) (60 samples, 0.23%)</title><rect x="18.2786%" y="244" width="0.2340%" height="15" fill="rgb(248,116,28)" fg:x="4687" fg:w="60"/><text x="18.5286%" y="254.50"></text></g><g><title>_wrapped_call_impl (torch/nn/modules/module.py:1773) (56 samples, 0.22%)</title><rect x="18.2942%" y="260" width="0.2184%" height="15" fill="rgb(219,72,43)" fg:x="4691" fg:w="56"/><text x="18.5442%" y="270.50"></text></g><g><title>_call_impl (torch/nn/modules/module.py:1784) (46 samples, 0.18%)</title><rect x="18.3332%" y="276" width="0.1794%" height="15" fill="rgb(209,138,14)" fg:x="4701" fg:w="46"/><text x="18.5832%" y="286.50"></text></g><g><title>forward (torch/nn/modules/linear.py:125) (46 samples, 0.18%)</title><rect x="18.3332%" y="292" width="0.1794%" height="15" fill="rgb(222,18,33)" fg:x="4701" fg:w="46"/><text x="18.5832%" y="302.50"></text></g><g><title>torch::autograd::THPVariable_linear (libtorch_python.so) (43 samples, 0.17%)</title><rect x="18.3449%" y="308" width="0.1677%" height="15" fill="rgb(213,199,7)" fg:x="4704" fg:w="43"/><text x="18.5949%" y="318.50"></text></g><g><title>0x7ac455c6ba58 (libcudnn_ops.so.9) (26 samples, 0.10%)</title><rect x="19.5032%" y="660" width="0.1014%" height="15" fill="rgb(250,110,10)" fg:x="5001" fg:w="26"/><text x="19.7532%" y="670.50"></text></g><g><title>cudnnBatchNormalizationForwardInference (libcudnn_ops.so.9) (35 samples, 0.14%)</title><rect x="19.4720%" y="644" width="0.1365%" height="15" fill="rgb(248,123,6)" fg:x="4993" fg:w="35"/><text x="19.7220%" y="654.50"></text></g><g><title>at::native::cudnn_batch_norm (libtorch_cuda.so) (115 samples, 0.45%)</title><rect x="19.1639%" y="628" width="0.4485%" height="15" fill="rgb(206,91,31)" fg:x="4914" fg:w="115"/><text x="19.4139%" y="638.50"></text></g><g><title>at::_ops::cudnn_batch_norm::redispatch (libtorch_cpu.so) (123 samples, 0.48%)</title><rect x="19.1561%" y="580" width="0.4797%" height="15" fill="rgb(211,154,13)" fg:x="4912" fg:w="123"/><text x="19.4061%" y="590.50"></text></g><g><title>c10::impl::wrap_kernel_functor_unboxed_&lt;c10::impl::detail::WrapFunctionIntoFunctor_&lt;c10::CompileTimeFunctionPointer&lt;std::tuple&lt;at::Tensor, at::Tensor, at::Tensor, at::Tensor&gt; (at::Tensor const&amp;, at::Tensor const&amp;, std::optional&lt;at::Tensor&gt; const&amp;, std::optional&lt;at::Tensor&gt; const&amp;, std::optional&lt;at::Tensor&gt; const&amp;, bool, double, double), &amp;at::(anonymous namespace)::(anonymous namespace)::wrapper_CUDA__cudnn_batch_norm(at::Tensor const&amp;, at::Tensor const&amp;, std::optional&lt;at::Tensor&gt; const&amp;, std::optional&lt;at::Tensor&gt; const&amp;, std::optional&lt;at::Tensor&gt; const&amp;, bool, double, double)&gt;, std::tuple&lt;at::Tensor, at::Tensor, at::Tensor, at::Tensor&gt;, c10::guts::typelist::typelist&lt;at::Tensor const&amp;, at::Tensor const&amp;, std::optional&lt;at::Tensor&gt; const&amp;, std::optional&lt;at::Tensor&gt; const&amp;, std::optional&lt;at::Tensor&gt; const&amp;, bool, double, double&gt; &gt;, std::tuple&lt;at::Tensor, at::Tensor, at::Tensor, at::Tensor&gt; (at::Tensor const&amp;, at::Tensor const&amp;, std::optional&lt;at::Tensor&gt; const&amp;, std::optional&lt;at::Tensor&gt; const&amp;, std::optional&lt;at::Tensor&gt; const&amp;, bool, double, double)&gt;::call (libtorch_cuda.so) (123 samples, 0.48%)</title><rect x="19.1561%" y="596" width="0.4797%" height="15" fill="rgb(225,148,7)" fg:x="4912" fg:w="123"/><text x="19.4061%" y="606.50"></text></g><g><title>at::(anonymous namespace)::(anonymous namespace)::wrapper_CUDA__cudnn_batch_norm (libtorch_cuda.so) (123 samples, 0.48%)</title><rect x="19.1561%" y="612" width="0.4797%" height="15" fill="rgb(220,160,43)" fg:x="4912" fg:w="123"/><text x="19.4061%" y="622.50"></text></g><g><title>at::_ops::cudnn_batch_norm::call (libtorch_cpu.so) (137 samples, 0.53%)</title><rect x="19.1444%" y="532" width="0.5343%" height="15" fill="rgb(213,52,39)" fg:x="4909" fg:w="137"/><text x="19.3944%" y="542.50"></text></g><g><title>c10::impl::wrap_kernel_functor_unboxed_&lt;c10::impl::detail::WrapFunctionIntoFunctor_&lt;c10::CompileTimeFunctionPointer&lt;std::tuple&lt;at::Tensor, at::Tensor, at::Tensor, at::Tensor&gt; (c10::DispatchKeySet, at::Tensor const&amp;, at::Tensor const&amp;, std::optional&lt;at::Tensor&gt; const&amp;, std::optional&lt;at::Tensor&gt; const&amp;, std::optional&lt;at::Tensor&gt; const&amp;, bool, double, double), &amp;torch::autograd::VariableType::(anonymous namespace)::cudnn_batch_norm(c10::DispatchKeySet, at::Tensor const&amp;, at::Tensor const&amp;, std::optional&lt;at::Tensor&gt; const&amp;, std::optional&lt;at::Tensor&gt; const&amp;, std::optional&lt;at::Tensor&gt; const&amp;, bool, double, double)&gt;, std::tuple&lt;at::Tensor, at::Tensor, at::Tensor, at::Tensor&gt;, c10::guts::typelist::typelist&lt;c10::DispatchKeySet, at::Tensor const&amp;, at::Tensor const&amp;, std::optional&lt;at::Tensor&gt; const&amp;, std::optional&lt;at::Tensor&gt; const&amp;, std::optional&lt;at::Tensor&gt; const&amp;, bool, double, double&gt; &gt;, std::tuple&lt;at::Tensor, at::Tensor, at::Tensor, at::Tensor&gt; (c10::DispatchKeySet, at::Tensor const&amp;, at::Tensor const&amp;, std::optional&lt;at::Tensor&gt; const&amp;, std::optional&lt;at::Tensor&gt; const&amp;, std::optional&lt;at::Tensor&gt; const&amp;, bool, double, double)&gt;::call (libtorch_cpu.so) (136 samples, 0.53%)</title><rect x="19.1483%" y="548" width="0.5304%" height="15" fill="rgb(243,137,7)" fg:x="4910" fg:w="136"/><text x="19.3983%" y="558.50"></text></g><g><title>torch::autograd::VariableType::(anonymous namespace)::cudnn_batch_norm (libtorch_cpu.so) (136 samples, 0.53%)</title><rect x="19.1483%" y="564" width="0.5304%" height="15" fill="rgb(230,79,13)" fg:x="4910" fg:w="136"/><text x="19.3983%" y="574.50"></text></g><g><title>at::_ops::batch_norm::call (libtorch_cpu.so) (152 samples, 0.59%)</title><rect x="19.1132%" y="436" width="0.5928%" height="15" fill="rgb(247,105,23)" fg:x="4901" fg:w="152"/><text x="19.3632%" y="446.50"></text></g><g><title>c10::impl::wrap_kernel_functor_unboxed_&lt;c10::impl::detail::WrapFunctionIntoFunctor_&lt;c10::CompileTimeFunctionPointer&lt;at::Tensor(at::Tensor const&amp;, std::optional&lt;at::Tensor&gt; const&amp;, std::optional&lt;at::Tensor&gt; const&amp;, std::optional&lt;at::Tensor&gt; const&amp;, std::optional&lt;at::Tensor&gt; const&amp;, bool, double, double, bool), &amp;at::(anonymous namespace)::(anonymous namespace)::wrapper_CompositeImplicitAutograd__batch_norm(at::Tensor const&amp;, std::optional&lt;at::Tensor&gt; const&amp;, std::optional&lt;at::Tensor&gt; const&amp;, std::optional&lt;at::Tensor&gt; const&amp;, std::optional&lt;at::Tensor&gt; const&amp;, bool, double, double, bool)&gt;, at::Tensor, c10::guts::typelist::typelist&lt;at::Tensor const&amp;, std::optional&lt;at::Tensor&gt; const&amp;, std::optional&lt;at::Tensor&gt; const&amp;, std::optional&lt;at::Tensor&gt; const&amp;, std::optional&lt;at::Tensor&gt; const&amp;, bool, double, double, bool&gt; &gt;, at::Tensor(at::Tensor const&amp;, std::optional&lt;at::Tensor&gt; const&amp;, std::optional&lt;at::Tensor&gt; const&amp;, std::optional&lt;at::Tensor&gt; const&amp;, std::optional&lt;at::Tensor&gt; const&amp;, bool, double, double, bool)&gt;::call (libtorch_cpu.so) (150 samples, 0.58%)</title><rect x="19.1210%" y="452" width="0.5850%" height="15" fill="rgb(223,179,41)" fg:x="4903" fg:w="150"/><text x="19.3710%" y="462.50"></text></g><g><title>at::native::batch_norm (libtorch_cpu.so) (149 samples, 0.58%)</title><rect x="19.1249%" y="468" width="0.5811%" height="15" fill="rgb(218,9,34)" fg:x="4904" fg:w="149"/><text x="19.3749%" y="478.50"></text></g><g><title>at::_ops::_batch_norm_impl_index::call (libtorch_cpu.so) (149 samples, 0.58%)</title><rect x="19.1249%" y="484" width="0.5811%" height="15" fill="rgb(222,106,8)" fg:x="4904" fg:w="149"/><text x="19.3749%" y="494.50"></text></g><g><title>c10::impl::wrap_kernel_functor_unboxed_&lt;c10::impl::detail::WrapFunctionIntoFunctor_&lt;c10::CompileTimeFunctionPointer&lt;std::tuple&lt;at::Tensor, at::Tensor, at::Tensor, at::Tensor, long&gt; (at::Tensor const&amp;, std::optional&lt;at::Tensor&gt; const&amp;, std::optional&lt;at::Tensor&gt; const&amp;, std::optional&lt;at::Tensor&gt; const&amp;, std::optional&lt;at::Tensor&gt; const&amp;, bool, double, double, bool), &amp;at::(anonymous namespace)::(anonymous namespace)::wrapper_CompositeImplicitAutograd___batch_norm_impl_index(at::Tensor const&amp;, std::optional&lt;at::Tensor&gt; const&amp;, std::optional&lt;at::Tensor&gt; const&amp;, std::optional&lt;at::Tensor&gt; const&amp;, std::optional&lt;at::Tensor&gt; const&amp;, bool, double, double, bool)&gt;, std::tuple&lt;at::Tensor, at::Tensor, at::Tensor, at::Tensor, long&gt;, c10::guts::typelist::typelist&lt;at::Tensor const&amp;, std::optional&lt;at::Tensor&gt; const&amp;, std::optional&lt;at::Tensor&gt; const&amp;, std::optional&lt;at::Tensor&gt; const&amp;, std::optional&lt;at::Tensor&gt; const&amp;, bool, double, double, bool&gt; &gt;, std::tuple&lt;at::Tensor, at::Tensor, at::Tensor, at::Tensor, long&gt; (at::Tensor const&amp;, std::optional&lt;at::Tensor&gt; const&amp;, std::optional&lt;at::Tensor&gt; const&amp;, std::optional&lt;at::Tensor&gt; const&amp;, std::optional&lt;at::Tensor&gt; const&amp;, bool, double, double, bool)&gt;::call (libtorch_cpu.so) (146 samples, 0.57%)</title><rect x="19.1366%" y="500" width="0.5694%" height="15" fill="rgb(211,220,0)" fg:x="4907" fg:w="146"/><text x="19.3866%" y="510.50"></text></g><g><title>at::native::_batch_norm_impl_index (libtorch_cpu.so) (146 samples, 0.57%)</title><rect x="19.1366%" y="516" width="0.5694%" height="15" fill="rgb(229,52,16)" fg:x="4907" fg:w="146"/><text x="19.3866%" y="526.50"></text></g><g><title>forward (torch/nn/modules/batchnorm.py:193) (178 samples, 0.69%)</title><rect x="19.0469%" y="388" width="0.6942%" height="15" fill="rgb(212,155,18)" fg:x="4884" fg:w="178"/><text x="19.2969%" y="398.50"></text></g><g><title>batch_norm (torch/nn/functional.py:2826) (174 samples, 0.68%)</title><rect x="19.0625%" y="404" width="0.6786%" height="15" fill="rgb(242,21,14)" fg:x="4888" fg:w="174"/><text x="19.3125%" y="414.50"></text></g><g><title>torch::autograd::THPVariable_batch_norm (libtorch_python.so) (165 samples, 0.64%)</title><rect x="19.0976%" y="420" width="0.6435%" height="15" fill="rgb(222,19,48)" fg:x="4897" fg:w="165"/><text x="19.3476%" y="430.50"></text></g><g><title>0x7ac46540db79 (libcudnn_engines_precompiled.so.9) (27 samples, 0.11%)</title><rect x="20.2324%" y="852" width="0.1053%" height="15" fill="rgb(232,45,27)" fg:x="5188" fg:w="27"/><text x="20.4824%" y="862.50"></text></g><g><title>0x7ac4653e902c (libcudnn_engines_precompiled.so.9) (27 samples, 0.11%)</title><rect x="20.2324%" y="868" width="0.1053%" height="15" fill="rgb(249,103,42)" fg:x="5188" fg:w="27"/><text x="20.4824%" y="878.50"></text></g><g><title>0x7ac4653e8334 (libcudnn_engines_precompiled.so.9) (26 samples, 0.10%)</title><rect x="20.2363%" y="884" width="0.1014%" height="15" fill="rgb(246,81,33)" fg:x="5189" fg:w="26"/><text x="20.4863%" y="894.50"></text></g><g><title>cudnn::cnn::EngineInterface::execute (libcudnn_graph.so.9) (26 samples, 0.10%)</title><rect x="20.2363%" y="900" width="0.1014%" height="15" fill="rgb(252,33,42)" fg:x="5189" fg:w="26"/><text x="20.4863%" y="910.50"></text></g><g><title>cudnn::cnn::EngineInterface::execute (libcudnn_graph.so.9) (26 samples, 0.10%)</title><rect x="20.2363%" y="916" width="0.1014%" height="15" fill="rgb(209,212,41)" fg:x="5189" fg:w="26"/><text x="20.4863%" y="926.50"></text></g><g><title>0x7ac465c80a2a (libcudnn_engines_precompiled.so.9) (26 samples, 0.10%)</title><rect x="20.2363%" y="932" width="0.1014%" height="15" fill="rgb(207,154,6)" fg:x="5189" fg:w="26"/><text x="20.4863%" y="942.50"></text></g><g><title>cudnnBackendExecute (libcudnn.so.9) (83 samples, 0.32%)</title><rect x="20.0725%" y="788" width="0.3237%" height="15" fill="rgb(223,64,47)" fg:x="5147" fg:w="83"/><text x="20.3225%" y="798.50"></text></g><g><title>cudnnBackendExecute (libcudnn_graph.so.9) (83 samples, 0.32%)</title><rect x="20.0725%" y="804" width="0.3237%" height="15" fill="rgb(211,161,38)" fg:x="5147" fg:w="83"/><text x="20.3225%" y="814.50"></text></g><g><title>cudnn::backend::execute (libcudnn_graph.so.9) (83 samples, 0.32%)</title><rect x="20.0725%" y="820" width="0.3237%" height="15" fill="rgb(219,138,40)" fg:x="5147" fg:w="83"/><text x="20.3225%" y="830.50"></text></g><g><title>cudnn::cnn::EngineInterface::execute (libcudnn_graph.so.9) (80 samples, 0.31%)</title><rect x="20.0842%" y="836" width="0.3120%" height="15" fill="rgb(241,228,46)" fg:x="5150" fg:w="80"/><text x="20.3342%" y="846.50"></text></g><g><title>at::native::run_conv_plan (libtorch_cuda.so) (112 samples, 0.44%)</title><rect x="20.0179%" y="772" width="0.4368%" height="15" fill="rgb(223,209,38)" fg:x="5133" fg:w="112"/><text x="20.2679%" y="782.50"></text></g><g><title>at::native::cudnn_convolution (libtorch_cuda.so) (160 samples, 0.62%)</title><rect x="19.8970%" y="708" width="0.6240%" height="15" fill="rgb(236,164,45)" fg:x="5102" fg:w="160"/><text x="20.1470%" y="718.50"></text></g><g><title>at::native::cudnn_convolution_forward_out (libtorch_cuda.so) (149 samples, 0.58%)</title><rect x="19.9399%" y="724" width="0.5811%" height="15" fill="rgb(231,15,5)" fg:x="5113" fg:w="149"/><text x="20.1899%" y="734.50"></text></g><g><title>at::native::raw_cudnn_convolution_forward_out (libtorch_cuda.so) (141 samples, 0.55%)</title><rect x="19.9711%" y="740" width="0.5499%" height="15" fill="rgb(252,35,15)" fg:x="5121" fg:w="141"/><text x="20.2211%" y="750.50"></text></g><g><title>at::native::run_single_conv (libtorch_cuda.so) (139 samples, 0.54%)</title><rect x="19.9789%" y="756" width="0.5421%" height="15" fill="rgb(248,181,18)" fg:x="5123" fg:w="139"/><text x="20.2289%" y="766.50"></text></g><g><title>at::_ops::cudnn_convolution::call (libtorch_cpu.so) (166 samples, 0.65%)</title><rect x="19.8892%" y="660" width="0.6474%" height="15" fill="rgb(233,39,42)" fg:x="5100" fg:w="166"/><text x="20.1392%" y="670.50"></text></g><g><title>c10::impl::wrap_kernel_functor_unboxed_&lt;c10::impl::detail::WrapFunctionIntoFunctor_&lt;c10::CompileTimeFunctionPointer&lt;at::Tensor(at::Tensor const&amp;, at::Tensor const&amp;, c10::ArrayRef&lt;c10::SymInt&gt;, c10::ArrayRef&lt;c10::SymInt&gt;, c10::ArrayRef&lt;c10::SymInt&gt;, c10::SymInt, bool, bool, bool), &amp;at::(anonymous namespace)::(anonymous namespace)::wrapper_CUDA__cudnn_convolution(at::Tensor const&amp;, at::Tensor const&amp;, c10::ArrayRef&lt;c10::SymInt&gt;, c10::ArrayRef&lt;c10::SymInt&gt;, c10::ArrayRef&lt;c10::SymInt&gt;, c10::SymInt, bool, bool, bool)&gt;, at::Tensor, c10::guts::typelist::typelist&lt;at::Tensor const&amp;, at::Tensor const&amp;, c10::ArrayRef&lt;c10::SymInt&gt;, c10::ArrayRef&lt;c10::SymInt&gt;, c10::ArrayRef&lt;c10::SymInt&gt;, c10::SymInt, bool, bool, bool&gt; &gt;, at::Tensor(at::Tensor const&amp;, at::Tensor const&amp;, c10::ArrayRef&lt;c10::SymInt&gt;, c10::ArrayRef&lt;c10::SymInt&gt;, c10::ArrayRef&lt;c10::SymInt&gt;, c10::SymInt, bool, bool, bool)&gt;::call (libtorch_cuda.so) (166 samples, 0.65%)</title><rect x="19.8892%" y="676" width="0.6474%" height="15" fill="rgb(238,110,33)" fg:x="5100" fg:w="166"/><text x="20.1392%" y="686.50"></text></g><g><title>at::(anonymous namespace)::(anonymous namespace)::wrapper_CUDA__cudnn_convolution (libtorch_cuda.so) (166 samples, 0.65%)</title><rect x="19.8892%" y="692" width="0.6474%" height="15" fill="rgb(233,195,10)" fg:x="5100" fg:w="166"/><text x="20.1392%" y="702.50"></text></g><g><title>at::_ops::_convolution::call (libtorch_cpu.so) (185 samples, 0.72%)</title><rect x="19.8775%" y="596" width="0.7215%" height="15" fill="rgb(254,105,3)" fg:x="5097" fg:w="185"/><text x="20.1275%" y="606.50"></text></g><g><title>c10::impl::wrap_kernel_functor_unboxed_&lt;c10::impl::detail::WrapFunctionIntoFunctor_&lt;c10::CompileTimeFunctionPointer&lt;at::Tensor(at::Tensor const&amp;, at::Tensor const&amp;, std::optional&lt;at::Tensor&gt; const&amp;, c10::ArrayRef&lt;c10::SymInt&gt;, c10::ArrayRef&lt;c10::SymInt&gt;, c10::ArrayRef&lt;c10::SymInt&gt;, bool, c10::ArrayRef&lt;c10::SymInt&gt;, c10::SymInt, bool, bool, bool, bool), &amp;at::(anonymous namespace)::(anonymous namespace)::wrapper_CompositeExplicitAutograd___convolution(at::Tensor const&amp;, at::Tensor const&amp;, std::optional&lt;at::Tensor&gt; const&amp;, c10::ArrayRef&lt;c10::SymInt&gt;, c10::ArrayRef&lt;c10::SymInt&gt;, c10::ArrayRef&lt;c10::SymInt&gt;, bool, c10::ArrayRef&lt;c10::SymInt&gt;, c10::SymInt, bool, bool, bool, bool)&gt;, at::Tensor, c10::guts::typelist::typelist&lt;at::Tensor const&amp;, at::Tensor const&amp;, std::optional&lt;at::Tensor&gt; const&amp;, c10::ArrayRef&lt;c10::SymInt&gt;, c10::ArrayRef&lt;c10::SymInt&gt;, c10::ArrayRef&lt;c10::SymInt&gt;, bool, c10::ArrayRef&lt;c10::SymInt&gt;, c10::SymInt, bool, bool, bool, bool&gt; &gt;, at::Tensor(at::Tensor const&amp;, at::Tensor const&amp;, std::optional&lt;at::Tensor&gt; const&amp;, c10::ArrayRef&lt;c10::SymInt&gt;, c10::ArrayRef&lt;c10::SymInt&gt;, c10::ArrayRef&lt;c10::SymInt&gt;, bool, c10::ArrayRef&lt;c10::SymInt&gt;, c10::SymInt, bool, bool, bool, bool)&gt;::call (libtorch_cpu.so) (183 samples, 0.71%)</title><rect x="19.8853%" y="612" width="0.7137%" height="15" fill="rgb(221,225,9)" fg:x="5099" fg:w="183"/><text x="20.1353%" y="622.50"></text></g><g><title>at::(anonymous namespace)::(anonymous namespace)::wrapper_CompositeExplicitAutograd___convolution (libtorch_cpu.so) (183 samples, 0.71%)</title><rect x="19.8853%" y="628" width="0.7137%" height="15" fill="rgb(224,227,45)" fg:x="5099" fg:w="183"/><text x="20.1353%" y="638.50"></text></g><g><title>at::native::_convolution (libtorch_cpu.so) (183 samples, 0.71%)</title><rect x="19.8853%" y="644" width="0.7137%" height="15" fill="rgb(229,198,43)" fg:x="5099" fg:w="183"/><text x="20.1353%" y="654.50"></text></g><g><title>at::_ops::convolution::redispatch (libtorch_cpu.so) (189 samples, 0.74%)</title><rect x="19.8658%" y="532" width="0.7371%" height="15" fill="rgb(206,209,35)" fg:x="5094" fg:w="189"/><text x="20.1158%" y="542.50"></text></g><g><title>c10::impl::wrap_kernel_functor_unboxed_&lt;c10::impl::detail::WrapFunctionIntoFunctor_&lt;c10::CompileTimeFunctionPointer&lt;at::Tensor(at::Tensor const&amp;, at::Tensor const&amp;, std::optional&lt;at::Tensor&gt; const&amp;, c10::ArrayRef&lt;c10::SymInt&gt;, c10::ArrayRef&lt;c10::SymInt&gt;, c10::ArrayRef&lt;c10::SymInt&gt;, bool, c10::ArrayRef&lt;c10::SymInt&gt;, c10::SymInt), &amp;at::(anonymous namespace)::(anonymous namespace)::wrapper_CompositeExplicitAutograd__convolution(at::Tensor const&amp;, at::Tensor const&amp;, std::optional&lt;at::Tensor&gt; const&amp;, c10::ArrayRef&lt;c10::SymInt&gt;, c10::ArrayRef&lt;c10::SymInt&gt;, c10::ArrayRef&lt;c10::SymInt&gt;, bool, c10::ArrayRef&lt;c10::SymInt&gt;, c10::SymInt)&gt;, at::Tensor, c10::guts::typelist::typelist&lt;at::Tensor const&amp;, at::Tensor const&amp;, std::optional&lt;at::Tensor&gt; const&amp;, c10::ArrayRef&lt;c10::SymInt&gt;, c10::ArrayRef&lt;c10::SymInt&gt;, c10::ArrayRef&lt;c10::SymInt&gt;, bool, c10::ArrayRef&lt;c10::SymInt&gt;, c10::SymInt&gt; &gt;, at::Tensor(at::Tensor const&amp;, at::Tensor const&amp;, std::optional&lt;at::Tensor&gt; const&amp;, c10::ArrayRef&lt;c10::SymInt&gt;, c10::ArrayRef&lt;c10::SymInt&gt;, c10::ArrayRef&lt;c10::SymInt&gt;, bool, c10::ArrayRef&lt;c10::SymInt&gt;, c10::SymInt)&gt;::call (libtorch_cpu.so) (188 samples, 0.73%)</title><rect x="19.8697%" y="548" width="0.7332%" height="15" fill="rgb(245,195,53)" fg:x="5095" fg:w="188"/><text x="20.1197%" y="558.50"></text></g><g><title>at::(anonymous namespace)::(anonymous namespace)::wrapper_CompositeExplicitAutograd__convolution (libtorch_cpu.so) (188 samples, 0.73%)</title><rect x="19.8697%" y="564" width="0.7332%" height="15" fill="rgb(240,92,26)" fg:x="5095" fg:w="188"/><text x="20.1197%" y="574.50"></text></g><g><title>at::native::convolution (libtorch_cpu.so) (188 samples, 0.73%)</title><rect x="19.8697%" y="580" width="0.7332%" height="15" fill="rgb(207,40,23)" fg:x="5095" fg:w="188"/><text x="20.1197%" y="590.50"></text></g><g><title>at::_ops::conv2d::call (libtorch_cpu.so) (199 samples, 0.78%)</title><rect x="19.8463%" y="436" width="0.7761%" height="15" fill="rgb(223,111,35)" fg:x="5089" fg:w="199"/><text x="20.0963%" y="446.50"></text></g><g><title>c10::impl::wrap_kernel_functor_unboxed_&lt;c10::impl::detail::WrapFunctionIntoFunctor_&lt;c10::CompileTimeFunctionPointer&lt;at::Tensor(at::Tensor const&amp;, at::Tensor const&amp;, std::optional&lt;at::Tensor&gt; const&amp;, c10::ArrayRef&lt;c10::SymInt&gt;, c10::ArrayRef&lt;c10::SymInt&gt;, c10::ArrayRef&lt;c10::SymInt&gt;, c10::SymInt), &amp;at::(anonymous namespace)::(anonymous namespace)::wrapper_CompositeImplicitAutograd__conv2d(at::Tensor const&amp;, at::Tensor const&amp;, std::optional&lt;at::Tensor&gt; const&amp;, c10::ArrayRef&lt;c10::SymInt&gt;, c10::ArrayRef&lt;c10::SymInt&gt;, c10::ArrayRef&lt;c10::SymInt&gt;, c10::SymInt)&gt;, at::Tensor, c10::guts::typelist::typelist&lt;at::Tensor const&amp;, at::Tensor const&amp;, std::optional&lt;at::Tensor&gt; const&amp;, c10::ArrayRef&lt;c10::SymInt&gt;, c10::ArrayRef&lt;c10::SymInt&gt;, c10::ArrayRef&lt;c10::SymInt&gt;, c10::SymInt&gt; &gt;, at::Tensor(at::Tensor const&amp;, at::Tensor const&amp;, std::optional&lt;at::Tensor&gt; const&amp;, c10::ArrayRef&lt;c10::SymInt&gt;, c10::ArrayRef&lt;c10::SymInt&gt;, c10::ArrayRef&lt;c10::SymInt&gt;, c10::SymInt)&gt;::call (libtorch_cpu.so) (198 samples, 0.77%)</title><rect x="19.8502%" y="452" width="0.7722%" height="15" fill="rgb(229,147,28)" fg:x="5090" fg:w="198"/><text x="20.1002%" y="462.50"></text></g><g><title>at::native::conv2d_symint (libtorch_cpu.so) (198 samples, 0.77%)</title><rect x="19.8502%" y="468" width="0.7722%" height="15" fill="rgb(211,29,28)" fg:x="5090" fg:w="198"/><text x="20.1002%" y="478.50"></text></g><g><title>at::_ops::convolution::call (libtorch_cpu.so) (197 samples, 0.77%)</title><rect x="19.8541%" y="484" width="0.7683%" height="15" fill="rgb(228,72,33)" fg:x="5091" fg:w="197"/><text x="20.1041%" y="494.50"></text></g><g><title>c10::impl::wrap_kernel_functor_unboxed_&lt;c10::impl::detail::WrapFunctionIntoFunctor_&lt;c10::CompileTimeFunctionPointer&lt;at::Tensor(c10::DispatchKeySet, at::Tensor const&amp;, at::Tensor const&amp;, std::optional&lt;at::Tensor&gt; const&amp;, c10::ArrayRef&lt;c10::SymInt&gt;, c10::ArrayRef&lt;c10::SymInt&gt;, c10::ArrayRef&lt;c10::SymInt&gt;, bool, c10::ArrayRef&lt;c10::SymInt&gt;, c10::SymInt), &amp;torch::autograd::VariableType::(anonymous namespace)::convolution(c10::DispatchKeySet, at::Tensor const&amp;, at::Tensor const&amp;, std::optional&lt;at::Tensor&gt; const&amp;, c10::ArrayRef&lt;c10::SymInt&gt;, c10::ArrayRef&lt;c10::SymInt&gt;, c10::ArrayRef&lt;c10::SymInt&gt;, bool, c10::ArrayRef&lt;c10::SymInt&gt;, c10::SymInt)&gt;, at::Tensor, c10::guts::typelist::typelist&lt;c10::DispatchKeySet, at::Tensor const&amp;, at::Tensor const&amp;, std::optional&lt;at::Tensor&gt; const&amp;, c10::ArrayRef&lt;c10::SymInt&gt;, c10::ArrayRef&lt;c10::SymInt&gt;, c10::ArrayRef&lt;c10::SymInt&gt;, bool, c10::ArrayRef&lt;c10::SymInt&gt;, c10::SymInt&gt; &gt;, at::Tensor(c10::DispatchKeySet, at::Tensor const&amp;, at::Tensor const&amp;, std::optional&lt;at::Tensor&gt; const&amp;, c10::ArrayRef&lt;c10::SymInt&gt;, c10::ArrayRef&lt;c10::SymInt&gt;, c10::ArrayRef&lt;c10::SymInt&gt;, bool, c10::ArrayRef&lt;c10::SymInt&gt;, c10::SymInt)&gt;::call (libtorch_cpu.so) (195 samples, 0.76%)</title><rect x="19.8619%" y="500" width="0.7605%" height="15" fill="rgb(205,214,31)" fg:x="5093" fg:w="195"/><text x="20.1119%" y="510.50"></text></g><g><title>torch::autograd::VariableType::(anonymous namespace)::convolution (libtorch_cpu.so) (195 samples, 0.76%)</title><rect x="19.8619%" y="516" width="0.7605%" height="15" fill="rgb(224,111,15)" fg:x="5093" fg:w="195"/><text x="20.1119%" y="526.50"></text></g><g><title>_wrapped_call_impl (torch/nn/modules/module.py:1773) (461 samples, 1.80%)</title><rect x="18.9065%" y="356" width="1.7978%" height="15" fill="rgb(253,21,26)" fg:x="4848" fg:w="461"/><text x="19.1565%" y="366.50">_..</text></g><g><title>_call_impl (torch/nn/modules/module.py:1784) (441 samples, 1.72%)</title><rect x="18.9845%" y="372" width="1.7198%" height="15" fill="rgb(245,139,43)" fg:x="4868" fg:w="441"/><text x="19.2345%" y="382.50"></text></g><g><title>forward (torch/nn/modules/conv.py:548) (246 samples, 0.96%)</title><rect x="19.7449%" y="388" width="0.9594%" height="15" fill="rgb(252,170,7)" fg:x="5063" fg:w="246"/><text x="19.9949%" y="398.50"></text></g><g><title>_conv_forward (torch/nn/modules/conv.py:544) (230 samples, 0.90%)</title><rect x="19.8073%" y="404" width="0.8970%" height="15" fill="rgb(231,118,14)" fg:x="5079" fg:w="230"/><text x="20.0573%" y="414.50"></text></g><g><title>torch::autograd::THPVariable_conv2d (libtorch_python.so) (223 samples, 0.87%)</title><rect x="19.8346%" y="420" width="0.8697%" height="15" fill="rgb(238,83,0)" fg:x="5086" fg:w="223"/><text x="20.0846%" y="430.50"></text></g><g><title>at::native::(anonymous namespace)::clamp_min_scalar_kernel_impl (libtorch_cuda.so) (32 samples, 0.12%)</title><rect x="20.8486%" y="548" width="0.1248%" height="15" fill="rgb(221,39,39)" fg:x="5346" fg:w="32"/><text x="21.0986%" y="558.50"></text></g><g><title>at::native::(anonymous namespace)::launch_clamp_scalar(at::TensorIteratorBase&amp;, c10::Scalar, c10::Scalar, at::native::detail::ClampLimits)::{lambda()#1}::operator() const (libtorch_cuda.so) (31 samples, 0.12%)</title><rect x="20.8525%" y="564" width="0.1209%" height="15" fill="rgb(222,119,46)" fg:x="5347" fg:w="31"/><text x="21.1025%" y="574.50"></text></g><g><title>at::native::relu (libtorch_cpu.so) (62 samples, 0.24%)</title><rect x="20.7394%" y="468" width="0.2418%" height="15" fill="rgb(222,165,49)" fg:x="5318" fg:w="62"/><text x="20.9894%" y="478.50"></text></g><g><title>at::_ops::clamp_min::call (libtorch_cpu.so) (60 samples, 0.23%)</title><rect x="20.7472%" y="484" width="0.2340%" height="15" fill="rgb(219,113,52)" fg:x="5320" fg:w="60"/><text x="20.9972%" y="494.50"></text></g><g><title>c10::impl::wrap_kernel_functor_unboxed_&lt;c10::impl::detail::WrapFunctionIntoFunctor_&lt;c10::CompileTimeFunctionPointer&lt;at::Tensor(at::Tensor const&amp;, c10::Scalar const&amp;), &amp;at::(anonymous namespace)::wrapper_CUDA_clamp_min(at::Tensor const&amp;, c10::Scalar const&amp;)&gt;, at::Tensor, c10::guts::typelist::typelist&lt;at::Tensor const&amp;, c10::Scalar const&amp;&gt; &gt;, at::Tensor(at::Tensor const&amp;, c10::Scalar const&amp;)&gt;::call (libtorch_cuda.so) (58 samples, 0.23%)</title><rect x="20.7550%" y="500" width="0.2262%" height="15" fill="rgb(214,7,15)" fg:x="5322" fg:w="58"/><text x="21.0050%" y="510.50"></text></g><g><title>at::(anonymous namespace)::wrapper_CUDA_clamp_min (libtorch_cuda.so) (58 samples, 0.23%)</title><rect x="20.7550%" y="516" width="0.2262%" height="15" fill="rgb(235,32,4)" fg:x="5322" fg:w="58"/><text x="21.0050%" y="526.50"></text></g><g><title>at::native::structured_clamp_min_out::impl (libtorch_cpu.so) (36 samples, 0.14%)</title><rect x="20.8408%" y="532" width="0.1404%" height="15" fill="rgb(238,90,54)" fg:x="5344" fg:w="36"/><text x="21.0908%" y="542.50"></text></g><g><title>at::_ops::relu::redispatch (libtorch_cpu.so) (63 samples, 0.25%)</title><rect x="20.7394%" y="436" width="0.2457%" height="15" fill="rgb(213,208,19)" fg:x="5318" fg:w="63"/><text x="20.9894%" y="446.50"></text></g><g><title>c10::impl::wrap_kernel_functor_unboxed_&lt;c10::impl::detail::WrapFunctionIntoFunctor_&lt;c10::CompileTimeFunctionPointer&lt;at::Tensor(at::Tensor const&amp;), &amp;at::(anonymous namespace)::(anonymous namespace)::wrapper_CUDA__relu(at::Tensor const&amp;)&gt;, at::Tensor, c10::guts::typelist::typelist&lt;at::Tensor const&amp;&gt; &gt;, at::Tensor(at::Tensor const&amp;)&gt;::call (libtorch_cuda.so) (63 samples, 0.25%)</title><rect x="20.7394%" y="452" width="0.2457%" height="15" fill="rgb(233,156,4)" fg:x="5318" fg:w="63"/><text x="20.9894%" y="462.50"></text></g><g><title>at::_ops::relu::call (libtorch_cpu.so) (68 samples, 0.27%)</title><rect x="20.7316%" y="388" width="0.2652%" height="15" fill="rgb(207,194,5)" fg:x="5316" fg:w="68"/><text x="20.9816%" y="398.50"></text></g><g><title>c10::impl::wrap_kernel_functor_unboxed_&lt;c10::impl::detail::WrapFunctionIntoFunctor_&lt;c10::CompileTimeFunctionPointer&lt;at::Tensor(c10::DispatchKeySet, at::Tensor const&amp;), &amp;torch::autograd::VariableType::(anonymous namespace)::relu(c10::DispatchKeySet, at::Tensor const&amp;)&gt;, at::Tensor, c10::guts::typelist::typelist&lt;c10::DispatchKeySet, at::Tensor const&amp;&gt; &gt;, at::Tensor(c10::DispatchKeySet, at::Tensor const&amp;)&gt;::call (libtorch_cpu.so) (68 samples, 0.27%)</title><rect x="20.7316%" y="404" width="0.2652%" height="15" fill="rgb(206,111,30)" fg:x="5316" fg:w="68"/><text x="20.9816%" y="414.50"></text></g><g><title>torch::autograd::VariableType::(anonymous namespace)::relu (libtorch_cpu.so) (67 samples, 0.26%)</title><rect x="20.7355%" y="420" width="0.2613%" height="15" fill="rgb(243,70,54)" fg:x="5317" fg:w="67"/><text x="20.9855%" y="430.50"></text></g><g><title>relu (torch/nn/functional.py:1701) (76 samples, 0.30%)</title><rect x="20.7121%" y="356" width="0.2964%" height="15" fill="rgb(242,28,8)" fg:x="5311" fg:w="76"/><text x="20.9621%" y="366.50"></text></g><g><title>torch::autograd::THPVariable_relu (libtorch_python.so) (74 samples, 0.29%)</title><rect x="20.7199%" y="372" width="0.2886%" height="15" fill="rgb(219,106,18)" fg:x="5313" fg:w="74"/><text x="20.9699%" y="382.50"></text></g><g><title>forward (armada_net.py:30) (572 samples, 2.23%)</title><rect x="18.7817%" y="340" width="2.2307%" height="15" fill="rgb(244,222,10)" fg:x="4816" fg:w="572"/><text x="19.0317%" y="350.50">f..</text></g><g><title>cudnnBatchNormalizationForwardInference (libcudnn_ops.so.9) (29 samples, 0.11%)</title><rect x="21.7144%" y="644" width="0.1131%" height="15" fill="rgb(236,179,52)" fg:x="5568" fg:w="29"/><text x="21.9644%" y="654.50"></text></g><g><title>at::native::cudnn_batch_norm (libtorch_cuda.so) (108 samples, 0.42%)</title><rect x="21.4102%" y="628" width="0.4212%" height="15" fill="rgb(213,23,39)" fg:x="5490" fg:w="108"/><text x="21.6602%" y="638.50"></text></g><g><title>at::_ops::cudnn_batch_norm::redispatch (libtorch_cpu.so) (111 samples, 0.43%)</title><rect x="21.4063%" y="580" width="0.4329%" height="15" fill="rgb(238,48,10)" fg:x="5489" fg:w="111"/><text x="21.6563%" y="590.50"></text></g><g><title>c10::impl::wrap_kernel_functor_unboxed_&lt;c10::impl::detail::WrapFunctionIntoFunctor_&lt;c10::CompileTimeFunctionPointer&lt;std::tuple&lt;at::Tensor, at::Tensor, at::Tensor, at::Tensor&gt; (at::Tensor const&amp;, at::Tensor const&amp;, std::optional&lt;at::Tensor&gt; const&amp;, std::optional&lt;at::Tensor&gt; const&amp;, std::optional&lt;at::Tensor&gt; const&amp;, bool, double, double), &amp;at::(anonymous namespace)::(anonymous namespace)::wrapper_CUDA__cudnn_batch_norm(at::Tensor const&amp;, at::Tensor const&amp;, std::optional&lt;at::Tensor&gt; const&amp;, std::optional&lt;at::Tensor&gt; const&amp;, std::optional&lt;at::Tensor&gt; const&amp;, bool, double, double)&gt;, std::tuple&lt;at::Tensor, at::Tensor, at::Tensor, at::Tensor&gt;, c10::guts::typelist::typelist&lt;at::Tensor const&amp;, at::Tensor const&amp;, std::optional&lt;at::Tensor&gt; const&amp;, std::optional&lt;at::Tensor&gt; const&amp;, std::optional&lt;at::Tensor&gt; const&amp;, bool, double, double&gt; &gt;, std::tuple&lt;at::Tensor, at::Tensor, at::Tensor, at::Tensor&gt; (at::Tensor const&amp;, at::Tensor const&amp;, std::optional&lt;at::Tensor&gt; const&amp;, std::optional&lt;at::Tensor&gt; const&amp;, std::optional&lt;at::Tensor&gt; const&amp;, bool, double, double)&gt;::call (libtorch_cuda.so) (111 samples, 0.43%)</title><rect x="21.4063%" y="596" width="0.4329%" height="15" fill="rgb(251,196,23)" fg:x="5489" fg:w="111"/><text x="21.6563%" y="606.50"></text></g><g><title>at::(anonymous namespace)::(anonymous namespace)::wrapper_CUDA__cudnn_batch_norm (libtorch_cuda.so) (111 samples, 0.43%)</title><rect x="21.4063%" y="612" width="0.4329%" height="15" fill="rgb(250,152,24)" fg:x="5489" fg:w="111"/><text x="21.6563%" y="622.50"></text></g><g><title>at::_ops::cudnn_batch_norm::call (libtorch_cpu.so) (119 samples, 0.46%)</title><rect x="21.4024%" y="532" width="0.4641%" height="15" fill="rgb(209,150,17)" fg:x="5488" fg:w="119"/><text x="21.6524%" y="542.50"></text></g><g><title>c10::impl::wrap_kernel_functor_unboxed_&lt;c10::impl::detail::WrapFunctionIntoFunctor_&lt;c10::CompileTimeFunctionPointer&lt;std::tuple&lt;at::Tensor, at::Tensor, at::Tensor, at::Tensor&gt; (c10::DispatchKeySet, at::Tensor const&amp;, at::Tensor const&amp;, std::optional&lt;at::Tensor&gt; const&amp;, std::optional&lt;at::Tensor&gt; const&amp;, std::optional&lt;at::Tensor&gt; const&amp;, bool, double, double), &amp;torch::autograd::VariableType::(anonymous namespace)::cudnn_batch_norm(c10::DispatchKeySet, at::Tensor const&amp;, at::Tensor const&amp;, std::optional&lt;at::Tensor&gt; const&amp;, std::optional&lt;at::Tensor&gt; const&amp;, std::optional&lt;at::Tensor&gt; const&amp;, bool, double, double)&gt;, std::tuple&lt;at::Tensor, at::Tensor, at::Tensor, at::Tensor&gt;, c10::guts::typelist::typelist&lt;c10::DispatchKeySet, at::Tensor const&amp;, at::Tensor const&amp;, std::optional&lt;at::Tensor&gt; const&amp;, std::optional&lt;at::Tensor&gt; const&amp;, std::optional&lt;at::Tensor&gt; const&amp;, bool, double, double&gt; &gt;, std::tuple&lt;at::Tensor, at::Tensor, at::Tensor, at::Tensor&gt; (c10::DispatchKeySet, at::Tensor const&amp;, at::Tensor const&amp;, std::optional&lt;at::Tensor&gt; const&amp;, std::optional&lt;at::Tensor&gt; const&amp;, std::optional&lt;at::Tensor&gt; const&amp;, bool, double, double)&gt;::call (libtorch_cpu.so) (118 samples, 0.46%)</title><rect x="21.4063%" y="548" width="0.4602%" height="15" fill="rgb(234,202,34)" fg:x="5489" fg:w="118"/><text x="21.6563%" y="558.50"></text></g><g><title>torch::autograd::VariableType::(anonymous namespace)::cudnn_batch_norm (libtorch_cpu.so) (118 samples, 0.46%)</title><rect x="21.4063%" y="564" width="0.4602%" height="15" fill="rgb(253,148,53)" fg:x="5489" fg:w="118"/><text x="21.6563%" y="574.50"></text></g><g><title>at::_ops::_batch_norm_impl_index::call (libtorch_cpu.so) (130 samples, 0.51%)</title><rect x="21.3907%" y="484" width="0.5070%" height="15" fill="rgb(218,129,16)" fg:x="5485" fg:w="130"/><text x="21.6407%" y="494.50"></text></g><g><title>c10::impl::wrap_kernel_functor_unboxed_&lt;c10::impl::detail::WrapFunctionIntoFunctor_&lt;c10::CompileTimeFunctionPointer&lt;std::tuple&lt;at::Tensor, at::Tensor, at::Tensor, at::Tensor, long&gt; (at::Tensor const&amp;, std::optional&lt;at::Tensor&gt; const&amp;, std::optional&lt;at::Tensor&gt; const&amp;, std::optional&lt;at::Tensor&gt; const&amp;, std::optional&lt;at::Tensor&gt; const&amp;, bool, double, double, bool), &amp;at::(anonymous namespace)::(anonymous namespace)::wrapper_CompositeImplicitAutograd___batch_norm_impl_index(at::Tensor const&amp;, std::optional&lt;at::Tensor&gt; const&amp;, std::optional&lt;at::Tensor&gt; const&amp;, std::optional&lt;at::Tensor&gt; const&amp;, std::optional&lt;at::Tensor&gt; const&amp;, bool, double, double, bool)&gt;, std::tuple&lt;at::Tensor, at::Tensor, at::Tensor, at::Tensor, long&gt;, c10::guts::typelist::typelist&lt;at::Tensor const&amp;, std::optional&lt;at::Tensor&gt; const&amp;, std::optional&lt;at::Tensor&gt; const&amp;, std::optional&lt;at::Tensor&gt; const&amp;, std::optional&lt;at::Tensor&gt; const&amp;, bool, double, double, bool&gt; &gt;, std::tuple&lt;at::Tensor, at::Tensor, at::Tensor, at::Tensor, long&gt; (at::Tensor const&amp;, std::optional&lt;at::Tensor&gt; const&amp;, std::optional&lt;at::Tensor&gt; const&amp;, std::optional&lt;at::Tensor&gt; const&amp;, std::optional&lt;at::Tensor&gt; const&amp;, bool, double, double, bool)&gt;::call (libtorch_cpu.so) (129 samples, 0.50%)</title><rect x="21.3946%" y="500" width="0.5031%" height="15" fill="rgb(216,85,19)" fg:x="5486" fg:w="129"/><text x="21.6446%" y="510.50"></text></g><g><title>at::native::_batch_norm_impl_index (libtorch_cpu.so) (129 samples, 0.50%)</title><rect x="21.3946%" y="516" width="0.5031%" height="15" fill="rgb(235,228,7)" fg:x="5486" fg:w="129"/><text x="21.6446%" y="526.50"></text></g><g><title>at::_ops::batch_norm::call (libtorch_cpu.so) (140 samples, 0.55%)</title><rect x="21.3751%" y="436" width="0.5460%" height="15" fill="rgb(245,175,0)" fg:x="5481" fg:w="140"/><text x="21.6251%" y="446.50"></text></g><g><title>c10::impl::wrap_kernel_functor_unboxed_&lt;c10::impl::detail::WrapFunctionIntoFunctor_&lt;c10::CompileTimeFunctionPointer&lt;at::Tensor(at::Tensor const&amp;, std::optional&lt;at::Tensor&gt; const&amp;, std::optional&lt;at::Tensor&gt; const&amp;, std::optional&lt;at::Tensor&gt; const&amp;, std::optional&lt;at::Tensor&gt; const&amp;, bool, double, double, bool), &amp;at::(anonymous namespace)::(anonymous namespace)::wrapper_CompositeImplicitAutograd__batch_norm(at::Tensor const&amp;, std::optional&lt;at::Tensor&gt; const&amp;, std::optional&lt;at::Tensor&gt; const&amp;, std::optional&lt;at::Tensor&gt; const&amp;, std::optional&lt;at::Tensor&gt; const&amp;, bool, double, double, bool)&gt;, at::Tensor, c10::guts::typelist::typelist&lt;at::Tensor const&amp;, std::optional&lt;at::Tensor&gt; const&amp;, std::optional&lt;at::Tensor&gt; const&amp;, std::optional&lt;at::Tensor&gt; const&amp;, std::optional&lt;at::Tensor&gt; const&amp;, bool, double, double, bool&gt; &gt;, at::Tensor(at::Tensor const&amp;, std::optional&lt;at::Tensor&gt; const&amp;, std::optional&lt;at::Tensor&gt; const&amp;, std::optional&lt;at::Tensor&gt; const&amp;, std::optional&lt;at::Tensor&gt; const&amp;, bool, double, double, bool)&gt;::call (libtorch_cpu.so) (138 samples, 0.54%)</title><rect x="21.3829%" y="452" width="0.5382%" height="15" fill="rgb(208,168,36)" fg:x="5483" fg:w="138"/><text x="21.6329%" y="462.50"></text></g><g><title>at::native::batch_norm (libtorch_cpu.so) (137 samples, 0.53%)</title><rect x="21.3868%" y="468" width="0.5343%" height="15" fill="rgb(246,171,24)" fg:x="5484" fg:w="137"/><text x="21.6368%" y="478.50"></text></g><g><title>forward (torch/nn/modules/batchnorm.py:193) (171 samples, 0.67%)</title><rect x="21.2971%" y="388" width="0.6669%" height="15" fill="rgb(215,142,24)" fg:x="5461" fg:w="171"/><text x="21.5471%" y="398.50"></text></g><g><title>batch_norm (torch/nn/functional.py:2826) (164 samples, 0.64%)</title><rect x="21.3244%" y="404" width="0.6396%" height="15" fill="rgb(250,187,7)" fg:x="5468" fg:w="164"/><text x="21.5744%" y="414.50"></text></g><g><title>torch::autograd::THPVariable_batch_norm (libtorch_python.so) (154 samples, 0.60%)</title><rect x="21.3634%" y="420" width="0.6006%" height="15" fill="rgb(228,66,33)" fg:x="5478" fg:w="154"/><text x="21.6134%" y="430.50"></text></g><g><title>0x7ac4653e902c (libcudnn_engines_precompiled.so.9) (26 samples, 0.10%)</title><rect x="22.3968%" y="868" width="0.1014%" height="15" fill="rgb(234,215,21)" fg:x="5743" fg:w="26"/><text x="22.6468%" y="878.50"></text></g><g><title>0x7ac4653e8334 (libcudnn_engines_precompiled.so.9) (26 samples, 0.10%)</title><rect x="22.3968%" y="884" width="0.1014%" height="15" fill="rgb(222,191,20)" fg:x="5743" fg:w="26"/><text x="22.6468%" y="894.50"></text></g><g><title>cudnn::cnn::EngineInterface::execute (libcudnn_graph.so.9) (26 samples, 0.10%)</title><rect x="22.3968%" y="900" width="0.1014%" height="15" fill="rgb(245,79,54)" fg:x="5743" fg:w="26"/><text x="22.6468%" y="910.50"></text></g><g><title>0x7ac465c89cdb (libcudnn_engines_precompiled.so.9) (26 samples, 0.10%)</title><rect x="22.3968%" y="916" width="0.1014%" height="15" fill="rgb(240,10,37)" fg:x="5743" fg:w="26"/><text x="22.6468%" y="926.50"></text></g><g><title>0x7ac465935569 (libcudnn_engines_precompiled.so.9) (26 samples, 0.10%)</title><rect x="22.3968%" y="932" width="0.1014%" height="15" fill="rgb(214,192,32)" fg:x="5743" fg:w="26"/><text x="22.6468%" y="942.50"></text></g><g><title>cudnnBackendExecute (libcudnn.so.9) (67 samples, 0.26%)</title><rect x="22.2409%" y="788" width="0.2613%" height="15" fill="rgb(209,36,54)" fg:x="5703" fg:w="67"/><text x="22.4909%" y="798.50"></text></g><g><title>cudnnBackendExecute (libcudnn_graph.so.9) (67 samples, 0.26%)</title><rect x="22.2409%" y="804" width="0.2613%" height="15" fill="rgb(220,10,11)" fg:x="5703" fg:w="67"/><text x="22.4909%" y="814.50"></text></g><g><title>cudnn::backend::execute (libcudnn_graph.so.9) (66 samples, 0.26%)</title><rect x="22.2448%" y="820" width="0.2574%" height="15" fill="rgb(221,106,17)" fg:x="5704" fg:w="66"/><text x="22.4948%" y="830.50"></text></g><g><title>cudnn::cnn::EngineInterface::execute (libcudnn_graph.so.9) (61 samples, 0.24%)</title><rect x="22.2643%" y="836" width="0.2379%" height="15" fill="rgb(251,142,44)" fg:x="5709" fg:w="61"/><text x="22.5143%" y="846.50"></text></g><g><title>0x7ac46540f8b9 (libcudnn_engines_precompiled.so.9) (27 samples, 0.11%)</title><rect x="22.3968%" y="852" width="0.1053%" height="15" fill="rgb(238,13,15)" fg:x="5743" fg:w="27"/><text x="22.6468%" y="862.50"></text></g><g><title>at::native::run_conv_plan (libtorch_cuda.so) (93 samples, 0.36%)</title><rect x="22.1902%" y="772" width="0.3627%" height="15" fill="rgb(208,107,27)" fg:x="5690" fg:w="93"/><text x="22.4402%" y="782.50"></text></g><g><title>at::native::cudnn_convolution (libtorch_cuda.so) (121 samples, 0.47%)</title><rect x="22.1005%" y="708" width="0.4719%" height="15" fill="rgb(205,136,37)" fg:x="5667" fg:w="121"/><text x="22.3505%" y="718.50"></text></g><g><title>at::native::cudnn_convolution_forward_out (libtorch_cuda.so) (110 samples, 0.43%)</title><rect x="22.1434%" y="724" width="0.4290%" height="15" fill="rgb(250,205,27)" fg:x="5678" fg:w="110"/><text x="22.3934%" y="734.50"></text></g><g><title>at::native::raw_cudnn_convolution_forward_out (libtorch_cuda.so) (104 samples, 0.41%)</title><rect x="22.1668%" y="740" width="0.4056%" height="15" fill="rgb(210,80,43)" fg:x="5684" fg:w="104"/><text x="22.4168%" y="750.50"></text></g><g><title>at::native::run_single_conv (libtorch_cuda.so) (104 samples, 0.41%)</title><rect x="22.1668%" y="756" width="0.4056%" height="15" fill="rgb(247,160,36)" fg:x="5684" fg:w="104"/><text x="22.4168%" y="766.50"></text></g><g><title>at::_ops::cudnn_convolution::call (libtorch_cpu.so) (128 samples, 0.50%)</title><rect x="22.0966%" y="660" width="0.4992%" height="15" fill="rgb(234,13,49)" fg:x="5666" fg:w="128"/><text x="22.3466%" y="670.50"></text></g><g><title>c10::impl::wrap_kernel_functor_unboxed_&lt;c10::impl::detail::WrapFunctionIntoFunctor_&lt;c10::CompileTimeFunctionPointer&lt;at::Tensor(at::Tensor const&amp;, at::Tensor const&amp;, c10::ArrayRef&lt;c10::SymInt&gt;, c10::ArrayRef&lt;c10::SymInt&gt;, c10::ArrayRef&lt;c10::SymInt&gt;, c10::SymInt, bool, bool, bool), &amp;at::(anonymous namespace)::(anonymous namespace)::wrapper_CUDA__cudnn_convolution(at::Tensor const&amp;, at::Tensor const&amp;, c10::ArrayRef&lt;c10::SymInt&gt;, c10::ArrayRef&lt;c10::SymInt&gt;, c10::ArrayRef&lt;c10::SymInt&gt;, c10::SymInt, bool, bool, bool)&gt;, at::Tensor, c10::guts::typelist::typelist&lt;at::Tensor const&amp;, at::Tensor const&amp;, c10::ArrayRef&lt;c10::SymInt&gt;, c10::ArrayRef&lt;c10::SymInt&gt;, c10::ArrayRef&lt;c10::SymInt&gt;, c10::SymInt, bool, bool, bool&gt; &gt;, at::Tensor(at::Tensor const&amp;, at::Tensor const&amp;, c10::ArrayRef&lt;c10::SymInt&gt;, c10::ArrayRef&lt;c10::SymInt&gt;, c10::ArrayRef&lt;c10::SymInt&gt;, c10::SymInt, bool, bool, bool)&gt;::call (libtorch_cuda.so) (127 samples, 0.50%)</title><rect x="22.1005%" y="676" width="0.4953%" height="15" fill="rgb(234,122,0)" fg:x="5667" fg:w="127"/><text x="22.3505%" y="686.50"></text></g><g><title>at::(anonymous namespace)::(anonymous namespace)::wrapper_CUDA__cudnn_convolution (libtorch_cuda.so) (127 samples, 0.50%)</title><rect x="22.1005%" y="692" width="0.4953%" height="15" fill="rgb(207,146,38)" fg:x="5667" fg:w="127"/><text x="22.3505%" y="702.50"></text></g><g><title>at::_ops::_convolution::call (libtorch_cpu.so) (145 samples, 0.57%)</title><rect x="22.0810%" y="596" width="0.5655%" height="15" fill="rgb(207,177,25)" fg:x="5662" fg:w="145"/><text x="22.3310%" y="606.50"></text></g><g><title>c10::impl::wrap_kernel_functor_unboxed_&lt;c10::impl::detail::WrapFunctionIntoFunctor_&lt;c10::CompileTimeFunctionPointer&lt;at::Tensor(at::Tensor const&amp;, at::Tensor const&amp;, std::optional&lt;at::Tensor&gt; const&amp;, c10::ArrayRef&lt;c10::SymInt&gt;, c10::ArrayRef&lt;c10::SymInt&gt;, c10::ArrayRef&lt;c10::SymInt&gt;, bool, c10::ArrayRef&lt;c10::SymInt&gt;, c10::SymInt, bool, bool, bool, bool), &amp;at::(anonymous namespace)::(anonymous namespace)::wrapper_CompositeExplicitAutograd___convolution(at::Tensor const&amp;, at::Tensor const&amp;, std::optional&lt;at::Tensor&gt; const&amp;, c10::ArrayRef&lt;c10::SymInt&gt;, c10::ArrayRef&lt;c10::SymInt&gt;, c10::ArrayRef&lt;c10::SymInt&gt;, bool, c10::ArrayRef&lt;c10::SymInt&gt;, c10::SymInt, bool, bool, bool, bool)&gt;, at::Tensor, c10::guts::typelist::typelist&lt;at::Tensor const&amp;, at::Tensor const&amp;, std::optional&lt;at::Tensor&gt; const&amp;, c10::ArrayRef&lt;c10::SymInt&gt;, c10::ArrayRef&lt;c10::SymInt&gt;, c10::ArrayRef&lt;c10::SymInt&gt;, bool, c10::ArrayRef&lt;c10::SymInt&gt;, c10::SymInt, bool, bool, bool, bool&gt; &gt;, at::Tensor(at::Tensor const&amp;, at::Tensor const&amp;, std::optional&lt;at::Tensor&gt; const&amp;, c10::ArrayRef&lt;c10::SymInt&gt;, c10::ArrayRef&lt;c10::SymInt&gt;, c10::ArrayRef&lt;c10::SymInt&gt;, bool, c10::ArrayRef&lt;c10::SymInt&gt;, c10::SymInt, bool, bool, bool, bool)&gt;::call (libtorch_cpu.so) (143 samples, 0.56%)</title><rect x="22.0888%" y="612" width="0.5577%" height="15" fill="rgb(211,178,42)" fg:x="5664" fg:w="143"/><text x="22.3388%" y="622.50"></text></g><g><title>at::(anonymous namespace)::(anonymous namespace)::wrapper_CompositeExplicitAutograd___convolution (libtorch_cpu.so) (143 samples, 0.56%)</title><rect x="22.0888%" y="628" width="0.5577%" height="15" fill="rgb(230,69,54)" fg:x="5664" fg:w="143"/><text x="22.3388%" y="638.50"></text></g><g><title>at::native::_convolution (libtorch_cpu.so) (141 samples, 0.55%)</title><rect x="22.0966%" y="644" width="0.5499%" height="15" fill="rgb(214,135,41)" fg:x="5666" fg:w="141"/><text x="22.3466%" y="654.50"></text></g><g><title>at::_ops::convolution::redispatch (libtorch_cpu.so) (148 samples, 0.58%)</title><rect x="22.0732%" y="532" width="0.5772%" height="15" fill="rgb(237,67,25)" fg:x="5660" fg:w="148"/><text x="22.3232%" y="542.50"></text></g><g><title>c10::impl::wrap_kernel_functor_unboxed_&lt;c10::impl::detail::WrapFunctionIntoFunctor_&lt;c10::CompileTimeFunctionPointer&lt;at::Tensor(at::Tensor const&amp;, at::Tensor const&amp;, std::optional&lt;at::Tensor&gt; const&amp;, c10::ArrayRef&lt;c10::SymInt&gt;, c10::ArrayRef&lt;c10::SymInt&gt;, c10::ArrayRef&lt;c10::SymInt&gt;, bool, c10::ArrayRef&lt;c10::SymInt&gt;, c10::SymInt), &amp;at::(anonymous namespace)::(anonymous namespace)::wrapper_CompositeExplicitAutograd__convolution(at::Tensor const&amp;, at::Tensor const&amp;, std::optional&lt;at::Tensor&gt; const&amp;, c10::ArrayRef&lt;c10::SymInt&gt;, c10::ArrayRef&lt;c10::SymInt&gt;, c10::ArrayRef&lt;c10::SymInt&gt;, bool, c10::ArrayRef&lt;c10::SymInt&gt;, c10::SymInt)&gt;, at::Tensor, c10::guts::typelist::typelist&lt;at::Tensor const&amp;, at::Tensor const&amp;, std::optional&lt;at::Tensor&gt; const&amp;, c10::ArrayRef&lt;c10::SymInt&gt;, c10::ArrayRef&lt;c10::SymInt&gt;, c10::ArrayRef&lt;c10::SymInt&gt;, bool, c10::ArrayRef&lt;c10::SymInt&gt;, c10::SymInt&gt; &gt;, at::Tensor(at::Tensor const&amp;, at::Tensor const&amp;, std::optional&lt;at::Tensor&gt; const&amp;, c10::ArrayRef&lt;c10::SymInt&gt;, c10::ArrayRef&lt;c10::SymInt&gt;, c10::ArrayRef&lt;c10::SymInt&gt;, bool, c10::ArrayRef&lt;c10::SymInt&gt;, c10::SymInt)&gt;::call (libtorch_cpu.so) (147 samples, 0.57%)</title><rect x="22.0771%" y="548" width="0.5733%" height="15" fill="rgb(222,189,50)" fg:x="5661" fg:w="147"/><text x="22.3271%" y="558.50"></text></g><g><title>at::(anonymous namespace)::(anonymous namespace)::wrapper_CompositeExplicitAutograd__convolution (libtorch_cpu.so) (147 samples, 0.57%)</title><rect x="22.0771%" y="564" width="0.5733%" height="15" fill="rgb(245,148,34)" fg:x="5661" fg:w="147"/><text x="22.3271%" y="574.50"></text></g><g><title>at::native::convolution (libtorch_cpu.so) (147 samples, 0.57%)</title><rect x="22.0771%" y="580" width="0.5733%" height="15" fill="rgb(222,29,6)" fg:x="5661" fg:w="147"/><text x="22.3271%" y="590.50"></text></g><g><title>at::_ops::conv2d::call (libtorch_cpu.so) (156 samples, 0.61%)</title><rect x="22.0459%" y="436" width="0.6084%" height="15" fill="rgb(221,189,43)" fg:x="5653" fg:w="156"/><text x="22.2959%" y="446.50"></text></g><g><title>c10::impl::wrap_kernel_functor_unboxed_&lt;c10::impl::detail::WrapFunctionIntoFunctor_&lt;c10::CompileTimeFunctionPointer&lt;at::Tensor(at::Tensor const&amp;, at::Tensor const&amp;, std::optional&lt;at::Tensor&gt; const&amp;, c10::ArrayRef&lt;c10::SymInt&gt;, c10::ArrayRef&lt;c10::SymInt&gt;, c10::ArrayRef&lt;c10::SymInt&gt;, c10::SymInt), &amp;at::(anonymous namespace)::(anonymous namespace)::wrapper_CompositeImplicitAutograd__conv2d(at::Tensor const&amp;, at::Tensor const&amp;, std::optional&lt;at::Tensor&gt; const&amp;, c10::ArrayRef&lt;c10::SymInt&gt;, c10::ArrayRef&lt;c10::SymInt&gt;, c10::ArrayRef&lt;c10::SymInt&gt;, c10::SymInt)&gt;, at::Tensor, c10::guts::typelist::typelist&lt;at::Tensor const&amp;, at::Tensor const&amp;, std::optional&lt;at::Tensor&gt; const&amp;, c10::ArrayRef&lt;c10::SymInt&gt;, c10::ArrayRef&lt;c10::SymInt&gt;, c10::ArrayRef&lt;c10::SymInt&gt;, c10::SymInt&gt; &gt;, at::Tensor(at::Tensor const&amp;, at::Tensor const&amp;, std::optional&lt;at::Tensor&gt; const&amp;, c10::ArrayRef&lt;c10::SymInt&gt;, c10::ArrayRef&lt;c10::SymInt&gt;, c10::ArrayRef&lt;c10::SymInt&gt;, c10::SymInt)&gt;::call (libtorch_cpu.so) (155 samples, 0.60%)</title><rect x="22.0498%" y="452" width="0.6045%" height="15" fill="rgb(207,36,27)" fg:x="5654" fg:w="155"/><text x="22.2998%" y="462.50"></text></g><g><title>at::native::conv2d_symint (libtorch_cpu.so) (154 samples, 0.60%)</title><rect x="22.0537%" y="468" width="0.6006%" height="15" fill="rgb(217,90,24)" fg:x="5655" fg:w="154"/><text x="22.3037%" y="478.50"></text></g><g><title>at::_ops::convolution::call (libtorch_cpu.so) (153 samples, 0.60%)</title><rect x="22.0576%" y="484" width="0.5967%" height="15" fill="rgb(224,66,35)" fg:x="5656" fg:w="153"/><text x="22.3076%" y="494.50"></text></g><g><title>c10::impl::wrap_kernel_functor_unboxed_&lt;c10::impl::detail::WrapFunctionIntoFunctor_&lt;c10::CompileTimeFunctionPointer&lt;at::Tensor(c10::DispatchKeySet, at::Tensor const&amp;, at::Tensor const&amp;, std::optional&lt;at::Tensor&gt; const&amp;, c10::ArrayRef&lt;c10::SymInt&gt;, c10::ArrayRef&lt;c10::SymInt&gt;, c10::ArrayRef&lt;c10::SymInt&gt;, bool, c10::ArrayRef&lt;c10::SymInt&gt;, c10::SymInt), &amp;torch::autograd::VariableType::(anonymous namespace)::convolution(c10::DispatchKeySet, at::Tensor const&amp;, at::Tensor const&amp;, std::optional&lt;at::Tensor&gt; const&amp;, c10::ArrayRef&lt;c10::SymInt&gt;, c10::ArrayRef&lt;c10::SymInt&gt;, c10::ArrayRef&lt;c10::SymInt&gt;, bool, c10::ArrayRef&lt;c10::SymInt&gt;, c10::SymInt)&gt;, at::Tensor, c10::guts::typelist::typelist&lt;c10::DispatchKeySet, at::Tensor const&amp;, at::Tensor const&amp;, std::optional&lt;at::Tensor&gt; const&amp;, c10::ArrayRef&lt;c10::SymInt&gt;, c10::ArrayRef&lt;c10::SymInt&gt;, c10::ArrayRef&lt;c10::SymInt&gt;, bool, c10::ArrayRef&lt;c10::SymInt&gt;, c10::SymInt&gt; &gt;, at::Tensor(c10::DispatchKeySet, at::Tensor const&amp;, at::Tensor const&amp;, std::optional&lt;at::Tensor&gt; const&amp;, c10::ArrayRef&lt;c10::SymInt&gt;, c10::ArrayRef&lt;c10::SymInt&gt;, c10::ArrayRef&lt;c10::SymInt&gt;, bool, c10::ArrayRef&lt;c10::SymInt&gt;, c10::SymInt)&gt;::call (libtorch_cpu.so) (151 samples, 0.59%)</title><rect x="22.0654%" y="500" width="0.5889%" height="15" fill="rgb(221,13,50)" fg:x="5658" fg:w="151"/><text x="22.3154%" y="510.50"></text></g><g><title>torch::autograd::VariableType::(anonymous namespace)::convolution (libtorch_cpu.so) (151 samples, 0.59%)</title><rect x="22.0654%" y="516" width="0.5889%" height="15" fill="rgb(236,68,49)" fg:x="5658" fg:w="151"/><text x="22.3154%" y="526.50"></text></g><g><title>forward (armada_net.py:31) (440 samples, 1.72%)</title><rect x="21.0124%" y="340" width="1.7159%" height="15" fill="rgb(229,146,28)" fg:x="5388" fg:w="440"/><text x="21.2624%" y="350.50"></text></g><g><title>_wrapped_call_impl (torch/nn/modules/module.py:1773) (407 samples, 1.59%)</title><rect x="21.1411%" y="356" width="1.5872%" height="15" fill="rgb(225,31,38)" fg:x="5421" fg:w="407"/><text x="21.3911%" y="366.50"></text></g><g><title>_call_impl (torch/nn/modules/module.py:1784) (380 samples, 1.48%)</title><rect x="21.2464%" y="372" width="1.4819%" height="15" fill="rgb(250,208,3)" fg:x="5448" fg:w="380"/><text x="21.4964%" y="382.50"></text></g><g><title>forward (torch/nn/modules/conv.py:548) (190 samples, 0.74%)</title><rect x="21.9874%" y="388" width="0.7410%" height="15" fill="rgb(246,54,23)" fg:x="5638" fg:w="190"/><text x="22.2374%" y="398.50"></text></g><g><title>_conv_forward (torch/nn/modules/conv.py:544) (183 samples, 0.71%)</title><rect x="22.0147%" y="404" width="0.7137%" height="15" fill="rgb(243,76,11)" fg:x="5645" fg:w="183"/><text x="22.2647%" y="414.50"></text></g><g><title>torch::autograd::THPVariable_conv2d (libtorch_python.so) (180 samples, 0.70%)</title><rect x="22.0264%" y="420" width="0.7020%" height="15" fill="rgb(245,21,50)" fg:x="5648" fg:w="180"/><text x="22.2764%" y="430.50"></text></g><g><title>at::native::cudnn_batch_norm (libtorch_cuda.so) (30 samples, 0.12%)</title><rect x="23.1300%" y="676" width="0.1170%" height="15" fill="rgb(228,9,43)" fg:x="5931" fg:w="30"/><text x="23.3800%" y="686.50"></text></g><g><title>at::_ops::cudnn_batch_norm::redispatch (libtorch_cpu.so) (32 samples, 0.12%)</title><rect x="23.1300%" y="628" width="0.1248%" height="15" fill="rgb(208,100,47)" fg:x="5931" fg:w="32"/><text x="23.3800%" y="638.50"></text></g><g><title>c10::impl::wrap_kernel_functor_unboxed_&lt;c10::impl::detail::WrapFunctionIntoFunctor_&lt;c10::CompileTimeFunctionPointer&lt;std::tuple&lt;at::Tensor, at::Tensor, at::Tensor, at::Tensor&gt; (at::Tensor const&amp;, at::Tensor const&amp;, std::optional&lt;at::Tensor&gt; const&amp;, std::optional&lt;at::Tensor&gt; const&amp;, std::optional&lt;at::Tensor&gt; const&amp;, bool, double, double), &amp;at::(anonymous namespace)::(anonymous namespace)::wrapper_CUDA__cudnn_batch_norm(at::Tensor const&amp;, at::Tensor const&amp;, std::optional&lt;at::Tensor&gt; const&amp;, std::optional&lt;at::Tensor&gt; const&amp;, std::optional&lt;at::Tensor&gt; const&amp;, bool, double, double)&gt;, std::tuple&lt;at::Tensor, at::Tensor, at::Tensor, at::Tensor&gt;, c10::guts::typelist::typelist&lt;at::Tensor const&amp;, at::Tensor const&amp;, std::optional&lt;at::Tensor&gt; const&amp;, std::optional&lt;at::Tensor&gt; const&amp;, std::optional&lt;at::Tensor&gt; const&amp;, bool, double, double&gt; &gt;, std::tuple&lt;at::Tensor, at::Tensor, at::Tensor, at::Tensor&gt; (at::Tensor const&amp;, at::Tensor const&amp;, std::optional&lt;at::Tensor&gt; const&amp;, std::optional&lt;at::Tensor&gt; const&amp;, std::optional&lt;at::Tensor&gt; const&amp;, bool, double, double)&gt;::call (libtorch_cuda.so) (32 samples, 0.12%)</title><rect x="23.1300%" y="644" width="0.1248%" height="15" fill="rgb(232,26,8)" fg:x="5931" fg:w="32"/><text x="23.3800%" y="654.50"></text></g><g><title>at::(anonymous namespace)::(anonymous namespace)::wrapper_CUDA__cudnn_batch_norm (libtorch_cuda.so) (32 samples, 0.12%)</title><rect x="23.1300%" y="660" width="0.1248%" height="15" fill="rgb(216,166,38)" fg:x="5931" fg:w="32"/><text x="23.3800%" y="670.50"></text></g><g><title>at::_ops::cudnn_batch_norm::call (libtorch_cpu.so) (33 samples, 0.13%)</title><rect x="23.1300%" y="580" width="0.1287%" height="15" fill="rgb(251,202,51)" fg:x="5931" fg:w="33"/><text x="23.3800%" y="590.50"></text></g><g><title>c10::impl::wrap_kernel_functor_unboxed_&lt;c10::impl::detail::WrapFunctionIntoFunctor_&lt;c10::CompileTimeFunctionPointer&lt;std::tuple&lt;at::Tensor, at::Tensor, at::Tensor, at::Tensor&gt; (c10::DispatchKeySet, at::Tensor const&amp;, at::Tensor const&amp;, std::optional&lt;at::Tensor&gt; const&amp;, std::optional&lt;at::Tensor&gt; const&amp;, std::optional&lt;at::Tensor&gt; const&amp;, bool, double, double), &amp;torch::autograd::VariableType::(anonymous namespace)::cudnn_batch_norm(c10::DispatchKeySet, at::Tensor const&amp;, at::Tensor const&amp;, std::optional&lt;at::Tensor&gt; const&amp;, std::optional&lt;at::Tensor&gt; const&amp;, std::optional&lt;at::Tensor&gt; const&amp;, bool, double, double)&gt;, std::tuple&lt;at::Tensor, at::Tensor, at::Tensor, at::Tensor&gt;, c10::guts::typelist::typelist&lt;c10::DispatchKeySet, at::Tensor const&amp;, at::Tensor const&amp;, std::optional&lt;at::Tensor&gt; const&amp;, std::optional&lt;at::Tensor&gt; const&amp;, std::optional&lt;at::Tensor&gt; const&amp;, bool, double, double&gt; &gt;, std::tuple&lt;at::Tensor, at::Tensor, at::Tensor, at::Tensor&gt; (c10::DispatchKeySet, at::Tensor const&amp;, at::Tensor const&amp;, std::optional&lt;at::Tensor&gt; const&amp;, std::optional&lt;at::Tensor&gt; const&amp;, std::optional&lt;at::Tensor&gt; const&amp;, bool, double, double)&gt;::call (libtorch_cpu.so) (33 samples, 0.13%)</title><rect x="23.1300%" y="596" width="0.1287%" height="15" fill="rgb(254,216,34)" fg:x="5931" fg:w="33"/><text x="23.3800%" y="606.50"></text></g><g><title>torch::autograd::VariableType::(anonymous namespace)::cudnn_batch_norm (libtorch_cpu.so) (33 samples, 0.13%)</title><rect x="23.1300%" y="612" width="0.1287%" height="15" fill="rgb(251,32,27)" fg:x="5931" fg:w="33"/><text x="23.3800%" y="622.50"></text></g><g><title>at::_ops::batch_norm::call (libtorch_cpu.so) (35 samples, 0.14%)</title><rect x="23.1300%" y="484" width="0.1365%" height="15" fill="rgb(208,127,28)" fg:x="5931" fg:w="35"/><text x="23.3800%" y="494.50"></text></g><g><title>c10::impl::wrap_kernel_functor_unboxed_&lt;c10::impl::detail::WrapFunctionIntoFunctor_&lt;c10::CompileTimeFunctionPointer&lt;at::Tensor(at::Tensor const&amp;, std::optional&lt;at::Tensor&gt; const&amp;, std::optional&lt;at::Tensor&gt; const&amp;, std::optional&lt;at::Tensor&gt; const&amp;, std::optional&lt;at::Tensor&gt; const&amp;, bool, double, double, bool), &amp;at::(anonymous namespace)::(anonymous namespace)::wrapper_CompositeImplicitAutograd__batch_norm(at::Tensor const&amp;, std::optional&lt;at::Tensor&gt; const&amp;, std::optional&lt;at::Tensor&gt; const&amp;, std::optional&lt;at::Tensor&gt; const&amp;, std::optional&lt;at::Tensor&gt; const&amp;, bool, double, double, bool)&gt;, at::Tensor, c10::guts::typelist::typelist&lt;at::Tensor const&amp;, std::optional&lt;at::Tensor&gt; const&amp;, std::optional&lt;at::Tensor&gt; const&amp;, std::optional&lt;at::Tensor&gt; const&amp;, std::optional&lt;at::Tensor&gt; const&amp;, bool, double, double, bool&gt; &gt;, at::Tensor(at::Tensor const&amp;, std::optional&lt;at::Tensor&gt; const&amp;, std::optional&lt;at::Tensor&gt; const&amp;, std::optional&lt;at::Tensor&gt; const&amp;, std::optional&lt;at::Tensor&gt; const&amp;, bool, double, double, bool)&gt;::call (libtorch_cpu.so) (35 samples, 0.14%)</title><rect x="23.1300%" y="500" width="0.1365%" height="15" fill="rgb(224,137,22)" fg:x="5931" fg:w="35"/><text x="23.3800%" y="510.50"></text></g><g><title>at::native::batch_norm (libtorch_cpu.so) (35 samples, 0.14%)</title><rect x="23.1300%" y="516" width="0.1365%" height="15" fill="rgb(254,70,32)" fg:x="5931" fg:w="35"/><text x="23.3800%" y="526.50"></text></g><g><title>at::_ops::_batch_norm_impl_index::call (libtorch_cpu.so) (35 samples, 0.14%)</title><rect x="23.1300%" y="532" width="0.1365%" height="15" fill="rgb(229,75,37)" fg:x="5931" fg:w="35"/><text x="23.3800%" y="542.50"></text></g><g><title>c10::impl::wrap_kernel_functor_unboxed_&lt;c10::impl::detail::WrapFunctionIntoFunctor_&lt;c10::CompileTimeFunctionPointer&lt;std::tuple&lt;at::Tensor, at::Tensor, at::Tensor, at::Tensor, long&gt; (at::Tensor const&amp;, std::optional&lt;at::Tensor&gt; const&amp;, std::optional&lt;at::Tensor&gt; const&amp;, std::optional&lt;at::Tensor&gt; const&amp;, std::optional&lt;at::Tensor&gt; const&amp;, bool, double, double, bool), &amp;at::(anonymous namespace)::(anonymous namespace)::wrapper_CompositeImplicitAutograd___batch_norm_impl_index(at::Tensor const&amp;, std::optional&lt;at::Tensor&gt; const&amp;, std::optional&lt;at::Tensor&gt; const&amp;, std::optional&lt;at::Tensor&gt; const&amp;, std::optional&lt;at::Tensor&gt; const&amp;, bool, double, double, bool)&gt;, std::tuple&lt;at::Tensor, at::Tensor, at::Tensor, at::Tensor, long&gt;, c10::guts::typelist::typelist&lt;at::Tensor const&amp;, std::optional&lt;at::Tensor&gt; const&amp;, std::optional&lt;at::Tensor&gt; const&amp;, std::optional&lt;at::Tensor&gt; const&amp;, std::optional&lt;at::Tensor&gt; const&amp;, bool, double, double, bool&gt; &gt;, std::tuple&lt;at::Tensor, at::Tensor, at::Tensor, at::Tensor, long&gt; (at::Tensor const&amp;, std::optional&lt;at::Tensor&gt; const&amp;, std::optional&lt;at::Tensor&gt; const&amp;, std::optional&lt;at::Tensor&gt; const&amp;, std::optional&lt;at::Tensor&gt; const&amp;, bool, double, double, bool)&gt;::call (libtorch_cpu.so) (35 samples, 0.14%)</title><rect x="23.1300%" y="548" width="0.1365%" height="15" fill="rgb(252,64,23)" fg:x="5931" fg:w="35"/><text x="23.3800%" y="558.50"></text></g><g><title>at::native::_batch_norm_impl_index (libtorch_cpu.so) (35 samples, 0.14%)</title><rect x="23.1300%" y="564" width="0.1365%" height="15" fill="rgb(232,162,48)" fg:x="5931" fg:w="35"/><text x="23.3800%" y="574.50"></text></g><g><title>forward (torch/nn/modules/batchnorm.py:193) (43 samples, 0.17%)</title><rect x="23.1027%" y="436" width="0.1677%" height="15" fill="rgb(246,160,12)" fg:x="5924" fg:w="43"/><text x="23.3527%" y="446.50"></text></g><g><title>batch_norm (torch/nn/functional.py:2826) (41 samples, 0.16%)</title><rect x="23.1105%" y="452" width="0.1599%" height="15" fill="rgb(247,166,0)" fg:x="5926" fg:w="41"/><text x="23.3605%" y="462.50"></text></g><g><title>torch::autograd::THPVariable_batch_norm (libtorch_python.so) (38 samples, 0.15%)</title><rect x="23.1222%" y="468" width="0.1482%" height="15" fill="rgb(249,219,21)" fg:x="5929" fg:w="38"/><text x="23.3722%" y="478.50"></text></g><g><title>at::native::cudnn_convolution (libtorch_cuda.so) (42 samples, 0.16%)</title><rect x="23.3445%" y="756" width="0.1638%" height="15" fill="rgb(205,209,3)" fg:x="5986" fg:w="42"/><text x="23.5945%" y="766.50"></text></g><g><title>at::native::cudnn_convolution_forward_out (libtorch_cuda.so) (33 samples, 0.13%)</title><rect x="23.3796%" y="772" width="0.1287%" height="15" fill="rgb(243,44,1)" fg:x="5995" fg:w="33"/><text x="23.6296%" y="782.50"></text></g><g><title>at::native::raw_cudnn_convolution_forward_out (libtorch_cuda.so) (28 samples, 0.11%)</title><rect x="23.3991%" y="788" width="0.1092%" height="15" fill="rgb(206,159,16)" fg:x="6000" fg:w="28"/><text x="23.6491%" y="798.50"></text></g><g><title>at::native::run_single_conv (libtorch_cuda.so) (28 samples, 0.11%)</title><rect x="23.3991%" y="804" width="0.1092%" height="15" fill="rgb(244,77,30)" fg:x="6000" fg:w="28"/><text x="23.6491%" y="814.50"></text></g><g><title>at::_ops::convolution::redispatch (libtorch_cpu.so) (48 samples, 0.19%)</title><rect x="23.3328%" y="580" width="0.1872%" height="15" fill="rgb(218,69,12)" fg:x="5983" fg:w="48"/><text x="23.5828%" y="590.50"></text></g><g><title>c10::impl::wrap_kernel_functor_unboxed_&lt;c10::impl::detail::WrapFunctionIntoFunctor_&lt;c10::CompileTimeFunctionPointer&lt;at::Tensor(at::Tensor const&amp;, at::Tensor const&amp;, std::optional&lt;at::Tensor&gt; const&amp;, c10::ArrayRef&lt;c10::SymInt&gt;, c10::ArrayRef&lt;c10::SymInt&gt;, c10::ArrayRef&lt;c10::SymInt&gt;, bool, c10::ArrayRef&lt;c10::SymInt&gt;, c10::SymInt), &amp;at::(anonymous namespace)::(anonymous namespace)::wrapper_CompositeExplicitAutograd__convolution(at::Tensor const&amp;, at::Tensor const&amp;, std::optional&lt;at::Tensor&gt; const&amp;, c10::ArrayRef&lt;c10::SymInt&gt;, c10::ArrayRef&lt;c10::SymInt&gt;, c10::ArrayRef&lt;c10::SymInt&gt;, bool, c10::ArrayRef&lt;c10::SymInt&gt;, c10::SymInt)&gt;, at::Tensor, c10::guts::typelist::typelist&lt;at::Tensor const&amp;, at::Tensor const&amp;, std::optional&lt;at::Tensor&gt; const&amp;, c10::ArrayRef&lt;c10::SymInt&gt;, c10::ArrayRef&lt;c10::SymInt&gt;, c10::ArrayRef&lt;c10::SymInt&gt;, bool, c10::ArrayRef&lt;c10::SymInt&gt;, c10::SymInt&gt; &gt;, at::Tensor(at::Tensor const&amp;, at::Tensor const&amp;, std::optional&lt;at::Tensor&gt; const&amp;, c10::ArrayRef&lt;c10::SymInt&gt;, c10::ArrayRef&lt;c10::SymInt&gt;, c10::ArrayRef&lt;c10::SymInt&gt;, bool, c10::ArrayRef&lt;c10::SymInt&gt;, c10::SymInt)&gt;::call (libtorch_cpu.so) (48 samples, 0.19%)</title><rect x="23.3328%" y="596" width="0.1872%" height="15" fill="rgb(212,87,7)" fg:x="5983" fg:w="48"/><text x="23.5828%" y="606.50"></text></g><g><title>at::(anonymous namespace)::(anonymous namespace)::wrapper_CompositeExplicitAutograd__convolution (libtorch_cpu.so) (48 samples, 0.19%)</title><rect x="23.3328%" y="612" width="0.1872%" height="15" fill="rgb(245,114,25)" fg:x="5983" fg:w="48"/><text x="23.5828%" y="622.50"></text></g><g><title>at::native::convolution (libtorch_cpu.so) (48 samples, 0.19%)</title><rect x="23.3328%" y="628" width="0.1872%" height="15" fill="rgb(210,61,42)" fg:x="5983" fg:w="48"/><text x="23.5828%" y="638.50"></text></g><g><title>at::_ops::_convolution::call (libtorch_cpu.so) (47 samples, 0.18%)</title><rect x="23.3367%" y="644" width="0.1833%" height="15" fill="rgb(211,52,33)" fg:x="5984" fg:w="47"/><text x="23.5867%" y="654.50"></text></g><g><title>c10::impl::wrap_kernel_functor_unboxed_&lt;c10::impl::detail::WrapFunctionIntoFunctor_&lt;c10::CompileTimeFunctionPointer&lt;at::Tensor(at::Tensor const&amp;, at::Tensor const&amp;, std::optional&lt;at::Tensor&gt; const&amp;, c10::ArrayRef&lt;c10::SymInt&gt;, c10::ArrayRef&lt;c10::SymInt&gt;, c10::ArrayRef&lt;c10::SymInt&gt;, bool, c10::ArrayRef&lt;c10::SymInt&gt;, c10::SymInt, bool, bool, bool, bool), &amp;at::(anonymous namespace)::(anonymous namespace)::wrapper_CompositeExplicitAutograd___convolution(at::Tensor const&amp;, at::Tensor const&amp;, std::optional&lt;at::Tensor&gt; const&amp;, c10::ArrayRef&lt;c10::SymInt&gt;, c10::ArrayRef&lt;c10::SymInt&gt;, c10::ArrayRef&lt;c10::SymInt&gt;, bool, c10::ArrayRef&lt;c10::SymInt&gt;, c10::SymInt, bool, bool, bool, bool)&gt;, at::Tensor, c10::guts::typelist::typelist&lt;at::Tensor const&amp;, at::Tensor const&amp;, std::optional&lt;at::Tensor&gt; const&amp;, c10::ArrayRef&lt;c10::SymInt&gt;, c10::ArrayRef&lt;c10::SymInt&gt;, c10::ArrayRef&lt;c10::SymInt&gt;, bool, c10::ArrayRef&lt;c10::SymInt&gt;, c10::SymInt, bool, bool, bool, bool&gt; &gt;, at::Tensor(at::Tensor const&amp;, at::Tensor const&amp;, std::optional&lt;at::Tensor&gt; const&amp;, c10::ArrayRef&lt;c10::SymInt&gt;, c10::ArrayRef&lt;c10::SymInt&gt;, c10::ArrayRef&lt;c10::SymInt&gt;, bool, c10::ArrayRef&lt;c10::SymInt&gt;, c10::SymInt, bool, bool, bool, bool)&gt;::call (libtorch_cpu.so) (47 samples, 0.18%)</title><rect x="23.3367%" y="660" width="0.1833%" height="15" fill="rgb(234,58,33)" fg:x="5984" fg:w="47"/><text x="23.5867%" y="670.50"></text></g><g><title>at::(anonymous namespace)::(anonymous namespace)::wrapper_CompositeExplicitAutograd___convolution (libtorch_cpu.so) (47 samples, 0.18%)</title><rect x="23.3367%" y="676" width="0.1833%" height="15" fill="rgb(220,115,36)" fg:x="5984" fg:w="47"/><text x="23.5867%" y="686.50"></text></g><g><title>at::native::_convolution (libtorch_cpu.so) (47 samples, 0.18%)</title><rect x="23.3367%" y="692" width="0.1833%" height="15" fill="rgb(243,153,54)" fg:x="5984" fg:w="47"/><text x="23.5867%" y="702.50"></text></g><g><title>at::_ops::cudnn_convolution::call (libtorch_cpu.so) (46 samples, 0.18%)</title><rect x="23.3406%" y="708" width="0.1794%" height="15" fill="rgb(251,47,18)" fg:x="5985" fg:w="46"/><text x="23.5906%" y="718.50"></text></g><g><title>c10::impl::wrap_kernel_functor_unboxed_&lt;c10::impl::detail::WrapFunctionIntoFunctor_&lt;c10::CompileTimeFunctionPointer&lt;at::Tensor(at::Tensor const&amp;, at::Tensor const&amp;, c10::ArrayRef&lt;c10::SymInt&gt;, c10::ArrayRef&lt;c10::SymInt&gt;, c10::ArrayRef&lt;c10::SymInt&gt;, c10::SymInt, bool, bool, bool), &amp;at::(anonymous namespace)::(anonymous namespace)::wrapper_CUDA__cudnn_convolution(at::Tensor const&amp;, at::Tensor const&amp;, c10::ArrayRef&lt;c10::SymInt&gt;, c10::ArrayRef&lt;c10::SymInt&gt;, c10::ArrayRef&lt;c10::SymInt&gt;, c10::SymInt, bool, bool, bool)&gt;, at::Tensor, c10::guts::typelist::typelist&lt;at::Tensor const&amp;, at::Tensor const&amp;, c10::ArrayRef&lt;c10::SymInt&gt;, c10::ArrayRef&lt;c10::SymInt&gt;, c10::ArrayRef&lt;c10::SymInt&gt;, c10::SymInt, bool, bool, bool&gt; &gt;, at::Tensor(at::Tensor const&amp;, at::Tensor const&amp;, c10::ArrayRef&lt;c10::SymInt&gt;, c10::ArrayRef&lt;c10::SymInt&gt;, c10::ArrayRef&lt;c10::SymInt&gt;, c10::SymInt, bool, bool, bool)&gt;::call (libtorch_cuda.so) (45 samples, 0.18%)</title><rect x="23.3445%" y="724" width="0.1755%" height="15" fill="rgb(242,102,42)" fg:x="5986" fg:w="45"/><text x="23.5945%" y="734.50"></text></g><g><title>at::(anonymous namespace)::(anonymous namespace)::wrapper_CUDA__cudnn_convolution (libtorch_cuda.so) (45 samples, 0.18%)</title><rect x="23.3445%" y="740" width="0.1755%" height="15" fill="rgb(234,31,38)" fg:x="5986" fg:w="45"/><text x="23.5945%" y="750.50"></text></g><g><title>at::_ops::conv2d::call (libtorch_cpu.so) (51 samples, 0.20%)</title><rect x="23.3250%" y="484" width="0.1989%" height="15" fill="rgb(221,117,51)" fg:x="5981" fg:w="51"/><text x="23.5750%" y="494.50"></text></g><g><title>c10::impl::wrap_kernel_functor_unboxed_&lt;c10::impl::detail::WrapFunctionIntoFunctor_&lt;c10::CompileTimeFunctionPointer&lt;at::Tensor(at::Tensor const&amp;, at::Tensor const&amp;, std::optional&lt;at::Tensor&gt; const&amp;, c10::ArrayRef&lt;c10::SymInt&gt;, c10::ArrayRef&lt;c10::SymInt&gt;, c10::ArrayRef&lt;c10::SymInt&gt;, c10::SymInt), &amp;at::(anonymous namespace)::(anonymous namespace)::wrapper_CompositeImplicitAutograd__conv2d(at::Tensor const&amp;, at::Tensor const&amp;, std::optional&lt;at::Tensor&gt; const&amp;, c10::ArrayRef&lt;c10::SymInt&gt;, c10::ArrayRef&lt;c10::SymInt&gt;, c10::ArrayRef&lt;c10::SymInt&gt;, c10::SymInt)&gt;, at::Tensor, c10::guts::typelist::typelist&lt;at::Tensor const&amp;, at::Tensor const&amp;, std::optional&lt;at::Tensor&gt; const&amp;, c10::ArrayRef&lt;c10::SymInt&gt;, c10::ArrayRef&lt;c10::SymInt&gt;, c10::ArrayRef&lt;c10::SymInt&gt;, c10::SymInt&gt; &gt;, at::Tensor(at::Tensor const&amp;, at::Tensor const&amp;, std::optional&lt;at::Tensor&gt; const&amp;, c10::ArrayRef&lt;c10::SymInt&gt;, c10::ArrayRef&lt;c10::SymInt&gt;, c10::ArrayRef&lt;c10::SymInt&gt;, c10::SymInt)&gt;::call (libtorch_cpu.so) (50 samples, 0.19%)</title><rect x="23.3289%" y="500" width="0.1950%" height="15" fill="rgb(212,20,18)" fg:x="5982" fg:w="50"/><text x="23.5789%" y="510.50"></text></g><g><title>at::native::conv2d_symint (libtorch_cpu.so) (50 samples, 0.19%)</title><rect x="23.3289%" y="516" width="0.1950%" height="15" fill="rgb(245,133,36)" fg:x="5982" fg:w="50"/><text x="23.5789%" y="526.50"></text></g><g><title>at::_ops::convolution::call (libtorch_cpu.so) (50 samples, 0.19%)</title><rect x="23.3289%" y="532" width="0.1950%" height="15" fill="rgb(212,6,19)" fg:x="5982" fg:w="50"/><text x="23.5789%" y="542.50"></text></g><g><title>c10::impl::wrap_kernel_functor_unboxed_&lt;c10::impl::detail::WrapFunctionIntoFunctor_&lt;c10::CompileTimeFunctionPointer&lt;at::Tensor(c10::DispatchKeySet, at::Tensor const&amp;, at::Tensor const&amp;, std::optional&lt;at::Tensor&gt; const&amp;, c10::ArrayRef&lt;c10::SymInt&gt;, c10::ArrayRef&lt;c10::SymInt&gt;, c10::ArrayRef&lt;c10::SymInt&gt;, bool, c10::ArrayRef&lt;c10::SymInt&gt;, c10::SymInt), &amp;torch::autograd::VariableType::(anonymous namespace)::convolution(c10::DispatchKeySet, at::Tensor const&amp;, at::Tensor const&amp;, std::optional&lt;at::Tensor&gt; const&amp;, c10::ArrayRef&lt;c10::SymInt&gt;, c10::ArrayRef&lt;c10::SymInt&gt;, c10::ArrayRef&lt;c10::SymInt&gt;, bool, c10::ArrayRef&lt;c10::SymInt&gt;, c10::SymInt)&gt;, at::Tensor, c10::guts::typelist::typelist&lt;c10::DispatchKeySet, at::Tensor const&amp;, at::Tensor const&amp;, std::optional&lt;at::Tensor&gt; const&amp;, c10::ArrayRef&lt;c10::SymInt&gt;, c10::ArrayRef&lt;c10::SymInt&gt;, c10::ArrayRef&lt;c10::SymInt&gt;, bool, c10::ArrayRef&lt;c10::SymInt&gt;, c10::SymInt&gt; &gt;, at::Tensor(c10::DispatchKeySet, at::Tensor const&amp;, at::Tensor const&amp;, std::optional&lt;at::Tensor&gt; const&amp;, c10::ArrayRef&lt;c10::SymInt&gt;, c10::ArrayRef&lt;c10::SymInt&gt;, c10::ArrayRef&lt;c10::SymInt&gt;, bool, c10::ArrayRef&lt;c10::SymInt&gt;, c10::SymInt)&gt;::call (libtorch_cpu.so) (50 samples, 0.19%)</title><rect x="23.3289%" y="548" width="0.1950%" height="15" fill="rgb(218,1,36)" fg:x="5982" fg:w="50"/><text x="23.5789%" y="558.50"></text></g><g><title>torch::autograd::VariableType::(anonymous namespace)::convolution (libtorch_cpu.so) (50 samples, 0.19%)</title><rect x="23.3289%" y="564" width="0.1950%" height="15" fill="rgb(246,84,54)" fg:x="5982" fg:w="50"/><text x="23.5789%" y="574.50"></text></g><g><title>_wrapped_call_impl (torch/nn/modules/module.py:1773) (190 samples, 0.74%)</title><rect x="22.8024%" y="356" width="0.7410%" height="15" fill="rgb(242,110,6)" fg:x="5847" fg:w="190"/><text x="23.0524%" y="366.50"></text></g><g><title>_call_impl (torch/nn/modules/module.py:1784) (177 samples, 0.69%)</title><rect x="22.8531%" y="372" width="0.6903%" height="15" fill="rgb(214,47,5)" fg:x="5860" fg:w="177"/><text x="23.1031%" y="382.50"></text></g><g><title>forward (torch/nn/modules/container.py:244) (170 samples, 0.66%)</title><rect x="22.8804%" y="388" width="0.6630%" height="15" fill="rgb(218,159,25)" fg:x="5867" fg:w="170"/><text x="23.1304%" y="398.50"></text></g><g><title>_wrapped_call_impl (torch/nn/modules/module.py:1773) (165 samples, 0.64%)</title><rect x="22.8999%" y="404" width="0.6435%" height="15" fill="rgb(215,211,28)" fg:x="5872" fg:w="165"/><text x="23.1499%" y="414.50"></text></g><g><title>_call_impl (torch/nn/modules/module.py:1784) (134 samples, 0.52%)</title><rect x="23.0208%" y="420" width="0.5226%" height="15" fill="rgb(238,59,32)" fg:x="5903" fg:w="134"/><text x="23.2708%" y="430.50"></text></g><g><title>forward (torch/nn/modules/conv.py:548) (65 samples, 0.25%)</title><rect x="23.2899%" y="436" width="0.2535%" height="15" fill="rgb(226,82,3)" fg:x="5972" fg:w="65"/><text x="23.5399%" y="446.50"></text></g><g><title>_conv_forward (torch/nn/modules/conv.py:544) (59 samples, 0.23%)</title><rect x="23.3133%" y="452" width="0.2301%" height="15" fill="rgb(240,164,32)" fg:x="5978" fg:w="59"/><text x="23.5633%" y="462.50"></text></g><g><title>torch::autograd::THPVariable_conv2d (libtorch_python.so) (56 samples, 0.22%)</title><rect x="23.3250%" y="468" width="0.2184%" height="15" fill="rgb(232,46,7)" fg:x="5981" fg:w="56"/><text x="23.5750%" y="478.50"></text></g><g><title>at::native::add_kernel (libtorch_cuda.so) (41 samples, 0.16%)</title><rect x="23.6331%" y="452" width="0.1599%" height="15" fill="rgb(229,129,53)" fg:x="6060" fg:w="41"/><text x="23.8831%" y="462.50"></text></g><g><title>at::native::add_kernel(at::TensorIteratorBase&amp;, c10::Scalar const&amp;)::{lambda()#1}::operator() const (libtorch_cuda.so) (41 samples, 0.16%)</title><rect x="23.6331%" y="468" width="0.1599%" height="15" fill="rgb(234,188,29)" fg:x="6060" fg:w="41"/><text x="23.8831%" y="478.50"></text></g><g><title>at::native::gpu_kernel_impl_nocast&lt;at::native::CUDAFunctor_add&lt;float&gt; &gt; (libtorch_cuda.so) (38 samples, 0.15%)</title><rect x="23.6448%" y="484" width="0.1482%" height="15" fill="rgb(246,141,4)" fg:x="6063" fg:w="38"/><text x="23.8948%" y="494.50"></text></g><g><title>cudaLaunchKernel (nvidia/cuda_runtime/lib/libcudart.so.12) (35 samples, 0.14%)</title><rect x="23.6565%" y="500" width="0.1365%" height="15" fill="rgb(229,23,39)" fg:x="6066" fg:w="35"/><text x="23.9065%" y="510.50"></text></g><g><title>at::(anonymous namespace)::wrapper_CUDA_add__Tensor (libtorch_cuda.so) (61 samples, 0.24%)</title><rect x="23.5590%" y="436" width="0.2379%" height="15" fill="rgb(206,12,3)" fg:x="6041" fg:w="61"/><text x="23.8090%" y="446.50"></text></g><g><title>at::_ops::add__Tensor::call (libtorch_cpu.so) (68 samples, 0.27%)</title><rect x="23.5473%" y="388" width="0.2652%" height="15" fill="rgb(252,226,20)" fg:x="6038" fg:w="68"/><text x="23.7973%" y="398.50"></text></g><g><title>torch::autograd::VariableType::(anonymous namespace)::add__Tensor (libtorch_cpu.so) (66 samples, 0.26%)</title><rect x="23.5551%" y="404" width="0.2574%" height="15" fill="rgb(216,123,35)" fg:x="6040" fg:w="66"/><text x="23.8051%" y="414.50"></text></g><g><title>c10::impl::wrap_kernel_functor_unboxed_&lt;c10::impl::detail::WrapFunctionIntoFunctor_&lt;c10::CompileTimeFunctionPointer&lt;at::Tensor&amp; (c10::DispatchKeySet, at::Tensor&amp;, at::Tensor const&amp;, c10::Scalar const&amp;), &amp;torch::ADInplaceOrView::(anonymous namespace)::add__Tensor(c10::DispatchKeySet, at::Tensor&amp;, at::Tensor const&amp;, c10::Scalar const&amp;)&gt;, at::Tensor&amp;, c10::guts::typelist::typelist&lt;c10::DispatchKeySet, at::Tensor&amp;, at::Tensor const&amp;, c10::Scalar const&amp;&gt; &gt;, at::Tensor&amp; (c10::DispatchKeySet, at::Tensor&amp;, at::Tensor const&amp;, c10::Scalar const&amp;)&gt;::call (libtorch_cpu.so) (66 samples, 0.26%)</title><rect x="23.5551%" y="420" width="0.2574%" height="15" fill="rgb(212,68,40)" fg:x="6040" fg:w="66"/><text x="23.8051%" y="430.50"></text></g><g><title>forward (armada_net.py:32) (282 samples, 1.10%)</title><rect x="22.7283%" y="340" width="1.0998%" height="15" fill="rgb(254,125,32)" fg:x="5828" fg:w="282"/><text x="22.9783%" y="350.50"></text></g><g><title>torch::autograd::TypeError_to_NotImplemented_&lt;&amp;torch::autograd::THPVariable_add_(_object*, _object*, _object*)&gt; (libtorch_python.so) (73 samples, 0.28%)</title><rect x="23.5434%" y="356" width="0.2847%" height="15" fill="rgb(253,97,22)" fg:x="6037" fg:w="73"/><text x="23.7934%" y="366.50"></text></g><g><title>torch::autograd::THPVariable_add_ (libtorch_python.so) (72 samples, 0.28%)</title><rect x="23.5473%" y="372" width="0.2808%" height="15" fill="rgb(241,101,14)" fg:x="6038" fg:w="72"/><text x="23.7973%" y="382.50"></text></g><g><title>at::native::relu (libtorch_cpu.so) (42 samples, 0.16%)</title><rect x="23.9061%" y="468" width="0.1638%" height="15" fill="rgb(238,103,29)" fg:x="6130" fg:w="42"/><text x="24.1561%" y="478.50"></text></g><g><title>at::_ops::clamp_min::call (libtorch_cpu.so) (42 samples, 0.16%)</title><rect x="23.9061%" y="484" width="0.1638%" height="15" fill="rgb(233,195,47)" fg:x="6130" fg:w="42"/><text x="24.1561%" y="494.50"></text></g><g><title>c10::impl::wrap_kernel_functor_unboxed_&lt;c10::impl::detail::WrapFunctionIntoFunctor_&lt;c10::CompileTimeFunctionPointer&lt;at::Tensor(at::Tensor const&amp;, c10::Scalar const&amp;), &amp;at::(anonymous namespace)::wrapper_CUDA_clamp_min(at::Tensor const&amp;, c10::Scalar const&amp;)&gt;, at::Tensor, c10::guts::typelist::typelist&lt;at::Tensor const&amp;, c10::Scalar const&amp;&gt; &gt;, at::Tensor(at::Tensor const&amp;, c10::Scalar const&amp;)&gt;::call (libtorch_cuda.so) (41 samples, 0.16%)</title><rect x="23.9100%" y="500" width="0.1599%" height="15" fill="rgb(246,218,30)" fg:x="6131" fg:w="41"/><text x="24.1600%" y="510.50"></text></g><g><title>at::(anonymous namespace)::wrapper_CUDA_clamp_min (libtorch_cuda.so) (41 samples, 0.16%)</title><rect x="23.9100%" y="516" width="0.1599%" height="15" fill="rgb(219,145,47)" fg:x="6131" fg:w="41"/><text x="24.1600%" y="526.50"></text></g><g><title>at::_ops::relu::redispatch (libtorch_cpu.so) (46 samples, 0.18%)</title><rect x="23.8983%" y="436" width="0.1794%" height="15" fill="rgb(243,12,26)" fg:x="6128" fg:w="46"/><text x="24.1483%" y="446.50"></text></g><g><title>c10::impl::wrap_kernel_functor_unboxed_&lt;c10::impl::detail::WrapFunctionIntoFunctor_&lt;c10::CompileTimeFunctionPointer&lt;at::Tensor(at::Tensor const&amp;), &amp;at::(anonymous namespace)::(anonymous namespace)::wrapper_CUDA__relu(at::Tensor const&amp;)&gt;, at::Tensor, c10::guts::typelist::typelist&lt;at::Tensor const&amp;&gt; &gt;, at::Tensor(at::Tensor const&amp;)&gt;::call (libtorch_cuda.so) (45 samples, 0.18%)</title><rect x="23.9022%" y="452" width="0.1755%" height="15" fill="rgb(214,87,16)" fg:x="6129" fg:w="45"/><text x="24.1522%" y="462.50"></text></g><g><title>at::_ops::relu::call (libtorch_cpu.so) (50 samples, 0.19%)</title><rect x="23.8866%" y="388" width="0.1950%" height="15" fill="rgb(208,99,42)" fg:x="6125" fg:w="50"/><text x="24.1366%" y="398.50"></text></g><g><title>c10::impl::wrap_kernel_functor_unboxed_&lt;c10::impl::detail::WrapFunctionIntoFunctor_&lt;c10::CompileTimeFunctionPointer&lt;at::Tensor(c10::DispatchKeySet, at::Tensor const&amp;), &amp;torch::autograd::VariableType::(anonymous namespace)::relu(c10::DispatchKeySet, at::Tensor const&amp;)&gt;, at::Tensor, c10::guts::typelist::typelist&lt;c10::DispatchKeySet, at::Tensor const&amp;&gt; &gt;, at::Tensor(c10::DispatchKeySet, at::Tensor const&amp;)&gt;::call (libtorch_cpu.so) (48 samples, 0.19%)</title><rect x="23.8944%" y="404" width="0.1872%" height="15" fill="rgb(253,99,2)" fg:x="6127" fg:w="48"/><text x="24.1444%" y="414.50"></text></g><g><title>torch::autograd::VariableType::(anonymous namespace)::relu (libtorch_cpu.so) (48 samples, 0.19%)</title><rect x="23.8944%" y="420" width="0.1872%" height="15" fill="rgb(220,168,23)" fg:x="6127" fg:w="48"/><text x="24.1444%" y="430.50"></text></g><g><title>forward (armada_net.py:33) (68 samples, 0.27%)</title><rect x="23.8281%" y="340" width="0.2652%" height="15" fill="rgb(242,38,24)" fg:x="6110" fg:w="68"/><text x="24.0781%" y="350.50"></text></g><g><title>relu (torch/nn/functional.py:1701) (57 samples, 0.22%)</title><rect x="23.8710%" y="356" width="0.2223%" height="15" fill="rgb(225,182,9)" fg:x="6121" fg:w="57"/><text x="24.1210%" y="366.50"></text></g><g><title>torch::autograd::THPVariable_relu (libtorch_python.so) (55 samples, 0.21%)</title><rect x="23.8788%" y="372" width="0.2145%" height="15" fill="rgb(243,178,37)" fg:x="6123" fg:w="55"/><text x="24.1288%" y="382.50"></text></g><g><title>at::_ops::relu::call (libtorch_cpu.so) (34 samples, 0.13%)</title><rect x="24.1050%" y="388" width="0.1326%" height="15" fill="rgb(232,139,19)" fg:x="6181" fg:w="34"/><text x="24.3550%" y="398.50"></text></g><g><title>c10::impl::wrap_kernel_functor_unboxed_&lt;c10::impl::detail::WrapFunctionIntoFunctor_&lt;c10::CompileTimeFunctionPointer&lt;at::Tensor(c10::DispatchKeySet, at::Tensor const&amp;), &amp;torch::autograd::VariableType::(anonymous namespace)::relu(c10::DispatchKeySet, at::Tensor const&amp;)&gt;, at::Tensor, c10::guts::typelist::typelist&lt;c10::DispatchKeySet, at::Tensor const&amp;&gt; &gt;, at::Tensor(c10::DispatchKeySet, at::Tensor const&amp;)&gt;::call (libtorch_cpu.so) (31 samples, 0.12%)</title><rect x="24.1167%" y="404" width="0.1209%" height="15" fill="rgb(225,201,24)" fg:x="6184" fg:w="31"/><text x="24.3667%" y="414.50"></text></g><g><title>torch::autograd::VariableType::(anonymous namespace)::relu (libtorch_cpu.so) (31 samples, 0.12%)</title><rect x="24.1167%" y="420" width="0.1209%" height="15" fill="rgb(221,47,46)" fg:x="6184" fg:w="31"/><text x="24.3667%" y="430.50"></text></g><g><title>at::_ops::relu::redispatch (libtorch_cpu.so) (29 samples, 0.11%)</title><rect x="24.1245%" y="436" width="0.1131%" height="15" fill="rgb(249,23,13)" fg:x="6186" fg:w="29"/><text x="24.3745%" y="446.50"></text></g><g><title>c10::impl::wrap_kernel_functor_unboxed_&lt;c10::impl::detail::WrapFunctionIntoFunctor_&lt;c10::CompileTimeFunctionPointer&lt;at::Tensor(at::Tensor const&amp;), &amp;at::(anonymous namespace)::(anonymous namespace)::wrapper_CUDA__relu(at::Tensor const&amp;)&gt;, at::Tensor, c10::guts::typelist::typelist&lt;at::Tensor const&amp;&gt; &gt;, at::Tensor(at::Tensor const&amp;)&gt;::call (libtorch_cuda.so) (29 samples, 0.11%)</title><rect x="24.1245%" y="452" width="0.1131%" height="15" fill="rgb(219,9,5)" fg:x="6186" fg:w="29"/><text x="24.3745%" y="462.50"></text></g><g><title>at::native::relu (libtorch_cpu.so) (28 samples, 0.11%)</title><rect x="24.1284%" y="468" width="0.1092%" height="15" fill="rgb(254,171,16)" fg:x="6187" fg:w="28"/><text x="24.3784%" y="478.50"></text></g><g><title>at::_ops::clamp_min::call (libtorch_cpu.so) (28 samples, 0.11%)</title><rect x="24.1284%" y="484" width="0.1092%" height="15" fill="rgb(230,171,20)" fg:x="6187" fg:w="28"/><text x="24.3784%" y="494.50"></text></g><g><title>c10::impl::wrap_kernel_functor_unboxed_&lt;c10::impl::detail::WrapFunctionIntoFunctor_&lt;c10::CompileTimeFunctionPointer&lt;at::Tensor(at::Tensor const&amp;, c10::Scalar const&amp;), &amp;at::(anonymous namespace)::wrapper_CUDA_clamp_min(at::Tensor const&amp;, c10::Scalar const&amp;)&gt;, at::Tensor, c10::guts::typelist::typelist&lt;at::Tensor const&amp;, c10::Scalar const&amp;&gt; &gt;, at::Tensor(at::Tensor const&amp;, c10::Scalar const&amp;)&gt;::call (libtorch_cuda.so) (28 samples, 0.11%)</title><rect x="24.1284%" y="500" width="0.1092%" height="15" fill="rgb(210,71,41)" fg:x="6187" fg:w="28"/><text x="24.3784%" y="510.50"></text></g><g><title>at::(anonymous namespace)::wrapper_CUDA_clamp_min (libtorch_cuda.so) (28 samples, 0.11%)</title><rect x="24.1284%" y="516" width="0.1092%" height="15" fill="rgb(206,173,20)" fg:x="6187" fg:w="28"/><text x="24.3784%" y="526.50"></text></g><g><title>forward (torch/nn/modules/activation.py:135) (39 samples, 0.15%)</title><rect x="24.0933%" y="340" width="0.1521%" height="15" fill="rgb(233,88,34)" fg:x="6178" fg:w="39"/><text x="24.3433%" y="350.50"></text></g><g><title>relu (torch/nn/functional.py:1701) (38 samples, 0.15%)</title><rect x="24.0972%" y="356" width="0.1482%" height="15" fill="rgb(223,209,46)" fg:x="6179" fg:w="38"/><text x="24.3472%" y="366.50"></text></g><g><title>torch::autograd::THPVariable_relu (libtorch_python.so) (37 samples, 0.14%)</title><rect x="24.1011%" y="372" width="0.1443%" height="15" fill="rgb(250,43,18)" fg:x="6180" fg:w="37"/><text x="24.3511%" y="382.50"></text></g><g><title>at::native::cudnn_batch_norm (libtorch_cuda.so) (55 samples, 0.21%)</title><rect x="24.3000%" y="580" width="0.2145%" height="15" fill="rgb(208,13,10)" fg:x="6231" fg:w="55"/><text x="24.5500%" y="590.50"></text></g><g><title>at::_ops::cudnn_batch_norm::redispatch (libtorch_cpu.so) (62 samples, 0.24%)</title><rect x="24.2961%" y="532" width="0.2418%" height="15" fill="rgb(212,200,36)" fg:x="6230" fg:w="62"/><text x="24.5461%" y="542.50"></text></g><g><title>c10::impl::wrap_kernel_functor_unboxed_&lt;c10::impl::detail::WrapFunctionIntoFunctor_&lt;c10::CompileTimeFunctionPointer&lt;std::tuple&lt;at::Tensor, at::Tensor, at::Tensor, at::Tensor&gt; (at::Tensor const&amp;, at::Tensor const&amp;, std::optional&lt;at::Tensor&gt; const&amp;, std::optional&lt;at::Tensor&gt; const&amp;, std::optional&lt;at::Tensor&gt; const&amp;, bool, double, double), &amp;at::(anonymous namespace)::(anonymous namespace)::wrapper_CUDA__cudnn_batch_norm(at::Tensor const&amp;, at::Tensor const&amp;, std::optional&lt;at::Tensor&gt; const&amp;, std::optional&lt;at::Tensor&gt; const&amp;, std::optional&lt;at::Tensor&gt; const&amp;, bool, double, double)&gt;, std::tuple&lt;at::Tensor, at::Tensor, at::Tensor, at::Tensor&gt;, c10::guts::typelist::typelist&lt;at::Tensor const&amp;, at::Tensor const&amp;, std::optional&lt;at::Tensor&gt; const&amp;, std::optional&lt;at::Tensor&gt; const&amp;, std::optional&lt;at::Tensor&gt; const&amp;, bool, double, double&gt; &gt;, std::tuple&lt;at::Tensor, at::Tensor, at::Tensor, at::Tensor&gt; (at::Tensor const&amp;, at::Tensor const&amp;, std::optional&lt;at::Tensor&gt; const&amp;, std::optional&lt;at::Tensor&gt; const&amp;, std::optional&lt;at::Tensor&gt; const&amp;, bool, double, double)&gt;::call (libtorch_cuda.so) (62 samples, 0.24%)</title><rect x="24.2961%" y="548" width="0.2418%" height="15" fill="rgb(225,90,30)" fg:x="6230" fg:w="62"/><text x="24.5461%" y="558.50"></text></g><g><title>at::(anonymous namespace)::(anonymous namespace)::wrapper_CUDA__cudnn_batch_norm (libtorch_cuda.so) (62 samples, 0.24%)</title><rect x="24.2961%" y="564" width="0.2418%" height="15" fill="rgb(236,182,39)" fg:x="6230" fg:w="62"/><text x="24.5461%" y="574.50"></text></g><g><title>at::_ops::cudnn_batch_norm::call (libtorch_cpu.so) (66 samples, 0.26%)</title><rect x="24.2922%" y="484" width="0.2574%" height="15" fill="rgb(212,144,35)" fg:x="6229" fg:w="66"/><text x="24.5422%" y="494.50"></text></g><g><title>c10::impl::wrap_kernel_functor_unboxed_&lt;c10::impl::detail::WrapFunctionIntoFunctor_&lt;c10::CompileTimeFunctionPointer&lt;std::tuple&lt;at::Tensor, at::Tensor, at::Tensor, at::Tensor&gt; (c10::DispatchKeySet, at::Tensor const&amp;, at::Tensor const&amp;, std::optional&lt;at::Tensor&gt; const&amp;, std::optional&lt;at::Tensor&gt; const&amp;, std::optional&lt;at::Tensor&gt; const&amp;, bool, double, double), &amp;torch::autograd::VariableType::(anonymous namespace)::cudnn_batch_norm(c10::DispatchKeySet, at::Tensor const&amp;, at::Tensor const&amp;, std::optional&lt;at::Tensor&gt; const&amp;, std::optional&lt;at::Tensor&gt; const&amp;, std::optional&lt;at::Tensor&gt; const&amp;, bool, double, double)&gt;, std::tuple&lt;at::Tensor, at::Tensor, at::Tensor, at::Tensor&gt;, c10::guts::typelist::typelist&lt;c10::DispatchKeySet, at::Tensor const&amp;, at::Tensor const&amp;, std::optional&lt;at::Tensor&gt; const&amp;, std::optional&lt;at::Tensor&gt; const&amp;, std::optional&lt;at::Tensor&gt; const&amp;, bool, double, double&gt; &gt;, std::tuple&lt;at::Tensor, at::Tensor, at::Tensor, at::Tensor&gt; (c10::DispatchKeySet, at::Tensor const&amp;, at::Tensor const&amp;, std::optional&lt;at::Tensor&gt; const&amp;, std::optional&lt;at::Tensor&gt; const&amp;, std::optional&lt;at::Tensor&gt; const&amp;, bool, double, double)&gt;::call (libtorch_cpu.so) (65 samples, 0.25%)</title><rect x="24.2961%" y="500" width="0.2535%" height="15" fill="rgb(228,63,44)" fg:x="6230" fg:w="65"/><text x="24.5461%" y="510.50"></text></g><g><title>torch::autograd::VariableType::(anonymous namespace)::cudnn_batch_norm (libtorch_cpu.so) (65 samples, 0.25%)</title><rect x="24.2961%" y="516" width="0.2535%" height="15" fill="rgb(228,109,6)" fg:x="6230" fg:w="65"/><text x="24.5461%" y="526.50"></text></g><g><title>at::_ops::batch_norm::call (libtorch_cpu.so) (74 samples, 0.29%)</title><rect x="24.2766%" y="388" width="0.2886%" height="15" fill="rgb(238,117,24)" fg:x="6225" fg:w="74"/><text x="24.5266%" y="398.50"></text></g><g><title>c10::impl::wrap_kernel_functor_unboxed_&lt;c10::impl::detail::WrapFunctionIntoFunctor_&lt;c10::CompileTimeFunctionPointer&lt;at::Tensor(at::Tensor const&amp;, std::optional&lt;at::Tensor&gt; const&amp;, std::optional&lt;at::Tensor&gt; const&amp;, std::optional&lt;at::Tensor&gt; const&amp;, std::optional&lt;at::Tensor&gt; const&amp;, bool, double, double, bool), &amp;at::(anonymous namespace)::(anonymous namespace)::wrapper_CompositeImplicitAutograd__batch_norm(at::Tensor const&amp;, std::optional&lt;at::Tensor&gt; const&amp;, std::optional&lt;at::Tensor&gt; const&amp;, std::optional&lt;at::Tensor&gt; const&amp;, std::optional&lt;at::Tensor&gt; const&amp;, bool, double, double, bool)&gt;, at::Tensor, c10::guts::typelist::typelist&lt;at::Tensor const&amp;, std::optional&lt;at::Tensor&gt; const&amp;, std::optional&lt;at::Tensor&gt; const&amp;, std::optional&lt;at::Tensor&gt; const&amp;, std::optional&lt;at::Tensor&gt; const&amp;, bool, double, double, bool&gt; &gt;, at::Tensor(at::Tensor const&amp;, std::optional&lt;at::Tensor&gt; const&amp;, std::optional&lt;at::Tensor&gt; const&amp;, std::optional&lt;at::Tensor&gt; const&amp;, std::optional&lt;at::Tensor&gt; const&amp;, bool, double, double, bool)&gt;::call (libtorch_cpu.so) (73 samples, 0.28%)</title><rect x="24.2805%" y="404" width="0.2847%" height="15" fill="rgb(242,26,26)" fg:x="6226" fg:w="73"/><text x="24.5305%" y="414.50"></text></g><g><title>at::native::batch_norm (libtorch_cpu.so) (73 samples, 0.28%)</title><rect x="24.2805%" y="420" width="0.2847%" height="15" fill="rgb(221,92,48)" fg:x="6226" fg:w="73"/><text x="24.5305%" y="430.50"></text></g><g><title>at::_ops::_batch_norm_impl_index::call (libtorch_cpu.so) (73 samples, 0.28%)</title><rect x="24.2805%" y="436" width="0.2847%" height="15" fill="rgb(209,209,32)" fg:x="6226" fg:w="73"/><text x="24.5305%" y="446.50"></text></g><g><title>c10::impl::wrap_kernel_functor_unboxed_&lt;c10::impl::detail::WrapFunctionIntoFunctor_&lt;c10::CompileTimeFunctionPointer&lt;std::tuple&lt;at::Tensor, at::Tensor, at::Tensor, at::Tensor, long&gt; (at::Tensor const&amp;, std::optional&lt;at::Tensor&gt; const&amp;, std::optional&lt;at::Tensor&gt; const&amp;, std::optional&lt;at::Tensor&gt; const&amp;, std::optional&lt;at::Tensor&gt; const&amp;, bool, double, double, bool), &amp;at::(anonymous namespace)::(anonymous namespace)::wrapper_CompositeImplicitAutograd___batch_norm_impl_index(at::Tensor const&amp;, std::optional&lt;at::Tensor&gt; const&amp;, std::optional&lt;at::Tensor&gt; const&amp;, std::optional&lt;at::Tensor&gt; const&amp;, std::optional&lt;at::Tensor&gt; const&amp;, bool, double, double, bool)&gt;, std::tuple&lt;at::Tensor, at::Tensor, at::Tensor, at::Tensor, long&gt;, c10::guts::typelist::typelist&lt;at::Tensor const&amp;, std::optional&lt;at::Tensor&gt; const&amp;, std::optional&lt;at::Tensor&gt; const&amp;, std::optional&lt;at::Tensor&gt; const&amp;, std::optional&lt;at::Tensor&gt; const&amp;, bool, double, double, bool&gt; &gt;, std::tuple&lt;at::Tensor, at::Tensor, at::Tensor, at::Tensor, long&gt; (at::Tensor const&amp;, std::optional&lt;at::Tensor&gt; const&amp;, std::optional&lt;at::Tensor&gt; const&amp;, std::optional&lt;at::Tensor&gt; const&amp;, std::optional&lt;at::Tensor&gt; const&amp;, bool, double, double, bool)&gt;::call (libtorch_cpu.so) (72 samples, 0.28%)</title><rect x="24.2844%" y="452" width="0.2808%" height="15" fill="rgb(221,70,22)" fg:x="6227" fg:w="72"/><text x="24.5344%" y="462.50"></text></g><g><title>at::native::_batch_norm_impl_index (libtorch_cpu.so) (72 samples, 0.28%)</title><rect x="24.2844%" y="468" width="0.2808%" height="15" fill="rgb(248,145,5)" fg:x="6227" fg:w="72"/><text x="24.5344%" y="478.50"></text></g><g><title>forward (torch/nn/modules/batchnorm.py:193) (82 samples, 0.32%)</title><rect x="24.2493%" y="340" width="0.3198%" height="15" fill="rgb(226,116,26)" fg:x="6218" fg:w="82"/><text x="24.4993%" y="350.50"></text></g><g><title>batch_norm (torch/nn/functional.py:2826) (80 samples, 0.31%)</title><rect x="24.2571%" y="356" width="0.3120%" height="15" fill="rgb(244,5,17)" fg:x="6220" fg:w="80"/><text x="24.5071%" y="366.50"></text></g><g><title>torch::autograd::THPVariable_batch_norm (libtorch_python.so) (77 samples, 0.30%)</title><rect x="24.2688%" y="372" width="0.3003%" height="15" fill="rgb(252,159,33)" fg:x="6223" fg:w="77"/><text x="24.5188%" y="382.50"></text></g><g><title>cudnn::cnn::EngineInterface::execute (libcudnn_graph.so.9) (40 samples, 0.16%)</title><rect x="24.7953%" y="788" width="0.1560%" height="15" fill="rgb(206,71,0)" fg:x="6358" fg:w="40"/><text x="25.0453%" y="798.50"></text></g><g><title>cudnnBackendExecute (libcudnn.so.9) (45 samples, 0.18%)</title><rect x="24.7797%" y="740" width="0.1755%" height="15" fill="rgb(233,118,54)" fg:x="6354" fg:w="45"/><text x="25.0297%" y="750.50"></text></g><g><title>cudnnBackendExecute (libcudnn_graph.so.9) (45 samples, 0.18%)</title><rect x="24.7797%" y="756" width="0.1755%" height="15" fill="rgb(234,83,48)" fg:x="6354" fg:w="45"/><text x="25.0297%" y="766.50"></text></g><g><title>cudnn::backend::execute (libcudnn_graph.so.9) (45 samples, 0.18%)</title><rect x="24.7797%" y="772" width="0.1755%" height="15" fill="rgb(228,3,54)" fg:x="6354" fg:w="45"/><text x="25.0297%" y="782.50"></text></g><g><title>at::native::run_conv_plan (libtorch_cuda.so) (58 samples, 0.23%)</title><rect x="24.7641%" y="724" width="0.2262%" height="15" fill="rgb(226,155,13)" fg:x="6350" fg:w="58"/><text x="25.0141%" y="734.50"></text></g><g><title>at::native::cudnn_convolution (libtorch_cuda.so) (96 samples, 0.37%)</title><rect x="24.6471%" y="660" width="0.3744%" height="15" fill="rgb(241,28,37)" fg:x="6320" fg:w="96"/><text x="24.8971%" y="670.50"></text></g><g><title>at::native::cudnn_convolution_forward_out (libtorch_cuda.so) (85 samples, 0.33%)</title><rect x="24.6900%" y="676" width="0.3315%" height="15" fill="rgb(233,93,10)" fg:x="6331" fg:w="85"/><text x="24.9400%" y="686.50"></text></g><g><title>at::native::raw_cudnn_convolution_forward_out (libtorch_cuda.so) (81 samples, 0.32%)</title><rect x="24.7056%" y="692" width="0.3159%" height="15" fill="rgb(225,113,19)" fg:x="6335" fg:w="81"/><text x="24.9556%" y="702.50"></text></g><g><title>at::native::run_single_conv (libtorch_cuda.so) (80 samples, 0.31%)</title><rect x="24.7095%" y="708" width="0.3120%" height="15" fill="rgb(241,2,18)" fg:x="6336" fg:w="80"/><text x="24.9595%" y="718.50"></text></g><g><title>at::_ops::cudnn_convolution::call (libtorch_cpu.so) (101 samples, 0.39%)</title><rect x="24.6471%" y="612" width="0.3939%" height="15" fill="rgb(228,207,21)" fg:x="6320" fg:w="101"/><text x="24.8971%" y="622.50"></text></g><g><title>c10::impl::wrap_kernel_functor_unboxed_&lt;c10::impl::detail::WrapFunctionIntoFunctor_&lt;c10::CompileTimeFunctionPointer&lt;at::Tensor(at::Tensor const&amp;, at::Tensor const&amp;, c10::ArrayRef&lt;c10::SymInt&gt;, c10::ArrayRef&lt;c10::SymInt&gt;, c10::ArrayRef&lt;c10::SymInt&gt;, c10::SymInt, bool, bool, bool), &amp;at::(anonymous namespace)::(anonymous namespace)::wrapper_CUDA__cudnn_convolution(at::Tensor const&amp;, at::Tensor const&amp;, c10::ArrayRef&lt;c10::SymInt&gt;, c10::ArrayRef&lt;c10::SymInt&gt;, c10::ArrayRef&lt;c10::SymInt&gt;, c10::SymInt, bool, bool, bool)&gt;, at::Tensor, c10::guts::typelist::typelist&lt;at::Tensor const&amp;, at::Tensor const&amp;, c10::ArrayRef&lt;c10::SymInt&gt;, c10::ArrayRef&lt;c10::SymInt&gt;, c10::ArrayRef&lt;c10::SymInt&gt;, c10::SymInt, bool, bool, bool&gt; &gt;, at::Tensor(at::Tensor const&amp;, at::Tensor const&amp;, c10::ArrayRef&lt;c10::SymInt&gt;, c10::ArrayRef&lt;c10::SymInt&gt;, c10::ArrayRef&lt;c10::SymInt&gt;, c10::SymInt, bool, bool, bool)&gt;::call (libtorch_cuda.so) (101 samples, 0.39%)</title><rect x="24.6471%" y="628" width="0.3939%" height="15" fill="rgb(213,211,35)" fg:x="6320" fg:w="101"/><text x="24.8971%" y="638.50"></text></g><g><title>at::(anonymous namespace)::(anonymous namespace)::wrapper_CUDA__cudnn_convolution (libtorch_cuda.so) (101 samples, 0.39%)</title><rect x="24.6471%" y="644" width="0.3939%" height="15" fill="rgb(209,83,10)" fg:x="6320" fg:w="101"/><text x="24.8971%" y="654.50"></text></g><g><title>at::_ops::convolution::redispatch (libtorch_cpu.so) (114 samples, 0.44%)</title><rect x="24.6276%" y="484" width="0.4446%" height="15" fill="rgb(209,164,1)" fg:x="6315" fg:w="114"/><text x="24.8776%" y="494.50"></text></g><g><title>c10::impl::wrap_kernel_functor_unboxed_&lt;c10::impl::detail::WrapFunctionIntoFunctor_&lt;c10::CompileTimeFunctionPointer&lt;at::Tensor(at::Tensor const&amp;, at::Tensor const&amp;, std::optional&lt;at::Tensor&gt; const&amp;, c10::ArrayRef&lt;c10::SymInt&gt;, c10::ArrayRef&lt;c10::SymInt&gt;, c10::ArrayRef&lt;c10::SymInt&gt;, bool, c10::ArrayRef&lt;c10::SymInt&gt;, c10::SymInt), &amp;at::(anonymous namespace)::(anonymous namespace)::wrapper_CompositeExplicitAutograd__convolution(at::Tensor const&amp;, at::Tensor const&amp;, std::optional&lt;at::Tensor&gt; const&amp;, c10::ArrayRef&lt;c10::SymInt&gt;, c10::ArrayRef&lt;c10::SymInt&gt;, c10::ArrayRef&lt;c10::SymInt&gt;, bool, c10::ArrayRef&lt;c10::SymInt&gt;, c10::SymInt)&gt;, at::Tensor, c10::guts::typelist::typelist&lt;at::Tensor const&amp;, at::Tensor const&amp;, std::optional&lt;at::Tensor&gt; const&amp;, c10::ArrayRef&lt;c10::SymInt&gt;, c10::ArrayRef&lt;c10::SymInt&gt;, c10::ArrayRef&lt;c10::SymInt&gt;, bool, c10::ArrayRef&lt;c10::SymInt&gt;, c10::SymInt&gt; &gt;, at::Tensor(at::Tensor const&amp;, at::Tensor const&amp;, std::optional&lt;at::Tensor&gt; const&amp;, c10::ArrayRef&lt;c10::SymInt&gt;, c10::ArrayRef&lt;c10::SymInt&gt;, c10::ArrayRef&lt;c10::SymInt&gt;, bool, c10::ArrayRef&lt;c10::SymInt&gt;, c10::SymInt)&gt;::call (libtorch_cpu.so) (113 samples, 0.44%)</title><rect x="24.6315%" y="500" width="0.4407%" height="15" fill="rgb(213,184,43)" fg:x="6316" fg:w="113"/><text x="24.8815%" y="510.50"></text></g><g><title>at::(anonymous namespace)::(anonymous namespace)::wrapper_CompositeExplicitAutograd__convolution (libtorch_cpu.so) (112 samples, 0.44%)</title><rect x="24.6354%" y="516" width="0.4368%" height="15" fill="rgb(231,61,34)" fg:x="6317" fg:w="112"/><text x="24.8854%" y="526.50"></text></g><g><title>at::native::convolution (libtorch_cpu.so) (112 samples, 0.44%)</title><rect x="24.6354%" y="532" width="0.4368%" height="15" fill="rgb(235,75,3)" fg:x="6317" fg:w="112"/><text x="24.8854%" y="542.50"></text></g><g><title>at::_ops::_convolution::call (libtorch_cpu.so) (111 samples, 0.43%)</title><rect x="24.6393%" y="548" width="0.4329%" height="15" fill="rgb(220,106,47)" fg:x="6318" fg:w="111"/><text x="24.8893%" y="558.50"></text></g><g><title>c10::impl::wrap_kernel_functor_unboxed_&lt;c10::impl::detail::WrapFunctionIntoFunctor_&lt;c10::CompileTimeFunctionPointer&lt;at::Tensor(at::Tensor const&amp;, at::Tensor const&amp;, std::optional&lt;at::Tensor&gt; const&amp;, c10::ArrayRef&lt;c10::SymInt&gt;, c10::ArrayRef&lt;c10::SymInt&gt;, c10::ArrayRef&lt;c10::SymInt&gt;, bool, c10::ArrayRef&lt;c10::SymInt&gt;, c10::SymInt, bool, bool, bool, bool), &amp;at::(anonymous namespace)::(anonymous namespace)::wrapper_CompositeExplicitAutograd___convolution(at::Tensor const&amp;, at::Tensor const&amp;, std::optional&lt;at::Tensor&gt; const&amp;, c10::ArrayRef&lt;c10::SymInt&gt;, c10::ArrayRef&lt;c10::SymInt&gt;, c10::ArrayRef&lt;c10::SymInt&gt;, bool, c10::ArrayRef&lt;c10::SymInt&gt;, c10::SymInt, bool, bool, bool, bool)&gt;, at::Tensor, c10::guts::typelist::typelist&lt;at::Tensor const&amp;, at::Tensor const&amp;, std::optional&lt;at::Tensor&gt; const&amp;, c10::ArrayRef&lt;c10::SymInt&gt;, c10::ArrayRef&lt;c10::SymInt&gt;, c10::ArrayRef&lt;c10::SymInt&gt;, bool, c10::ArrayRef&lt;c10::SymInt&gt;, c10::SymInt, bool, bool, bool, bool&gt; &gt;, at::Tensor(at::Tensor const&amp;, at::Tensor const&amp;, std::optional&lt;at::Tensor&gt; const&amp;, c10::ArrayRef&lt;c10::SymInt&gt;, c10::ArrayRef&lt;c10::SymInt&gt;, c10::ArrayRef&lt;c10::SymInt&gt;, bool, c10::ArrayRef&lt;c10::SymInt&gt;, c10::SymInt, bool, bool, bool, bool)&gt;::call (libtorch_cpu.so) (111 samples, 0.43%)</title><rect x="24.6393%" y="564" width="0.4329%" height="15" fill="rgb(210,196,33)" fg:x="6318" fg:w="111"/><text x="24.8893%" y="574.50"></text></g><g><title>at::(anonymous namespace)::(anonymous namespace)::wrapper_CompositeExplicitAutograd___convolution (libtorch_cpu.so) (109 samples, 0.43%)</title><rect x="24.6471%" y="580" width="0.4251%" height="15" fill="rgb(229,154,42)" fg:x="6320" fg:w="109"/><text x="24.8971%" y="590.50"></text></g><g><title>at::native::_convolution (libtorch_cpu.so) (109 samples, 0.43%)</title><rect x="24.6471%" y="596" width="0.4251%" height="15" fill="rgb(228,114,26)" fg:x="6320" fg:w="109"/><text x="24.8971%" y="606.50"></text></g><g><title>at::_ops::conv2d::call (libtorch_cpu.so) (118 samples, 0.46%)</title><rect x="24.6159%" y="388" width="0.4602%" height="15" fill="rgb(208,144,1)" fg:x="6312" fg:w="118"/><text x="24.8659%" y="398.50"></text></g><g><title>c10::impl::wrap_kernel_functor_unboxed_&lt;c10::impl::detail::WrapFunctionIntoFunctor_&lt;c10::CompileTimeFunctionPointer&lt;at::Tensor(at::Tensor const&amp;, at::Tensor const&amp;, std::optional&lt;at::Tensor&gt; const&amp;, c10::ArrayRef&lt;c10::SymInt&gt;, c10::ArrayRef&lt;c10::SymInt&gt;, c10::ArrayRef&lt;c10::SymInt&gt;, c10::SymInt), &amp;at::(anonymous namespace)::(anonymous namespace)::wrapper_CompositeImplicitAutograd__conv2d(at::Tensor const&amp;, at::Tensor const&amp;, std::optional&lt;at::Tensor&gt; const&amp;, c10::ArrayRef&lt;c10::SymInt&gt;, c10::ArrayRef&lt;c10::SymInt&gt;, c10::ArrayRef&lt;c10::SymInt&gt;, c10::SymInt)&gt;, at::Tensor, c10::guts::typelist::typelist&lt;at::Tensor const&amp;, at::Tensor const&amp;, std::optional&lt;at::Tensor&gt; const&amp;, c10::ArrayRef&lt;c10::SymInt&gt;, c10::ArrayRef&lt;c10::SymInt&gt;, c10::ArrayRef&lt;c10::SymInt&gt;, c10::SymInt&gt; &gt;, at::Tensor(at::Tensor const&amp;, at::Tensor const&amp;, std::optional&lt;at::Tensor&gt; const&amp;, c10::ArrayRef&lt;c10::SymInt&gt;, c10::ArrayRef&lt;c10::SymInt&gt;, c10::ArrayRef&lt;c10::SymInt&gt;, c10::SymInt)&gt;::call (libtorch_cpu.so) (116 samples, 0.45%)</title><rect x="24.6237%" y="404" width="0.4524%" height="15" fill="rgb(239,112,37)" fg:x="6314" fg:w="116"/><text x="24.8737%" y="414.50"></text></g><g><title>at::native::conv2d_symint (libtorch_cpu.so) (116 samples, 0.45%)</title><rect x="24.6237%" y="420" width="0.4524%" height="15" fill="rgb(210,96,50)" fg:x="6314" fg:w="116"/><text x="24.8737%" y="430.50"></text></g><g><title>at::_ops::convolution::call (libtorch_cpu.so) (115 samples, 0.45%)</title><rect x="24.6276%" y="436" width="0.4485%" height="15" fill="rgb(222,178,2)" fg:x="6315" fg:w="115"/><text x="24.8776%" y="446.50"></text></g><g><title>c10::impl::wrap_kernel_functor_unboxed_&lt;c10::impl::detail::WrapFunctionIntoFunctor_&lt;c10::CompileTimeFunctionPointer&lt;at::Tensor(c10::DispatchKeySet, at::Tensor const&amp;, at::Tensor const&amp;, std::optional&lt;at::Tensor&gt; const&amp;, c10::ArrayRef&lt;c10::SymInt&gt;, c10::ArrayRef&lt;c10::SymInt&gt;, c10::ArrayRef&lt;c10::SymInt&gt;, bool, c10::ArrayRef&lt;c10::SymInt&gt;, c10::SymInt), &amp;torch::autograd::VariableType::(anonymous namespace)::convolution(c10::DispatchKeySet, at::Tensor const&amp;, at::Tensor const&amp;, std::optional&lt;at::Tensor&gt; const&amp;, c10::ArrayRef&lt;c10::SymInt&gt;, c10::ArrayRef&lt;c10::SymInt&gt;, c10::ArrayRef&lt;c10::SymInt&gt;, bool, c10::ArrayRef&lt;c10::SymInt&gt;, c10::SymInt)&gt;, at::Tensor, c10::guts::typelist::typelist&lt;c10::DispatchKeySet, at::Tensor const&amp;, at::Tensor const&amp;, std::optional&lt;at::Tensor&gt; const&amp;, c10::ArrayRef&lt;c10::SymInt&gt;, c10::ArrayRef&lt;c10::SymInt&gt;, c10::ArrayRef&lt;c10::SymInt&gt;, bool, c10::ArrayRef&lt;c10::SymInt&gt;, c10::SymInt&gt; &gt;, at::Tensor(c10::DispatchKeySet, at::Tensor const&amp;, at::Tensor const&amp;, std::optional&lt;at::Tensor&gt; const&amp;, c10::ArrayRef&lt;c10::SymInt&gt;, c10::ArrayRef&lt;c10::SymInt&gt;, c10::ArrayRef&lt;c10::SymInt&gt;, bool, c10::ArrayRef&lt;c10::SymInt&gt;, c10::SymInt)&gt;::call (libtorch_cpu.so) (115 samples, 0.45%)</title><rect x="24.6276%" y="452" width="0.4485%" height="15" fill="rgb(226,74,18)" fg:x="6315" fg:w="115"/><text x="24.8776%" y="462.50"></text></g><g><title>torch::autograd::VariableType::(anonymous namespace)::convolution (libtorch_cpu.so) (115 samples, 0.45%)</title><rect x="24.6276%" y="468" width="0.4485%" height="15" fill="rgb(225,67,54)" fg:x="6315" fg:w="115"/><text x="24.8776%" y="478.50"></text></g><g><title>forward (torch/nn/modules/conv.py:548) (135 samples, 0.53%)</title><rect x="24.5808%" y="340" width="0.5265%" height="15" fill="rgb(251,92,32)" fg:x="6303" fg:w="135"/><text x="24.8308%" y="350.50"></text></g><g><title>_conv_forward (torch/nn/modules/conv.py:544) (131 samples, 0.51%)</title><rect x="24.5964%" y="356" width="0.5109%" height="15" fill="rgb(228,149,22)" fg:x="6307" fg:w="131"/><text x="24.8464%" y="366.50"></text></g><g><title>torch::autograd::THPVariable_conv2d (libtorch_python.so) (130 samples, 0.51%)</title><rect x="24.6003%" y="372" width="0.5070%" height="15" fill="rgb(243,54,13)" fg:x="6308" fg:w="130"/><text x="24.8503%" y="382.50"></text></g><g><title>at::_ops::mean_dim::call (libtorch_cpu.so) (34 samples, 0.13%)</title><rect x="25.1891%" y="436" width="0.1326%" height="15" fill="rgb(243,180,28)" fg:x="6459" fg:w="34"/><text x="25.4391%" y="446.50"></text></g><g><title>c10::impl::wrap_kernel_functor_unboxed_&lt;c10::impl::detail::WrapFunctionIntoFunctor_&lt;c10::CompileTimeFunctionPointer&lt;at::Tensor(c10::DispatchKeySet, at::Tensor const&amp;, c10::OptionalArrayRef&lt;long&gt;, bool, std::optional&lt;c10::ScalarType&gt;), &amp;torch::autograd::VariableType::(anonymous namespace)::mean_dim(c10::DispatchKeySet, at::Tensor const&amp;, c10::OptionalArrayRef&lt;long&gt;, bool, std::optional&lt;c10::ScalarType&gt;)&gt;, at::Tensor, c10::guts::typelist::typelist&lt;c10::DispatchKeySet, at::Tensor const&amp;, c10::OptionalArrayRef&lt;long&gt;, bool, std::optional&lt;c10::ScalarType&gt; &gt; &gt;, at::Tensor(c10::DispatchKeySet, at::Tensor const&amp;, c10::OptionalArrayRef&lt;long&gt;, bool, std::optional&lt;c10::ScalarType&gt;)&gt;::call (libtorch_cpu.so) (34 samples, 0.13%)</title><rect x="25.1891%" y="452" width="0.1326%" height="15" fill="rgb(208,167,24)" fg:x="6459" fg:w="34"/><text x="25.4391%" y="462.50"></text></g><g><title>torch::autograd::VariableType::(anonymous namespace)::mean_dim (libtorch_cpu.so) (34 samples, 0.13%)</title><rect x="25.1891%" y="468" width="0.1326%" height="15" fill="rgb(245,73,45)" fg:x="6459" fg:w="34"/><text x="25.4391%" y="478.50"></text></g><g><title>at::_ops::mean_dim::redispatch (libtorch_cpu.so) (34 samples, 0.13%)</title><rect x="25.1891%" y="484" width="0.1326%" height="15" fill="rgb(237,203,48)" fg:x="6459" fg:w="34"/><text x="25.4391%" y="494.50"></text></g><g><title>c10::impl::wrap_kernel_functor_unboxed_&lt;c10::impl::detail::WrapFunctionIntoFunctor_&lt;c10::CompileTimeFunctionPointer&lt;at::Tensor(at::Tensor const&amp;, c10::OptionalArrayRef&lt;long&gt;, bool, std::optional&lt;c10::ScalarType&gt;), &amp;at::(anonymous namespace)::wrapper_CUDA_mean_dim(at::Tensor const&amp;, c10::OptionalArrayRef&lt;long&gt;, bool, std::optional&lt;c10::ScalarType&gt;)&gt;, at::Tensor, c10::guts::typelist::typelist&lt;at::Tensor const&amp;, c10::OptionalArrayRef&lt;long&gt;, bool, std::optional&lt;c10::ScalarType&gt; &gt; &gt;, at::Tensor(at::Tensor const&amp;, c10::OptionalArrayRef&lt;long&gt;, bool, std::optional&lt;c10::ScalarType&gt;)&gt;::call (libtorch_cuda.so) (32 samples, 0.12%)</title><rect x="25.1969%" y="500" width="0.1248%" height="15" fill="rgb(211,197,16)" fg:x="6461" fg:w="32"/><text x="25.4469%" y="510.50"></text></g><g><title>at::(anonymous namespace)::wrapper_CUDA_mean_dim (libtorch_cuda.so) (32 samples, 0.12%)</title><rect x="25.1969%" y="516" width="0.1248%" height="15" fill="rgb(243,99,51)" fg:x="6461" fg:w="32"/><text x="25.4469%" y="526.50"></text></g><g><title>at::_ops::adaptive_avg_pool2d::call (libtorch_cpu.so) (36 samples, 0.14%)</title><rect x="25.1852%" y="388" width="0.1404%" height="15" fill="rgb(215,123,29)" fg:x="6458" fg:w="36"/><text x="25.4352%" y="398.50"></text></g><g><title>c10::impl::wrap_kernel_functor_unboxed_&lt;c10::impl::detail::WrapFunctionIntoFunctor_&lt;c10::CompileTimeFunctionPointer&lt;at::Tensor(at::Tensor const&amp;, c10::ArrayRef&lt;c10::SymInt&gt;), &amp;at::(anonymous namespace)::(anonymous namespace)::wrapper_CompositeImplicitAutograd__adaptive_avg_pool2d(at::Tensor const&amp;, c10::ArrayRef&lt;c10::SymInt&gt;)&gt;, at::Tensor, c10::guts::typelist::typelist&lt;at::Tensor const&amp;, c10::ArrayRef&lt;c10::SymInt&gt; &gt; &gt;, at::Tensor(at::Tensor const&amp;, c10::ArrayRef&lt;c10::SymInt&gt;)&gt;::call (libtorch_cpu.so) (36 samples, 0.14%)</title><rect x="25.1852%" y="404" width="0.1404%" height="15" fill="rgb(239,186,37)" fg:x="6458" fg:w="36"/><text x="25.4352%" y="414.50"></text></g><g><title>at::native::adaptive_avg_pool2d_symint (libtorch_cpu.so) (36 samples, 0.14%)</title><rect x="25.1852%" y="420" width="0.1404%" height="15" fill="rgb(252,136,39)" fg:x="6458" fg:w="36"/><text x="25.4352%" y="430.50"></text></g><g><title>forward (armada_net.py:167) (1,751 samples, 6.83%)</title><rect x="18.5126%" y="244" width="6.8286%" height="15" fill="rgb(223,213,32)" fg:x="4747" fg:w="1751"/><text x="18.7626%" y="254.50">forward (..</text></g><g><title>_wrapped_call_impl (torch/nn/modules/module.py:1773) (1,748 samples, 6.82%)</title><rect x="18.5243%" y="260" width="6.8169%" height="15" fill="rgb(233,115,5)" fg:x="4750" fg:w="1748"/><text x="18.7743%" y="270.50">_wrapped_..</text></g><g><title>_call_impl (torch/nn/modules/module.py:1784) (1,746 samples, 6.81%)</title><rect x="18.5321%" y="276" width="6.8091%" height="15" fill="rgb(207,226,44)" fg:x="4752" fg:w="1746"/><text x="18.7821%" y="286.50">_call_imp..</text></g><g><title>forward (torch/nn/modules/container.py:244) (1,739 samples, 6.78%)</title><rect x="18.5594%" y="292" width="6.7818%" height="15" fill="rgb(208,126,0)" fg:x="4759" fg:w="1739"/><text x="18.8094%" y="302.50">forward (..</text></g><g><title>_wrapped_call_impl (torch/nn/modules/module.py:1773) (1,717 samples, 6.70%)</title><rect x="18.6452%" y="308" width="6.6960%" height="15" fill="rgb(244,66,21)" fg:x="4781" fg:w="1717"/><text x="18.8952%" y="318.50">_wrapped_..</text></g><g><title>_call_impl (torch/nn/modules/module.py:1784) (1,687 samples, 6.58%)</title><rect x="18.7622%" y="324" width="6.5790%" height="15" fill="rgb(222,97,12)" fg:x="4811" fg:w="1687"/><text x="19.0122%" y="334.50">_call_imp..</text></g><g><title>forward (torch/nn/modules/pooling.py:1475) (59 samples, 0.23%)</title><rect x="25.1111%" y="340" width="0.2301%" height="15" fill="rgb(219,213,19)" fg:x="6439" fg:w="59"/><text x="25.3611%" y="350.50"></text></g><g><title>adaptive_avg_pool2d (torch/nn/functional.py:1379) (41 samples, 0.16%)</title><rect x="25.1813%" y="356" width="0.1599%" height="15" fill="rgb(252,169,30)" fg:x="6457" fg:w="41"/><text x="25.4313%" y="366.50"></text></g><g><title>torch::autograd::THPVariable_adaptive_avg_pool2d (libtorch_python.so) (41 samples, 0.16%)</title><rect x="25.1813%" y="372" width="0.1599%" height="15" fill="rgb(206,32,51)" fg:x="6457" fg:w="41"/><text x="25.4313%" y="382.50"></text></g><g><title>at::_ops::relu::redispatch (libtorch_cpu.so) (34 samples, 0.13%)</title><rect x="25.5869%" y="436" width="0.1326%" height="15" fill="rgb(250,172,42)" fg:x="6561" fg:w="34"/><text x="25.8369%" y="446.50"></text></g><g><title>c10::impl::wrap_kernel_functor_unboxed_&lt;c10::impl::detail::WrapFunctionIntoFunctor_&lt;c10::CompileTimeFunctionPointer&lt;at::Tensor(at::Tensor const&amp;), &amp;at::(anonymous namespace)::(anonymous namespace)::wrapper_CUDA__relu(at::Tensor const&amp;)&gt;, at::Tensor, c10::guts::typelist::typelist&lt;at::Tensor const&amp;&gt; &gt;, at::Tensor(at::Tensor const&amp;)&gt;::call (libtorch_cuda.so) (34 samples, 0.13%)</title><rect x="25.5869%" y="452" width="0.1326%" height="15" fill="rgb(209,34,43)" fg:x="6561" fg:w="34"/><text x="25.8369%" y="462.50"></text></g><g><title>at::native::relu (libtorch_cpu.so) (33 samples, 0.13%)</title><rect x="25.5908%" y="468" width="0.1287%" height="15" fill="rgb(223,11,35)" fg:x="6562" fg:w="33"/><text x="25.8408%" y="478.50"></text></g><g><title>at::_ops::clamp_min::call (libtorch_cpu.so) (33 samples, 0.13%)</title><rect x="25.5908%" y="484" width="0.1287%" height="15" fill="rgb(251,219,26)" fg:x="6562" fg:w="33"/><text x="25.8408%" y="494.50"></text></g><g><title>c10::impl::wrap_kernel_functor_unboxed_&lt;c10::impl::detail::WrapFunctionIntoFunctor_&lt;c10::CompileTimeFunctionPointer&lt;at::Tensor(at::Tensor const&amp;, c10::Scalar const&amp;), &amp;at::(anonymous namespace)::wrapper_CUDA_clamp_min(at::Tensor const&amp;, c10::Scalar const&amp;)&gt;, at::Tensor, c10::guts::typelist::typelist&lt;at::Tensor const&amp;, c10::Scalar const&amp;&gt; &gt;, at::Tensor(at::Tensor const&amp;, c10::Scalar const&amp;)&gt;::call (libtorch_cuda.so) (33 samples, 0.13%)</title><rect x="25.5908%" y="500" width="0.1287%" height="15" fill="rgb(231,119,3)" fg:x="6562" fg:w="33"/><text x="25.8408%" y="510.50"></text></g><g><title>at::(anonymous namespace)::wrapper_CUDA_clamp_min (libtorch_cuda.so) (33 samples, 0.13%)</title><rect x="25.5908%" y="516" width="0.1287%" height="15" fill="rgb(216,97,11)" fg:x="6562" fg:w="33"/><text x="25.8408%" y="526.50"></text></g><g><title>at::_ops::relu::call (libtorch_cpu.so) (36 samples, 0.14%)</title><rect x="25.5869%" y="388" width="0.1404%" height="15" fill="rgb(223,59,9)" fg:x="6561" fg:w="36"/><text x="25.8369%" y="398.50"></text></g><g><title>c10::impl::wrap_kernel_functor_unboxed_&lt;c10::impl::detail::WrapFunctionIntoFunctor_&lt;c10::CompileTimeFunctionPointer&lt;at::Tensor(c10::DispatchKeySet, at::Tensor const&amp;), &amp;torch::autograd::VariableType::(anonymous namespace)::relu(c10::DispatchKeySet, at::Tensor const&amp;)&gt;, at::Tensor, c10::guts::typelist::typelist&lt;c10::DispatchKeySet, at::Tensor const&amp;&gt; &gt;, at::Tensor(c10::DispatchKeySet, at::Tensor const&amp;)&gt;::call (libtorch_cpu.so) (36 samples, 0.14%)</title><rect x="25.5869%" y="404" width="0.1404%" height="15" fill="rgb(233,93,31)" fg:x="6561" fg:w="36"/><text x="25.8369%" y="414.50"></text></g><g><title>torch::autograd::VariableType::(anonymous namespace)::relu (libtorch_cpu.so) (36 samples, 0.14%)</title><rect x="25.5869%" y="420" width="0.1404%" height="15" fill="rgb(239,81,33)" fg:x="6561" fg:w="36"/><text x="25.8369%" y="430.50"></text></g><g><title>forward (torch/nn/modules/activation.py:135) (44 samples, 0.17%)</title><rect x="25.5674%" y="340" width="0.1716%" height="15" fill="rgb(213,120,34)" fg:x="6556" fg:w="44"/><text x="25.8174%" y="350.50"></text></g><g><title>relu (torch/nn/functional.py:1701) (42 samples, 0.16%)</title><rect x="25.5752%" y="356" width="0.1638%" height="15" fill="rgb(243,49,53)" fg:x="6558" fg:w="42"/><text x="25.8252%" y="366.50"></text></g><g><title>torch::autograd::THPVariable_relu (libtorch_python.so) (41 samples, 0.16%)</title><rect x="25.5791%" y="372" width="0.1599%" height="15" fill="rgb(247,216,33)" fg:x="6559" fg:w="41"/><text x="25.8291%" y="382.50"></text></g><g><title>at::_ops::add__Tensor::call (libtorch_cpu.so) (30 samples, 0.12%)</title><rect x="25.8326%" y="612" width="0.1170%" height="15" fill="rgb(226,26,14)" fg:x="6624" fg:w="30"/><text x="26.0826%" y="622.50"></text></g><g><title>at::(anonymous namespace)::wrapper_CUDA_add__Tensor (libtorch_cuda.so) (30 samples, 0.12%)</title><rect x="25.8326%" y="628" width="0.1170%" height="15" fill="rgb(215,49,53)" fg:x="6624" fg:w="30"/><text x="26.0826%" y="638.50"></text></g><g><title>cudnn::cnn::EngineInterface::execute (libcudnn_graph.so.9) (33 samples, 0.13%)</title><rect x="26.0939%" y="788" width="0.1287%" height="15" fill="rgb(245,162,40)" fg:x="6691" fg:w="33"/><text x="26.3439%" y="798.50"></text></g><g><title>cudnnBackendExecute (libcudnn.so.9) (36 samples, 0.14%)</title><rect x="26.0861%" y="740" width="0.1404%" height="15" fill="rgb(229,68,17)" fg:x="6689" fg:w="36"/><text x="26.3361%" y="750.50"></text></g><g><title>cudnnBackendExecute (libcudnn_graph.so.9) (36 samples, 0.14%)</title><rect x="26.0861%" y="756" width="0.1404%" height="15" fill="rgb(213,182,10)" fg:x="6689" fg:w="36"/><text x="26.3361%" y="766.50"></text></g><g><title>cudnn::backend::execute (libcudnn_graph.so.9) (36 samples, 0.14%)</title><rect x="26.0861%" y="772" width="0.1404%" height="15" fill="rgb(245,125,30)" fg:x="6689" fg:w="36"/><text x="26.3361%" y="782.50"></text></g><g><title>at::native::run_conv_plan (libtorch_cuda.so) (54 samples, 0.21%)</title><rect x="26.0549%" y="724" width="0.2106%" height="15" fill="rgb(232,202,2)" fg:x="6681" fg:w="54"/><text x="26.3049%" y="734.50"></text></g><g><title>at::native::cudnn_convolution (libtorch_cuda.so) (83 samples, 0.32%)</title><rect x="25.9496%" y="660" width="0.3237%" height="15" fill="rgb(237,140,51)" fg:x="6654" fg:w="83"/><text x="26.1996%" y="670.50"></text></g><g><title>at::native::cudnn_convolution_forward_out (libtorch_cuda.so) (70 samples, 0.27%)</title><rect x="26.0003%" y="676" width="0.2730%" height="15" fill="rgb(236,157,25)" fg:x="6667" fg:w="70"/><text x="26.2503%" y="686.50"></text></g><g><title>at::native::raw_cudnn_convolution_forward_out (libtorch_cuda.so) (66 samples, 0.26%)</title><rect x="26.0159%" y="692" width="0.2574%" height="15" fill="rgb(219,209,0)" fg:x="6671" fg:w="66"/><text x="26.2659%" y="702.50"></text></g><g><title>at::native::run_single_conv (libtorch_cuda.so) (66 samples, 0.26%)</title><rect x="26.0159%" y="708" width="0.2574%" height="15" fill="rgb(240,116,54)" fg:x="6671" fg:w="66"/><text x="26.2659%" y="718.50"></text></g><g><title>at::_ops::cudnn_convolution::call (libtorch_cpu.so) (86 samples, 0.34%)</title><rect x="25.9496%" y="612" width="0.3354%" height="15" fill="rgb(216,10,36)" fg:x="6654" fg:w="86"/><text x="26.1996%" y="622.50"></text></g><g><title>c10::impl::wrap_kernel_functor_unboxed_&lt;c10::impl::detail::WrapFunctionIntoFunctor_&lt;c10::CompileTimeFunctionPointer&lt;at::Tensor(at::Tensor const&amp;, at::Tensor const&amp;, c10::ArrayRef&lt;c10::SymInt&gt;, c10::ArrayRef&lt;c10::SymInt&gt;, c10::ArrayRef&lt;c10::SymInt&gt;, c10::SymInt, bool, bool, bool), &amp;at::(anonymous namespace)::(anonymous namespace)::wrapper_CUDA__cudnn_convolution(at::Tensor const&amp;, at::Tensor const&amp;, c10::ArrayRef&lt;c10::SymInt&gt;, c10::ArrayRef&lt;c10::SymInt&gt;, c10::ArrayRef&lt;c10::SymInt&gt;, c10::SymInt, bool, bool, bool)&gt;, at::Tensor, c10::guts::typelist::typelist&lt;at::Tensor const&amp;, at::Tensor const&amp;, c10::ArrayRef&lt;c10::SymInt&gt;, c10::ArrayRef&lt;c10::SymInt&gt;, c10::ArrayRef&lt;c10::SymInt&gt;, c10::SymInt, bool, bool, bool&gt; &gt;, at::Tensor(at::Tensor const&amp;, at::Tensor const&amp;, c10::ArrayRef&lt;c10::SymInt&gt;, c10::ArrayRef&lt;c10::SymInt&gt;, c10::ArrayRef&lt;c10::SymInt&gt;, c10::SymInt, bool, bool, bool)&gt;::call (libtorch_cuda.so) (86 samples, 0.34%)</title><rect x="25.9496%" y="628" width="0.3354%" height="15" fill="rgb(222,72,44)" fg:x="6654" fg:w="86"/><text x="26.1996%" y="638.50"></text></g><g><title>at::(anonymous namespace)::(anonymous namespace)::wrapper_CUDA__cudnn_convolution (libtorch_cuda.so) (86 samples, 0.34%)</title><rect x="25.9496%" y="644" width="0.3354%" height="15" fill="rgb(232,159,9)" fg:x="6654" fg:w="86"/><text x="26.1996%" y="654.50"></text></g><g><title>at::_ops::convolution::redispatch (libtorch_cpu.so) (143 samples, 0.56%)</title><rect x="25.8053%" y="484" width="0.5577%" height="15" fill="rgb(210,39,32)" fg:x="6617" fg:w="143"/><text x="26.0553%" y="494.50"></text></g><g><title>c10::impl::wrap_kernel_functor_unboxed_&lt;c10::impl::detail::WrapFunctionIntoFunctor_&lt;c10::CompileTimeFunctionPointer&lt;at::Tensor(at::Tensor const&amp;, at::Tensor const&amp;, std::optional&lt;at::Tensor&gt; const&amp;, c10::ArrayRef&lt;c10::SymInt&gt;, c10::ArrayRef&lt;c10::SymInt&gt;, c10::ArrayRef&lt;c10::SymInt&gt;, bool, c10::ArrayRef&lt;c10::SymInt&gt;, c10::SymInt), &amp;at::(anonymous namespace)::(anonymous namespace)::wrapper_CompositeExplicitAutograd__convolution(at::Tensor const&amp;, at::Tensor const&amp;, std::optional&lt;at::Tensor&gt; const&amp;, c10::ArrayRef&lt;c10::SymInt&gt;, c10::ArrayRef&lt;c10::SymInt&gt;, c10::ArrayRef&lt;c10::SymInt&gt;, bool, c10::ArrayRef&lt;c10::SymInt&gt;, c10::SymInt)&gt;, at::Tensor, c10::guts::typelist::typelist&lt;at::Tensor const&amp;, at::Tensor const&amp;, std::optional&lt;at::Tensor&gt; const&amp;, c10::ArrayRef&lt;c10::SymInt&gt;, c10::ArrayRef&lt;c10::SymInt&gt;, c10::ArrayRef&lt;c10::SymInt&gt;, bool, c10::ArrayRef&lt;c10::SymInt&gt;, c10::SymInt&gt; &gt;, at::Tensor(at::Tensor const&amp;, at::Tensor const&amp;, std::optional&lt;at::Tensor&gt; const&amp;, c10::ArrayRef&lt;c10::SymInt&gt;, c10::ArrayRef&lt;c10::SymInt&gt;, c10::ArrayRef&lt;c10::SymInt&gt;, bool, c10::ArrayRef&lt;c10::SymInt&gt;, c10::SymInt)&gt;::call (libtorch_cpu.so) (143 samples, 0.56%)</title><rect x="25.8053%" y="500" width="0.5577%" height="15" fill="rgb(216,194,45)" fg:x="6617" fg:w="143"/><text x="26.0553%" y="510.50"></text></g><g><title>at::(anonymous namespace)::(anonymous namespace)::wrapper_CompositeExplicitAutograd__convolution (libtorch_cpu.so) (143 samples, 0.56%)</title><rect x="25.8053%" y="516" width="0.5577%" height="15" fill="rgb(218,18,35)" fg:x="6617" fg:w="143"/><text x="26.0553%" y="526.50"></text></g><g><title>at::native::convolution (libtorch_cpu.so) (143 samples, 0.56%)</title><rect x="25.8053%" y="532" width="0.5577%" height="15" fill="rgb(207,83,51)" fg:x="6617" fg:w="143"/><text x="26.0553%" y="542.50"></text></g><g><title>at::_ops::_convolution::call (libtorch_cpu.so) (143 samples, 0.56%)</title><rect x="25.8053%" y="548" width="0.5577%" height="15" fill="rgb(225,63,43)" fg:x="6617" fg:w="143"/><text x="26.0553%" y="558.50"></text></g><g><title>c10::impl::wrap_kernel_functor_unboxed_&lt;c10::impl::detail::WrapFunctionIntoFunctor_&lt;c10::CompileTimeFunctionPointer&lt;at::Tensor(at::Tensor const&amp;, at::Tensor const&amp;, std::optional&lt;at::Tensor&gt; const&amp;, c10::ArrayRef&lt;c10::SymInt&gt;, c10::ArrayRef&lt;c10::SymInt&gt;, c10::ArrayRef&lt;c10::SymInt&gt;, bool, c10::ArrayRef&lt;c10::SymInt&gt;, c10::SymInt, bool, bool, bool, bool), &amp;at::(anonymous namespace)::(anonymous namespace)::wrapper_CompositeExplicitAutograd___convolution(at::Tensor const&amp;, at::Tensor const&amp;, std::optional&lt;at::Tensor&gt; const&amp;, c10::ArrayRef&lt;c10::SymInt&gt;, c10::ArrayRef&lt;c10::SymInt&gt;, c10::ArrayRef&lt;c10::SymInt&gt;, bool, c10::ArrayRef&lt;c10::SymInt&gt;, c10::SymInt, bool, bool, bool, bool)&gt;, at::Tensor, c10::guts::typelist::typelist&lt;at::Tensor const&amp;, at::Tensor const&amp;, std::optional&lt;at::Tensor&gt; const&amp;, c10::ArrayRef&lt;c10::SymInt&gt;, c10::ArrayRef&lt;c10::SymInt&gt;, c10::ArrayRef&lt;c10::SymInt&gt;, bool, c10::ArrayRef&lt;c10::SymInt&gt;, c10::SymInt, bool, bool, bool, bool&gt; &gt;, at::Tensor(at::Tensor const&amp;, at::Tensor const&amp;, std::optional&lt;at::Tensor&gt; const&amp;, c10::ArrayRef&lt;c10::SymInt&gt;, c10::ArrayRef&lt;c10::SymInt&gt;, c10::ArrayRef&lt;c10::SymInt&gt;, bool, c10::ArrayRef&lt;c10::SymInt&gt;, c10::SymInt, bool, bool, bool, bool)&gt;::call (libtorch_cpu.so) (141 samples, 0.55%)</title><rect x="25.8131%" y="564" width="0.5499%" height="15" fill="rgb(207,57,36)" fg:x="6619" fg:w="141"/><text x="26.0631%" y="574.50"></text></g><g><title>at::(anonymous namespace)::(anonymous namespace)::wrapper_CompositeExplicitAutograd___convolution (libtorch_cpu.so) (141 samples, 0.55%)</title><rect x="25.8131%" y="580" width="0.5499%" height="15" fill="rgb(216,99,33)" fg:x="6619" fg:w="141"/><text x="26.0631%" y="590.50"></text></g><g><title>at::native::_convolution (libtorch_cpu.so) (140 samples, 0.55%)</title><rect x="25.8170%" y="596" width="0.5460%" height="15" fill="rgb(225,42,16)" fg:x="6620" fg:w="140"/><text x="26.0670%" y="606.50"></text></g><g><title>at::_ops::conv2d::call (libtorch_cpu.so) (150 samples, 0.58%)</title><rect x="25.7897%" y="388" width="0.5850%" height="15" fill="rgb(220,201,45)" fg:x="6613" fg:w="150"/><text x="26.0397%" y="398.50"></text></g><g><title>c10::impl::wrap_kernel_functor_unboxed_&lt;c10::impl::detail::WrapFunctionIntoFunctor_&lt;c10::CompileTimeFunctionPointer&lt;at::Tensor(at::Tensor const&amp;, at::Tensor const&amp;, std::optional&lt;at::Tensor&gt; const&amp;, c10::ArrayRef&lt;c10::SymInt&gt;, c10::ArrayRef&lt;c10::SymInt&gt;, c10::ArrayRef&lt;c10::SymInt&gt;, c10::SymInt), &amp;at::(anonymous namespace)::(anonymous namespace)::wrapper_CompositeImplicitAutograd__conv2d(at::Tensor const&amp;, at::Tensor const&amp;, std::optional&lt;at::Tensor&gt; const&amp;, c10::ArrayRef&lt;c10::SymInt&gt;, c10::ArrayRef&lt;c10::SymInt&gt;, c10::ArrayRef&lt;c10::SymInt&gt;, c10::SymInt)&gt;, at::Tensor, c10::guts::typelist::typelist&lt;at::Tensor const&amp;, at::Tensor const&amp;, std::optional&lt;at::Tensor&gt; const&amp;, c10::ArrayRef&lt;c10::SymInt&gt;, c10::ArrayRef&lt;c10::SymInt&gt;, c10::ArrayRef&lt;c10::SymInt&gt;, c10::SymInt&gt; &gt;, at::Tensor(at::Tensor const&amp;, at::Tensor const&amp;, std::optional&lt;at::Tensor&gt; const&amp;, c10::ArrayRef&lt;c10::SymInt&gt;, c10::ArrayRef&lt;c10::SymInt&gt;, c10::ArrayRef&lt;c10::SymInt&gt;, c10::SymInt)&gt;::call (libtorch_cpu.so) (150 samples, 0.58%)</title><rect x="25.7897%" y="404" width="0.5850%" height="15" fill="rgb(225,33,4)" fg:x="6613" fg:w="150"/><text x="26.0397%" y="414.50"></text></g><g><title>at::native::conv2d_symint (libtorch_cpu.so) (150 samples, 0.58%)</title><rect x="25.7897%" y="420" width="0.5850%" height="15" fill="rgb(224,33,50)" fg:x="6613" fg:w="150"/><text x="26.0397%" y="430.50"></text></g><g><title>at::_ops::convolution::call (libtorch_cpu.so) (150 samples, 0.58%)</title><rect x="25.7897%" y="436" width="0.5850%" height="15" fill="rgb(246,198,51)" fg:x="6613" fg:w="150"/><text x="26.0397%" y="446.50"></text></g><g><title>c10::impl::wrap_kernel_functor_unboxed_&lt;c10::impl::detail::WrapFunctionIntoFunctor_&lt;c10::CompileTimeFunctionPointer&lt;at::Tensor(c10::DispatchKeySet, at::Tensor const&amp;, at::Tensor const&amp;, std::optional&lt;at::Tensor&gt; const&amp;, c10::ArrayRef&lt;c10::SymInt&gt;, c10::ArrayRef&lt;c10::SymInt&gt;, c10::ArrayRef&lt;c10::SymInt&gt;, bool, c10::ArrayRef&lt;c10::SymInt&gt;, c10::SymInt), &amp;torch::autograd::VariableType::(anonymous namespace)::convolution(c10::DispatchKeySet, at::Tensor const&amp;, at::Tensor const&amp;, std::optional&lt;at::Tensor&gt; const&amp;, c10::ArrayRef&lt;c10::SymInt&gt;, c10::ArrayRef&lt;c10::SymInt&gt;, c10::ArrayRef&lt;c10::SymInt&gt;, bool, c10::ArrayRef&lt;c10::SymInt&gt;, c10::SymInt)&gt;, at::Tensor, c10::guts::typelist::typelist&lt;c10::DispatchKeySet, at::Tensor const&amp;, at::Tensor const&amp;, std::optional&lt;at::Tensor&gt; const&amp;, c10::ArrayRef&lt;c10::SymInt&gt;, c10::ArrayRef&lt;c10::SymInt&gt;, c10::ArrayRef&lt;c10::SymInt&gt;, bool, c10::ArrayRef&lt;c10::SymInt&gt;, c10::SymInt&gt; &gt;, at::Tensor(c10::DispatchKeySet, at::Tensor const&amp;, at::Tensor const&amp;, std::optional&lt;at::Tensor&gt; const&amp;, c10::ArrayRef&lt;c10::SymInt&gt;, c10::ArrayRef&lt;c10::SymInt&gt;, c10::ArrayRef&lt;c10::SymInt&gt;, bool, c10::ArrayRef&lt;c10::SymInt&gt;, c10::SymInt)&gt;::call (libtorch_cpu.so) (148 samples, 0.58%)</title><rect x="25.7975%" y="452" width="0.5772%" height="15" fill="rgb(205,22,4)" fg:x="6615" fg:w="148"/><text x="26.0475%" y="462.50"></text></g><g><title>torch::autograd::VariableType::(anonymous namespace)::convolution (libtorch_cpu.so) (148 samples, 0.58%)</title><rect x="25.7975%" y="468" width="0.5772%" height="15" fill="rgb(206,3,8)" fg:x="6615" fg:w="148"/><text x="26.0475%" y="478.50"></text></g><g><title>forward (torch/nn/modules/conv.py:548) (173 samples, 0.67%)</title><rect x="25.7390%" y="340" width="0.6747%" height="15" fill="rgb(251,23,15)" fg:x="6600" fg:w="173"/><text x="25.9890%" y="350.50"></text></g><g><title>_conv_forward (torch/nn/modules/conv.py:544) (168 samples, 0.66%)</title><rect x="25.7585%" y="356" width="0.6552%" height="15" fill="rgb(252,88,28)" fg:x="6605" fg:w="168"/><text x="26.0085%" y="366.50"></text></g><g><title>torch::autograd::THPVariable_conv2d (libtorch_python.so) (163 samples, 0.64%)</title><rect x="25.7780%" y="372" width="0.6357%" height="15" fill="rgb(212,127,14)" fg:x="6610" fg:w="163"/><text x="26.0280%" y="382.50"></text></g><g><title>at::_ops::adaptive_avg_pool2d::call (libtorch_cpu.so) (28 samples, 0.11%)</title><rect x="26.4800%" y="388" width="0.1092%" height="15" fill="rgb(247,145,37)" fg:x="6790" fg:w="28"/><text x="26.7300%" y="398.50"></text></g><g><title>c10::impl::wrap_kernel_functor_unboxed_&lt;c10::impl::detail::WrapFunctionIntoFunctor_&lt;c10::CompileTimeFunctionPointer&lt;at::Tensor(at::Tensor const&amp;, c10::ArrayRef&lt;c10::SymInt&gt;), &amp;at::(anonymous namespace)::(anonymous namespace)::wrapper_CompositeImplicitAutograd__adaptive_avg_pool2d(at::Tensor const&amp;, c10::ArrayRef&lt;c10::SymInt&gt;)&gt;, at::Tensor, c10::guts::typelist::typelist&lt;at::Tensor const&amp;, c10::ArrayRef&lt;c10::SymInt&gt; &gt; &gt;, at::Tensor(at::Tensor const&amp;, c10::ArrayRef&lt;c10::SymInt&gt;)&gt;::call (libtorch_cpu.so) (28 samples, 0.11%)</title><rect x="26.4800%" y="404" width="0.1092%" height="15" fill="rgb(209,117,53)" fg:x="6790" fg:w="28"/><text x="26.7300%" y="414.50"></text></g><g><title>at::native::adaptive_avg_pool2d_symint (libtorch_cpu.so) (28 samples, 0.11%)</title><rect x="26.4800%" y="420" width="0.1092%" height="15" fill="rgb(212,90,42)" fg:x="6790" fg:w="28"/><text x="26.7300%" y="430.50"></text></g><g><title>at::_ops::mean_dim::call (libtorch_cpu.so) (28 samples, 0.11%)</title><rect x="26.4800%" y="436" width="0.1092%" height="15" fill="rgb(218,164,37)" fg:x="6790" fg:w="28"/><text x="26.7300%" y="446.50"></text></g><g><title>c10::impl::wrap_kernel_functor_unboxed_&lt;c10::impl::detail::WrapFunctionIntoFunctor_&lt;c10::CompileTimeFunctionPointer&lt;at::Tensor(c10::DispatchKeySet, at::Tensor const&amp;, c10::OptionalArrayRef&lt;long&gt;, bool, std::optional&lt;c10::ScalarType&gt;), &amp;torch::autograd::VariableType::(anonymous namespace)::mean_dim(c10::DispatchKeySet, at::Tensor const&amp;, c10::OptionalArrayRef&lt;long&gt;, bool, std::optional&lt;c10::ScalarType&gt;)&gt;, at::Tensor, c10::guts::typelist::typelist&lt;c10::DispatchKeySet, at::Tensor const&amp;, c10::OptionalArrayRef&lt;long&gt;, bool, std::optional&lt;c10::ScalarType&gt; &gt; &gt;, at::Tensor(c10::DispatchKeySet, at::Tensor const&amp;, c10::OptionalArrayRef&lt;long&gt;, bool, std::optional&lt;c10::ScalarType&gt;)&gt;::call (libtorch_cpu.so) (28 samples, 0.11%)</title><rect x="26.4800%" y="452" width="0.1092%" height="15" fill="rgb(246,65,34)" fg:x="6790" fg:w="28"/><text x="26.7300%" y="462.50"></text></g><g><title>torch::autograd::VariableType::(anonymous namespace)::mean_dim (libtorch_cpu.so) (28 samples, 0.11%)</title><rect x="26.4800%" y="468" width="0.1092%" height="15" fill="rgb(231,100,33)" fg:x="6790" fg:w="28"/><text x="26.7300%" y="478.50"></text></g><g><title>at::_ops::mean_dim::redispatch (libtorch_cpu.so) (27 samples, 0.11%)</title><rect x="26.4839%" y="484" width="0.1053%" height="15" fill="rgb(228,126,14)" fg:x="6791" fg:w="27"/><text x="26.7339%" y="494.50"></text></g><g><title>c10::impl::wrap_kernel_functor_unboxed_&lt;c10::impl::detail::WrapFunctionIntoFunctor_&lt;c10::CompileTimeFunctionPointer&lt;at::Tensor(at::Tensor const&amp;, c10::OptionalArrayRef&lt;long&gt;, bool, std::optional&lt;c10::ScalarType&gt;), &amp;at::(anonymous namespace)::wrapper_CUDA_mean_dim(at::Tensor const&amp;, c10::OptionalArrayRef&lt;long&gt;, bool, std::optional&lt;c10::ScalarType&gt;)&gt;, at::Tensor, c10::guts::typelist::typelist&lt;at::Tensor const&amp;, c10::OptionalArrayRef&lt;long&gt;, bool, std::optional&lt;c10::ScalarType&gt; &gt; &gt;, at::Tensor(at::Tensor const&amp;, c10::OptionalArrayRef&lt;long&gt;, bool, std::optional&lt;c10::ScalarType&gt;)&gt;::call (libtorch_cuda.so) (26 samples, 0.10%)</title><rect x="26.4878%" y="500" width="0.1014%" height="15" fill="rgb(215,173,21)" fg:x="6792" fg:w="26"/><text x="26.7378%" y="510.50"></text></g><g><title>at::(anonymous namespace)::wrapper_CUDA_mean_dim (libtorch_cuda.so) (26 samples, 0.10%)</title><rect x="26.4878%" y="516" width="0.1014%" height="15" fill="rgb(210,6,40)" fg:x="6792" fg:w="26"/><text x="26.7378%" y="526.50"></text></g><g><title>_wrapped_call_impl (torch/nn/modules/module.py:1773) (310 samples, 1.21%)</title><rect x="25.4036%" y="260" width="1.2090%" height="15" fill="rgb(212,48,18)" fg:x="6514" fg:w="310"/><text x="25.6536%" y="270.50"></text></g><g><title>_call_impl (torch/nn/modules/module.py:1784) (308 samples, 1.20%)</title><rect x="25.4114%" y="276" width="1.2012%" height="15" fill="rgb(230,214,11)" fg:x="6516" fg:w="308"/><text x="25.6614%" y="286.50"></text></g><g><title>forward (torch/nn/modules/container.py:244) (306 samples, 1.19%)</title><rect x="25.4192%" y="292" width="1.1934%" height="15" fill="rgb(254,105,39)" fg:x="6518" fg:w="306"/><text x="25.6692%" y="302.50"></text></g><g><title>_wrapped_call_impl (torch/nn/modules/module.py:1773) (292 samples, 1.14%)</title><rect x="25.4738%" y="308" width="1.1388%" height="15" fill="rgb(245,158,5)" fg:x="6532" fg:w="292"/><text x="25.7238%" y="318.50"></text></g><g><title>_call_impl (torch/nn/modules/module.py:1784) (269 samples, 1.05%)</title><rect x="25.5635%" y="324" width="1.0491%" height="15" fill="rgb(249,208,11)" fg:x="6555" fg:w="269"/><text x="25.8135%" y="334.50"></text></g><g><title>forward (torch/nn/modules/pooling.py:1475) (51 samples, 0.20%)</title><rect x="26.4137%" y="340" width="0.1989%" height="15" fill="rgb(210,39,28)" fg:x="6773" fg:w="51"/><text x="26.6637%" y="350.50"></text></g><g><title>adaptive_avg_pool2d (torch/nn/functional.py:1379) (36 samples, 0.14%)</title><rect x="26.4722%" y="356" width="0.1404%" height="15" fill="rgb(211,56,53)" fg:x="6788" fg:w="36"/><text x="26.7222%" y="366.50"></text></g><g><title>torch::autograd::THPVariable_adaptive_avg_pool2d (libtorch_python.so) (35 samples, 0.14%)</title><rect x="26.4761%" y="372" width="0.1365%" height="15" fill="rgb(226,201,30)" fg:x="6789" fg:w="35"/><text x="26.7261%" y="382.50"></text></g><g><title>forward (armada_net.py:171) (322 samples, 1.26%)</title><rect x="25.3841%" y="244" width="1.2558%" height="15" fill="rgb(239,101,34)" fg:x="6509" fg:w="322"/><text x="25.6341%" y="254.50"></text></g><g><title>at::_ops::cat::call (libtorch_cpu.so) (43 samples, 0.17%)</title><rect x="26.6672%" y="276" width="0.1677%" height="15" fill="rgb(226,209,5)" fg:x="6838" fg:w="43"/><text x="26.9172%" y="286.50"></text></g><g><title>c10::impl::wrap_kernel_functor_unboxed_&lt;c10::impl::detail::WrapFunctionIntoFunctor_&lt;c10::CompileTimeFunctionPointer&lt;at::Tensor(c10::DispatchKeySet, c10::IListRef&lt;at::Tensor&gt; const&amp;, long), &amp;torch::autograd::VariableType::(anonymous namespace)::cat(c10::DispatchKeySet, c10::IListRef&lt;at::Tensor&gt; const&amp;, long)&gt;, at::Tensor, c10::guts::typelist::typelist&lt;c10::DispatchKeySet, c10::IListRef&lt;at::Tensor&gt; const&amp;, long&gt; &gt;, at::Tensor(c10::DispatchKeySet, c10::IListRef&lt;at::Tensor&gt; const&amp;, long)&gt;::call (libtorch_cpu.so) (42 samples, 0.16%)</title><rect x="26.6711%" y="292" width="0.1638%" height="15" fill="rgb(250,105,47)" fg:x="6839" fg:w="42"/><text x="26.9211%" y="302.50"></text></g><g><title>torch::autograd::VariableType::(anonymous namespace)::cat (libtorch_cpu.so) (42 samples, 0.16%)</title><rect x="26.6711%" y="308" width="0.1638%" height="15" fill="rgb(230,72,3)" fg:x="6839" fg:w="42"/><text x="26.9211%" y="318.50"></text></g><g><title>at::_ops::cat::redispatch (libtorch_cpu.so) (42 samples, 0.16%)</title><rect x="26.6711%" y="324" width="0.1638%" height="15" fill="rgb(232,218,39)" fg:x="6839" fg:w="42"/><text x="26.9211%" y="334.50"></text></g><g><title>c10::impl::wrap_kernel_functor_unboxed_&lt;c10::impl::detail::WrapFunctionIntoFunctor_&lt;c10::CompileTimeFunctionPointer&lt;at::Tensor(c10::IListRef&lt;at::Tensor&gt; const&amp;, long), &amp;at::(anonymous namespace)::wrapper_CUDA_cat(c10::IListRef&lt;at::Tensor&gt; const&amp;, long)&gt;, at::Tensor, c10::guts::typelist::typelist&lt;c10::IListRef&lt;at::Tensor&gt; const&amp;, long&gt; &gt;, at::Tensor(c10::IListRef&lt;at::Tensor&gt; const&amp;, long)&gt;::call (libtorch_cuda.so) (41 samples, 0.16%)</title><rect x="26.6750%" y="340" width="0.1599%" height="15" fill="rgb(248,166,6)" fg:x="6840" fg:w="41"/><text x="26.9250%" y="350.50"></text></g><g><title>at::(anonymous namespace)::wrapper_CUDA_cat (libtorch_cuda.so) (41 samples, 0.16%)</title><rect x="26.6750%" y="356" width="0.1599%" height="15" fill="rgb(247,89,20)" fg:x="6840" fg:w="41"/><text x="26.9250%" y="366.50"></text></g><g><title>forward (armada_net.py:177) (52 samples, 0.20%)</title><rect x="26.6555%" y="244" width="0.2028%" height="15" fill="rgb(248,130,54)" fg:x="6835" fg:w="52"/><text x="26.9055%" y="254.50"></text></g><g><title>torch::autograd::THPVariable_cat (libtorch_python.so) (49 samples, 0.19%)</title><rect x="26.6672%" y="260" width="0.1911%" height="15" fill="rgb(234,196,4)" fg:x="6838" fg:w="49"/><text x="26.9172%" y="270.50"></text></g><g><title>forward (torch/nn/modules/activation.py:135) (26 samples, 0.10%)</title><rect x="26.9675%" y="340" width="0.1014%" height="15" fill="rgb(250,143,31)" fg:x="6915" fg:w="26"/><text x="27.2175%" y="350.50"></text></g><g><title>cublasLtMatmul (nvidia/cublas/lib/libcublasLt.so.12) (34 samples, 0.13%)</title><rect x="27.3263%" y="564" width="0.1326%" height="15" fill="rgb(211,110,34)" fg:x="7007" fg:w="34"/><text x="27.5763%" y="574.50"></text></g><g><title>0x7ac4e246b6ab (nvidia/cublas/lib/libcublasLt.so.12) (29 samples, 0.11%)</title><rect x="27.3458%" y="580" width="0.1131%" height="15" fill="rgb(215,124,48)" fg:x="7012" fg:w="29"/><text x="27.5958%" y="590.50"></text></g><g><title>0x7ac4e2394df1 (nvidia/cublas/lib/libcublasLt.so.12) (26 samples, 0.10%)</title><rect x="27.3575%" y="596" width="0.1014%" height="15" fill="rgb(216,46,13)" fg:x="7015" fg:w="26"/><text x="27.6075%" y="606.50"></text></g><g><title>at::cuda::blas::gemm_and_bias&lt;float, float&gt; (libtorch_cuda.so) (75 samples, 0.29%)</title><rect x="27.2327%" y="548" width="0.2925%" height="15" fill="rgb(205,184,25)" fg:x="6983" fg:w="75"/><text x="27.4827%" y="558.50"></text></g><g><title>at::native::structured_addmm_out_cuda::impl (libtorch_cuda.so) (85 samples, 0.33%)</title><rect x="27.2093%" y="516" width="0.3315%" height="15" fill="rgb(228,1,10)" fg:x="6977" fg:w="85"/><text x="27.4593%" y="526.50"></text></g><g><title>at::native::(anonymous namespace)::addmm_out_cuda_impl (libtorch_cuda.so) (85 samples, 0.33%)</title><rect x="27.2093%" y="532" width="0.3315%" height="15" fill="rgb(213,116,27)" fg:x="6977" fg:w="85"/><text x="27.4593%" y="542.50"></text></g><g><title>at::_ops::addmm::redispatch (libtorch_cpu.so) (107 samples, 0.42%)</title><rect x="27.1274%" y="468" width="0.4173%" height="15" fill="rgb(241,95,50)" fg:x="6956" fg:w="107"/><text x="27.3774%" y="478.50"></text></g><g><title>c10::impl::wrap_kernel_functor_unboxed_&lt;c10::impl::detail::WrapFunctionIntoFunctor_&lt;c10::CompileTimeFunctionPointer&lt;at::Tensor(at::Tensor const&amp;, at::Tensor const&amp;, at::Tensor const&amp;, c10::Scalar const&amp;, c10::Scalar const&amp;), &amp;at::(anonymous namespace)::wrapper_CUDA_addmm(at::Tensor const&amp;, at::Tensor const&amp;, at::Tensor const&amp;, c10::Scalar const&amp;, c10::Scalar const&amp;)&gt;, at::Tensor, c10::guts::typelist::typelist&lt;at::Tensor const&amp;, at::Tensor const&amp;, at::Tensor const&amp;, c10::Scalar const&amp;, c10::Scalar const&amp;&gt; &gt;, at::Tensor(at::Tensor const&amp;, at::Tensor const&amp;, at::Tensor const&amp;, c10::Scalar const&amp;, c10::Scalar const&amp;)&gt;::call (libtorch_cuda.so) (107 samples, 0.42%)</title><rect x="27.1274%" y="484" width="0.4173%" height="15" fill="rgb(238,48,32)" fg:x="6956" fg:w="107"/><text x="27.3774%" y="494.50"></text></g><g><title>at::(anonymous namespace)::wrapper_CUDA_addmm (libtorch_cuda.so) (107 samples, 0.42%)</title><rect x="27.1274%" y="500" width="0.4173%" height="15" fill="rgb(235,113,49)" fg:x="6956" fg:w="107"/><text x="27.3774%" y="510.50"></text></g><g><title>at::_ops::addmm::call (libtorch_cpu.so) (112 samples, 0.44%)</title><rect x="27.1196%" y="420" width="0.4368%" height="15" fill="rgb(205,127,43)" fg:x="6954" fg:w="112"/><text x="27.3696%" y="430.50"></text></g><g><title>c10::impl::wrap_kernel_functor_unboxed_&lt;c10::impl::detail::WrapFunctionIntoFunctor_&lt;c10::CompileTimeFunctionPointer&lt;at::Tensor(c10::DispatchKeySet, at::Tensor const&amp;, at::Tensor const&amp;, at::Tensor const&amp;, c10::Scalar const&amp;, c10::Scalar const&amp;), &amp;torch::autograd::VariableType::(anonymous namespace)::addmm(c10::DispatchKeySet, at::Tensor const&amp;, at::Tensor const&amp;, at::Tensor const&amp;, c10::Scalar const&amp;, c10::Scalar const&amp;)&gt;, at::Tensor, c10::guts::typelist::typelist&lt;c10::DispatchKeySet, at::Tensor const&amp;, at::Tensor const&amp;, at::Tensor const&amp;, c10::Scalar const&amp;, c10::Scalar const&amp;&gt; &gt;, at::Tensor(c10::DispatchKeySet, at::Tensor const&amp;, at::Tensor const&amp;, at::Tensor const&amp;, c10::Scalar const&amp;, c10::Scalar const&amp;)&gt;::call (libtorch_cpu.so) (111 samples, 0.43%)</title><rect x="27.1235%" y="436" width="0.4329%" height="15" fill="rgb(250,162,2)" fg:x="6955" fg:w="111"/><text x="27.3735%" y="446.50"></text></g><g><title>torch::autograd::VariableType::(anonymous namespace)::addmm (libtorch_cpu.so) (111 samples, 0.43%)</title><rect x="27.1235%" y="452" width="0.4329%" height="15" fill="rgb(220,13,41)" fg:x="6955" fg:w="111"/><text x="27.3735%" y="462.50"></text></g><g><title>at::_ops::linear::call (libtorch_cpu.so) (133 samples, 0.52%)</title><rect x="27.1157%" y="372" width="0.5187%" height="15" fill="rgb(249,221,25)" fg:x="6953" fg:w="133"/><text x="27.3657%" y="382.50"></text></g><g><title>c10::impl::wrap_kernel_functor_unboxed_&lt;c10::impl::detail::WrapFunctionIntoFunctor_&lt;c10::CompileTimeFunctionPointer&lt;at::Tensor(at::Tensor const&amp;, at::Tensor const&amp;, std::optional&lt;at::Tensor&gt; const&amp;), &amp;at::(anonymous namespace)::(anonymous namespace)::wrapper_CompositeImplicitAutograd__linear(at::Tensor const&amp;, at::Tensor const&amp;, std::optional&lt;at::Tensor&gt; const&amp;)&gt;, at::Tensor, c10::guts::typelist::typelist&lt;at::Tensor const&amp;, at::Tensor const&amp;, std::optional&lt;at::Tensor&gt; const&amp;&gt; &gt;, at::Tensor(at::Tensor const&amp;, at::Tensor const&amp;, std::optional&lt;at::Tensor&gt; const&amp;)&gt;::call (libtorch_cpu.so) (133 samples, 0.52%)</title><rect x="27.1157%" y="388" width="0.5187%" height="15" fill="rgb(215,208,19)" fg:x="6953" fg:w="133"/><text x="27.3657%" y="398.50"></text></g><g><title>at::native::linear (libtorch_cpu.so) (133 samples, 0.52%)</title><rect x="27.1157%" y="404" width="0.5187%" height="15" fill="rgb(236,175,2)" fg:x="6953" fg:w="133"/><text x="27.3657%" y="414.50"></text></g><g><title>forward (armada_net.py:179) (202 samples, 0.79%)</title><rect x="26.8583%" y="244" width="0.7878%" height="15" fill="rgb(241,52,2)" fg:x="6887" fg:w="202"/><text x="27.1083%" y="254.50"></text></g><g><title>_wrapped_call_impl (torch/nn/modules/module.py:1773) (199 samples, 0.78%)</title><rect x="26.8700%" y="260" width="0.7761%" height="15" fill="rgb(248,140,14)" fg:x="6890" fg:w="199"/><text x="27.1200%" y="270.50"></text></g><g><title>_call_impl (torch/nn/modules/module.py:1784) (196 samples, 0.76%)</title><rect x="26.8817%" y="276" width="0.7644%" height="15" fill="rgb(253,22,42)" fg:x="6893" fg:w="196"/><text x="27.1317%" y="286.50"></text></g><g><title>forward (torch/nn/modules/container.py:244) (195 samples, 0.76%)</title><rect x="26.8856%" y="292" width="0.7605%" height="15" fill="rgb(234,61,47)" fg:x="6894" fg:w="195"/><text x="27.1356%" y="302.50"></text></g><g><title>_wrapped_call_impl (torch/nn/modules/module.py:1773) (190 samples, 0.74%)</title><rect x="26.9051%" y="308" width="0.7410%" height="15" fill="rgb(208,226,15)" fg:x="6899" fg:w="190"/><text x="27.1551%" y="318.50"></text></g><g><title>_call_impl (torch/nn/modules/module.py:1784) (176 samples, 0.69%)</title><rect x="26.9597%" y="324" width="0.6864%" height="15" fill="rgb(217,221,4)" fg:x="6913" fg:w="176"/><text x="27.2097%" y="334.50"></text></g><g><title>forward (torch/nn/modules/linear.py:125) (148 samples, 0.58%)</title><rect x="27.0689%" y="340" width="0.5772%" height="15" fill="rgb(212,174,34)" fg:x="6941" fg:w="148"/><text x="27.3189%" y="350.50"></text></g><g><title>torch::autograd::THPVariable_linear (libtorch_python.so) (141 samples, 0.55%)</title><rect x="27.0962%" y="356" width="0.5499%" height="15" fill="rgb(253,83,4)" fg:x="6948" fg:w="141"/><text x="27.3462%" y="366.50"></text></g><g><title>forward (torch/nn/modules/activation.py:135) (37 samples, 0.14%)</title><rect x="27.7786%" y="340" width="0.1443%" height="15" fill="rgb(250,195,49)" fg:x="7123" fg:w="37"/><text x="28.0286%" y="350.50"></text></g><g><title>relu (torch/nn/functional.py:1701) (37 samples, 0.14%)</title><rect x="27.7786%" y="356" width="0.1443%" height="15" fill="rgb(241,192,25)" fg:x="7123" fg:w="37"/><text x="28.0286%" y="366.50"></text></g><g><title>torch::autograd::THPVariable_relu (libtorch_python.so) (36 samples, 0.14%)</title><rect x="27.7825%" y="372" width="0.1404%" height="15" fill="rgb(208,124,10)" fg:x="7124" fg:w="36"/><text x="28.0325%" y="382.50"></text></g><g><title>at::_ops::relu::call (libtorch_cpu.so) (35 samples, 0.14%)</title><rect x="27.7864%" y="388" width="0.1365%" height="15" fill="rgb(222,33,0)" fg:x="7125" fg:w="35"/><text x="28.0364%" y="398.50"></text></g><g><title>c10::impl::wrap_kernel_functor_unboxed_&lt;c10::impl::detail::WrapFunctionIntoFunctor_&lt;c10::CompileTimeFunctionPointer&lt;at::Tensor(c10::DispatchKeySet, at::Tensor const&amp;), &amp;torch::autograd::VariableType::(anonymous namespace)::relu(c10::DispatchKeySet, at::Tensor const&amp;)&gt;, at::Tensor, c10::guts::typelist::typelist&lt;c10::DispatchKeySet, at::Tensor const&amp;&gt; &gt;, at::Tensor(c10::DispatchKeySet, at::Tensor const&amp;)&gt;::call (libtorch_cpu.so) (35 samples, 0.14%)</title><rect x="27.7864%" y="404" width="0.1365%" height="15" fill="rgb(234,209,28)" fg:x="7125" fg:w="35"/><text x="28.0364%" y="414.50"></text></g><g><title>torch::autograd::VariableType::(anonymous namespace)::relu (libtorch_cpu.so) (35 samples, 0.14%)</title><rect x="27.7864%" y="420" width="0.1365%" height="15" fill="rgb(224,11,23)" fg:x="7125" fg:w="35"/><text x="28.0364%" y="430.50"></text></g><g><title>at::_ops::relu::redispatch (libtorch_cpu.so) (35 samples, 0.14%)</title><rect x="27.7864%" y="436" width="0.1365%" height="15" fill="rgb(232,99,1)" fg:x="7125" fg:w="35"/><text x="28.0364%" y="446.50"></text></g><g><title>c10::impl::wrap_kernel_functor_unboxed_&lt;c10::impl::detail::WrapFunctionIntoFunctor_&lt;c10::CompileTimeFunctionPointer&lt;at::Tensor(at::Tensor const&amp;), &amp;at::(anonymous namespace)::(anonymous namespace)::wrapper_CUDA__relu(at::Tensor const&amp;)&gt;, at::Tensor, c10::guts::typelist::typelist&lt;at::Tensor const&amp;&gt; &gt;, at::Tensor(at::Tensor const&amp;)&gt;::call (libtorch_cuda.so) (35 samples, 0.14%)</title><rect x="27.7864%" y="452" width="0.1365%" height="15" fill="rgb(237,95,45)" fg:x="7125" fg:w="35"/><text x="28.0364%" y="462.50"></text></g><g><title>at::native::relu (libtorch_cpu.so) (35 samples, 0.14%)</title><rect x="27.7864%" y="468" width="0.1365%" height="15" fill="rgb(208,109,11)" fg:x="7125" fg:w="35"/><text x="28.0364%" y="478.50"></text></g><g><title>at::_ops::clamp_min::call (libtorch_cpu.so) (35 samples, 0.14%)</title><rect x="27.7864%" y="484" width="0.1365%" height="15" fill="rgb(216,190,48)" fg:x="7125" fg:w="35"/><text x="28.0364%" y="494.50"></text></g><g><title>c10::impl::wrap_kernel_functor_unboxed_&lt;c10::impl::detail::WrapFunctionIntoFunctor_&lt;c10::CompileTimeFunctionPointer&lt;at::Tensor(at::Tensor const&amp;, c10::Scalar const&amp;), &amp;at::(anonymous namespace)::wrapper_CUDA_clamp_min(at::Tensor const&amp;, c10::Scalar const&amp;)&gt;, at::Tensor, c10::guts::typelist::typelist&lt;at::Tensor const&amp;, c10::Scalar const&amp;&gt; &gt;, at::Tensor(at::Tensor const&amp;, c10::Scalar const&amp;)&gt;::call (libtorch_cuda.so) (35 samples, 0.14%)</title><rect x="27.7864%" y="500" width="0.1365%" height="15" fill="rgb(251,171,36)" fg:x="7125" fg:w="35"/><text x="28.0364%" y="510.50"></text></g><g><title>at::(anonymous namespace)::wrapper_CUDA_clamp_min (libtorch_cuda.so) (35 samples, 0.14%)</title><rect x="27.7864%" y="516" width="0.1365%" height="15" fill="rgb(230,62,22)" fg:x="7125" fg:w="35"/><text x="28.0364%" y="526.50"></text></g><g><title>forward (torch/nn/modules/activation.py:394) (28 samples, 0.11%)</title><rect x="27.9229%" y="340" width="0.1092%" height="15" fill="rgb(225,114,35)" fg:x="7160" fg:w="28"/><text x="28.1729%" y="350.50"></text></g><g><title>torch::autograd::THPVariable_tanh (libtorch_python.so) (28 samples, 0.11%)</title><rect x="27.9229%" y="356" width="0.1092%" height="15" fill="rgb(215,118,42)" fg:x="7160" fg:w="28"/><text x="28.1729%" y="366.50"></text></g><g><title>at::cuda::blas::gemm_internal_cublas&lt;float, float&gt; (libtorch_cuda.so) (31 samples, 0.12%)</title><rect x="28.2739%" y="548" width="0.1209%" height="15" fill="rgb(243,119,21)" fg:x="7250" fg:w="31"/><text x="28.5239%" y="558.50"></text></g><g><title>cublasSgemm_v2 (nvidia/cublas/lib/libcublas.so.12) (28 samples, 0.11%)</title><rect x="28.2856%" y="564" width="0.1092%" height="15" fill="rgb(252,177,53)" fg:x="7253" fg:w="28"/><text x="28.5356%" y="574.50"></text></g><g><title>0x7ac5037cda1d (nvidia/cublas/lib/libcublas.so.12) (28 samples, 0.11%)</title><rect x="28.2856%" y="580" width="0.1092%" height="15" fill="rgb(237,209,29)" fg:x="7253" fg:w="28"/><text x="28.5356%" y="590.50"></text></g><g><title>0x7ac5036ab0e6 (nvidia/cublas/lib/libcublas.so.12) (28 samples, 0.11%)</title><rect x="28.2856%" y="596" width="0.1092%" height="15" fill="rgb(212,65,23)" fg:x="7253" fg:w="28"/><text x="28.5356%" y="606.50"></text></g><g><title>at::native::structured_addmm_out_cuda::impl (libtorch_cuda.so) (89 samples, 0.35%)</title><rect x="28.1413%" y="516" width="0.3471%" height="15" fill="rgb(230,222,46)" fg:x="7216" fg:w="89"/><text x="28.3913%" y="526.50"></text></g><g><title>at::native::(anonymous namespace)::addmm_out_cuda_impl (libtorch_cuda.so) (89 samples, 0.35%)</title><rect x="28.1413%" y="532" width="0.3471%" height="15" fill="rgb(215,135,32)" fg:x="7216" fg:w="89"/><text x="28.3913%" y="542.50"></text></g><g><title>at::_ops::addmm::call (libtorch_cpu.so) (109 samples, 0.43%)</title><rect x="28.0750%" y="420" width="0.4251%" height="15" fill="rgb(246,101,22)" fg:x="7199" fg:w="109"/><text x="28.3250%" y="430.50"></text></g><g><title>c10::impl::wrap_kernel_functor_unboxed_&lt;c10::impl::detail::WrapFunctionIntoFunctor_&lt;c10::CompileTimeFunctionPointer&lt;at::Tensor(c10::DispatchKeySet, at::Tensor const&amp;, at::Tensor const&amp;, at::Tensor const&amp;, c10::Scalar const&amp;, c10::Scalar const&amp;), &amp;torch::autograd::VariableType::(anonymous namespace)::addmm(c10::DispatchKeySet, at::Tensor const&amp;, at::Tensor const&amp;, at::Tensor const&amp;, c10::Scalar const&amp;, c10::Scalar const&amp;)&gt;, at::Tensor, c10::guts::typelist::typelist&lt;c10::DispatchKeySet, at::Tensor const&amp;, at::Tensor const&amp;, at::Tensor const&amp;, c10::Scalar const&amp;, c10::Scalar const&amp;&gt; &gt;, at::Tensor(c10::DispatchKeySet, at::Tensor const&amp;, at::Tensor const&amp;, at::Tensor const&amp;, c10::Scalar const&amp;, c10::Scalar const&amp;)&gt;::call (libtorch_cpu.so) (109 samples, 0.43%)</title><rect x="28.0750%" y="436" width="0.4251%" height="15" fill="rgb(206,107,13)" fg:x="7199" fg:w="109"/><text x="28.3250%" y="446.50"></text></g><g><title>torch::autograd::VariableType::(anonymous namespace)::addmm (libtorch_cpu.so) (109 samples, 0.43%)</title><rect x="28.0750%" y="452" width="0.4251%" height="15" fill="rgb(250,100,44)" fg:x="7199" fg:w="109"/><text x="28.3250%" y="462.50"></text></g><g><title>at::_ops::addmm::redispatch (libtorch_cpu.so) (108 samples, 0.42%)</title><rect x="28.0789%" y="468" width="0.4212%" height="15" fill="rgb(231,147,38)" fg:x="7200" fg:w="108"/><text x="28.3289%" y="478.50"></text></g><g><title>c10::impl::wrap_kernel_functor_unboxed_&lt;c10::impl::detail::WrapFunctionIntoFunctor_&lt;c10::CompileTimeFunctionPointer&lt;at::Tensor(at::Tensor const&amp;, at::Tensor const&amp;, at::Tensor const&amp;, c10::Scalar const&amp;, c10::Scalar const&amp;), &amp;at::(anonymous namespace)::wrapper_CUDA_addmm(at::Tensor const&amp;, at::Tensor const&amp;, at::Tensor const&amp;, c10::Scalar const&amp;, c10::Scalar const&amp;)&gt;, at::Tensor, c10::guts::typelist::typelist&lt;at::Tensor const&amp;, at::Tensor const&amp;, at::Tensor const&amp;, c10::Scalar const&amp;, c10::Scalar const&amp;&gt; &gt;, at::Tensor(at::Tensor const&amp;, at::Tensor const&amp;, at::Tensor const&amp;, c10::Scalar const&amp;, c10::Scalar const&amp;)&gt;::call (libtorch_cuda.so) (108 samples, 0.42%)</title><rect x="28.0789%" y="484" width="0.4212%" height="15" fill="rgb(229,8,40)" fg:x="7200" fg:w="108"/><text x="28.3289%" y="494.50"></text></g><g><title>at::(anonymous namespace)::wrapper_CUDA_addmm (libtorch_cuda.so) (108 samples, 0.42%)</title><rect x="28.0789%" y="500" width="0.4212%" height="15" fill="rgb(221,135,30)" fg:x="7200" fg:w="108"/><text x="28.3289%" y="510.50"></text></g><g><title>at::_ops::linear::call (libtorch_cpu.so) (128 samples, 0.50%)</title><rect x="28.0594%" y="372" width="0.4992%" height="15" fill="rgb(249,193,18)" fg:x="7195" fg:w="128"/><text x="28.3094%" y="382.50"></text></g><g><title>c10::impl::wrap_kernel_functor_unboxed_&lt;c10::impl::detail::WrapFunctionIntoFunctor_&lt;c10::CompileTimeFunctionPointer&lt;at::Tensor(at::Tensor const&amp;, at::Tensor const&amp;, std::optional&lt;at::Tensor&gt; const&amp;), &amp;at::(anonymous namespace)::(anonymous namespace)::wrapper_CompositeImplicitAutograd__linear(at::Tensor const&amp;, at::Tensor const&amp;, std::optional&lt;at::Tensor&gt; const&amp;)&gt;, at::Tensor, c10::guts::typelist::typelist&lt;at::Tensor const&amp;, at::Tensor const&amp;, std::optional&lt;at::Tensor&gt; const&amp;&gt; &gt;, at::Tensor(at::Tensor const&amp;, at::Tensor const&amp;, std::optional&lt;at::Tensor&gt; const&amp;)&gt;::call (libtorch_cpu.so) (126 samples, 0.49%)</title><rect x="28.0672%" y="388" width="0.4914%" height="15" fill="rgb(209,133,39)" fg:x="7197" fg:w="126"/><text x="28.3172%" y="398.50"></text></g><g><title>at::native::linear (libtorch_cpu.so) (125 samples, 0.49%)</title><rect x="28.0711%" y="404" width="0.4875%" height="15" fill="rgb(232,100,14)" fg:x="7198" fg:w="125"/><text x="28.3211%" y="414.50"></text></g><g><title>forward (armada_net.py:183) (242 samples, 0.94%)</title><rect x="27.6460%" y="244" width="0.9438%" height="15" fill="rgb(224,185,1)" fg:x="7089" fg:w="242"/><text x="27.8960%" y="254.50"></text></g><g><title>_wrapped_call_impl (torch/nn/modules/module.py:1773) (240 samples, 0.94%)</title><rect x="27.6538%" y="260" width="0.9360%" height="15" fill="rgb(223,139,8)" fg:x="7091" fg:w="240"/><text x="27.9038%" y="270.50"></text></g><g><title>_call_impl (torch/nn/modules/module.py:1784) (238 samples, 0.93%)</title><rect x="27.6616%" y="276" width="0.9282%" height="15" fill="rgb(232,213,38)" fg:x="7093" fg:w="238"/><text x="27.9116%" y="286.50"></text></g><g><title>forward (torch/nn/modules/container.py:244) (238 samples, 0.93%)</title><rect x="27.6616%" y="292" width="0.9282%" height="15" fill="rgb(207,94,22)" fg:x="7093" fg:w="238"/><text x="27.9116%" y="302.50"></text></g><g><title>_wrapped_call_impl (torch/nn/modules/module.py:1773) (223 samples, 0.87%)</title><rect x="27.7201%" y="308" width="0.8697%" height="15" fill="rgb(219,183,54)" fg:x="7108" fg:w="223"/><text x="27.9701%" y="318.50"></text></g><g><title>_call_impl (torch/nn/modules/module.py:1784) (210 samples, 0.82%)</title><rect x="27.7708%" y="324" width="0.8190%" height="15" fill="rgb(216,185,54)" fg:x="7121" fg:w="210"/><text x="28.0208%" y="334.50"></text></g><g><title>forward (torch/nn/modules/linear.py:125) (142 samples, 0.55%)</title><rect x="28.0360%" y="340" width="0.5538%" height="15" fill="rgb(254,217,39)" fg:x="7189" fg:w="142"/><text x="28.2860%" y="350.50"></text></g><g><title>torch::autograd::THPVariable_linear (libtorch_python.so) (137 samples, 0.53%)</title><rect x="28.0555%" y="356" width="0.5343%" height="15" fill="rgb(240,178,23)" fg:x="7194" fg:w="137"/><text x="28.3055%" y="366.50"></text></g><g><title>at::_ops::zeros::call (libtorch_cpu.so) (28 samples, 0.11%)</title><rect x="28.6132%" y="276" width="0.1092%" height="15" fill="rgb(218,11,47)" fg:x="7337" fg:w="28"/><text x="28.8632%" y="286.50"></text></g><g><title>c10::impl::wrap_kernel_functor_unboxed_&lt;c10::impl::detail::WrapFunctionIntoFunctor_&lt;c10::CompileTimeFunctionPointer&lt;at::Tensor(c10::ArrayRef&lt;c10::SymInt&gt;, std::optional&lt;c10::ScalarType&gt;, std::optional&lt;c10::Layout&gt;, std::optional&lt;c10::Device&gt;, std::optional&lt;bool&gt;), &amp;at::(anonymous namespace)::zeros(c10::ArrayRef&lt;c10::SymInt&gt;, std::optional&lt;c10::ScalarType&gt;, std::optional&lt;c10::Layout&gt;, std::optional&lt;c10::Device&gt;, std::optional&lt;bool&gt;)&gt;, at::Tensor, c10::guts::typelist::typelist&lt;c10::ArrayRef&lt;c10::SymInt&gt;, std::optional&lt;c10::ScalarType&gt;, std::optional&lt;c10::Layout&gt;, std::optional&lt;c10::Device&gt;, std::optional&lt;bool&gt; &gt; &gt;, at::Tensor(c10::ArrayRef&lt;c10::SymInt&gt;, std::optional&lt;c10::ScalarType&gt;, std::optional&lt;c10::Layout&gt;, std::optional&lt;c10::Device&gt;, std::optional&lt;bool&gt;)&gt;::call (libtorch_cpu.so) (27 samples, 0.11%)</title><rect x="28.6171%" y="292" width="0.1053%" height="15" fill="rgb(218,51,51)" fg:x="7338" fg:w="27"/><text x="28.8671%" y="302.50"></text></g><g><title>at::_ops::zeros::redispatch (libtorch_cpu.so) (27 samples, 0.11%)</title><rect x="28.6171%" y="308" width="0.1053%" height="15" fill="rgb(238,126,27)" fg:x="7338" fg:w="27"/><text x="28.8671%" y="318.50"></text></g><g><title>c10::impl::wrap_kernel_functor_unboxed_&lt;c10::impl::detail::WrapFunctionIntoFunctor_&lt;c10::CompileTimeFunctionPointer&lt;at::Tensor(c10::ArrayRef&lt;c10::SymInt&gt;, std::optional&lt;c10::ScalarType&gt;, std::optional&lt;c10::Layout&gt;, std::optional&lt;c10::Device&gt;, std::optional&lt;bool&gt;), &amp;at::(anonymous namespace)::(anonymous namespace)::wrapper_CompositeExplicitAutograd__zeros(c10::ArrayRef&lt;c10::SymInt&gt;, std::optional&lt;c10::ScalarType&gt;, std::optional&lt;c10::Layout&gt;, std::optional&lt;c10::Device&gt;, std::optional&lt;bool&gt;)&gt;, at::Tensor, c10::guts::typelist::typelist&lt;c10::ArrayRef&lt;c10::SymInt&gt;, std::optional&lt;c10::ScalarType&gt;, std::optional&lt;c10::Layout&gt;, std::optional&lt;c10::Device&gt;, std::optional&lt;bool&gt; &gt; &gt;, at::Tensor(c10::ArrayRef&lt;c10::SymInt&gt;, std::optional&lt;c10::ScalarType&gt;, std::optional&lt;c10::Layout&gt;, std::optional&lt;c10::Device&gt;, std::optional&lt;bool&gt;)&gt;::call (libtorch_cpu.so) (27 samples, 0.11%)</title><rect x="28.6171%" y="324" width="0.1053%" height="15" fill="rgb(249,202,22)" fg:x="7338" fg:w="27"/><text x="28.8671%" y="334.50"></text></g><g><title>at::native::zeros_symint (libtorch_cpu.so) (27 samples, 0.11%)</title><rect x="28.6171%" y="340" width="0.1053%" height="15" fill="rgb(254,195,49)" fg:x="7338" fg:w="27"/><text x="28.8671%" y="350.50"></text></g><g><title>forward (armada_net.py:187) (40 samples, 0.16%)</title><rect x="28.5898%" y="244" width="0.1560%" height="15" fill="rgb(208,123,14)" fg:x="7331" fg:w="40"/><text x="28.8398%" y="254.50"></text></g><g><title>torch::autograd::THPVariable_zeros (libtorch_python.so) (37 samples, 0.14%)</title><rect x="28.6015%" y="260" width="0.1443%" height="15" fill="rgb(224,200,8)" fg:x="7334" fg:w="37"/><text x="28.8515%" y="270.50"></text></g><g><title>at::TensorIteratorBase::build (libtorch_cpu.so) (32 samples, 0.12%)</title><rect x="29.0149%" y="404" width="0.1248%" height="15" fill="rgb(217,61,36)" fg:x="7440" fg:w="32"/><text x="29.2649%" y="414.50"></text></g><g><title>at::native::AdvancedIndex::AdvancedIndex (libtorch_cpu.so) (29 samples, 0.11%)</title><rect x="29.1670%" y="420" width="0.1131%" height="15" fill="rgb(206,35,45)" fg:x="7479" fg:w="29"/><text x="29.4170%" y="430.50"></text></g><g><title>at::native::make_info (libtorch_cpu.so) (36 samples, 0.14%)</title><rect x="29.1475%" y="404" width="0.1404%" height="15" fill="rgb(217,65,33)" fg:x="7474" fg:w="36"/><text x="29.3975%" y="414.50"></text></g><g><title>at::meta::structured_index_Tensor::meta (libtorch_cpu.so) (75 samples, 0.29%)</title><rect x="29.0032%" y="388" width="0.2925%" height="15" fill="rgb(222,158,48)" fg:x="7437" fg:w="75"/><text x="29.2532%" y="398.50"></text></g><g><title>at::native::gpu_index_kernel&lt;__nv_dl_wrapper_t&lt;__nv_dl_tag&lt;void (*)(at::TensorIteratorBase&amp;, c10::ArrayRef&lt;long&gt;, c10::ArrayRef&lt;long&gt;), &amp;at::native::index_kernel_impl&lt;at::native::OpaqueType&lt;4&gt; &gt;(at::TensorIteratorBase&amp;, c10::ArrayRef&lt;long&gt;, c10::ArrayRef&lt;long&gt;), (unsigned int)1&gt;, &gt; &gt; (libtorch_cuda.so) (57 samples, 0.22%)</title><rect x="29.2957%" y="404" width="0.2223%" height="15" fill="rgb(254,2,54)" fg:x="7512" fg:w="57"/><text x="29.5457%" y="414.50"></text></g><g><title>at::native::index_kernel (libtorch_cuda.so) (58 samples, 0.23%)</title><rect x="29.2957%" y="388" width="0.2262%" height="15" fill="rgb(250,143,38)" fg:x="7512" fg:w="58"/><text x="29.5457%" y="398.50"></text></g><g><title>at::_ops::index_Tensor::redispatch (libtorch_cpu.so) (147 samples, 0.57%)</title><rect x="28.9720%" y="340" width="0.5733%" height="15" fill="rgb(248,25,0)" fg:x="7429" fg:w="147"/><text x="29.2220%" y="350.50"></text></g><g><title>c10::impl::wrap_kernel_functor_unboxed_&lt;c10::impl::detail::WrapFunctionIntoFunctor_&lt;c10::CompileTimeFunctionPointer&lt;at::Tensor(at::Tensor const&amp;, c10::List&lt;std::optional&lt;at::Tensor&gt; &gt; const&amp;), &amp;at::(anonymous namespace)::wrapper_CUDA_index_Tensor(at::Tensor const&amp;, c10::List&lt;std::optional&lt;at::Tensor&gt; &gt; const&amp;)&gt;, at::Tensor, c10::guts::typelist::typelist&lt;at::Tensor const&amp;, c10::List&lt;std::optional&lt;at::Tensor&gt; &gt; const&amp;&gt; &gt;, at::Tensor(at::Tensor const&amp;, c10::List&lt;std::optional&lt;at::Tensor&gt; &gt; const&amp;)&gt;::call (libtorch_cuda.so) (144 samples, 0.56%)</title><rect x="28.9837%" y="356" width="0.5616%" height="15" fill="rgb(206,152,27)" fg:x="7432" fg:w="144"/><text x="29.2337%" y="366.50"></text></g><g><title>at::(anonymous namespace)::wrapper_CUDA_index_Tensor (libtorch_cuda.so) (143 samples, 0.56%)</title><rect x="28.9876%" y="372" width="0.5577%" height="15" fill="rgb(240,77,30)" fg:x="7433" fg:w="143"/><text x="29.2376%" y="382.50"></text></g><g><title>at::_ops::index_Tensor::call (libtorch_cpu.so) (157 samples, 0.61%)</title><rect x="28.9603%" y="292" width="0.6123%" height="15" fill="rgb(231,5,3)" fg:x="7426" fg:w="157"/><text x="29.2103%" y="302.50"></text></g><g><title>c10::impl::wrap_kernel_functor_unboxed_&lt;c10::impl::detail::WrapFunctionIntoFunctor_&lt;c10::CompileTimeFunctionPointer&lt;at::Tensor(c10::DispatchKeySet, at::Tensor const&amp;, c10::List&lt;std::optional&lt;at::Tensor&gt; &gt; const&amp;), &amp;torch::autograd::VariableType::(anonymous namespace)::index_Tensor(c10::DispatchKeySet, at::Tensor const&amp;, c10::List&lt;std::optional&lt;at::Tensor&gt; &gt; const&amp;)&gt;, at::Tensor, c10::guts::typelist::typelist&lt;c10::DispatchKeySet, at::Tensor const&amp;, c10::List&lt;std::optional&lt;at::Tensor&gt; &gt; const&amp;&gt; &gt;, at::Tensor(c10::DispatchKeySet, at::Tensor const&amp;, c10::List&lt;std::optional&lt;at::Tensor&gt; &gt; const&amp;)&gt;::call (libtorch_cpu.so) (154 samples, 0.60%)</title><rect x="28.9720%" y="308" width="0.6006%" height="15" fill="rgb(207,226,32)" fg:x="7429" fg:w="154"/><text x="29.2220%" y="318.50"></text></g><g><title>torch::autograd::VariableType::(anonymous namespace)::index_Tensor (libtorch_cpu.so) (154 samples, 0.60%)</title><rect x="28.9720%" y="324" width="0.6006%" height="15" fill="rgb(222,207,47)" fg:x="7429" fg:w="154"/><text x="29.2220%" y="334.50"></text></g><g><title>at::indexing::dispatch_index (libtorch_python.so) (165 samples, 0.64%)</title><rect x="28.9603%" y="276" width="0.6435%" height="15" fill="rgb(229,115,45)" fg:x="7426" fg:w="165"/><text x="29.2103%" y="286.50"></text></g><g><title>0x7ac4dff3f5f7 (libcuda.so.550.54.15) (26 samples, 0.10%)</title><rect x="29.9119%" y="580" width="0.1014%" height="15" fill="rgb(224,191,6)" fg:x="7670" fg:w="26"/><text x="30.1619%" y="590.50"></text></g><g><title>cudaMemcpyAsync (nvidia/cuda_runtime/lib/libcudart.so.12) (44 samples, 0.17%)</title><rect x="29.8846%" y="516" width="0.1716%" height="15" fill="rgb(230,227,24)" fg:x="7663" fg:w="44"/><text x="30.1346%" y="526.50"></text></g><g><title>0x7ac5be418cb2 (nvidia/cuda_runtime/lib/libcudart.so.12) (40 samples, 0.16%)</title><rect x="29.9002%" y="532" width="0.1560%" height="15" fill="rgb(228,80,19)" fg:x="7667" fg:w="40"/><text x="30.1502%" y="542.50"></text></g><g><title>0x7ac5be448c59 (nvidia/cuda_runtime/lib/libcudart.so.12) (39 samples, 0.15%)</title><rect x="29.9041%" y="548" width="0.1521%" height="15" fill="rgb(247,229,0)" fg:x="7668" fg:w="39"/><text x="30.1541%" y="558.50"></text></g><g><title>0x7ac4e00e8cc9 (libcuda.so.550.54.15) (39 samples, 0.15%)</title><rect x="29.9041%" y="564" width="0.1521%" height="15" fill="rgb(237,194,15)" fg:x="7668" fg:w="39"/><text x="30.1541%" y="574.50"></text></g><g><title>at::native::copy_kernel_cuda (libtorch_cuda.so) (80 samples, 0.31%)</title><rect x="29.8456%" y="500" width="0.3120%" height="15" fill="rgb(219,203,20)" fg:x="7653" fg:w="80"/><text x="30.0956%" y="510.50"></text></g><g><title>cudaStreamSynchronize (nvidia/cuda_runtime/lib/libcudart.so.12) (26 samples, 0.10%)</title><rect x="30.0562%" y="516" width="0.1014%" height="15" fill="rgb(234,128,8)" fg:x="7707" fg:w="26"/><text x="30.3062%" y="526.50"></text></g><g><title>at::native::copy_impl (libtorch_cpu.so) (91 samples, 0.35%)</title><rect x="29.8066%" y="484" width="0.3549%" height="15" fill="rgb(248,202,8)" fg:x="7643" fg:w="91"/><text x="30.0566%" y="494.50"></text></g><g><title>at::native::copy_ (libtorch_cpu.so) (97 samples, 0.38%)</title><rect x="29.7910%" y="468" width="0.3783%" height="15" fill="rgb(206,104,37)" fg:x="7639" fg:w="97"/><text x="30.0410%" y="478.50"></text></g><g><title>at::_ops::copy_::call (libtorch_cpu.so) (100 samples, 0.39%)</title><rect x="29.7832%" y="452" width="0.3900%" height="15" fill="rgb(223,8,27)" fg:x="7637" fg:w="100"/><text x="30.0332%" y="462.50"></text></g><g><title>at::_ops::empty_strided::call (libtorch_cpu.so) (32 samples, 0.12%)</title><rect x="30.1810%" y="468" width="0.1248%" height="15" fill="rgb(216,217,28)" fg:x="7739" fg:w="32"/><text x="30.4310%" y="478.50"></text></g><g><title>c10::impl::wrap_kernel_functor_unboxed_&lt;c10::impl::detail::WrapFunctionIntoFunctor_&lt;c10::CompileTimeFunctionPointer&lt;at::Tensor(c10::ArrayRef&lt;c10::SymInt&gt;, c10::ArrayRef&lt;c10::SymInt&gt;, std::optional&lt;c10::ScalarType&gt;, std::optional&lt;c10::Layout&gt;, std::optional&lt;c10::Device&gt;, std::optional&lt;bool&gt;), &amp;at::(anonymous namespace)::empty_strided(c10::ArrayRef&lt;c10::SymInt&gt;, c10::ArrayRef&lt;c10::SymInt&gt;, std::optional&lt;c10::ScalarType&gt;, std::optional&lt;c10::Layout&gt;, std::optional&lt;c10::Device&gt;, std::optional&lt;bool&gt;)&gt;, at::Tensor, c10::guts::typelist::typelist&lt;c10::ArrayRef&lt;c10::SymInt&gt;, c10::ArrayRef&lt;c10::SymInt&gt;, std::optional&lt;c10::ScalarType&gt;, std::optional&lt;c10::Layout&gt;, std::optional&lt;c10::Device&gt;, std::optional&lt;bool&gt; &gt; &gt;, at::Tensor(c10::ArrayRef&lt;c10::SymInt&gt;, c10::ArrayRef&lt;c10::SymInt&gt;, std::optional&lt;c10::ScalarType&gt;, std::optional&lt;c10::Layout&gt;, std::optional&lt;c10::Device&gt;, std::optional&lt;bool&gt;)&gt;::call (libtorch_cpu.so) (29 samples, 0.11%)</title><rect x="30.1927%" y="484" width="0.1131%" height="15" fill="rgb(249,199,1)" fg:x="7742" fg:w="29"/><text x="30.4427%" y="494.50"></text></g><g><title>at::_ops::empty_strided::redispatch (libtorch_cpu.so) (29 samples, 0.11%)</title><rect x="30.1927%" y="500" width="0.1131%" height="15" fill="rgb(240,85,17)" fg:x="7742" fg:w="29"/><text x="30.4427%" y="510.50"></text></g><g><title>c10::impl::wrap_kernel_functor_unboxed_&lt;c10::impl::detail::WrapFunctionIntoFunctor_&lt;c10::CompileTimeFunctionPointer&lt;at::Tensor(c10::ArrayRef&lt;c10::SymInt&gt;, c10::ArrayRef&lt;c10::SymInt&gt;, std::optional&lt;c10::ScalarType&gt;, std::optional&lt;c10::Layout&gt;, std::optional&lt;c10::Device&gt;, std::optional&lt;bool&gt;), &amp;at::(anonymous namespace)::(anonymous namespace)::wrapper_CUDA__empty_strided(c10::ArrayRef&lt;c10::SymInt&gt;, c10::ArrayRef&lt;c10::SymInt&gt;, std::optional&lt;c10::ScalarType&gt;, std::optional&lt;c10::Layout&gt;, std::optional&lt;c10::Device&gt;, std::optional&lt;bool&gt;)&gt;, at::Tensor, c10::guts::typelist::typelist&lt;c10::ArrayRef&lt;c10::SymInt&gt;, c10::ArrayRef&lt;c10::SymInt&gt;, std::optional&lt;c10::ScalarType&gt;, std::optional&lt;c10::Layout&gt;, std::optional&lt;c10::Device&gt;, std::optional&lt;bool&gt; &gt; &gt;, at::Tensor(c10::ArrayRef&lt;c10::SymInt&gt;, c10::ArrayRef&lt;c10::SymInt&gt;, std::optional&lt;c10::ScalarType&gt;, std::optional&lt;c10::Layout&gt;, std::optional&lt;c10::Device&gt;, std::optional&lt;bool&gt;)&gt;::call (libtorch_cuda.so) (27 samples, 0.11%)</title><rect x="30.2005%" y="516" width="0.1053%" height="15" fill="rgb(206,108,45)" fg:x="7744" fg:w="27"/><text x="30.4505%" y="526.50"></text></g><g><title>at::(anonymous namespace)::(anonymous namespace)::wrapper_CUDA__empty_strided (libtorch_cuda.so) (27 samples, 0.11%)</title><rect x="30.2005%" y="532" width="0.1053%" height="15" fill="rgb(245,210,41)" fg:x="7744" fg:w="27"/><text x="30.4505%" y="542.50"></text></g><g><title>at::_ops::to_device::call (libtorch_cpu.so) (146 samples, 0.57%)</title><rect x="29.7442%" y="324" width="0.5694%" height="15" fill="rgb(206,13,37)" fg:x="7627" fg:w="146"/><text x="29.9942%" y="334.50"></text></g><g><title>c10::impl::wrap_kernel_functor_unboxed_&lt;c10::impl::detail::WrapFunctionIntoFunctor_&lt;c10::CompileTimeFunctionPointer&lt;at::Tensor(at::Tensor const&amp;, c10::Device, c10::ScalarType, bool, bool, std::optional&lt;c10::MemoryFormat&gt;), &amp;at::(anonymous namespace)::(anonymous namespace)::wrapper_CompositeImplicitAutograd_device_to(at::Tensor const&amp;, c10::Device, c10::ScalarType, bool, bool, std::optional&lt;c10::MemoryFormat&gt;)&gt;, at::Tensor, c10::guts::typelist::typelist&lt;at::Tensor const&amp;, c10::Device, c10::ScalarType, bool, bool, std::optional&lt;c10::MemoryFormat&gt; &gt; &gt;, at::Tensor(at::Tensor const&amp;, c10::Device, c10::ScalarType, bool, bool, std::optional&lt;c10::MemoryFormat&gt;)&gt;::call (libtorch_cpu.so) (144 samples, 0.56%)</title><rect x="29.7520%" y="340" width="0.5616%" height="15" fill="rgb(250,61,18)" fg:x="7629" fg:w="144"/><text x="30.0020%" y="350.50"></text></g><g><title>at::native::to (libtorch_cpu.so) (143 samples, 0.56%)</title><rect x="29.7559%" y="356" width="0.5577%" height="15" fill="rgb(235,172,48)" fg:x="7630" fg:w="143"/><text x="30.0059%" y="366.50"></text></g><g><title>at::_ops::_to_copy::call (libtorch_cpu.so) (142 samples, 0.55%)</title><rect x="29.7598%" y="372" width="0.5538%" height="15" fill="rgb(249,201,17)" fg:x="7631" fg:w="142"/><text x="30.0098%" y="382.50"></text></g><g><title>c10::impl::wrap_kernel_functor_unboxed_&lt;c10::impl::detail::WrapFunctionIntoFunctor_&lt;c10::CompileTimeFunctionPointer&lt;at::Tensor(at::Tensor const&amp;, std::optional&lt;c10::ScalarType&gt;, std::optional&lt;c10::Layout&gt;, std::optional&lt;c10::Device&gt;, std::optional&lt;bool&gt;, bool, std::optional&lt;c10::MemoryFormat&gt;), &amp;at::(anonymous namespace)::_to_copy(at::Tensor const&amp;, std::optional&lt;c10::ScalarType&gt;, std::optional&lt;c10::Layout&gt;, std::optional&lt;c10::Device&gt;, std::optional&lt;bool&gt;, bool, std::optional&lt;c10::MemoryFormat&gt;)&gt;, at::Tensor, c10::guts::typelist::typelist&lt;at::Tensor const&amp;, std::optional&lt;c10::ScalarType&gt;, std::optional&lt;c10::Layout&gt;, std::optional&lt;c10::Device&gt;, std::optional&lt;bool&gt;, bool, std::optional&lt;c10::MemoryFormat&gt; &gt; &gt;, at::Tensor(at::Tensor const&amp;, std::optional&lt;c10::ScalarType&gt;, std::optional&lt;c10::Layout&gt;, std::optional&lt;c10::Device&gt;, std::optional&lt;bool&gt;, bool, std::optional&lt;c10::MemoryFormat&gt;)&gt;::call (libtorch_cpu.so) (140 samples, 0.55%)</title><rect x="29.7676%" y="388" width="0.5460%" height="15" fill="rgb(219,208,6)" fg:x="7633" fg:w="140"/><text x="30.0176%" y="398.50"></text></g><g><title>at::_ops::_to_copy::redispatch (libtorch_cpu.so) (140 samples, 0.55%)</title><rect x="29.7676%" y="404" width="0.5460%" height="15" fill="rgb(248,31,23)" fg:x="7633" fg:w="140"/><text x="30.0176%" y="414.50"></text></g><g><title>c10::impl::wrap_kernel_functor_unboxed_&lt;c10::impl::detail::WrapFunctionIntoFunctor_&lt;c10::CompileTimeFunctionPointer&lt;at::Tensor(at::Tensor const&amp;, std::optional&lt;c10::ScalarType&gt;, std::optional&lt;c10::Layout&gt;, std::optional&lt;c10::Device&gt;, std::optional&lt;bool&gt;, bool, std::optional&lt;c10::MemoryFormat&gt;), &amp;at::(anonymous namespace)::(anonymous namespace)::wrapper_CompositeExplicitAutograd___to_copy(at::Tensor const&amp;, std::optional&lt;c10::ScalarType&gt;, std::optional&lt;c10::Layout&gt;, std::optional&lt;c10::Device&gt;, std::optional&lt;bool&gt;, bool, std::optional&lt;c10::MemoryFormat&gt;)&gt;, at::Tensor, c10::guts::typelist::typelist&lt;at::Tensor const&amp;, std::optional&lt;c10::ScalarType&gt;, std::optional&lt;c10::Layout&gt;, std::optional&lt;c10::Device&gt;, std::optional&lt;bool&gt;, bool, std::optional&lt;c10::MemoryFormat&gt; &gt; &gt;, at::Tensor(at::Tensor const&amp;, std::optional&lt;c10::ScalarType&gt;, std::optional&lt;c10::Layout&gt;, std::optional&lt;c10::Device&gt;, std::optional&lt;bool&gt;, bool, std::optional&lt;c10::MemoryFormat&gt;)&gt;::call (libtorch_cpu.so) (138 samples, 0.54%)</title><rect x="29.7754%" y="420" width="0.5382%" height="15" fill="rgb(245,15,42)" fg:x="7635" fg:w="138"/><text x="30.0254%" y="430.50"></text></g><g><title>at::native::_to_copy (libtorch_cpu.so) (138 samples, 0.54%)</title><rect x="29.7754%" y="436" width="0.5382%" height="15" fill="rgb(222,217,39)" fg:x="7635" fg:w="138"/><text x="30.0254%" y="446.50"></text></g><g><title>at::empty_strided (libtorch_cpu.so) (36 samples, 0.14%)</title><rect x="30.1732%" y="452" width="0.1404%" height="15" fill="rgb(210,219,27)" fg:x="7737" fg:w="36"/><text x="30.4232%" y="462.50"></text></g><g><title>torch::autograd::applySlicing (libtorch_python.so) (233 samples, 0.91%)</title><rect x="29.6233%" y="276" width="0.9087%" height="15" fill="rgb(252,166,36)" fg:x="7596" fg:w="233"/><text x="29.8733%" y="286.50"></text></g><g><title>torch::utils::indexing_tensor_from_data (libtorch_python.so) (226 samples, 0.88%)</title><rect x="29.6506%" y="292" width="0.8814%" height="15" fill="rgb(245,132,34)" fg:x="7603" fg:w="226"/><text x="29.9006%" y="302.50"></text></g><g><title>torch::utils::(anonymous namespace)::internal_new_from_data (libtorch_python.so) (219 samples, 0.85%)</title><rect x="29.6779%" y="308" width="0.8541%" height="15" fill="rgb(236,54,3)" fg:x="7610" fg:w="219"/><text x="29.9279%" y="318.50"></text></g><g><title>forward (armada_net.py:202) (451 samples, 1.76%)</title><rect x="28.8550%" y="244" width="1.7588%" height="15" fill="rgb(241,173,43)" fg:x="7399" fg:w="451"/><text x="29.1050%" y="254.50"></text></g><g><title>torch::autograd::THPVariable_getitem (libtorch_python.so) (433 samples, 1.69%)</title><rect x="28.9252%" y="260" width="1.6886%" height="15" fill="rgb(215,190,9)" fg:x="7417" fg:w="433"/><text x="29.1752%" y="270.50"></text></g><g><title>THPVariable_subclass_clear (libtorch_python.so) (35 samples, 0.14%)</title><rect x="30.9453%" y="324" width="0.1365%" height="15" fill="rgb(242,101,16)" fg:x="7935" fg:w="35"/><text x="31.1953%" y="334.50"></text></g><g><title>THPVariable_subclass_dealloc (libtorch_python.so) (43 samples, 0.17%)</title><rect x="30.9180%" y="308" width="0.1677%" height="15" fill="rgb(223,190,21)" fg:x="7928" fg:w="43"/><text x="31.1680%" y="318.50"></text></g><g><title>_call_impl (torch/nn/modules/module.py:1778) (34 samples, 0.13%)</title><rect x="31.1637%" y="324" width="0.1326%" height="15" fill="rgb(215,228,25)" fg:x="7991" fg:w="34"/><text x="31.4137%" y="334.50"></text></g><g><title>at::detail::empty_generic (libtorch_cpu.so) (30 samples, 0.12%)</title><rect x="31.7136%" y="660" width="0.1170%" height="15" fill="rgb(225,36,22)" fg:x="8132" fg:w="30"/><text x="31.9636%" y="670.50"></text></g><g><title>at::detail::_empty_generic&lt;long&gt; (libtorch_cpu.so) (30 samples, 0.12%)</title><rect x="31.7136%" y="676" width="0.1170%" height="15" fill="rgb(251,106,46)" fg:x="8132" fg:w="30"/><text x="31.9636%" y="686.50"></text></g><g><title>at::detail::empty_cuda (libtorch_cuda.so) (38 samples, 0.15%)</title><rect x="31.7097%" y="644" width="0.1482%" height="15" fill="rgb(208,90,1)" fg:x="8131" fg:w="38"/><text x="31.9597%" y="654.50"></text></g><g><title>at::(anonymous namespace)::create_out (libtorch_cuda.so) (42 samples, 0.16%)</title><rect x="31.7019%" y="596" width="0.1638%" height="15" fill="rgb(243,10,4)" fg:x="8129" fg:w="42"/><text x="31.9519%" y="606.50"></text></g><g><title>at::detail::empty_cuda (libtorch_cuda.so) (42 samples, 0.16%)</title><rect x="31.7019%" y="612" width="0.1638%" height="15" fill="rgb(212,137,27)" fg:x="8129" fg:w="42"/><text x="31.9519%" y="622.50"></text></g><g><title>at::detail::empty_cuda (libtorch_cuda.so) (40 samples, 0.16%)</title><rect x="31.7097%" y="628" width="0.1560%" height="15" fill="rgb(231,220,49)" fg:x="8131" fg:w="40"/><text x="31.9597%" y="638.50"></text></g><g><title>at::(anonymous namespace)::structured_clamp_min_out_functional::set_output_raw_strided (libtorch_cuda.so) (49 samples, 0.19%)</title><rect x="31.6941%" y="580" width="0.1911%" height="15" fill="rgb(237,96,20)" fg:x="8127" fg:w="49"/><text x="31.9441%" y="590.50"></text></g><g><title>at::TensorIteratorBase::fast_set_up (libtorch_cpu.so) (54 samples, 0.21%)</title><rect x="31.6785%" y="564" width="0.2106%" height="15" fill="rgb(239,229,30)" fg:x="8123" fg:w="54"/><text x="31.9285%" y="574.50"></text></g><g><title>at::TensorIteratorBase::build_borrowing_unary_op (libtorch_cpu.so) (68 samples, 0.27%)</title><rect x="31.6356%" y="532" width="0.2652%" height="15" fill="rgb(219,65,33)" fg:x="8112" fg:w="68"/><text x="31.8856%" y="542.50"></text></g><g><title>at::TensorIteratorBase::build (libtorch_cpu.so) (65 samples, 0.25%)</title><rect x="31.6473%" y="548" width="0.2535%" height="15" fill="rgb(243,134,7)" fg:x="8115" fg:w="65"/><text x="31.8973%" y="558.50"></text></g><g><title>0x7ac4dff2be78 (libcuda.so.550.54.15) (50 samples, 0.19%)</title><rect x="32.1192%" y="660" width="0.1950%" height="15" fill="rgb(216,177,54)" fg:x="8236" fg:w="50"/><text x="32.3692%" y="670.50"></text></g><g><title>0x7ac4dff2b605 (libcuda.so.550.54.15) (50 samples, 0.19%)</title><rect x="32.1192%" y="676" width="0.1950%" height="15" fill="rgb(211,160,20)" fg:x="8236" fg:w="50"/><text x="32.3692%" y="686.50"></text></g><g><title>0x7ac5be415aa8 (nvidia/cuda_runtime/lib/libcudart.so.12) (57 samples, 0.22%)</title><rect x="32.0958%" y="612" width="0.2223%" height="15" fill="rgb(239,85,39)" fg:x="8230" fg:w="57"/><text x="32.3458%" y="622.50"></text></g><g><title>0x7ac4e00ef270 (libcuda.so.550.54.15) (56 samples, 0.22%)</title><rect x="32.0997%" y="628" width="0.2184%" height="15" fill="rgb(232,125,22)" fg:x="8231" fg:w="56"/><text x="32.3497%" y="638.50"></text></g><g><title>0x7ac4dff32a6f (libcuda.so.550.54.15) (54 samples, 0.21%)</title><rect x="32.1075%" y="644" width="0.2106%" height="15" fill="rgb(244,57,34)" fg:x="8233" fg:w="54"/><text x="32.3575%" y="654.50"></text></g><g><title>cudaLaunchKernel (nvidia/cuda_runtime/lib/libcudart.so.12) (72 samples, 0.28%)</title><rect x="32.0451%" y="596" width="0.2808%" height="15" fill="rgb(214,203,32)" fg:x="8217" fg:w="72"/><text x="32.2951%" y="606.50"></text></g><g><title>at::native::gpu_kernel_impl_nocast&lt;__nv_hdl_wrapper_t&lt;false, false, false, __nv_dl_tag&lt;void (*)(at::TensorIteratorBase&amp;, c10::Scalar, c10::Scalar, at::native::detail::ClampLimits), &amp;at::native::(anonymous namespace)::launch_clamp_scalar(at::TensorIteratorBase&amp;, c10::Scalar, c10::Scalar, at::native::detail::ClampLimits), (unsigned int)7&gt;, float (float), at::native::detail::ClampLimits, float, float&gt; &gt; (libtorch_cuda.so) (95 samples, 0.37%)</title><rect x="31.9593%" y="580" width="0.3705%" height="15" fill="rgb(207,58,43)" fg:x="8195" fg:w="95"/><text x="32.2093%" y="590.50"></text></g><g><title>at::native::(anonymous namespace)::clamp_min_scalar_kernel_impl (libtorch_cuda.so) (106 samples, 0.41%)</title><rect x="31.9203%" y="548" width="0.4134%" height="15" fill="rgb(215,193,15)" fg:x="8185" fg:w="106"/><text x="32.1703%" y="558.50"></text></g><g><title>at::native::(anonymous namespace)::launch_clamp_scalar(at::TensorIteratorBase&amp;, c10::Scalar, c10::Scalar, at::native::detail::ClampLimits)::{lambda()#1}::operator() const (libtorch_cuda.so) (106 samples, 0.41%)</title><rect x="31.9203%" y="564" width="0.4134%" height="15" fill="rgb(232,15,44)" fg:x="8185" fg:w="106"/><text x="32.1703%" y="574.50"></text></g><g><title>at::native::structured_clamp_min_out::impl (libtorch_cpu.so) (110 samples, 0.43%)</title><rect x="31.9203%" y="532" width="0.4290%" height="15" fill="rgb(212,3,48)" fg:x="8185" fg:w="110"/><text x="32.1703%" y="542.50"></text></g><g><title>at::native::relu (libtorch_cpu.so) (189 samples, 0.74%)</title><rect x="31.6161%" y="468" width="0.7371%" height="15" fill="rgb(218,128,7)" fg:x="8107" fg:w="189"/><text x="31.8661%" y="478.50"></text></g><g><title>at::_ops::clamp_min::call (libtorch_cpu.so) (187 samples, 0.73%)</title><rect x="31.6239%" y="484" width="0.7293%" height="15" fill="rgb(226,216,39)" fg:x="8109" fg:w="187"/><text x="31.8739%" y="494.50"></text></g><g><title>c10::impl::wrap_kernel_functor_unboxed_&lt;c10::impl::detail::WrapFunctionIntoFunctor_&lt;c10::CompileTimeFunctionPointer&lt;at::Tensor(at::Tensor const&amp;, c10::Scalar const&amp;), &amp;at::(anonymous namespace)::wrapper_CUDA_clamp_min(at::Tensor const&amp;, c10::Scalar const&amp;)&gt;, at::Tensor, c10::guts::typelist::typelist&lt;at::Tensor const&amp;, c10::Scalar const&amp;&gt; &gt;, at::Tensor(at::Tensor const&amp;, c10::Scalar const&amp;)&gt;::call (libtorch_cuda.so) (186 samples, 0.73%)</title><rect x="31.6278%" y="500" width="0.7254%" height="15" fill="rgb(243,47,51)" fg:x="8110" fg:w="186"/><text x="31.8778%" y="510.50"></text></g><g><title>at::(anonymous namespace)::wrapper_CUDA_clamp_min (libtorch_cuda.so) (186 samples, 0.73%)</title><rect x="31.6278%" y="516" width="0.7254%" height="15" fill="rgb(241,183,40)" fg:x="8110" fg:w="186"/><text x="31.8778%" y="526.50"></text></g><g><title>at::_ops::relu::redispatch (libtorch_cpu.so) (205 samples, 0.80%)</title><rect x="31.5966%" y="436" width="0.7995%" height="15" fill="rgb(231,217,32)" fg:x="8102" fg:w="205"/><text x="31.8466%" y="446.50"></text></g><g><title>c10::impl::wrap_kernel_functor_unboxed_&lt;c10::impl::detail::WrapFunctionIntoFunctor_&lt;c10::CompileTimeFunctionPointer&lt;at::Tensor(at::Tensor const&amp;), &amp;at::(anonymous namespace)::(anonymous namespace)::wrapper_CUDA__relu(at::Tensor const&amp;)&gt;, at::Tensor, c10::guts::typelist::typelist&lt;at::Tensor const&amp;&gt; &gt;, at::Tensor(at::Tensor const&amp;)&gt;::call (libtorch_cuda.so) (200 samples, 0.78%)</title><rect x="31.6161%" y="452" width="0.7800%" height="15" fill="rgb(229,61,38)" fg:x="8107" fg:w="200"/><text x="31.8661%" y="462.50"></text></g><g><title>at::_ops::relu::call (libtorch_cpu.so) (216 samples, 0.84%)</title><rect x="31.5693%" y="388" width="0.8424%" height="15" fill="rgb(225,210,5)" fg:x="8095" fg:w="216"/><text x="31.8193%" y="398.50"></text></g><g><title>c10::impl::wrap_kernel_functor_unboxed_&lt;c10::impl::detail::WrapFunctionIntoFunctor_&lt;c10::CompileTimeFunctionPointer&lt;at::Tensor(c10::DispatchKeySet, at::Tensor const&amp;), &amp;torch::autograd::VariableType::(anonymous namespace)::relu(c10::DispatchKeySet, at::Tensor const&amp;)&gt;, at::Tensor, c10::guts::typelist::typelist&lt;c10::DispatchKeySet, at::Tensor const&amp;&gt; &gt;, at::Tensor(c10::DispatchKeySet, at::Tensor const&amp;)&gt;::call (libtorch_cpu.so) (211 samples, 0.82%)</title><rect x="31.5888%" y="404" width="0.8229%" height="15" fill="rgb(231,79,45)" fg:x="8100" fg:w="211"/><text x="31.8388%" y="414.50"></text></g><g><title>torch::autograd::VariableType::(anonymous namespace)::relu (libtorch_cpu.so) (211 samples, 0.82%)</title><rect x="31.5888%" y="420" width="0.8229%" height="15" fill="rgb(224,100,7)" fg:x="8100" fg:w="211"/><text x="31.8388%" y="430.50"></text></g><g><title>forward (torch/nn/modules/activation.py:135) (259 samples, 1.01%)</title><rect x="31.4523%" y="340" width="1.0101%" height="15" fill="rgb(241,198,18)" fg:x="8065" fg:w="259"/><text x="31.7023%" y="350.50"></text></g><g><title>relu (torch/nn/functional.py:1701) (246 samples, 0.96%)</title><rect x="31.5030%" y="356" width="0.9594%" height="15" fill="rgb(252,97,53)" fg:x="8078" fg:w="246"/><text x="31.7530%" y="366.50"></text></g><g><title>torch::autograd::THPVariable_relu (libtorch_python.so) (238 samples, 0.93%)</title><rect x="31.5342%" y="372" width="0.9282%" height="15" fill="rgb(220,88,7)" fg:x="8086" fg:w="238"/><text x="31.7842%" y="382.50"></text></g><g><title>at::detail::empty_cuda (libtorch_cuda.so) (31 samples, 0.12%)</title><rect x="32.7783%" y="596" width="0.1209%" height="15" fill="rgb(213,176,14)" fg:x="8405" fg:w="31"/><text x="33.0283%" y="606.50"></text></g><g><title>at::(anonymous namespace)::create_out (libtorch_cuda.so) (40 samples, 0.16%)</title><rect x="32.7510%" y="548" width="0.1560%" height="15" fill="rgb(246,73,7)" fg:x="8398" fg:w="40"/><text x="33.0010%" y="558.50"></text></g><g><title>at::detail::empty_cuda (libtorch_cuda.so) (40 samples, 0.16%)</title><rect x="32.7510%" y="564" width="0.1560%" height="15" fill="rgb(245,64,36)" fg:x="8398" fg:w="40"/><text x="33.0010%" y="574.50"></text></g><g><title>at::detail::empty_cuda (libtorch_cuda.so) (34 samples, 0.13%)</title><rect x="32.7744%" y="580" width="0.1326%" height="15" fill="rgb(245,80,10)" fg:x="8404" fg:w="34"/><text x="33.0244%" y="590.50"></text></g><g><title>at::(anonymous namespace)::structured_addmm_out_cuda_functional::set_output_raw_strided (libtorch_cuda.so) (48 samples, 0.19%)</title><rect x="32.7471%" y="532" width="0.1872%" height="15" fill="rgb(232,107,50)" fg:x="8397" fg:w="48"/><text x="32.9971%" y="542.50"></text></g><g><title>at::meta::structured_addmm::meta (libtorch_cpu.so) (54 samples, 0.21%)</title><rect x="32.7354%" y="516" width="0.2106%" height="15" fill="rgb(253,3,0)" fg:x="8394" fg:w="54"/><text x="32.9854%" y="526.50"></text></g><g><title>at::cuda::getCurrentCUDABlasHandle (libtorch_cuda.so) (65 samples, 0.25%)</title><rect x="33.2735%" y="564" width="0.2535%" height="15" fill="rgb(212,99,53)" fg:x="8532" fg:w="65"/><text x="33.5235%" y="574.50"></text></g><g><title>0x7ac4e2b8988c (nvidia/cublas/lib/libcublasLt.so.12) (50 samples, 0.19%)</title><rect x="33.8819%" y="612" width="0.1950%" height="15" fill="rgb(249,111,54)" fg:x="8688" fg:w="50"/><text x="34.1319%" y="622.50"></text></g><g><title>0x7ac4e2d1ec4d (nvidia/cublas/lib/libcublasLt.so.12) (29 samples, 0.11%)</title><rect x="33.9638%" y="628" width="0.1131%" height="15" fill="rgb(249,55,30)" fg:x="8709" fg:w="29"/><text x="34.2138%" y="638.50"></text></g><g><title>0x7ac4e54fd49b (nvidia/cublas/lib/libcublasLt.so.12) (29 samples, 0.11%)</title><rect x="33.9638%" y="644" width="0.1131%" height="15" fill="rgb(237,47,42)" fg:x="8709" fg:w="29"/><text x="34.2138%" y="654.50"></text></g><g><title>0x7ac4e549a7ce (nvidia/cublas/lib/libcublasLt.so.12) (26 samples, 0.10%)</title><rect x="33.9755%" y="660" width="0.1014%" height="15" fill="rgb(211,20,18)" fg:x="8712" fg:w="26"/><text x="34.2255%" y="670.50"></text></g><g><title>0x7ac4e2e9130d (nvidia/cublas/lib/libcublasLt.so.12) (29 samples, 0.11%)</title><rect x="34.2758%" y="628" width="0.1131%" height="15" fill="rgb(231,203,46)" fg:x="8789" fg:w="29"/><text x="34.5258%" y="638.50"></text></g><g><title>0x7ac4e54fd49b (nvidia/cublas/lib/libcublasLt.so.12) (28 samples, 0.11%)</title><rect x="34.2797%" y="644" width="0.1092%" height="15" fill="rgb(237,142,3)" fg:x="8790" fg:w="28"/><text x="34.5297%" y="654.50"></text></g><g><title>cublasLtMatmul (nvidia/cublas/lib/libcublasLt.so.12) (200 samples, 0.78%)</title><rect x="33.6362%" y="564" width="0.7800%" height="15" fill="rgb(241,107,1)" fg:x="8625" fg:w="200"/><text x="33.8862%" y="574.50"></text></g><g><title>0x7ac4e246b6ab (nvidia/cublas/lib/libcublasLt.so.12) (174 samples, 0.68%)</title><rect x="33.7376%" y="580" width="0.6786%" height="15" fill="rgb(229,83,13)" fg:x="8651" fg:w="174"/><text x="33.9876%" y="590.50"></text></g><g><title>0x7ac4e2394df1 (nvidia/cublas/lib/libcublasLt.so.12) (141 samples, 0.55%)</title><rect x="33.8663%" y="596" width="0.5499%" height="15" fill="rgb(241,91,40)" fg:x="8684" fg:w="141"/><text x="34.1163%" y="606.50"></text></g><g><title>0x7ac4e2d6def3 (nvidia/cublas/lib/libcublasLt.so.12) (58 samples, 0.23%)</title><rect x="34.1900%" y="612" width="0.2262%" height="15" fill="rgb(225,3,45)" fg:x="8767" fg:w="58"/><text x="34.4400%" y="622.50"></text></g><g><title>cublasLtMatmulAlgoGetHeuristic (nvidia/cublas/lib/libcublasLt.so.12) (42 samples, 0.16%)</title><rect x="34.4162%" y="564" width="0.1638%" height="15" fill="rgb(244,223,14)" fg:x="8825" fg:w="42"/><text x="34.6662%" y="574.50"></text></g><g><title>at::cuda::blas::gemm_and_bias&lt;float, float&gt; (libtorch_cuda.so) (396 samples, 1.54%)</title><rect x="33.0434%" y="548" width="1.5443%" height="15" fill="rgb(224,124,37)" fg:x="8473" fg:w="396"/><text x="33.2934%" y="558.50"></text></g><g><title>at::native::structured_addmm_out_cuda::impl (libtorch_cuda.so) (439 samples, 1.71%)</title><rect x="32.9459%" y="516" width="1.7120%" height="15" fill="rgb(251,171,30)" fg:x="8448" fg:w="439"/><text x="33.1959%" y="526.50"></text></g><g><title>at::native::(anonymous namespace)::addmm_out_cuda_impl (libtorch_cuda.so) (437 samples, 1.70%)</title><rect x="32.9537%" y="532" width="1.7042%" height="15" fill="rgb(236,46,54)" fg:x="8450" fg:w="437"/><text x="33.2037%" y="542.50"></text></g><g><title>at::_ops::addmm::redispatch (libtorch_cpu.so) (508 samples, 1.98%)</title><rect x="32.7120%" y="468" width="1.9811%" height="15" fill="rgb(245,213,5)" fg:x="8388" fg:w="508"/><text x="32.9620%" y="478.50">a..</text></g><g><title>c10::impl::wrap_kernel_functor_unboxed_&lt;c10::impl::detail::WrapFunctionIntoFunctor_&lt;c10::CompileTimeFunctionPointer&lt;at::Tensor(at::Tensor const&amp;, at::Tensor const&amp;, at::Tensor const&amp;, c10::Scalar const&amp;, c10::Scalar const&amp;), &amp;at::(anonymous namespace)::wrapper_CUDA_addmm(at::Tensor const&amp;, at::Tensor const&amp;, at::Tensor const&amp;, c10::Scalar const&amp;, c10::Scalar const&amp;)&gt;, at::Tensor, c10::guts::typelist::typelist&lt;at::Tensor const&amp;, at::Tensor const&amp;, at::Tensor const&amp;, c10::Scalar const&amp;, c10::Scalar const&amp;&gt; &gt;, at::Tensor(at::Tensor const&amp;, at::Tensor const&amp;, at::Tensor const&amp;, c10::Scalar const&amp;, c10::Scalar const&amp;)&gt;::call (libtorch_cuda.so) (505 samples, 1.97%)</title><rect x="32.7237%" y="484" width="1.9694%" height="15" fill="rgb(230,144,27)" fg:x="8391" fg:w="505"/><text x="32.9737%" y="494.50">c..</text></g><g><title>at::(anonymous namespace)::wrapper_CUDA_addmm (libtorch_cuda.so) (505 samples, 1.97%)</title><rect x="32.7237%" y="500" width="1.9694%" height="15" fill="rgb(220,86,6)" fg:x="8391" fg:w="505"/><text x="32.9737%" y="510.50">a..</text></g><g><title>at::_ops::addmm::call (libtorch_cpu.so) (535 samples, 2.09%)</title><rect x="32.6652%" y="420" width="2.0864%" height="15" fill="rgb(240,20,13)" fg:x="8376" fg:w="535"/><text x="32.9152%" y="430.50">a..</text></g><g><title>c10::impl::wrap_kernel_functor_unboxed_&lt;c10::impl::detail::WrapFunctionIntoFunctor_&lt;c10::CompileTimeFunctionPointer&lt;at::Tensor(c10::DispatchKeySet, at::Tensor const&amp;, at::Tensor const&amp;, at::Tensor const&amp;, c10::Scalar const&amp;, c10::Scalar const&amp;), &amp;torch::autograd::VariableType::(anonymous namespace)::addmm(c10::DispatchKeySet, at::Tensor const&amp;, at::Tensor const&amp;, at::Tensor const&amp;, c10::Scalar const&amp;, c10::Scalar const&amp;)&gt;, at::Tensor, c10::guts::typelist::typelist&lt;c10::DispatchKeySet, at::Tensor const&amp;, at::Tensor const&amp;, at::Tensor const&amp;, c10::Scalar const&amp;, c10::Scalar const&amp;&gt; &gt;, at::Tensor(c10::DispatchKeySet, at::Tensor const&amp;, at::Tensor const&amp;, at::Tensor const&amp;, c10::Scalar const&amp;, c10::Scalar const&amp;)&gt;::call (libtorch_cpu.so) (527 samples, 2.06%)</title><rect x="32.6964%" y="436" width="2.0552%" height="15" fill="rgb(217,89,34)" fg:x="8384" fg:w="527"/><text x="32.9464%" y="446.50">c..</text></g><g><title>torch::autograd::VariableType::(anonymous namespace)::addmm (libtorch_cpu.so) (525 samples, 2.05%)</title><rect x="32.7042%" y="452" width="2.0474%" height="15" fill="rgb(229,13,5)" fg:x="8386" fg:w="525"/><text x="32.9542%" y="462.50">t..</text></g><g><title>at::native::as_strided_tensorimpl (libtorch_cpu.so) (27 samples, 0.11%)</title><rect x="34.8530%" y="676" width="0.1053%" height="15" fill="rgb(244,67,35)" fg:x="8937" fg:w="27"/><text x="35.1030%" y="686.50"></text></g><g><title>at::Tensor::as_strided_symint (libtorch_cpu.so) (34 samples, 0.13%)</title><rect x="34.8296%" y="612" width="0.1326%" height="15" fill="rgb(221,40,2)" fg:x="8931" fg:w="34"/><text x="35.0796%" y="622.50"></text></g><g><title>at::_ops::as_strided::call (libtorch_cpu.so) (33 samples, 0.13%)</title><rect x="34.8335%" y="628" width="0.1287%" height="15" fill="rgb(237,157,21)" fg:x="8932" fg:w="33"/><text x="35.0835%" y="638.50"></text></g><g><title>c10::impl::wrap_kernel_functor_unboxed_&lt;c10::impl::detail::WrapFunctionIntoFunctor_&lt;c10::CompileTimeFunctionPointer&lt;at::Tensor(at::Tensor const&amp;, c10::ArrayRef&lt;c10::SymInt&gt;, c10::ArrayRef&lt;c10::SymInt&gt;, std::optional&lt;c10::SymInt&gt;), &amp;at::(anonymous namespace)::(anonymous namespace)::wrapper_CUDA__as_strided(at::Tensor const&amp;, c10::ArrayRef&lt;c10::SymInt&gt;, c10::ArrayRef&lt;c10::SymInt&gt;, std::optional&lt;c10::SymInt&gt;)&gt;, at::Tensor, c10::guts::typelist::typelist&lt;at::Tensor const&amp;, c10::ArrayRef&lt;c10::SymInt&gt;, c10::ArrayRef&lt;c10::SymInt&gt;, std::optional&lt;c10::SymInt&gt; &gt; &gt;, at::Tensor(at::Tensor const&amp;, c10::ArrayRef&lt;c10::SymInt&gt;, c10::ArrayRef&lt;c10::SymInt&gt;, std::optional&lt;c10::SymInt&gt;)&gt;::call (libtorch_cuda.so) (31 samples, 0.12%)</title><rect x="34.8413%" y="644" width="0.1209%" height="15" fill="rgb(222,94,11)" fg:x="8934" fg:w="31"/><text x="35.0913%" y="654.50"></text></g><g><title>at::(anonymous namespace)::(anonymous namespace)::wrapper_CUDA__as_strided (libtorch_cuda.so) (28 samples, 0.11%)</title><rect x="34.8530%" y="660" width="0.1092%" height="15" fill="rgb(249,113,6)" fg:x="8937" fg:w="28"/><text x="35.1030%" y="670.50"></text></g><g><title>at::_ops::t::redispatch (libtorch_cpu.so) (58 samples, 0.23%)</title><rect x="34.7828%" y="516" width="0.2262%" height="15" fill="rgb(238,137,36)" fg:x="8919" fg:w="58"/><text x="35.0328%" y="526.50"></text></g><g><title>c10::impl::wrap_kernel_functor_unboxed_&lt;c10::impl::detail::WrapFunctionIntoFunctor_&lt;c10::CompileTimeFunctionPointer&lt;at::Tensor(at::Tensor const&amp;), &amp;at::(anonymous namespace)::(anonymous namespace)::wrapper_CompositeExplicitAutograd__t(at::Tensor const&amp;)&gt;, at::Tensor, c10::guts::typelist::typelist&lt;at::Tensor const&amp;&gt; &gt;, at::Tensor(at::Tensor const&amp;)&gt;::call (libtorch_cpu.so) (55 samples, 0.21%)</title><rect x="34.7945%" y="532" width="0.2145%" height="15" fill="rgb(210,102,26)" fg:x="8922" fg:w="55"/><text x="35.0445%" y="542.50"></text></g><g><title>at::native::t (libtorch_cpu.so) (53 samples, 0.21%)</title><rect x="34.8023%" y="548" width="0.2067%" height="15" fill="rgb(218,30,30)" fg:x="8924" fg:w="53"/><text x="35.0523%" y="558.50"></text></g><g><title>at::_ops::transpose_int::call (libtorch_cpu.so) (52 samples, 0.20%)</title><rect x="34.8062%" y="564" width="0.2028%" height="15" fill="rgb(214,67,26)" fg:x="8925" fg:w="52"/><text x="35.0562%" y="574.50"></text></g><g><title>c10::impl::wrap_kernel_functor_unboxed_&lt;c10::impl::detail::WrapFunctionIntoFunctor_&lt;c10::CompileTimeFunctionPointer&lt;at::Tensor(at::Tensor const&amp;, long, long), &amp;at::(anonymous namespace)::(anonymous namespace)::wrapper_CompositeExplicitAutograd_int_transpose(at::Tensor const&amp;, long, long)&gt;, at::Tensor, c10::guts::typelist::typelist&lt;at::Tensor const&amp;, long, long&gt; &gt;, at::Tensor(at::Tensor const&amp;, long, long)&gt;::call (libtorch_cpu.so) (48 samples, 0.19%)</title><rect x="34.8218%" y="580" width="0.1872%" height="15" fill="rgb(251,9,53)" fg:x="8929" fg:w="48"/><text x="35.0718%" y="590.50"></text></g><g><title>at::native::transpose (libtorch_cpu.so) (48 samples, 0.19%)</title><rect x="34.8218%" y="596" width="0.1872%" height="15" fill="rgb(228,204,25)" fg:x="8929" fg:w="48"/><text x="35.0718%" y="606.50"></text></g><g><title>at::_ops::t::redispatch (libtorch_cpu.so) (80 samples, 0.31%)</title><rect x="34.7633%" y="468" width="0.3120%" height="15" fill="rgb(207,153,8)" fg:x="8914" fg:w="80"/><text x="35.0133%" y="478.50"></text></g><g><title>c10::impl::wrap_kernel_functor_unboxed_&lt;c10::impl::detail::WrapFunctionIntoFunctor_&lt;c10::CompileTimeFunctionPointer&lt;at::Tensor(c10::DispatchKeySet, at::Tensor const&amp;), &amp;torch::ADInplaceOrView::(anonymous namespace)::t(c10::DispatchKeySet, at::Tensor const&amp;)&gt;, at::Tensor, c10::guts::typelist::typelist&lt;c10::DispatchKeySet, at::Tensor const&amp;&gt; &gt;, at::Tensor(c10::DispatchKeySet, at::Tensor const&amp;)&gt;::call (libtorch_cpu.so) (78 samples, 0.30%)</title><rect x="34.7711%" y="484" width="0.3042%" height="15" fill="rgb(242,9,16)" fg:x="8916" fg:w="78"/><text x="35.0211%" y="494.50"></text></g><g><title>torch::ADInplaceOrView::(anonymous namespace)::t (libtorch_cpu.so) (77 samples, 0.30%)</title><rect x="34.7750%" y="500" width="0.3003%" height="15" fill="rgb(217,211,10)" fg:x="8917" fg:w="77"/><text x="35.0250%" y="510.50"></text></g><g><title>at::_ops::t::call (libtorch_cpu.so) (93 samples, 0.36%)</title><rect x="34.7516%" y="420" width="0.3627%" height="15" fill="rgb(219,228,52)" fg:x="8911" fg:w="93"/><text x="35.0016%" y="430.50"></text></g><g><title>c10::impl::wrap_kernel_functor_unboxed_&lt;c10::impl::detail::WrapFunctionIntoFunctor_&lt;c10::CompileTimeFunctionPointer&lt;at::Tensor(c10::DispatchKeySet, at::Tensor const&amp;), &amp;torch::autograd::VariableType::(anonymous namespace)::t(c10::DispatchKeySet, at::Tensor const&amp;)&gt;, at::Tensor, c10::guts::typelist::typelist&lt;c10::DispatchKeySet, at::Tensor const&amp;&gt; &gt;, at::Tensor(c10::DispatchKeySet, at::Tensor const&amp;)&gt;::call (libtorch_cpu.so) (91 samples, 0.35%)</title><rect x="34.7594%" y="436" width="0.3549%" height="15" fill="rgb(231,92,29)" fg:x="8913" fg:w="91"/><text x="35.0094%" y="446.50"></text></g><g><title>torch::autograd::VariableType::(anonymous namespace)::t (libtorch_cpu.so) (91 samples, 0.35%)</title><rect x="34.7594%" y="452" width="0.3549%" height="15" fill="rgb(232,8,23)" fg:x="8913" fg:w="91"/><text x="35.0094%" y="462.50"></text></g><g><title>at::_ops::linear::call (libtorch_cpu.so) (649 samples, 2.53%)</title><rect x="32.6340%" y="372" width="2.5310%" height="15" fill="rgb(216,211,34)" fg:x="8368" fg:w="649"/><text x="32.8840%" y="382.50">at..</text></g><g><title>c10::impl::wrap_kernel_functor_unboxed_&lt;c10::impl::detail::WrapFunctionIntoFunctor_&lt;c10::CompileTimeFunctionPointer&lt;at::Tensor(at::Tensor const&amp;, at::Tensor const&amp;, std::optional&lt;at::Tensor&gt; const&amp;), &amp;at::(anonymous namespace)::(anonymous namespace)::wrapper_CompositeImplicitAutograd__linear(at::Tensor const&amp;, at::Tensor const&amp;, std::optional&lt;at::Tensor&gt; const&amp;)&gt;, at::Tensor, c10::guts::typelist::typelist&lt;at::Tensor const&amp;, at::Tensor const&amp;, std::optional&lt;at::Tensor&gt; const&amp;&gt; &gt;, at::Tensor(at::Tensor const&amp;, at::Tensor const&amp;, std::optional&lt;at::Tensor&gt; const&amp;)&gt;::call (libtorch_cpu.so) (645 samples, 2.52%)</title><rect x="32.6496%" y="388" width="2.5154%" height="15" fill="rgb(236,151,0)" fg:x="8372" fg:w="645"/><text x="32.8996%" y="398.50">c1..</text></g><g><title>at::native::linear (libtorch_cpu.so) (644 samples, 2.51%)</title><rect x="32.6535%" y="404" width="2.5115%" height="15" fill="rgb(209,168,3)" fg:x="8373" fg:w="644"/><text x="32.9035%" y="414.50">at..</text></g><g><title>forward (torch/nn/modules/container.py:244) (1,137 samples, 4.43%)</title><rect x="30.8634%" y="292" width="4.4341%" height="15" fill="rgb(208,129,28)" fg:x="7914" fg:w="1137"/><text x="31.1134%" y="302.50">forwa..</text></g><g><title>_wrapped_call_impl (torch/nn/modules/module.py:1773) (1,076 samples, 4.20%)</title><rect x="31.1013%" y="308" width="4.1962%" height="15" fill="rgb(229,78,22)" fg:x="7975" fg:w="1076"/><text x="31.3513%" y="318.50">_wrap..</text></g><g><title>_call_impl (torch/nn/modules/module.py:1784) (998 samples, 3.89%)</title><rect x="31.4055%" y="324" width="3.8921%" height="15" fill="rgb(228,187,13)" fg:x="8053" fg:w="998"/><text x="31.6555%" y="334.50">_cal..</text></g><g><title>forward (torch/nn/modules/linear.py:125) (725 samples, 2.83%)</title><rect x="32.4702%" y="340" width="2.8274%" height="15" fill="rgb(240,119,24)" fg:x="8326" fg:w="725"/><text x="32.7202%" y="350.50">fo..</text></g><g><title>torch::autograd::THPVariable_linear (libtorch_python.so) (694 samples, 2.71%)</title><rect x="32.5911%" y="356" width="2.7065%" height="15" fill="rgb(209,194,42)" fg:x="8357" fg:w="694"/><text x="32.8411%" y="366.50">to..</text></g><g><title>forward (armada_net.py:205) (1,202 samples, 4.69%)</title><rect x="30.6138%" y="244" width="4.6876%" height="15" fill="rgb(247,200,46)" fg:x="7850" fg:w="1202"/><text x="30.8638%" y="254.50">forwa..</text></g><g><title>_wrapped_call_impl (torch/nn/modules/module.py:1773) (1,179 samples, 4.60%)</title><rect x="30.7035%" y="260" width="4.5979%" height="15" fill="rgb(218,76,16)" fg:x="7873" fg:w="1179"/><text x="30.9535%" y="270.50">_wrap..</text></g><g><title>_call_impl (torch/nn/modules/module.py:1784) (1,158 samples, 4.52%)</title><rect x="30.7854%" y="276" width="4.5160%" height="15" fill="rgb(225,21,48)" fg:x="7894" fg:w="1158"/><text x="31.0354%" y="286.50">_call..</text></g><g><title>0x7ac4dff2b605 (libcuda.so.550.54.15) (37 samples, 0.14%)</title><rect x="35.6680%" y="500" width="0.1443%" height="15" fill="rgb(239,223,50)" fg:x="9146" fg:w="37"/><text x="35.9180%" y="510.50"></text></g><g><title>0x7ac5be415aa8 (nvidia/cuda_runtime/lib/libcudart.so.12) (43 samples, 0.17%)</title><rect x="35.6485%" y="436" width="0.1677%" height="15" fill="rgb(244,45,21)" fg:x="9141" fg:w="43"/><text x="35.8985%" y="446.50"></text></g><g><title>0x7ac4e00ef270 (libcuda.so.550.54.15) (43 samples, 0.17%)</title><rect x="35.6485%" y="452" width="0.1677%" height="15" fill="rgb(232,33,43)" fg:x="9141" fg:w="43"/><text x="35.8985%" y="462.50"></text></g><g><title>0x7ac4dff32a6f (libcuda.so.550.54.15) (39 samples, 0.15%)</title><rect x="35.6641%" y="468" width="0.1521%" height="15" fill="rgb(209,8,3)" fg:x="9145" fg:w="39"/><text x="35.9141%" y="478.50"></text></g><g><title>0x7ac4dff2be78 (libcuda.so.550.54.15) (38 samples, 0.15%)</title><rect x="35.6680%" y="484" width="0.1482%" height="15" fill="rgb(214,25,53)" fg:x="9146" fg:w="38"/><text x="35.9180%" y="494.50"></text></g><g><title>at::native::gpu_index_kernel&lt;__nv_dl_wrapper_t&lt;__nv_dl_tag&lt;void (*)(at::TensorIterator&amp;, c10::ArrayRef&lt;long&gt;, c10::ArrayRef&lt;long&gt;), &amp;at::native::index_put_kernel_impl&lt;at::native::OpaqueType&lt;4&gt; &gt;(at::TensorIterator&amp;, c10::ArrayRef&lt;long&gt;, c10::ArrayRef&lt;long&gt;), (unsigned int)1&gt;, &gt; &gt; (libtorch_cuda.so) (70 samples, 0.27%)</title><rect x="35.5471%" y="404" width="0.2730%" height="15" fill="rgb(254,186,54)" fg:x="9115" fg:w="70"/><text x="35.7971%" y="414.50"></text></g><g><title>cudaLaunchKernel (nvidia/cuda_runtime/lib/libcudart.so.12) (59 samples, 0.23%)</title><rect x="35.5900%" y="420" width="0.2301%" height="15" fill="rgb(208,174,49)" fg:x="9126" fg:w="59"/><text x="35.8400%" y="430.50"></text></g><g><title>at::native::index_put_kernel (libtorch_cuda.so) (73 samples, 0.28%)</title><rect x="35.5393%" y="388" width="0.2847%" height="15" fill="rgb(233,191,51)" fg:x="9113" fg:w="73"/><text x="35.7893%" y="398.50"></text></g><g><title>at::native::_index_put_impl_ (libtorch_cpu.so) (121 samples, 0.47%)</title><rect x="35.4575%" y="372" width="0.4719%" height="15" fill="rgb(222,134,10)" fg:x="9092" fg:w="121"/><text x="35.7075%" y="382.50"></text></g><g><title>at::_ops::_index_put_impl_::call (libtorch_cpu.so) (129 samples, 0.50%)</title><rect x="35.4497%" y="340" width="0.5031%" height="15" fill="rgb(230,226,20)" fg:x="9090" fg:w="129"/><text x="35.6997%" y="350.50"></text></g><g><title>c10::impl::wrap_kernel_functor_unboxed_&lt;c10::impl::detail::WrapFunctionIntoFunctor_&lt;c10::CompileTimeFunctionPointer&lt;at::Tensor&amp; (at::Tensor&amp;, c10::List&lt;std::optional&lt;at::Tensor&gt; &gt; const&amp;, at::Tensor const&amp;, bool, bool), &amp;at::(anonymous namespace)::(anonymous namespace)::wrapper_CUDA___index_put_impl_(at::Tensor&amp;, c10::List&lt;std::optional&lt;at::Tensor&gt; &gt; const&amp;, at::Tensor const&amp;, bool, bool)&gt;, at::Tensor&amp;, c10::guts::typelist::typelist&lt;at::Tensor&amp;, c10::List&lt;std::optional&lt;at::Tensor&gt; &gt; const&amp;, at::Tensor const&amp;, bool, bool&gt; &gt;, at::Tensor&amp; (at::Tensor&amp;, c10::List&lt;std::optional&lt;at::Tensor&gt; &gt; const&amp;, at::Tensor const&amp;, bool, bool)&gt;::call (libtorch_cuda.so) (128 samples, 0.50%)</title><rect x="35.4536%" y="356" width="0.4992%" height="15" fill="rgb(251,111,25)" fg:x="9091" fg:w="128"/><text x="35.7036%" y="366.50"></text></g><g><title>c10::impl::wrap_kernel_functor_unboxed_&lt;c10::impl::detail::WrapFunctionIntoFunctor_&lt;c10::CompileTimeFunctionPointer&lt;at::Tensor&amp; (c10::DispatchKeySet, at::Tensor&amp;, c10::List&lt;std::optional&lt;at::Tensor&gt; &gt; const&amp;, at::Tensor const&amp;, bool), &amp;torch::ADInplaceOrView::(anonymous namespace)::index_put_(c10::DispatchKeySet, at::Tensor&amp;, c10::List&lt;std::optional&lt;at::Tensor&gt; &gt; const&amp;, at::Tensor const&amp;, bool)&gt;, at::Tensor&amp;, c10::guts::typelist::typelist&lt;c10::DispatchKeySet, at::Tensor&amp;, c10::List&lt;std::optional&lt;at::Tensor&gt; &gt; const&amp;, at::Tensor const&amp;, bool&gt; &gt;, at::Tensor&amp; (c10::DispatchKeySet, at::Tensor&amp;, c10::List&lt;std::optional&lt;at::Tensor&gt; &gt; const&amp;, at::Tensor const&amp;, bool)&gt;::call (libtorch_cpu.so) (131 samples, 0.51%)</title><rect x="35.4458%" y="324" width="0.5109%" height="15" fill="rgb(224,40,46)" fg:x="9089" fg:w="131"/><text x="35.6958%" y="334.50"></text></g><g><title>at::_ops::index_put_::call (libtorch_cpu.so) (135 samples, 0.53%)</title><rect x="35.4419%" y="292" width="0.5265%" height="15" fill="rgb(236,108,47)" fg:x="9088" fg:w="135"/><text x="35.6919%" y="302.50"></text></g><g><title>torch::autograd::VariableType::(anonymous namespace)::index_put_ (libtorch_cpu.so) (135 samples, 0.53%)</title><rect x="35.4419%" y="308" width="0.5265%" height="15" fill="rgb(234,93,0)" fg:x="9088" fg:w="135"/><text x="35.6919%" y="318.50"></text></g><g><title>at::indexing::dispatch_index_put_ (libtorch_python.so) (145 samples, 0.57%)</title><rect x="35.4380%" y="276" width="0.5655%" height="15" fill="rgb(224,213,32)" fg:x="9087" fg:w="145"/><text x="35.6880%" y="286.50"></text></g><g><title>at::indexing::impl::applySlice (libtorch_python.so) (28 samples, 0.11%)</title><rect x="36.1048%" y="308" width="0.1092%" height="15" fill="rgb(251,11,48)" fg:x="9258" fg:w="28"/><text x="36.3548%" y="318.50"></text></g><g><title>at::indexing::handleDimInMultiDimIndexing (libtorch_python.so) (31 samples, 0.12%)</title><rect x="36.1048%" y="292" width="0.1209%" height="15" fill="rgb(236,173,5)" fg:x="9258" fg:w="31"/><text x="36.3548%" y="302.50"></text></g><g><title>0x7ac4dff3f5f7 (libcuda.so.550.54.15) (27 samples, 0.11%)</title><rect x="36.5689%" y="580" width="0.1053%" height="15" fill="rgb(230,95,12)" fg:x="9377" fg:w="27"/><text x="36.8189%" y="590.50"></text></g><g><title>0x7ac4e00e8cc9 (libcuda.so.550.54.15) (46 samples, 0.18%)</title><rect x="36.5572%" y="564" width="0.1794%" height="15" fill="rgb(232,209,1)" fg:x="9374" fg:w="46"/><text x="36.8072%" y="574.50"></text></g><g><title>0x7ac5be418cb2 (nvidia/cuda_runtime/lib/libcudart.so.12) (50 samples, 0.19%)</title><rect x="36.5533%" y="532" width="0.1950%" height="15" fill="rgb(232,6,1)" fg:x="9373" fg:w="50"/><text x="36.8033%" y="542.50"></text></g><g><title>0x7ac5be448c59 (nvidia/cuda_runtime/lib/libcudart.so.12) (49 samples, 0.19%)</title><rect x="36.5572%" y="548" width="0.1911%" height="15" fill="rgb(210,224,50)" fg:x="9374" fg:w="49"/><text x="36.8072%" y="558.50"></text></g><g><title>cudaMemcpyAsync (nvidia/cuda_runtime/lib/libcudart.so.12) (53 samples, 0.21%)</title><rect x="36.5455%" y="516" width="0.2067%" height="15" fill="rgb(228,127,35)" fg:x="9371" fg:w="53"/><text x="36.7955%" y="526.50"></text></g><g><title>at::native::copy_impl (libtorch_cpu.so) (107 samples, 0.42%)</title><rect x="36.4324%" y="484" width="0.4173%" height="15" fill="rgb(245,102,45)" fg:x="9342" fg:w="107"/><text x="36.6824%" y="494.50"></text></g><g><title>at::native::copy_kernel_cuda (libtorch_cuda.so) (84 samples, 0.33%)</title><rect x="36.5221%" y="500" width="0.3276%" height="15" fill="rgb(214,1,49)" fg:x="9365" fg:w="84"/><text x="36.7721%" y="510.50"></text></g><g><title>at::_ops::copy_::call (libtorch_cpu.so) (110 samples, 0.43%)</title><rect x="36.4246%" y="452" width="0.4290%" height="15" fill="rgb(226,163,40)" fg:x="9340" fg:w="110"/><text x="36.6746%" y="462.50"></text></g><g><title>at::native::copy_ (libtorch_cpu.so) (109 samples, 0.43%)</title><rect x="36.4285%" y="468" width="0.4251%" height="15" fill="rgb(239,212,28)" fg:x="9341" fg:w="109"/><text x="36.6785%" y="478.50"></text></g><g><title>at::_ops::_to_copy::call (libtorch_cpu.so) (152 samples, 0.59%)</title><rect x="36.3700%" y="372" width="0.5928%" height="15" fill="rgb(220,20,13)" fg:x="9326" fg:w="152"/><text x="36.6200%" y="382.50"></text></g><g><title>c10::impl::wrap_kernel_functor_unboxed_&lt;c10::impl::detail::WrapFunctionIntoFunctor_&lt;c10::CompileTimeFunctionPointer&lt;at::Tensor(at::Tensor const&amp;, std::optional&lt;c10::ScalarType&gt;, std::optional&lt;c10::Layout&gt;, std::optional&lt;c10::Device&gt;, std::optional&lt;bool&gt;, bool, std::optional&lt;c10::MemoryFormat&gt;), &amp;at::(anonymous namespace)::_to_copy(at::Tensor const&amp;, std::optional&lt;c10::ScalarType&gt;, std::optional&lt;c10::Layout&gt;, std::optional&lt;c10::Device&gt;, std::optional&lt;bool&gt;, bool, std::optional&lt;c10::MemoryFormat&gt;)&gt;, at::Tensor, c10::guts::typelist::typelist&lt;at::Tensor const&amp;, std::optional&lt;c10::ScalarType&gt;, std::optional&lt;c10::Layout&gt;, std::optional&lt;c10::Device&gt;, std::optional&lt;bool&gt;, bool, std::optional&lt;c10::MemoryFormat&gt; &gt; &gt;, at::Tensor(at::Tensor const&amp;, std::optional&lt;c10::ScalarType&gt;, std::optional&lt;c10::Layout&gt;, std::optional&lt;c10::Device&gt;, std::optional&lt;bool&gt;, bool, std::optional&lt;c10::MemoryFormat&gt;)&gt;::call (libtorch_cpu.so) (151 samples, 0.59%)</title><rect x="36.3739%" y="388" width="0.5889%" height="15" fill="rgb(210,164,35)" fg:x="9327" fg:w="151"/><text x="36.6239%" y="398.50"></text></g><g><title>at::_ops::_to_copy::redispatch (libtorch_cpu.so) (150 samples, 0.58%)</title><rect x="36.3778%" y="404" width="0.5850%" height="15" fill="rgb(248,109,41)" fg:x="9328" fg:w="150"/><text x="36.6278%" y="414.50"></text></g><g><title>c10::impl::wrap_kernel_functor_unboxed_&lt;c10::impl::detail::WrapFunctionIntoFunctor_&lt;c10::CompileTimeFunctionPointer&lt;at::Tensor(at::Tensor const&amp;, std::optional&lt;c10::ScalarType&gt;, std::optional&lt;c10::Layout&gt;, std::optional&lt;c10::Device&gt;, std::optional&lt;bool&gt;, bool, std::optional&lt;c10::MemoryFormat&gt;), &amp;at::(anonymous namespace)::(anonymous namespace)::wrapper_CompositeExplicitAutograd___to_copy(at::Tensor const&amp;, std::optional&lt;c10::ScalarType&gt;, std::optional&lt;c10::Layout&gt;, std::optional&lt;c10::Device&gt;, std::optional&lt;bool&gt;, bool, std::optional&lt;c10::MemoryFormat&gt;)&gt;, at::Tensor, c10::guts::typelist::typelist&lt;at::Tensor const&amp;, std::optional&lt;c10::ScalarType&gt;, std::optional&lt;c10::Layout&gt;, std::optional&lt;c10::Device&gt;, std::optional&lt;bool&gt;, bool, std::optional&lt;c10::MemoryFormat&gt; &gt; &gt;, at::Tensor(at::Tensor const&amp;, std::optional&lt;c10::ScalarType&gt;, std::optional&lt;c10::Layout&gt;, std::optional&lt;c10::Device&gt;, std::optional&lt;bool&gt;, bool, std::optional&lt;c10::MemoryFormat&gt;)&gt;::call (libtorch_cpu.so) (148 samples, 0.58%)</title><rect x="36.3856%" y="420" width="0.5772%" height="15" fill="rgb(238,23,50)" fg:x="9330" fg:w="148"/><text x="36.6356%" y="430.50"></text></g><g><title>at::native::_to_copy (libtorch_cpu.so) (147 samples, 0.57%)</title><rect x="36.3895%" y="436" width="0.5733%" height="15" fill="rgb(211,48,49)" fg:x="9331" fg:w="147"/><text x="36.6395%" y="446.50"></text></g><g><title>at::_ops::to_device::call (libtorch_cpu.so) (159 samples, 0.62%)</title><rect x="36.3505%" y="324" width="0.6201%" height="15" fill="rgb(223,36,21)" fg:x="9321" fg:w="159"/><text x="36.6005%" y="334.50"></text></g><g><title>c10::impl::wrap_kernel_functor_unboxed_&lt;c10::impl::detail::WrapFunctionIntoFunctor_&lt;c10::CompileTimeFunctionPointer&lt;at::Tensor(at::Tensor const&amp;, c10::Device, c10::ScalarType, bool, bool, std::optional&lt;c10::MemoryFormat&gt;), &amp;at::(anonymous namespace)::(anonymous namespace)::wrapper_CompositeImplicitAutograd_device_to(at::Tensor const&amp;, c10::Device, c10::ScalarType, bool, bool, std::optional&lt;c10::MemoryFormat&gt;)&gt;, at::Tensor, c10::guts::typelist::typelist&lt;at::Tensor const&amp;, c10::Device, c10::ScalarType, bool, bool, std::optional&lt;c10::MemoryFormat&gt; &gt; &gt;, at::Tensor(at::Tensor const&amp;, c10::Device, c10::ScalarType, bool, bool, std::optional&lt;c10::MemoryFormat&gt;)&gt;::call (libtorch_cpu.so) (156 samples, 0.61%)</title><rect x="36.3622%" y="340" width="0.6084%" height="15" fill="rgb(207,123,46)" fg:x="9324" fg:w="156"/><text x="36.6122%" y="350.50"></text></g><g><title>at::native::to (libtorch_cpu.so) (155 samples, 0.60%)</title><rect x="36.3661%" y="356" width="0.6045%" height="15" fill="rgb(240,218,32)" fg:x="9325" fg:w="155"/><text x="36.6161%" y="366.50"></text></g><g><title>at::_ops::empty_memory_format::call (libtorch_cpu.so) (27 samples, 0.11%)</title><rect x="36.9706%" y="340" width="0.1053%" height="15" fill="rgb(252,5,43)" fg:x="9480" fg:w="27"/><text x="37.2206%" y="350.50"></text></g><g><title>at::empty (libtorch_python.so) (28 samples, 0.11%)</title><rect x="36.9706%" y="324" width="0.1092%" height="15" fill="rgb(252,84,19)" fg:x="9480" fg:w="28"/><text x="37.2206%" y="334.50"></text></g><g><title>torch::utils::indexing_tensor_from_data (libtorch_python.so) (237 samples, 0.92%)</title><rect x="36.2452%" y="292" width="0.9243%" height="15" fill="rgb(243,152,39)" fg:x="9294" fg:w="237"/><text x="36.4952%" y="302.50"></text></g><g><title>torch::utils::(anonymous namespace)::internal_new_from_data (libtorch_python.so) (229 samples, 0.89%)</title><rect x="36.2764%" y="308" width="0.8931%" height="15" fill="rgb(234,160,15)" fg:x="9302" fg:w="229"/><text x="36.5264%" y="318.50"></text></g><g><title>torch::autograd::applySlicing (libtorch_python.so) (282 samples, 1.10%)</title><rect x="36.0736%" y="276" width="1.0998%" height="15" fill="rgb(237,34,20)" fg:x="9250" fg:w="282"/><text x="36.3236%" y="286.50"></text></g><g><title>torch::autograd::THPVariable_setitem (libtorch_python.so) (467 samples, 1.82%)</title><rect x="35.3717%" y="260" width="1.8212%" height="15" fill="rgb(229,97,13)" fg:x="9070" fg:w="467"/><text x="35.6217%" y="270.50">t..</text></g><g><title>forward (armada_net.py:209) (486 samples, 1.90%)</title><rect x="35.3015%" y="244" width="1.8953%" height="15" fill="rgb(234,71,50)" fg:x="9052" fg:w="486"/><text x="35.5515%" y="254.50">f..</text></g><g><title>at::_ops::relu::call (libtorch_cpu.so) (28 samples, 0.11%)</title><rect x="37.3918%" y="388" width="0.1092%" height="15" fill="rgb(253,155,4)" fg:x="9588" fg:w="28"/><text x="37.6418%" y="398.50"></text></g><g><title>c10::impl::wrap_kernel_functor_unboxed_&lt;c10::impl::detail::WrapFunctionIntoFunctor_&lt;c10::CompileTimeFunctionPointer&lt;at::Tensor(c10::DispatchKeySet, at::Tensor const&amp;), &amp;torch::autograd::VariableType::(anonymous namespace)::relu(c10::DispatchKeySet, at::Tensor const&amp;)&gt;, at::Tensor, c10::guts::typelist::typelist&lt;c10::DispatchKeySet, at::Tensor const&amp;&gt; &gt;, at::Tensor(c10::DispatchKeySet, at::Tensor const&amp;)&gt;::call (libtorch_cpu.so) (27 samples, 0.11%)</title><rect x="37.3957%" y="404" width="0.1053%" height="15" fill="rgb(222,185,37)" fg:x="9589" fg:w="27"/><text x="37.6457%" y="414.50"></text></g><g><title>torch::autograd::VariableType::(anonymous namespace)::relu (libtorch_cpu.so) (27 samples, 0.11%)</title><rect x="37.3957%" y="420" width="0.1053%" height="15" fill="rgb(251,177,13)" fg:x="9589" fg:w="27"/><text x="37.6457%" y="430.50"></text></g><g><title>forward (torch/nn/modules/activation.py:135) (34 samples, 0.13%)</title><rect x="37.3762%" y="340" width="0.1326%" height="15" fill="rgb(250,179,40)" fg:x="9584" fg:w="34"/><text x="37.6262%" y="350.50"></text></g><g><title>relu (torch/nn/functional.py:1701) (33 samples, 0.13%)</title><rect x="37.3801%" y="356" width="0.1287%" height="15" fill="rgb(242,44,2)" fg:x="9585" fg:w="33"/><text x="37.6301%" y="366.50"></text></g><g><title>torch::autograd::THPVariable_relu (libtorch_python.so) (33 samples, 0.13%)</title><rect x="37.3801%" y="372" width="0.1287%" height="15" fill="rgb(216,177,13)" fg:x="9585" fg:w="33"/><text x="37.6301%" y="382.50"></text></g><g><title>at::_ops::sigmoid::call (libtorch_cpu.so) (27 samples, 0.11%)</title><rect x="37.5244%" y="372" width="0.1053%" height="15" fill="rgb(216,106,43)" fg:x="9622" fg:w="27"/><text x="37.7744%" y="382.50"></text></g><g><title>forward (torch/nn/modules/activation.py:329) (32 samples, 0.12%)</title><rect x="37.5127%" y="340" width="0.1248%" height="15" fill="rgb(216,183,2)" fg:x="9619" fg:w="32"/><text x="37.7627%" y="350.50"></text></g><g><title>torch::autograd::THPVariable_sigmoid (libtorch_python.so) (30 samples, 0.12%)</title><rect x="37.5205%" y="356" width="0.1170%" height="15" fill="rgb(249,75,3)" fg:x="9621" fg:w="30"/><text x="37.7705%" y="366.50"></text></g><g><title>cublasLtMatmul (nvidia/cublas/lib/libcublasLt.so.12) (30 samples, 0.12%)</title><rect x="37.8091%" y="564" width="0.1170%" height="15" fill="rgb(219,67,39)" fg:x="9695" fg:w="30"/><text x="38.0591%" y="574.50"></text></g><g><title>0x7ac4e246b6ab (nvidia/cublas/lib/libcublasLt.so.12) (28 samples, 0.11%)</title><rect x="37.8169%" y="580" width="0.1092%" height="15" fill="rgb(253,228,2)" fg:x="9697" fg:w="28"/><text x="38.0669%" y="590.50"></text></g><g><title>at::cuda::blas::gemm_and_bias&lt;float, float&gt; (libtorch_cuda.so) (62 samples, 0.24%)</title><rect x="37.7428%" y="548" width="0.2418%" height="15" fill="rgb(235,138,27)" fg:x="9678" fg:w="62"/><text x="37.9928%" y="558.50"></text></g><g><title>at::native::structured_addmm_out_cuda::impl (libtorch_cuda.so) (69 samples, 0.27%)</title><rect x="37.7194%" y="516" width="0.2691%" height="15" fill="rgb(236,97,51)" fg:x="9672" fg:w="69"/><text x="37.9694%" y="526.50"></text></g><g><title>at::native::(anonymous namespace)::addmm_out_cuda_impl (libtorch_cuda.so) (68 samples, 0.27%)</title><rect x="37.7233%" y="532" width="0.2652%" height="15" fill="rgb(240,80,30)" fg:x="9673" fg:w="68"/><text x="37.9733%" y="542.50"></text></g><g><title>at::_ops::addmm::call (libtorch_cpu.so) (83 samples, 0.32%)</title><rect x="37.6687%" y="420" width="0.3237%" height="15" fill="rgb(230,178,19)" fg:x="9659" fg:w="83"/><text x="37.9187%" y="430.50"></text></g><g><title>c10::impl::wrap_kernel_functor_unboxed_&lt;c10::impl::detail::WrapFunctionIntoFunctor_&lt;c10::CompileTimeFunctionPointer&lt;at::Tensor(c10::DispatchKeySet, at::Tensor const&amp;, at::Tensor const&amp;, at::Tensor const&amp;, c10::Scalar const&amp;, c10::Scalar const&amp;), &amp;torch::autograd::VariableType::(anonymous namespace)::addmm(c10::DispatchKeySet, at::Tensor const&amp;, at::Tensor const&amp;, at::Tensor const&amp;, c10::Scalar const&amp;, c10::Scalar const&amp;)&gt;, at::Tensor, c10::guts::typelist::typelist&lt;c10::DispatchKeySet, at::Tensor const&amp;, at::Tensor const&amp;, at::Tensor const&amp;, c10::Scalar const&amp;, c10::Scalar const&amp;&gt; &gt;, at::Tensor(c10::DispatchKeySet, at::Tensor const&amp;, at::Tensor const&amp;, at::Tensor const&amp;, c10::Scalar const&amp;, c10::Scalar const&amp;)&gt;::call (libtorch_cpu.so) (82 samples, 0.32%)</title><rect x="37.6726%" y="436" width="0.3198%" height="15" fill="rgb(210,190,27)" fg:x="9660" fg:w="82"/><text x="37.9226%" y="446.50"></text></g><g><title>torch::autograd::VariableType::(anonymous namespace)::addmm (libtorch_cpu.so) (82 samples, 0.32%)</title><rect x="37.6726%" y="452" width="0.3198%" height="15" fill="rgb(222,107,31)" fg:x="9660" fg:w="82"/><text x="37.9226%" y="462.50"></text></g><g><title>at::_ops::addmm::redispatch (libtorch_cpu.so) (81 samples, 0.32%)</title><rect x="37.6765%" y="468" width="0.3159%" height="15" fill="rgb(216,127,34)" fg:x="9661" fg:w="81"/><text x="37.9265%" y="478.50"></text></g><g><title>c10::impl::wrap_kernel_functor_unboxed_&lt;c10::impl::detail::WrapFunctionIntoFunctor_&lt;c10::CompileTimeFunctionPointer&lt;at::Tensor(at::Tensor const&amp;, at::Tensor const&amp;, at::Tensor const&amp;, c10::Scalar const&amp;, c10::Scalar const&amp;), &amp;at::(anonymous namespace)::wrapper_CUDA_addmm(at::Tensor const&amp;, at::Tensor const&amp;, at::Tensor const&amp;, c10::Scalar const&amp;, c10::Scalar const&amp;)&gt;, at::Tensor, c10::guts::typelist::typelist&lt;at::Tensor const&amp;, at::Tensor const&amp;, at::Tensor const&amp;, c10::Scalar const&amp;, c10::Scalar const&amp;&gt; &gt;, at::Tensor(at::Tensor const&amp;, at::Tensor const&amp;, at::Tensor const&amp;, c10::Scalar const&amp;, c10::Scalar const&amp;)&gt;::call (libtorch_cuda.so) (81 samples, 0.32%)</title><rect x="37.6765%" y="484" width="0.3159%" height="15" fill="rgb(234,116,52)" fg:x="9661" fg:w="81"/><text x="37.9265%" y="494.50"></text></g><g><title>at::(anonymous namespace)::wrapper_CUDA_addmm (libtorch_cuda.so) (81 samples, 0.32%)</title><rect x="37.6765%" y="500" width="0.3159%" height="15" fill="rgb(222,124,15)" fg:x="9661" fg:w="81"/><text x="37.9265%" y="510.50"></text></g><g><title>at::_ops::linear::call (libtorch_cpu.so) (105 samples, 0.41%)</title><rect x="37.6648%" y="372" width="0.4095%" height="15" fill="rgb(231,179,28)" fg:x="9658" fg:w="105"/><text x="37.9148%" y="382.50"></text></g><g><title>c10::impl::wrap_kernel_functor_unboxed_&lt;c10::impl::detail::WrapFunctionIntoFunctor_&lt;c10::CompileTimeFunctionPointer&lt;at::Tensor(at::Tensor const&amp;, at::Tensor const&amp;, std::optional&lt;at::Tensor&gt; const&amp;), &amp;at::(anonymous namespace)::(anonymous namespace)::wrapper_CompositeImplicitAutograd__linear(at::Tensor const&amp;, at::Tensor const&amp;, std::optional&lt;at::Tensor&gt; const&amp;)&gt;, at::Tensor, c10::guts::typelist::typelist&lt;at::Tensor const&amp;, at::Tensor const&amp;, std::optional&lt;at::Tensor&gt; const&amp;&gt; &gt;, at::Tensor(at::Tensor const&amp;, at::Tensor const&amp;, std::optional&lt;at::Tensor&gt; const&amp;)&gt;::call (libtorch_cpu.so) (104 samples, 0.41%)</title><rect x="37.6687%" y="388" width="0.4056%" height="15" fill="rgb(226,93,45)" fg:x="9659" fg:w="104"/><text x="37.9187%" y="398.50"></text></g><g><title>at::native::linear (libtorch_cpu.so) (104 samples, 0.41%)</title><rect x="37.6687%" y="404" width="0.4056%" height="15" fill="rgb(215,8,51)" fg:x="9659" fg:w="104"/><text x="37.9187%" y="414.50"></text></g><g><title>forward (armada_net.py:213) (229 samples, 0.89%)</title><rect x="37.1968%" y="244" width="0.8931%" height="15" fill="rgb(223,106,5)" fg:x="9538" fg:w="229"/><text x="37.4468%" y="254.50"></text></g><g><title>_wrapped_call_impl (torch/nn/modules/module.py:1773) (224 samples, 0.87%)</title><rect x="37.2163%" y="260" width="0.8736%" height="15" fill="rgb(250,191,5)" fg:x="9543" fg:w="224"/><text x="37.4663%" y="270.50"></text></g><g><title>_call_impl (torch/nn/modules/module.py:1784) (220 samples, 0.86%)</title><rect x="37.2319%" y="276" width="0.8580%" height="15" fill="rgb(242,132,44)" fg:x="9547" fg:w="220"/><text x="37.4819%" y="286.50"></text></g><g><title>forward (torch/nn/modules/container.py:244) (215 samples, 0.84%)</title><rect x="37.2514%" y="292" width="0.8385%" height="15" fill="rgb(251,152,29)" fg:x="9552" fg:w="215"/><text x="37.5014%" y="302.50"></text></g><g><title>_wrapped_call_impl (torch/nn/modules/module.py:1773) (203 samples, 0.79%)</title><rect x="37.2982%" y="308" width="0.7917%" height="15" fill="rgb(218,179,5)" fg:x="9564" fg:w="203"/><text x="37.5482%" y="318.50"></text></g><g><title>_call_impl (torch/nn/modules/module.py:1784) (183 samples, 0.71%)</title><rect x="37.3762%" y="324" width="0.7137%" height="15" fill="rgb(227,67,19)" fg:x="9584" fg:w="183"/><text x="37.6262%" y="334.50"></text></g><g><title>forward (torch/nn/modules/linear.py:125) (116 samples, 0.45%)</title><rect x="37.6375%" y="340" width="0.4524%" height="15" fill="rgb(233,119,31)" fg:x="9651" fg:w="116"/><text x="37.8875%" y="350.50"></text></g><g><title>torch::autograd::THPVariable_linear (libtorch_python.so) (112 samples, 0.44%)</title><rect x="37.6531%" y="356" width="0.4368%" height="15" fill="rgb(241,120,22)" fg:x="9655" fg:w="112"/><text x="37.9031%" y="366.50"></text></g><g><title>at::cuda::blas::gemm_and_bias&lt;float, float&gt; (libtorch_cuda.so) (47 samples, 0.18%)</title><rect x="38.5032%" y="548" width="0.1833%" height="15" fill="rgb(224,102,30)" fg:x="9873" fg:w="47"/><text x="38.7532%" y="558.50"></text></g><g><title>at::_ops::addmm::redispatch (libtorch_cpu.so) (65 samples, 0.25%)</title><rect x="38.4447%" y="468" width="0.2535%" height="15" fill="rgb(210,164,37)" fg:x="9858" fg:w="65"/><text x="38.6947%" y="478.50"></text></g><g><title>c10::impl::wrap_kernel_functor_unboxed_&lt;c10::impl::detail::WrapFunctionIntoFunctor_&lt;c10::CompileTimeFunctionPointer&lt;at::Tensor(at::Tensor const&amp;, at::Tensor const&amp;, at::Tensor const&amp;, c10::Scalar const&amp;, c10::Scalar const&amp;), &amp;at::(anonymous namespace)::wrapper_CUDA_addmm(at::Tensor const&amp;, at::Tensor const&amp;, at::Tensor const&amp;, c10::Scalar const&amp;, c10::Scalar const&amp;)&gt;, at::Tensor, c10::guts::typelist::typelist&lt;at::Tensor const&amp;, at::Tensor const&amp;, at::Tensor const&amp;, c10::Scalar const&amp;, c10::Scalar const&amp;&gt; &gt;, at::Tensor(at::Tensor const&amp;, at::Tensor const&amp;, at::Tensor const&amp;, c10::Scalar const&amp;, c10::Scalar const&amp;)&gt;::call (libtorch_cuda.so) (65 samples, 0.25%)</title><rect x="38.4447%" y="484" width="0.2535%" height="15" fill="rgb(226,191,16)" fg:x="9858" fg:w="65"/><text x="38.6947%" y="494.50"></text></g><g><title>at::(anonymous namespace)::wrapper_CUDA_addmm (libtorch_cuda.so) (65 samples, 0.25%)</title><rect x="38.4447%" y="500" width="0.2535%" height="15" fill="rgb(214,40,45)" fg:x="9858" fg:w="65"/><text x="38.6947%" y="510.50"></text></g><g><title>at::native::structured_addmm_out_cuda::impl (libtorch_cuda.so) (55 samples, 0.21%)</title><rect x="38.4837%" y="516" width="0.2145%" height="15" fill="rgb(244,29,26)" fg:x="9868" fg:w="55"/><text x="38.7337%" y="526.50"></text></g><g><title>at::native::(anonymous namespace)::addmm_out_cuda_impl (libtorch_cuda.so) (55 samples, 0.21%)</title><rect x="38.4837%" y="532" width="0.2145%" height="15" fill="rgb(216,16,5)" fg:x="9868" fg:w="55"/><text x="38.7337%" y="542.50"></text></g><g><title>at::_ops::addmm::call (libtorch_cpu.so) (68 samples, 0.27%)</title><rect x="38.4408%" y="420" width="0.2652%" height="15" fill="rgb(249,76,35)" fg:x="9857" fg:w="68"/><text x="38.6908%" y="430.50"></text></g><g><title>c10::impl::wrap_kernel_functor_unboxed_&lt;c10::impl::detail::WrapFunctionIntoFunctor_&lt;c10::CompileTimeFunctionPointer&lt;at::Tensor(c10::DispatchKeySet, at::Tensor const&amp;, at::Tensor const&amp;, at::Tensor const&amp;, c10::Scalar const&amp;, c10::Scalar const&amp;), &amp;torch::autograd::VariableType::(anonymous namespace)::addmm(c10::DispatchKeySet, at::Tensor const&amp;, at::Tensor const&amp;, at::Tensor const&amp;, c10::Scalar const&amp;, c10::Scalar const&amp;)&gt;, at::Tensor, c10::guts::typelist::typelist&lt;c10::DispatchKeySet, at::Tensor const&amp;, at::Tensor const&amp;, at::Tensor const&amp;, c10::Scalar const&amp;, c10::Scalar const&amp;&gt; &gt;, at::Tensor(c10::DispatchKeySet, at::Tensor const&amp;, at::Tensor const&amp;, at::Tensor const&amp;, c10::Scalar const&amp;, c10::Scalar const&amp;)&gt;::call (libtorch_cpu.so) (67 samples, 0.26%)</title><rect x="38.4447%" y="436" width="0.2613%" height="15" fill="rgb(207,11,44)" fg:x="9858" fg:w="67"/><text x="38.6947%" y="446.50"></text></g><g><title>torch::autograd::VariableType::(anonymous namespace)::addmm (libtorch_cpu.so) (67 samples, 0.26%)</title><rect x="38.4447%" y="452" width="0.2613%" height="15" fill="rgb(228,190,49)" fg:x="9858" fg:w="67"/><text x="38.6947%" y="462.50"></text></g><g><title>at::_ops::linear::call (libtorch_cpu.so) (79 samples, 0.31%)</title><rect x="38.4252%" y="372" width="0.3081%" height="15" fill="rgb(214,173,12)" fg:x="9853" fg:w="79"/><text x="38.6752%" y="382.50"></text></g><g><title>c10::impl::wrap_kernel_functor_unboxed_&lt;c10::impl::detail::WrapFunctionIntoFunctor_&lt;c10::CompileTimeFunctionPointer&lt;at::Tensor(at::Tensor const&amp;, at::Tensor const&amp;, std::optional&lt;at::Tensor&gt; const&amp;), &amp;at::(anonymous namespace)::(anonymous namespace)::wrapper_CompositeImplicitAutograd__linear(at::Tensor const&amp;, at::Tensor const&amp;, std::optional&lt;at::Tensor&gt; const&amp;)&gt;, at::Tensor, c10::guts::typelist::typelist&lt;at::Tensor const&amp;, at::Tensor const&amp;, std::optional&lt;at::Tensor&gt; const&amp;&gt; &gt;, at::Tensor(at::Tensor const&amp;, at::Tensor const&amp;, std::optional&lt;at::Tensor&gt; const&amp;)&gt;::call (libtorch_cpu.so) (79 samples, 0.31%)</title><rect x="38.4252%" y="388" width="0.3081%" height="15" fill="rgb(218,26,35)" fg:x="9853" fg:w="79"/><text x="38.6752%" y="398.50"></text></g><g><title>at::native::linear (libtorch_cpu.so) (75 samples, 0.29%)</title><rect x="38.4408%" y="404" width="0.2925%" height="15" fill="rgb(220,200,19)" fg:x="9857" fg:w="75"/><text x="38.6908%" y="414.50"></text></g><g><title>forward (armada_net.py:214) (168 samples, 0.66%)</title><rect x="38.0899%" y="244" width="0.6552%" height="15" fill="rgb(239,95,49)" fg:x="9767" fg:w="168"/><text x="38.3399%" y="254.50"></text></g><g><title>_wrapped_call_impl (torch/nn/modules/module.py:1773) (166 samples, 0.65%)</title><rect x="38.0977%" y="260" width="0.6474%" height="15" fill="rgb(235,85,53)" fg:x="9769" fg:w="166"/><text x="38.3477%" y="270.50"></text></g><g><title>_call_impl (torch/nn/modules/module.py:1784) (159 samples, 0.62%)</title><rect x="38.1250%" y="276" width="0.6201%" height="15" fill="rgb(233,133,31)" fg:x="9776" fg:w="159"/><text x="38.3750%" y="286.50"></text></g><g><title>forward (torch/nn/modules/container.py:244) (159 samples, 0.62%)</title><rect x="38.1250%" y="292" width="0.6201%" height="15" fill="rgb(218,25,20)" fg:x="9776" fg:w="159"/><text x="38.3750%" y="302.50"></text></g><g><title>_wrapped_call_impl (torch/nn/modules/module.py:1773) (151 samples, 0.59%)</title><rect x="38.1562%" y="308" width="0.5889%" height="15" fill="rgb(252,210,38)" fg:x="9784" fg:w="151"/><text x="38.4062%" y="318.50"></text></g><g><title>_call_impl (torch/nn/modules/module.py:1784) (138 samples, 0.54%)</title><rect x="38.2068%" y="324" width="0.5382%" height="15" fill="rgb(242,134,21)" fg:x="9797" fg:w="138"/><text x="38.4568%" y="334.50"></text></g><g><title>forward (torch/nn/modules/linear.py:125) (89 samples, 0.35%)</title><rect x="38.3979%" y="340" width="0.3471%" height="15" fill="rgb(213,28,48)" fg:x="9846" fg:w="89"/><text x="38.6479%" y="350.50"></text></g><g><title>torch::autograd::THPVariable_linear (libtorch_python.so) (85 samples, 0.33%)</title><rect x="38.4135%" y="356" width="0.3315%" height="15" fill="rgb(250,196,2)" fg:x="9850" fg:w="85"/><text x="38.6635%" y="366.50"></text></g><g><title>forward (torch/nn/modules/activation.py:135) (33 samples, 0.13%)</title><rect x="38.8425%" y="340" width="0.1287%" height="15" fill="rgb(227,5,17)" fg:x="9960" fg:w="33"/><text x="39.0925%" y="350.50"></text></g><g><title>relu (torch/nn/functional.py:1701) (31 samples, 0.12%)</title><rect x="38.8503%" y="356" width="0.1209%" height="15" fill="rgb(221,226,24)" fg:x="9962" fg:w="31"/><text x="39.1003%" y="366.50"></text></g><g><title>torch::autograd::THPVariable_relu (libtorch_python.so) (29 samples, 0.11%)</title><rect x="38.8581%" y="372" width="0.1131%" height="15" fill="rgb(211,5,48)" fg:x="9964" fg:w="29"/><text x="39.1081%" y="382.50"></text></g><g><title>at::_ops::relu::call (libtorch_cpu.so) (26 samples, 0.10%)</title><rect x="38.8698%" y="388" width="0.1014%" height="15" fill="rgb(219,150,6)" fg:x="9967" fg:w="26"/><text x="39.1198%" y="398.50"></text></g><g><title>at::cuda::blas::gemm_and_bias&lt;float, float&gt; (libtorch_cuda.so) (48 samples, 0.19%)</title><rect x="39.0804%" y="548" width="0.1872%" height="15" fill="rgb(251,46,16)" fg:x="10021" fg:w="48"/><text x="39.3304%" y="558.50"></text></g><g><title>at::native::structured_addmm_out_cuda::impl (libtorch_cuda.so) (53 samples, 0.21%)</title><rect x="39.0687%" y="516" width="0.2067%" height="15" fill="rgb(220,204,40)" fg:x="10018" fg:w="53"/><text x="39.3187%" y="526.50"></text></g><g><title>at::native::(anonymous namespace)::addmm_out_cuda_impl (libtorch_cuda.so) (53 samples, 0.21%)</title><rect x="39.0687%" y="532" width="0.2067%" height="15" fill="rgb(211,85,2)" fg:x="10018" fg:w="53"/><text x="39.3187%" y="542.50"></text></g><g><title>at::_ops::addmm::redispatch (libtorch_cpu.so) (67 samples, 0.26%)</title><rect x="39.0219%" y="468" width="0.2613%" height="15" fill="rgb(229,17,7)" fg:x="10006" fg:w="67"/><text x="39.2719%" y="478.50"></text></g><g><title>c10::impl::wrap_kernel_functor_unboxed_&lt;c10::impl::detail::WrapFunctionIntoFunctor_&lt;c10::CompileTimeFunctionPointer&lt;at::Tensor(at::Tensor const&amp;, at::Tensor const&amp;, at::Tensor const&amp;, c10::Scalar const&amp;, c10::Scalar const&amp;), &amp;at::(anonymous namespace)::wrapper_CUDA_addmm(at::Tensor const&amp;, at::Tensor const&amp;, at::Tensor const&amp;, c10::Scalar const&amp;, c10::Scalar const&amp;)&gt;, at::Tensor, c10::guts::typelist::typelist&lt;at::Tensor const&amp;, at::Tensor const&amp;, at::Tensor const&amp;, c10::Scalar const&amp;, c10::Scalar const&amp;&gt; &gt;, at::Tensor(at::Tensor const&amp;, at::Tensor const&amp;, at::Tensor const&amp;, c10::Scalar const&amp;, c10::Scalar const&amp;)&gt;::call (libtorch_cuda.so) (67 samples, 0.26%)</title><rect x="39.0219%" y="484" width="0.2613%" height="15" fill="rgb(239,72,28)" fg:x="10006" fg:w="67"/><text x="39.2719%" y="494.50"></text></g><g><title>at::(anonymous namespace)::wrapper_CUDA_addmm (libtorch_cuda.so) (67 samples, 0.26%)</title><rect x="39.0219%" y="500" width="0.2613%" height="15" fill="rgb(230,47,54)" fg:x="10006" fg:w="67"/><text x="39.2719%" y="510.50"></text></g><g><title>at::_ops::addmm::call (libtorch_cpu.so) (70 samples, 0.27%)</title><rect x="39.0180%" y="420" width="0.2730%" height="15" fill="rgb(214,50,8)" fg:x="10005" fg:w="70"/><text x="39.2680%" y="430.50"></text></g><g><title>c10::impl::wrap_kernel_functor_unboxed_&lt;c10::impl::detail::WrapFunctionIntoFunctor_&lt;c10::CompileTimeFunctionPointer&lt;at::Tensor(c10::DispatchKeySet, at::Tensor const&amp;, at::Tensor const&amp;, at::Tensor const&amp;, c10::Scalar const&amp;, c10::Scalar const&amp;), &amp;torch::autograd::VariableType::(anonymous namespace)::addmm(c10::DispatchKeySet, at::Tensor const&amp;, at::Tensor const&amp;, at::Tensor const&amp;, c10::Scalar const&amp;, c10::Scalar const&amp;)&gt;, at::Tensor, c10::guts::typelist::typelist&lt;c10::DispatchKeySet, at::Tensor const&amp;, at::Tensor const&amp;, at::Tensor const&amp;, c10::Scalar const&amp;, c10::Scalar const&amp;&gt; &gt;, at::Tensor(c10::DispatchKeySet, at::Tensor const&amp;, at::Tensor const&amp;, at::Tensor const&amp;, c10::Scalar const&amp;, c10::Scalar const&amp;)&gt;::call (libtorch_cpu.so) (70 samples, 0.27%)</title><rect x="39.0180%" y="436" width="0.2730%" height="15" fill="rgb(216,198,43)" fg:x="10005" fg:w="70"/><text x="39.2680%" y="446.50"></text></g><g><title>torch::autograd::VariableType::(anonymous namespace)::addmm (libtorch_cpu.so) (70 samples, 0.27%)</title><rect x="39.0180%" y="452" width="0.2730%" height="15" fill="rgb(234,20,35)" fg:x="10005" fg:w="70"/><text x="39.2680%" y="462.50"></text></g><g><title>at::_ops::linear::call (libtorch_cpu.so) (85 samples, 0.33%)</title><rect x="39.0024%" y="372" width="0.3315%" height="15" fill="rgb(254,45,19)" fg:x="10001" fg:w="85"/><text x="39.2524%" y="382.50"></text></g><g><title>c10::impl::wrap_kernel_functor_unboxed_&lt;c10::impl::detail::WrapFunctionIntoFunctor_&lt;c10::CompileTimeFunctionPointer&lt;at::Tensor(at::Tensor const&amp;, at::Tensor const&amp;, std::optional&lt;at::Tensor&gt; const&amp;), &amp;at::(anonymous namespace)::(anonymous namespace)::wrapper_CompositeImplicitAutograd__linear(at::Tensor const&amp;, at::Tensor const&amp;, std::optional&lt;at::Tensor&gt; const&amp;)&gt;, at::Tensor, c10::guts::typelist::typelist&lt;at::Tensor const&amp;, at::Tensor const&amp;, std::optional&lt;at::Tensor&gt; const&amp;&gt; &gt;, at::Tensor(at::Tensor const&amp;, at::Tensor const&amp;, std::optional&lt;at::Tensor&gt; const&amp;)&gt;::call (libtorch_cpu.so) (83 samples, 0.32%)</title><rect x="39.0102%" y="388" width="0.3237%" height="15" fill="rgb(219,14,44)" fg:x="10003" fg:w="83"/><text x="39.2602%" y="398.50"></text></g><g><title>at::native::linear (libtorch_cpu.so) (83 samples, 0.32%)</title><rect x="39.0102%" y="404" width="0.3237%" height="15" fill="rgb(217,220,26)" fg:x="10003" fg:w="83"/><text x="39.2602%" y="414.50"></text></g><g><title>forward (armada_net.py:215) (154 samples, 0.60%)</title><rect x="38.7450%" y="244" width="0.6006%" height="15" fill="rgb(213,158,28)" fg:x="9935" fg:w="154"/><text x="38.9950%" y="254.50"></text></g><g><title>_wrapped_call_impl (torch/nn/modules/module.py:1773) (154 samples, 0.60%)</title><rect x="38.7450%" y="260" width="0.6006%" height="15" fill="rgb(252,51,52)" fg:x="9935" fg:w="154"/><text x="38.9950%" y="270.50"></text></g><g><title>_call_impl (torch/nn/modules/module.py:1784) (152 samples, 0.59%)</title><rect x="38.7528%" y="276" width="0.5928%" height="15" fill="rgb(246,89,16)" fg:x="9937" fg:w="152"/><text x="39.0028%" y="286.50"></text></g><g><title>forward (torch/nn/modules/container.py:244) (152 samples, 0.59%)</title><rect x="38.7528%" y="292" width="0.5928%" height="15" fill="rgb(216,158,49)" fg:x="9937" fg:w="152"/><text x="39.0028%" y="302.50"></text></g><g><title>_wrapped_call_impl (torch/nn/modules/module.py:1773) (140 samples, 0.55%)</title><rect x="38.7996%" y="308" width="0.5460%" height="15" fill="rgb(236,107,19)" fg:x="9949" fg:w="140"/><text x="39.0496%" y="318.50"></text></g><g><title>_call_impl (torch/nn/modules/module.py:1784) (130 samples, 0.51%)</title><rect x="38.8386%" y="324" width="0.5070%" height="15" fill="rgb(228,185,30)" fg:x="9959" fg:w="130"/><text x="39.0886%" y="334.50"></text></g><g><title>forward (torch/nn/modules/linear.py:125) (96 samples, 0.37%)</title><rect x="38.9712%" y="340" width="0.3744%" height="15" fill="rgb(246,134,8)" fg:x="9993" fg:w="96"/><text x="39.2212%" y="350.50"></text></g><g><title>torch::autograd::THPVariable_linear (libtorch_python.so) (91 samples, 0.35%)</title><rect x="38.9907%" y="356" width="0.3549%" height="15" fill="rgb(214,143,50)" fg:x="9998" fg:w="91"/><text x="39.2407%" y="366.50"></text></g><g><title>MCTS__get_value_policy (para_mcts.pyx:389) (8,601 samples, 33.54%)</title><rect x="5.8069%" y="196" width="33.5426%" height="15" fill="rgb(228,75,8)" fg:x="1489" fg:w="8601"/><text x="6.0569%" y="206.50">MCTS__get_value_policy (para_mcts.pyx:389)</text></g><g><title>_wrapped_call_impl (torch/nn/modules/module.py:1773) (8,457 samples, 32.98%)</title><rect x="6.3685%" y="212" width="32.9810%" height="15" fill="rgb(207,175,4)" fg:x="1633" fg:w="8457"/><text x="6.6185%" y="222.50">_wrapped_call_impl (torch/nn/modules/module.py:1773)</text></g><g><title>_call_impl (torch/nn/modules/module.py:1784) (8,453 samples, 32.97%)</title><rect x="6.3841%" y="228" width="32.9654%" height="15" fill="rgb(205,108,24)" fg:x="1637" fg:w="8453"/><text x="6.6341%" y="238.50">_call_impl (torch/nn/modules/module.py:1784)</text></g><g><title>0x7ac4dff3ec60 (libcuda.so.550.54.15) (29 samples, 0.11%)</title><rect x="39.4899%" y="612" width="0.1131%" height="15" fill="rgb(244,120,49)" fg:x="10126" fg:w="29"/><text x="39.7399%" y="622.50"></text></g><g><title>0x7ac4dff3e746 (libcuda.so.550.54.15) (29 samples, 0.11%)</title><rect x="39.4899%" y="628" width="0.1131%" height="15" fill="rgb(223,47,38)" fg:x="10126" fg:w="29"/><text x="39.7399%" y="638.50"></text></g><g><title>0x7ac4e02de2fe (libcuda.so.550.54.15) (28 samples, 0.11%)</title><rect x="39.4938%" y="644" width="0.1092%" height="15" fill="rgb(229,179,11)" fg:x="10127" fg:w="28"/><text x="39.7438%" y="654.50"></text></g><g><title>0x7ac4dff3f9b7 (libcuda.so.550.54.15) (30 samples, 0.12%)</title><rect x="39.4899%" y="596" width="0.1170%" height="15" fill="rgb(231,122,1)" fg:x="10126" fg:w="30"/><text x="39.7399%" y="606.50"></text></g><g><title>0x7ac5be448c89 (nvidia/cuda_runtime/lib/libcudart.so.12) (34 samples, 0.13%)</title><rect x="39.4860%" y="564" width="0.1326%" height="15" fill="rgb(245,119,9)" fg:x="10125" fg:w="34"/><text x="39.7360%" y="574.50"></text></g><g><title>0x7ac4e00e8f31 (libcuda.so.550.54.15) (33 samples, 0.13%)</title><rect x="39.4899%" y="580" width="0.1287%" height="15" fill="rgb(241,163,25)" fg:x="10126" fg:w="33"/><text x="39.7399%" y="590.50"></text></g><g><title>cudaMemcpyAsync (nvidia/cuda_runtime/lib/libcudart.so.12) (36 samples, 0.14%)</title><rect x="39.4821%" y="532" width="0.1404%" height="15" fill="rgb(217,214,3)" fg:x="10124" fg:w="36"/><text x="39.7321%" y="542.50"></text></g><g><title>0x7ac5be418cb2 (nvidia/cuda_runtime/lib/libcudart.so.12) (35 samples, 0.14%)</title><rect x="39.4860%" y="548" width="0.1365%" height="15" fill="rgb(240,86,28)" fg:x="10125" fg:w="35"/><text x="39.7360%" y="558.50"></text></g><g><title>at::_ops::copy_::call (libtorch_cpu.so) (53 samples, 0.21%)</title><rect x="39.4392%" y="468" width="0.2067%" height="15" fill="rgb(215,47,9)" fg:x="10113" fg:w="53"/><text x="39.6892%" y="478.50"></text></g><g><title>at::native::copy_ (libtorch_cpu.so) (53 samples, 0.21%)</title><rect x="39.4392%" y="484" width="0.2067%" height="15" fill="rgb(252,25,45)" fg:x="10113" fg:w="53"/><text x="39.6892%" y="494.50"></text></g><g><title>at::native::copy_impl (libtorch_cpu.so) (53 samples, 0.21%)</title><rect x="39.4392%" y="500" width="0.2067%" height="15" fill="rgb(251,164,9)" fg:x="10113" fg:w="53"/><text x="39.6892%" y="510.50"></text></g><g><title>at::native::copy_kernel_cuda (libtorch_cuda.so) (43 samples, 0.17%)</title><rect x="39.4782%" y="516" width="0.1677%" height="15" fill="rgb(233,194,0)" fg:x="10123" fg:w="43"/><text x="39.7282%" y="526.50"></text></g><g><title>at::_ops::_to_copy::redispatch (libtorch_cpu.so) (71 samples, 0.28%)</title><rect x="39.4275%" y="388" width="0.2769%" height="15" fill="rgb(249,111,24)" fg:x="10110" fg:w="71"/><text x="39.6775%" y="398.50"></text></g><g><title>c10::impl::wrap_kernel_functor_unboxed_&lt;c10::impl::detail::WrapFunctionIntoFunctor_&lt;c10::CompileTimeFunctionPointer&lt;at::Tensor(at::Tensor const&amp;, std::optional&lt;c10::ScalarType&gt;, std::optional&lt;c10::Layout&gt;, std::optional&lt;c10::Device&gt;, std::optional&lt;bool&gt;, bool, std::optional&lt;c10::MemoryFormat&gt;), &amp;at::(anonymous namespace)::_to_copy(at::Tensor const&amp;, std::optional&lt;c10::ScalarType&gt;, std::optional&lt;c10::Layout&gt;, std::optional&lt;c10::Device&gt;, std::optional&lt;bool&gt;, bool, std::optional&lt;c10::MemoryFormat&gt;)&gt;, at::Tensor, c10::guts::typelist::typelist&lt;at::Tensor const&amp;, std::optional&lt;c10::ScalarType&gt;, std::optional&lt;c10::Layout&gt;, std::optional&lt;c10::Device&gt;, std::optional&lt;bool&gt;, bool, std::optional&lt;c10::MemoryFormat&gt; &gt; &gt;, at::Tensor(at::Tensor const&amp;, std::optional&lt;c10::ScalarType&gt;, std::optional&lt;c10::Layout&gt;, std::optional&lt;c10::Device&gt;, std::optional&lt;bool&gt;, bool, std::optional&lt;c10::MemoryFormat&gt;)&gt;::call (libtorch_cpu.so) (70 samples, 0.27%)</title><rect x="39.4314%" y="404" width="0.2730%" height="15" fill="rgb(250,223,3)" fg:x="10111" fg:w="70"/><text x="39.6814%" y="414.50"></text></g><g><title>at::_ops::_to_copy::redispatch (libtorch_cpu.so) (70 samples, 0.27%)</title><rect x="39.4314%" y="420" width="0.2730%" height="15" fill="rgb(236,178,37)" fg:x="10111" fg:w="70"/><text x="39.6814%" y="430.50"></text></g><g><title>c10::impl::wrap_kernel_functor_unboxed_&lt;c10::impl::detail::WrapFunctionIntoFunctor_&lt;c10::CompileTimeFunctionPointer&lt;at::Tensor(at::Tensor const&amp;, std::optional&lt;c10::ScalarType&gt;, std::optional&lt;c10::Layout&gt;, std::optional&lt;c10::Device&gt;, std::optional&lt;bool&gt;, bool, std::optional&lt;c10::MemoryFormat&gt;), &amp;at::(anonymous namespace)::(anonymous namespace)::wrapper_CompositeExplicitAutograd___to_copy(at::Tensor const&amp;, std::optional&lt;c10::ScalarType&gt;, std::optional&lt;c10::Layout&gt;, std::optional&lt;c10::Device&gt;, std::optional&lt;bool&gt;, bool, std::optional&lt;c10::MemoryFormat&gt;)&gt;, at::Tensor, c10::guts::typelist::typelist&lt;at::Tensor const&amp;, std::optional&lt;c10::ScalarType&gt;, std::optional&lt;c10::Layout&gt;, std::optional&lt;c10::Device&gt;, std::optional&lt;bool&gt;, bool, std::optional&lt;c10::MemoryFormat&gt; &gt; &gt;, at::Tensor(at::Tensor const&amp;, std::optional&lt;c10::ScalarType&gt;, std::optional&lt;c10::Layout&gt;, std::optional&lt;c10::Device&gt;, std::optional&lt;bool&gt;, bool, std::optional&lt;c10::MemoryFormat&gt;)&gt;::call (libtorch_cpu.so) (69 samples, 0.27%)</title><rect x="39.4353%" y="436" width="0.2691%" height="15" fill="rgb(241,158,50)" fg:x="10112" fg:w="69"/><text x="39.6853%" y="446.50"></text></g><g><title>at::native::_to_copy (libtorch_cpu.so) (69 samples, 0.27%)</title><rect x="39.4353%" y="452" width="0.2691%" height="15" fill="rgb(213,121,41)" fg:x="10112" fg:w="69"/><text x="39.6853%" y="462.50"></text></g><g><title>torch::autograd::THPVariable_cpu (libtorch_python.so) (84 samples, 0.33%)</title><rect x="39.3807%" y="244" width="0.3276%" height="15" fill="rgb(240,92,3)" fg:x="10098" fg:w="84"/><text x="39.6307%" y="254.50"></text></g><g><title>torch::autograd::dispatch_to (libtorch_python.so) (77 samples, 0.30%)</title><rect x="39.4080%" y="260" width="0.3003%" height="15" fill="rgb(205,123,3)" fg:x="10105" fg:w="77"/><text x="39.6580%" y="270.50"></text></g><g><title>at::Tensor::to (libtorch_python.so) (76 samples, 0.30%)</title><rect x="39.4119%" y="276" width="0.2964%" height="15" fill="rgb(205,97,47)" fg:x="10106" fg:w="76"/><text x="39.6619%" y="286.50"></text></g><g><title>at::_ops::to_dtype_layout::call (libtorch_cpu.so) (76 samples, 0.30%)</title><rect x="39.4119%" y="292" width="0.2964%" height="15" fill="rgb(247,152,14)" fg:x="10106" fg:w="76"/><text x="39.6619%" y="302.50"></text></g><g><title>c10::impl::wrap_kernel_functor_unboxed_&lt;c10::impl::detail::WrapFunctionIntoFunctor_&lt;c10::CompileTimeFunctionPointer&lt;at::Tensor(at::Tensor const&amp;, std::optional&lt;c10::ScalarType&gt;, std::optional&lt;c10::Layout&gt;, std::optional&lt;c10::Device&gt;, std::optional&lt;bool&gt;, bool, bool, std::optional&lt;c10::MemoryFormat&gt;), &amp;at::(anonymous namespace)::(anonymous namespace)::wrapper_CompositeImplicitAutograd_dtype_layout_to(at::Tensor const&amp;, std::optional&lt;c10::ScalarType&gt;, std::optional&lt;c10::Layout&gt;, std::optional&lt;c10::Device&gt;, std::optional&lt;bool&gt;, bool, bool, std::optional&lt;c10::MemoryFormat&gt;)&gt;, at::Tensor, c10::guts::typelist::typelist&lt;at::Tensor const&amp;, std::optional&lt;c10::ScalarType&gt;, std::optional&lt;c10::Layout&gt;, std::optional&lt;c10::Device&gt;, std::optional&lt;bool&gt;, bool, bool, std::optional&lt;c10::MemoryFormat&gt; &gt; &gt;, at::Tensor(at::Tensor const&amp;, std::optional&lt;c10::ScalarType&gt;, std::optional&lt;c10::Layout&gt;, std::optional&lt;c10::Device&gt;, std::optional&lt;bool&gt;, bool, bool, std::optional&lt;c10::MemoryFormat&gt;)&gt;::call (libtorch_cpu.so) (74 samples, 0.29%)</title><rect x="39.4197%" y="308" width="0.2886%" height="15" fill="rgb(248,195,53)" fg:x="10108" fg:w="74"/><text x="39.6697%" y="318.50"></text></g><g><title>at::native::to (libtorch_cpu.so) (74 samples, 0.29%)</title><rect x="39.4197%" y="324" width="0.2886%" height="15" fill="rgb(226,201,16)" fg:x="10108" fg:w="74"/><text x="39.6697%" y="334.50"></text></g><g><title>at::_ops::_to_copy::call (libtorch_cpu.so) (73 samples, 0.28%)</title><rect x="39.4236%" y="340" width="0.2847%" height="15" fill="rgb(205,98,0)" fg:x="10109" fg:w="73"/><text x="39.6736%" y="350.50"></text></g><g><title>c10::impl::wrap_kernel_functor_unboxed_&lt;c10::impl::detail::WrapFunctionIntoFunctor_&lt;c10::CompileTimeFunctionPointer&lt;at::Tensor(c10::DispatchKeySet, at::Tensor const&amp;, std::optional&lt;c10::ScalarType&gt;, std::optional&lt;c10::Layout&gt;, std::optional&lt;c10::Device&gt;, std::optional&lt;bool&gt;, bool, std::optional&lt;c10::MemoryFormat&gt;), &amp;torch::autograd::VariableType::(anonymous namespace)::_to_copy(c10::DispatchKeySet, at::Tensor const&amp;, std::optional&lt;c10::ScalarType&gt;, std::optional&lt;c10::Layout&gt;, std::optional&lt;c10::Device&gt;, std::optional&lt;bool&gt;, bool, std::optional&lt;c10::MemoryFormat&gt;)&gt;, at::Tensor, c10::guts::typelist::typelist&lt;c10::DispatchKeySet, at::Tensor const&amp;, std::optional&lt;c10::ScalarType&gt;, std::optional&lt;c10::Layout&gt;, std::optional&lt;c10::Device&gt;, std::optional&lt;bool&gt;, bool, std::optional&lt;c10::MemoryFormat&gt; &gt; &gt;, at::Tensor(c10::DispatchKeySet, at::Tensor const&amp;, std::optional&lt;c10::ScalarType&gt;, std::optional&lt;c10::Layout&gt;, std::optional&lt;c10::Device&gt;, std::optional&lt;bool&gt;, bool, std::optional&lt;c10::MemoryFormat&gt;)&gt;::call (libtorch_cpu.so) (72 samples, 0.28%)</title><rect x="39.4275%" y="356" width="0.2808%" height="15" fill="rgb(214,191,48)" fg:x="10110" fg:w="72"/><text x="39.6775%" y="366.50"></text></g><g><title>torch::autograd::VariableType::(anonymous namespace)::_to_copy (libtorch_cpu.so) (72 samples, 0.28%)</title><rect x="39.4275%" y="372" width="0.2808%" height="15" fill="rgb(237,112,39)" fg:x="10110" fg:w="72"/><text x="39.6775%" y="382.50"></text></g><g><title>__Pyx_PyObject_FastCallDict (para_mcts.pyx:1) (108 samples, 0.42%)</title><rect x="39.3729%" y="212" width="0.4212%" height="15" fill="rgb(247,203,27)" fg:x="10096" fg:w="108"/><text x="39.6229%" y="222.50"></text></g><g><title>__Pyx_PyObject_FastCallDict (para_mcts.pyx:1) (108 samples, 0.42%)</title><rect x="39.3729%" y="228" width="0.4212%" height="15" fill="rgb(235,124,28)" fg:x="10096" fg:w="108"/><text x="39.6229%" y="238.50"></text></g><g><title>at::_ops::_softmax::redispatch (libtorch_cpu.so) (28 samples, 0.11%)</title><rect x="39.8487%" y="340" width="0.1092%" height="15" fill="rgb(208,207,46)" fg:x="10218" fg:w="28"/><text x="40.0987%" y="350.50"></text></g><g><title>c10::impl::wrap_kernel_functor_unboxed_&lt;c10::impl::detail::WrapFunctionIntoFunctor_&lt;c10::CompileTimeFunctionPointer&lt;at::Tensor(at::Tensor const&amp;, long, bool), &amp;at::(anonymous namespace)::wrapper_CUDA__softmax(at::Tensor const&amp;, long, bool)&gt;, at::Tensor, c10::guts::typelist::typelist&lt;at::Tensor const&amp;, long, bool&gt; &gt;, at::Tensor(at::Tensor const&amp;, long, bool)&gt;::call (libtorch_cuda.so) (28 samples, 0.11%)</title><rect x="39.8487%" y="356" width="0.1092%" height="15" fill="rgb(234,176,4)" fg:x="10218" fg:w="28"/><text x="40.0987%" y="366.50"></text></g><g><title>at::(anonymous namespace)::wrapper_CUDA__softmax (libtorch_cuda.so) (27 samples, 0.11%)</title><rect x="39.8526%" y="372" width="0.1053%" height="15" fill="rgb(230,133,28)" fg:x="10219" fg:w="27"/><text x="40.1026%" y="382.50"></text></g><g><title>at::_ops::_softmax::call (libtorch_cpu.so) (32 samples, 0.12%)</title><rect x="39.8370%" y="292" width="0.1248%" height="15" fill="rgb(211,137,40)" fg:x="10215" fg:w="32"/><text x="40.0870%" y="302.50"></text></g><g><title>c10::impl::wrap_kernel_functor_unboxed_&lt;c10::impl::detail::WrapFunctionIntoFunctor_&lt;c10::CompileTimeFunctionPointer&lt;at::Tensor(c10::DispatchKeySet, at::Tensor const&amp;, long, bool), &amp;torch::autograd::VariableType::(anonymous namespace)::_softmax(c10::DispatchKeySet, at::Tensor const&amp;, long, bool)&gt;, at::Tensor, c10::guts::typelist::typelist&lt;c10::DispatchKeySet, at::Tensor const&amp;, long, bool&gt; &gt;, at::Tensor(c10::DispatchKeySet, at::Tensor const&amp;, long, bool)&gt;::call (libtorch_cpu.so) (30 samples, 0.12%)</title><rect x="39.8448%" y="308" width="0.1170%" height="15" fill="rgb(254,35,13)" fg:x="10217" fg:w="30"/><text x="40.0948%" y="318.50"></text></g><g><title>torch::autograd::VariableType::(anonymous namespace)::_softmax (libtorch_cpu.so) (30 samples, 0.12%)</title><rect x="39.8448%" y="324" width="0.1170%" height="15" fill="rgb(225,49,51)" fg:x="10217" fg:w="30"/><text x="40.0948%" y="334.50"></text></g><g><title>at::_ops::softmax_int::call (libtorch_cpu.so) (37 samples, 0.14%)</title><rect x="39.8253%" y="244" width="0.1443%" height="15" fill="rgb(251,10,15)" fg:x="10212" fg:w="37"/><text x="40.0753%" y="254.50"></text></g><g><title>c10::impl::wrap_kernel_functor_unboxed_&lt;c10::impl::detail::WrapFunctionIntoFunctor_&lt;c10::CompileTimeFunctionPointer&lt;at::Tensor(at::Tensor const&amp;, long, std::optional&lt;c10::ScalarType&gt;), &amp;at::(anonymous namespace)::(anonymous namespace)::wrapper_CompositeImplicitAutograd_int_softmax(at::Tensor const&amp;, long, std::optional&lt;c10::ScalarType&gt;)&gt;, at::Tensor, c10::guts::typelist::typelist&lt;at::Tensor const&amp;, long, std::optional&lt;c10::ScalarType&gt; &gt; &gt;, at::Tensor(at::Tensor const&amp;, long, std::optional&lt;c10::ScalarType&gt;)&gt;::call (libtorch_cpu.so) (36 samples, 0.14%)</title><rect x="39.8292%" y="260" width="0.1404%" height="15" fill="rgb(228,207,15)" fg:x="10213" fg:w="36"/><text x="40.0792%" y="270.50"></text></g><g><title>at::native::softmax (libtorch_cpu.so) (36 samples, 0.14%)</title><rect x="39.8292%" y="276" width="0.1404%" height="15" fill="rgb(241,99,19)" fg:x="10213" fg:w="36"/><text x="40.0792%" y="286.50"></text></g><g><title>MCTS__get_value_policy (para_mcts.pyx:395) (164 samples, 0.64%)</title><rect x="39.3495%" y="196" width="0.6396%" height="15" fill="rgb(207,104,49)" fg:x="10090" fg:w="164"/><text x="39.5995%" y="206.50"></text></g><g><title>softmax (torch/nn/functional.py:2137) (47 samples, 0.18%)</title><rect x="39.8058%" y="212" width="0.1833%" height="15" fill="rgb(234,99,18)" fg:x="10207" fg:w="47"/><text x="40.0558%" y="222.50"></text></g><g><title>torch::autograd::THPVariable_softmax (libtorch_python.so) (45 samples, 0.18%)</title><rect x="39.8136%" y="228" width="0.1755%" height="15" fill="rgb(213,191,49)" fg:x="10209" fg:w="45"/><text x="40.0636%" y="238.50"></text></g><g><title>at::_ops::copy_::call (libtorch_cpu.so) (32 samples, 0.12%)</title><rect x="40.0125%" y="468" width="0.1248%" height="15" fill="rgb(210,226,19)" fg:x="10260" fg:w="32"/><text x="40.2625%" y="478.50"></text></g><g><title>at::native::copy_ (libtorch_cpu.so) (32 samples, 0.12%)</title><rect x="40.0125%" y="484" width="0.1248%" height="15" fill="rgb(229,97,18)" fg:x="10260" fg:w="32"/><text x="40.2625%" y="494.50"></text></g><g><title>at::native::copy_impl (libtorch_cpu.so) (32 samples, 0.12%)</title><rect x="40.0125%" y="500" width="0.1248%" height="15" fill="rgb(211,167,15)" fg:x="10260" fg:w="32"/><text x="40.2625%" y="510.50"></text></g><g><title>at::native::copy_kernel_cuda (libtorch_cuda.so) (28 samples, 0.11%)</title><rect x="40.0281%" y="516" width="0.1092%" height="15" fill="rgb(210,169,34)" fg:x="10264" fg:w="28"/><text x="40.2781%" y="526.50"></text></g><g><title>at::_ops::_to_copy::redispatch (libtorch_cpu.so) (40 samples, 0.16%)</title><rect x="40.0086%" y="420" width="0.1560%" height="15" fill="rgb(241,121,31)" fg:x="10259" fg:w="40"/><text x="40.2586%" y="430.50"></text></g><g><title>c10::impl::wrap_kernel_functor_unboxed_&lt;c10::impl::detail::WrapFunctionIntoFunctor_&lt;c10::CompileTimeFunctionPointer&lt;at::Tensor(at::Tensor const&amp;, std::optional&lt;c10::ScalarType&gt;, std::optional&lt;c10::Layout&gt;, std::optional&lt;c10::Device&gt;, std::optional&lt;bool&gt;, bool, std::optional&lt;c10::MemoryFormat&gt;), &amp;at::(anonymous namespace)::(anonymous namespace)::wrapper_CompositeExplicitAutograd___to_copy(at::Tensor const&amp;, std::optional&lt;c10::ScalarType&gt;, std::optional&lt;c10::Layout&gt;, std::optional&lt;c10::Device&gt;, std::optional&lt;bool&gt;, bool, std::optional&lt;c10::MemoryFormat&gt;)&gt;, at::Tensor, c10::guts::typelist::typelist&lt;at::Tensor const&amp;, std::optional&lt;c10::ScalarType&gt;, std::optional&lt;c10::Layout&gt;, std::optional&lt;c10::Device&gt;, std::optional&lt;bool&gt;, bool, std::optional&lt;c10::MemoryFormat&gt; &gt; &gt;, at::Tensor(at::Tensor const&amp;, std::optional&lt;c10::ScalarType&gt;, std::optional&lt;c10::Layout&gt;, std::optional&lt;c10::Device&gt;, std::optional&lt;bool&gt;, bool, std::optional&lt;c10::MemoryFormat&gt;)&gt;::call (libtorch_cpu.so) (40 samples, 0.16%)</title><rect x="40.0086%" y="436" width="0.1560%" height="15" fill="rgb(232,40,11)" fg:x="10259" fg:w="40"/><text x="40.2586%" y="446.50"></text></g><g><title>at::native::_to_copy (libtorch_cpu.so) (40 samples, 0.16%)</title><rect x="40.0086%" y="452" width="0.1560%" height="15" fill="rgb(205,86,26)" fg:x="10259" fg:w="40"/><text x="40.2586%" y="462.50"></text></g><g><title>at::_ops::_to_copy::redispatch (libtorch_cpu.so) (41 samples, 0.16%)</title><rect x="40.0086%" y="388" width="0.1599%" height="15" fill="rgb(231,126,28)" fg:x="10259" fg:w="41"/><text x="40.2586%" y="398.50"></text></g><g><title>c10::impl::wrap_kernel_functor_unboxed_&lt;c10::impl::detail::WrapFunctionIntoFunctor_&lt;c10::CompileTimeFunctionPointer&lt;at::Tensor(at::Tensor const&amp;, std::optional&lt;c10::ScalarType&gt;, std::optional&lt;c10::Layout&gt;, std::optional&lt;c10::Device&gt;, std::optional&lt;bool&gt;, bool, std::optional&lt;c10::MemoryFormat&gt;), &amp;at::(anonymous namespace)::_to_copy(at::Tensor const&amp;, std::optional&lt;c10::ScalarType&gt;, std::optional&lt;c10::Layout&gt;, std::optional&lt;c10::Device&gt;, std::optional&lt;bool&gt;, bool, std::optional&lt;c10::MemoryFormat&gt;)&gt;, at::Tensor, c10::guts::typelist::typelist&lt;at::Tensor const&amp;, std::optional&lt;c10::ScalarType&gt;, std::optional&lt;c10::Layout&gt;, std::optional&lt;c10::Device&gt;, std::optional&lt;bool&gt;, bool, std::optional&lt;c10::MemoryFormat&gt; &gt; &gt;, at::Tensor(at::Tensor const&amp;, std::optional&lt;c10::ScalarType&gt;, std::optional&lt;c10::Layout&gt;, std::optional&lt;c10::Device&gt;, std::optional&lt;bool&gt;, bool, std::optional&lt;c10::MemoryFormat&gt;)&gt;::call (libtorch_cpu.so) (41 samples, 0.16%)</title><rect x="40.0086%" y="404" width="0.1599%" height="15" fill="rgb(219,221,18)" fg:x="10259" fg:w="41"/><text x="40.2586%" y="414.50"></text></g><g><title>at::Tensor::to (libtorch_python.so) (44 samples, 0.17%)</title><rect x="40.0047%" y="276" width="0.1716%" height="15" fill="rgb(211,40,0)" fg:x="10258" fg:w="44"/><text x="40.2547%" y="286.50"></text></g><g><title>at::_ops::to_dtype_layout::call (libtorch_cpu.so) (44 samples, 0.17%)</title><rect x="40.0047%" y="292" width="0.1716%" height="15" fill="rgb(239,85,43)" fg:x="10258" fg:w="44"/><text x="40.2547%" y="302.50"></text></g><g><title>c10::impl::wrap_kernel_functor_unboxed_&lt;c10::impl::detail::WrapFunctionIntoFunctor_&lt;c10::CompileTimeFunctionPointer&lt;at::Tensor(at::Tensor const&amp;, std::optional&lt;c10::ScalarType&gt;, std::optional&lt;c10::Layout&gt;, std::optional&lt;c10::Device&gt;, std::optional&lt;bool&gt;, bool, bool, std::optional&lt;c10::MemoryFormat&gt;), &amp;at::(anonymous namespace)::(anonymous namespace)::wrapper_CompositeImplicitAutograd_dtype_layout_to(at::Tensor const&amp;, std::optional&lt;c10::ScalarType&gt;, std::optional&lt;c10::Layout&gt;, std::optional&lt;c10::Device&gt;, std::optional&lt;bool&gt;, bool, bool, std::optional&lt;c10::MemoryFormat&gt;)&gt;, at::Tensor, c10::guts::typelist::typelist&lt;at::Tensor const&amp;, std::optional&lt;c10::ScalarType&gt;, std::optional&lt;c10::Layout&gt;, std::optional&lt;c10::Device&gt;, std::optional&lt;bool&gt;, bool, bool, std::optional&lt;c10::MemoryFormat&gt; &gt; &gt;, at::Tensor(at::Tensor const&amp;, std::optional&lt;c10::ScalarType&gt;, std::optional&lt;c10::Layout&gt;, std::optional&lt;c10::Device&gt;, std::optional&lt;bool&gt;, bool, bool, std::optional&lt;c10::MemoryFormat&gt;)&gt;::call (libtorch_cpu.so) (44 samples, 0.17%)</title><rect x="40.0047%" y="308" width="0.1716%" height="15" fill="rgb(231,55,21)" fg:x="10258" fg:w="44"/><text x="40.2547%" y="318.50"></text></g><g><title>at::native::to (libtorch_cpu.so) (44 samples, 0.17%)</title><rect x="40.0047%" y="324" width="0.1716%" height="15" fill="rgb(225,184,43)" fg:x="10258" fg:w="44"/><text x="40.2547%" y="334.50"></text></g><g><title>at::_ops::_to_copy::call (libtorch_cpu.so) (44 samples, 0.17%)</title><rect x="40.0047%" y="340" width="0.1716%" height="15" fill="rgb(251,158,41)" fg:x="10258" fg:w="44"/><text x="40.2547%" y="350.50"></text></g><g><title>c10::impl::wrap_kernel_functor_unboxed_&lt;c10::impl::detail::WrapFunctionIntoFunctor_&lt;c10::CompileTimeFunctionPointer&lt;at::Tensor(c10::DispatchKeySet, at::Tensor const&amp;, std::optional&lt;c10::ScalarType&gt;, std::optional&lt;c10::Layout&gt;, std::optional&lt;c10::Device&gt;, std::optional&lt;bool&gt;, bool, std::optional&lt;c10::MemoryFormat&gt;), &amp;torch::autograd::VariableType::(anonymous namespace)::_to_copy(c10::DispatchKeySet, at::Tensor const&amp;, std::optional&lt;c10::ScalarType&gt;, std::optional&lt;c10::Layout&gt;, std::optional&lt;c10::Device&gt;, std::optional&lt;bool&gt;, bool, std::optional&lt;c10::MemoryFormat&gt;)&gt;, at::Tensor, c10::guts::typelist::typelist&lt;c10::DispatchKeySet, at::Tensor const&amp;, std::optional&lt;c10::ScalarType&gt;, std::optional&lt;c10::Layout&gt;, std::optional&lt;c10::Device&gt;, std::optional&lt;bool&gt;, bool, std::optional&lt;c10::MemoryFormat&gt; &gt; &gt;, at::Tensor(c10::DispatchKeySet, at::Tensor const&amp;, std::optional&lt;c10::ScalarType&gt;, std::optional&lt;c10::Layout&gt;, std::optional&lt;c10::Device&gt;, std::optional&lt;bool&gt;, bool, std::optional&lt;c10::MemoryFormat&gt;)&gt;::call (libtorch_cpu.so) (44 samples, 0.17%)</title><rect x="40.0047%" y="356" width="0.1716%" height="15" fill="rgb(234,159,37)" fg:x="10258" fg:w="44"/><text x="40.2547%" y="366.50"></text></g><g><title>torch::autograd::VariableType::(anonymous namespace)::_to_copy (libtorch_cpu.so) (43 samples, 0.17%)</title><rect x="40.0086%" y="372" width="0.1677%" height="15" fill="rgb(216,204,22)" fg:x="10259" fg:w="43"/><text x="40.2586%" y="382.50"></text></g><g><title>torch::autograd::THPVariable_cpu (libtorch_python.so) (46 samples, 0.18%)</title><rect x="40.0008%" y="244" width="0.1794%" height="15" fill="rgb(214,17,3)" fg:x="10257" fg:w="46"/><text x="40.2508%" y="254.50"></text></g><g><title>torch::autograd::dispatch_to (libtorch_python.so) (45 samples, 0.18%)</title><rect x="40.0047%" y="260" width="0.1755%" height="15" fill="rgb(212,111,17)" fg:x="10258" fg:w="45"/><text x="40.2547%" y="270.50"></text></g><g><title>__Pyx_PyObject_FastCallDict (para_mcts.pyx:1) (58 samples, 0.23%)</title><rect x="39.9969%" y="212" width="0.2262%" height="15" fill="rgb(221,157,24)" fg:x="10256" fg:w="58"/><text x="40.2469%" y="222.50"></text></g><g><title>__Pyx_PyObject_FastCallDict (para_mcts.pyx:1) (58 samples, 0.23%)</title><rect x="39.9969%" y="228" width="0.2262%" height="15" fill="rgb(252,16,13)" fg:x="10256" fg:w="58"/><text x="40.2469%" y="238.50"></text></g><g><title>MCTS__get_value_policy (para_mcts.pyx:398) (72 samples, 0.28%)</title><rect x="39.9891%" y="196" width="0.2808%" height="15" fill="rgb(221,62,2)" fg:x="10254" fg:w="72"/><text x="40.2391%" y="206.50"></text></g><g><title>Py_DECREF (object.h:705) (33 samples, 0.13%)</title><rect x="40.2699%" y="196" width="0.1287%" height="15" fill="rgb(247,87,22)" fg:x="10326" fg:w="33"/><text x="40.5199%" y="206.50"></text></g><g><title>array_dealloc (numpy/_core/_multiarray_umath.cpython-312-x86_64-linux-gnu.so) (26 samples, 0.10%)</title><rect x="40.2972%" y="212" width="0.1014%" height="15" fill="rgb(215,73,9)" fg:x="10333" fg:w="26"/><text x="40.5472%" y="222.50"></text></g><g><title>MCTS_para_search (para_mcts.pyx:201) (9,331 samples, 36.39%)</title><rect x="4.0168%" y="180" width="36.3895%" height="15" fill="rgb(207,175,33)" fg:x="1030" fg:w="9331"/><text x="4.2668%" y="190.50">MCTS_para_search (para_mcts.pyx:201)</text></g><g><title>__Pyx_ListComp_Append (para_mcts.pyx:132) (32 samples, 0.12%)</title><rect x="40.4493%" y="196" width="0.1248%" height="15" fill="rgb(243,129,54)" fg:x="10372" fg:w="32"/><text x="40.6993%" y="206.50"></text></g><g><title>Py_SIZE (object.h:233) (32 samples, 0.12%)</title><rect x="40.4493%" y="212" width="0.1248%" height="15" fill="rgb(227,119,45)" fg:x="10372" fg:w="32"/><text x="40.6993%" y="222.50"></text></g><g><title>game_encoder_encode_scalar_features (game_encoder.pyx:62) (37 samples, 0.14%)</title><rect x="40.8353%" y="212" width="0.1443%" height="15" fill="rgb(205,109,36)" fg:x="10471" fg:w="37"/><text x="41.0853%" y="222.50"></text></g><g><title>PyArray_DiscoverDTypeAndShape (numpy/_core/_multiarray_umath.cpython-312-x86_64-linux-gnu.so) (73 samples, 0.28%)</title><rect x="41.1122%" y="276" width="0.2847%" height="15" fill="rgb(205,6,39)" fg:x="10542" fg:w="73"/><text x="41.3622%" y="286.50"></text></g><g><title>PyArray_DiscoverDTypeAndShape_Recursive (numpy/_core/_multiarray_umath.cpython-312-x86_64-linux-gnu.so) (73 samples, 0.28%)</title><rect x="41.1122%" y="292" width="0.2847%" height="15" fill="rgb(221,32,16)" fg:x="10542" fg:w="73"/><text x="41.3622%" y="302.50"></text></g><g><title>PyArray_CheckFromAny_int (numpy/_core/_multiarray_umath.cpython-312-x86_64-linux-gnu.so) (86 samples, 0.34%)</title><rect x="41.0927%" y="244" width="0.3354%" height="15" fill="rgb(228,144,50)" fg:x="10537" fg:w="86"/><text x="41.3427%" y="254.50"></text></g><g><title>PyArray_FromAny_int (numpy/_core/_multiarray_umath.cpython-312-x86_64-linux-gnu.so) (86 samples, 0.34%)</title><rect x="41.0927%" y="260" width="0.3354%" height="15" fill="rgb(229,201,53)" fg:x="10537" fg:w="86"/><text x="41.3427%" y="270.50"></text></g><g><title>game_encoder_encode_scalar_features (game_encoder.pyx:70) (121 samples, 0.47%)</title><rect x="40.9796%" y="212" width="0.4719%" height="15" fill="rgb(249,153,27)" fg:x="10508" fg:w="121"/><text x="41.2296%" y="222.50"></text></g><g><title>array_array (numpy/_core/_multiarray_umath.cpython-312-x86_64-linux-gnu.so) (92 samples, 0.36%)</title><rect x="41.0927%" y="228" width="0.3588%" height="15" fill="rgb(227,106,25)" fg:x="10537" fg:w="92"/><text x="41.3427%" y="238.50"></text></g><g><title>game_encoder_encode_scalar_features (game_encoder.pyx:72) (46 samples, 0.18%)</title><rect x="41.4515%" y="212" width="0.1794%" height="15" fill="rgb(230,65,29)" fg:x="10629" fg:w="46"/><text x="41.7015%" y="222.50"></text></g><g><title>PyArray_ConcatenateInto (numpy/_core/_multiarray_umath.cpython-312-x86_64-linux-gnu.so) (34 samples, 0.13%)</title><rect x="41.9546%" y="260" width="0.1326%" height="15" fill="rgb(221,57,46)" fg:x="10758" fg:w="34"/><text x="42.2046%" y="270.50"></text></g><g><title>array_concatenate (numpy/_core/_multiarray_umath.cpython-312-x86_64-linux-gnu.so) (36 samples, 0.14%)</title><rect x="41.9507%" y="244" width="0.1404%" height="15" fill="rgb(229,161,17)" fg:x="10757" fg:w="36"/><text x="42.2007%" y="254.50"></text></g><g><title>game_encoder_encode_scalar_features (game_encoder.pyx:91) (45 samples, 0.18%)</title><rect x="41.9273%" y="212" width="0.1755%" height="15" fill="rgb(222,213,11)" fg:x="10751" fg:w="45"/><text x="42.1773%" y="222.50"></text></g><g><title>dispatcher_vectorcall (numpy/_core/_multiarray_umath.cpython-312-x86_64-linux-gnu.so) (44 samples, 0.17%)</title><rect x="41.9312%" y="228" width="0.1716%" height="15" fill="rgb(235,35,13)" fg:x="10752" fg:w="44"/><text x="42.1812%" y="238.50"></text></g><g><title>game_encoder_encode_game_state (game_encoder.pyx:55) (403 samples, 1.57%)</title><rect x="40.5858%" y="196" width="1.5716%" height="15" fill="rgb(233,158,34)" fg:x="10407" fg:w="403"/><text x="40.8358%" y="206.50"></text></g><g><title>game_encoder_encode_ship_entity_features (game_encoder.pyx:142) (28 samples, 0.11%)</title><rect x="42.2471%" y="212" width="0.1092%" height="15" fill="rgb(215,151,48)" fg:x="10833" fg:w="28"/><text x="42.4971%" y="222.50"></text></g><g><title>game_encoder_encode_ship_entity_features (game_encoder.pyx:166) (42 samples, 0.16%)</title><rect x="42.4265%" y="212" width="0.1638%" height="15" fill="rgb(229,84,14)" fg:x="10879" fg:w="42"/><text x="42.6765%" y="222.50"></text></g><g><title>game_encoder_encode_ship_entity_features (game_encoder.pyx:169) (138 samples, 0.54%)</title><rect x="42.5981%" y="212" width="0.5382%" height="15" fill="rgb(229,68,14)" fg:x="10923" fg:w="138"/><text x="42.8481%" y="222.50"></text></g><g><title>array_true_divide (numpy/_core/_multiarray_umath.cpython-312-x86_64-linux-gnu.so) (100 samples, 0.39%)</title><rect x="42.7463%" y="228" width="0.3900%" height="15" fill="rgb(243,106,26)" fg:x="10961" fg:w="100"/><text x="42.9963%" y="238.50"></text></g><g><title>ufunc_generic_fastcall (numpy/_core/_multiarray_umath.cpython-312-x86_64-linux-gnu.so) (85 samples, 0.33%)</title><rect x="42.8048%" y="244" width="0.3315%" height="15" fill="rgb(206,45,38)" fg:x="10976" fg:w="85"/><text x="43.0548%" y="254.50"></text></g><g><title>game_encoder_encode_ship_entity_features (game_encoder.pyx:170) (59 samples, 0.23%)</title><rect x="43.1363%" y="212" width="0.2301%" height="15" fill="rgb(226,6,15)" fg:x="11061" fg:w="59"/><text x="43.3863%" y="222.50"></text></g><g><title>array_array (numpy/_core/_multiarray_umath.cpython-312-x86_64-linux-gnu.so) (36 samples, 0.14%)</title><rect x="43.2260%" y="228" width="0.1404%" height="15" fill="rgb(232,22,54)" fg:x="11084" fg:w="36"/><text x="43.4760%" y="238.50"></text></g><g><title>ufunc_generic_fastcall (numpy/_core/_multiarray_umath.cpython-312-x86_64-linux-gnu.so) (74 samples, 0.29%)</title><rect x="43.6315%" y="244" width="0.2886%" height="15" fill="rgb(229,222,32)" fg:x="11188" fg:w="74"/><text x="43.8815%" y="254.50"></text></g><g><title>game_encoder_encode_ship_entity_features (game_encoder.pyx:179) (99 samples, 0.39%)</title><rect x="43.5379%" y="212" width="0.3861%" height="15" fill="rgb(228,62,29)" fg:x="11164" fg:w="99"/><text x="43.7879%" y="222.50"></text></g><g><title>array_true_divide (numpy/_core/_multiarray_umath.cpython-312-x86_64-linux-gnu.so) (80 samples, 0.31%)</title><rect x="43.6120%" y="228" width="0.3120%" height="15" fill="rgb(251,103,34)" fg:x="11183" fg:w="80"/><text x="43.8620%" y="238.50"></text></g><g><title>PyArray_CheckFromAny_int (numpy/_core/_multiarray_umath.cpython-312-x86_64-linux-gnu.so) (28 samples, 0.11%)</title><rect x="44.0644%" y="244" width="0.1092%" height="15" fill="rgb(233,12,30)" fg:x="11299" fg:w="28"/><text x="44.3144%" y="254.50"></text></g><g><title>PyArray_FromAny_int (numpy/_core/_multiarray_umath.cpython-312-x86_64-linux-gnu.so) (28 samples, 0.11%)</title><rect x="44.0644%" y="260" width="0.1092%" height="15" fill="rgb(238,52,0)" fg:x="11299" fg:w="28"/><text x="44.3144%" y="270.50"></text></g><g><title>array_array (numpy/_core/_multiarray_umath.cpython-312-x86_64-linux-gnu.so) (35 samples, 0.14%)</title><rect x="44.0605%" y="228" width="0.1365%" height="15" fill="rgb(223,98,5)" fg:x="11298" fg:w="35"/><text x="44.3105%" y="238.50"></text></g><g><title>game_encoder_encode_ship_entity_features (game_encoder.pyx:182) (74 samples, 0.29%)</title><rect x="43.9240%" y="212" width="0.2886%" height="15" fill="rgb(228,75,37)" fg:x="11263" fg:w="74"/><text x="44.1740%" y="222.50"></text></g><g><title>array_array (numpy/_core/_multiarray_umath.cpython-312-x86_64-linux-gnu.so) (27 samples, 0.11%)</title><rect x="44.4427%" y="228" width="0.1053%" height="15" fill="rgb(205,115,49)" fg:x="11396" fg:w="27"/><text x="44.6927%" y="238.50"></text></g><g><title>game_encoder_encode_ship_entity_features (game_encoder.pyx:191) (52 samples, 0.20%)</title><rect x="44.3491%" y="212" width="0.2028%" height="15" fill="rgb(250,154,43)" fg:x="11372" fg:w="52"/><text x="44.5991%" y="222.50"></text></g><g><title>game_encoder_encode_ship_entity_features (game_encoder.pyx:199) (32 samples, 0.12%)</title><rect x="44.5831%" y="212" width="0.1248%" height="15" fill="rgb(226,43,29)" fg:x="11432" fg:w="32"/><text x="44.8331%" y="222.50"></text></g><g><title>game_encoder_encode_ship_entity_features (game_encoder.pyx:207) (44 samples, 0.17%)</title><rect x="44.7469%" y="212" width="0.1716%" height="15" fill="rgb(249,228,39)" fg:x="11474" fg:w="44"/><text x="44.9969%" y="222.50"></text></g><g><title>game_encoder_encode_ship_entity_features (game_encoder.pyx:210) (40 samples, 0.16%)</title><rect x="44.9224%" y="212" width="0.1560%" height="15" fill="rgb(216,79,43)" fg:x="11519" fg:w="40"/><text x="45.1724%" y="222.50"></text></g><g><title>game_encoder_encode_ship_entity_features (game_encoder.pyx:226) (40 samples, 0.16%)</title><rect x="45.2227%" y="212" width="0.1560%" height="15" fill="rgb(228,95,12)" fg:x="11596" fg:w="40"/><text x="45.4727%" y="222.50"></text></g><g><title>game_encoder_encode_ship_entity_features (game_encoder.pyx:239) (32 samples, 0.12%)</title><rect x="45.4333%" y="212" width="0.1248%" height="15" fill="rgb(249,221,15)" fg:x="11650" fg:w="32"/><text x="45.6833%" y="222.50"></text></g><g><title>PyArray_AssignFromCache_Recursive (numpy/_core/_multiarray_umath.cpython-312-x86_64-linux-gnu.so) (28 samples, 0.11%)</title><rect x="46.1313%" y="276" width="0.1092%" height="15" fill="rgb(233,34,13)" fg:x="11829" fg:w="28"/><text x="46.3813%" y="286.50"></text></g><g><title>PyArray_DiscoverDTypeAndShape (numpy/_core/_multiarray_umath.cpython-312-x86_64-linux-gnu.so) (31 samples, 0.12%)</title><rect x="46.2405%" y="276" width="0.1209%" height="15" fill="rgb(214,103,39)" fg:x="11857" fg:w="31"/><text x="46.4905%" y="286.50"></text></g><g><title>PyArray_DiscoverDTypeAndShape_Recursive (numpy/_core/_multiarray_umath.cpython-312-x86_64-linux-gnu.so) (29 samples, 0.11%)</title><rect x="46.2483%" y="292" width="0.1131%" height="15" fill="rgb(251,126,39)" fg:x="11859" fg:w="29"/><text x="46.4983%" y="302.50"></text></g><g><title>PyArray_CheckFromAny_int (numpy/_core/_multiarray_umath.cpython-312-x86_64-linux-gnu.so) (81 samples, 0.32%)</title><rect x="46.1235%" y="244" width="0.3159%" height="15" fill="rgb(214,216,36)" fg:x="11827" fg:w="81"/><text x="46.3735%" y="254.50"></text></g><g><title>PyArray_FromAny_int (numpy/_core/_multiarray_umath.cpython-312-x86_64-linux-gnu.so) (81 samples, 0.32%)</title><rect x="46.1235%" y="260" width="0.3159%" height="15" fill="rgb(220,221,8)" fg:x="11827" fg:w="81"/><text x="46.3735%" y="270.50"></text></g><g><title>array_array (numpy/_core/_multiarray_umath.cpython-312-x86_64-linux-gnu.so) (101 samples, 0.39%)</title><rect x="46.1001%" y="228" width="0.3939%" height="15" fill="rgb(240,216,3)" fg:x="11821" fg:w="101"/><text x="46.3501%" y="238.50"></text></g><g><title>PyArray_AssignArray (numpy/_core/_multiarray_umath.cpython-312-x86_64-linux-gnu.so) (35 samples, 0.14%)</title><rect x="46.5213%" y="260" width="0.1365%" height="15" fill="rgb(232,218,17)" fg:x="11929" fg:w="35"/><text x="46.7713%" y="270.50"></text></g><g><title>PyArray_CopyObject (numpy/_core/_multiarray_umath.cpython-312-x86_64-linux-gnu.so) (44 samples, 0.17%)</title><rect x="46.5174%" y="244" width="0.1716%" height="15" fill="rgb(229,163,45)" fg:x="11928" fg:w="44"/><text x="46.7674%" y="254.50"></text></g><g><title>array_assign_subscript (numpy/_core/_multiarray_umath.cpython-312-x86_64-linux-gnu.so) (75 samples, 0.29%)</title><rect x="46.4940%" y="228" width="0.2925%" height="15" fill="rgb(231,110,42)" fg:x="11922" fg:w="75"/><text x="46.7440%" y="238.50"></text></g><g><title>PyArray_FromAny (numpy/_core/_multiarray_umath.cpython-312-x86_64-linux-gnu.so) (36 samples, 0.14%)</title><rect x="47.0907%" y="260" width="0.1404%" height="15" fill="rgb(208,170,48)" fg:x="12075" fg:w="36"/><text x="47.3407%" y="270.50"></text></g><g><title>PyArray_FromAny_int (numpy/_core/_multiarray_umath.cpython-312-x86_64-linux-gnu.so) (32 samples, 0.12%)</title><rect x="47.1063%" y="276" width="0.1248%" height="15" fill="rgb(239,116,25)" fg:x="12079" fg:w="32"/><text x="47.3563%" y="286.50"></text></g><g><title>ufunc_generic_fastcall (numpy/_core/_multiarray_umath.cpython-312-x86_64-linux-gnu.so) (194 samples, 0.76%)</title><rect x="46.8762%" y="244" width="0.7566%" height="15" fill="rgb(219,200,50)" fg:x="12020" fg:w="194"/><text x="47.1262%" y="254.50"></text></g><g><title>try_trivial_single_output_loop (numpy/_core/_multiarray_umath.cpython-312-x86_64-linux-gnu.so) (33 samples, 0.13%)</title><rect x="47.5041%" y="260" width="0.1287%" height="15" fill="rgb(245,200,0)" fg:x="12181" fg:w="33"/><text x="47.7541%" y="270.50"></text></g><g><title>game_encoder_encode_ship_entity_features (game_encoder.pyx:242) (507 samples, 1.98%)</title><rect x="45.6595%" y="212" width="1.9772%" height="15" fill="rgb(245,119,33)" fg:x="11708" fg:w="507"/><text x="45.9095%" y="222.50">g..</text></g><g><title>array_true_divide (numpy/_core/_multiarray_umath.cpython-312-x86_64-linux-gnu.so) (218 samples, 0.85%)</title><rect x="46.7865%" y="228" width="0.8502%" height="15" fill="rgb(231,125,12)" fg:x="11997" fg:w="218"/><text x="47.0365%" y="238.50"></text></g><g><title>PyArray_CheckFromAny_int (numpy/_core/_multiarray_umath.cpython-312-x86_64-linux-gnu.so) (27 samples, 0.11%)</title><rect x="47.7537%" y="244" width="0.1053%" height="15" fill="rgb(216,96,41)" fg:x="12245" fg:w="27"/><text x="48.0037%" y="254.50"></text></g><g><title>PyArray_FromAny_int (numpy/_core/_multiarray_umath.cpython-312-x86_64-linux-gnu.so) (27 samples, 0.11%)</title><rect x="47.7537%" y="260" width="0.1053%" height="15" fill="rgb(248,43,45)" fg:x="12245" fg:w="27"/><text x="48.0037%" y="270.50"></text></g><g><title>array_array (numpy/_core/_multiarray_umath.cpython-312-x86_64-linux-gnu.so) (34 samples, 0.13%)</title><rect x="47.7459%" y="228" width="0.1326%" height="15" fill="rgb(217,222,7)" fg:x="12243" fg:w="34"/><text x="47.9959%" y="238.50"></text></g><g><title>game_encoder_encode_ship_entity_features (game_encoder.pyx:243) (147 samples, 0.57%)</title><rect x="47.6367%" y="212" width="0.5733%" height="15" fill="rgb(233,28,6)" fg:x="12215" fg:w="147"/><text x="47.8867%" y="222.50"></text></g><g><title>array_true_divide (numpy/_core/_multiarray_umath.cpython-312-x86_64-linux-gnu.so) (66 samples, 0.26%)</title><rect x="47.9526%" y="228" width="0.2574%" height="15" fill="rgb(231,218,15)" fg:x="12296" fg:w="66"/><text x="48.2026%" y="238.50"></text></g><g><title>ufunc_generic_fastcall (numpy/_core/_multiarray_umath.cpython-312-x86_64-linux-gnu.so) (57 samples, 0.22%)</title><rect x="47.9877%" y="244" width="0.2223%" height="15" fill="rgb(226,171,48)" fg:x="12305" fg:w="57"/><text x="48.2377%" y="254.50"></text></g><g><title>PyArray_CheckFromAny_int (numpy/_core/_multiarray_umath.cpython-312-x86_64-linux-gnu.so) (30 samples, 0.12%)</title><rect x="48.2997%" y="244" width="0.1170%" height="15" fill="rgb(235,201,9)" fg:x="12385" fg:w="30"/><text x="48.5497%" y="254.50"></text></g><g><title>PyArray_FromAny_int (numpy/_core/_multiarray_umath.cpython-312-x86_64-linux-gnu.so) (30 samples, 0.12%)</title><rect x="48.2997%" y="260" width="0.1170%" height="15" fill="rgb(217,80,15)" fg:x="12385" fg:w="30"/><text x="48.5497%" y="270.50"></text></g><g><title>array_array (numpy/_core/_multiarray_umath.cpython-312-x86_64-linux-gnu.so) (41 samples, 0.16%)</title><rect x="48.2919%" y="228" width="0.1599%" height="15" fill="rgb(219,152,8)" fg:x="12383" fg:w="41"/><text x="48.5419%" y="238.50"></text></g><g><title>game_encoder_encode_ship_entity_features (game_encoder.pyx:246) (65 samples, 0.25%)</title><rect x="48.2100%" y="212" width="0.2535%" height="15" fill="rgb(243,107,38)" fg:x="12362" fg:w="65"/><text x="48.4600%" y="222.50"></text></g><g><title>__Pyx_SetItemInt_Fast (game_encoder.pyx:1) (33 samples, 0.13%)</title><rect x="48.6390%" y="228" width="0.1287%" height="15" fill="rgb(231,17,5)" fg:x="12472" fg:w="33"/><text x="48.8890%" y="238.50"></text></g><g><title>Py_DECREF (object.h:700) (32 samples, 0.12%)</title><rect x="48.6429%" y="244" width="0.1248%" height="15" fill="rgb(209,25,54)" fg:x="12473" fg:w="32"/><text x="48.8929%" y="254.50"></text></g><g><title>_Py_IsImmortal (object.h:242) (32 samples, 0.12%)</title><rect x="48.6429%" y="260" width="0.1248%" height="15" fill="rgb(219,0,2)" fg:x="12473" fg:w="32"/><text x="48.8929%" y="270.50"></text></g><g><title>array_assign_subscript (numpy/_core/_multiarray_umath.cpython-312-x86_64-linux-gnu.so) (32 samples, 0.12%)</title><rect x="48.6429%" y="276" width="0.1248%" height="15" fill="rgb(246,9,5)" fg:x="12473" fg:w="32"/><text x="48.8929%" y="286.50"></text></g><g><title>game_encoder_encode_ship_entity_features (game_encoder.pyx:257) (46 samples, 0.18%)</title><rect x="48.6000%" y="212" width="0.1794%" height="15" fill="rgb(226,159,4)" fg:x="12462" fg:w="46"/><text x="48.8500%" y="222.50"></text></g><g><title>PyArray_AssignArray (numpy/_core/_multiarray_umath.cpython-312-x86_64-linux-gnu.so) (50 samples, 0.19%)</title><rect x="48.9509%" y="292" width="0.1950%" height="15" fill="rgb(219,175,34)" fg:x="12552" fg:w="50"/><text x="49.2009%" y="302.50"></text></g><g><title>raw_array_assign_array (numpy/_core/_multiarray_umath.cpython-312-x86_64-linux-gnu.so) (40 samples, 0.16%)</title><rect x="48.9899%" y="308" width="0.1560%" height="15" fill="rgb(236,10,46)" fg:x="12562" fg:w="40"/><text x="49.2399%" y="318.50"></text></g><g><title>PyArray_ConcatenateArrays (numpy/_core/_multiarray_umath.cpython-312-x86_64-linux-gnu.so) (91 samples, 0.35%)</title><rect x="48.9353%" y="276" width="0.3549%" height="15" fill="rgb(240,211,16)" fg:x="12548" fg:w="91"/><text x="49.1853%" y="286.50"></text></g><g><title>PyArray_FromAny (numpy/_core/_multiarray_umath.cpython-312-x86_64-linux-gnu.so) (37 samples, 0.14%)</title><rect x="49.2902%" y="276" width="0.1443%" height="15" fill="rgb(205,3,43)" fg:x="12639" fg:w="37"/><text x="49.5402%" y="286.50"></text></g><g><title>PyArray_FromAny_int (numpy/_core/_multiarray_umath.cpython-312-x86_64-linux-gnu.so) (31 samples, 0.12%)</title><rect x="49.3136%" y="292" width="0.1209%" height="15" fill="rgb(245,7,22)" fg:x="12645" fg:w="31"/><text x="49.5636%" y="302.50"></text></g><g><title>PyArray_ConcatenateInto (numpy/_core/_multiarray_umath.cpython-312-x86_64-linux-gnu.so) (149 samples, 0.58%)</title><rect x="48.8729%" y="260" width="0.5811%" height="15" fill="rgb(239,132,32)" fg:x="12532" fg:w="149"/><text x="49.1229%" y="270.50"></text></g><g><title>array_concatenate (numpy/_core/_multiarray_umath.cpython-312-x86_64-linux-gnu.so) (152 samples, 0.59%)</title><rect x="48.8651%" y="244" width="0.5928%" height="15" fill="rgb(228,202,34)" fg:x="12530" fg:w="152"/><text x="49.1151%" y="254.50"></text></g><g><title>game_encoder_encode_ship_entity_features (game_encoder.pyx:259) (181 samples, 0.71%)</title><rect x="48.7793%" y="212" width="0.7059%" height="15" fill="rgb(254,200,22)" fg:x="12508" fg:w="181"/><text x="49.0293%" y="222.50"></text></g><g><title>dispatcher_vectorcall (numpy/_core/_multiarray_umath.cpython-312-x86_64-linux-gnu.so) (172 samples, 0.67%)</title><rect x="48.8144%" y="228" width="0.6708%" height="15" fill="rgb(219,10,39)" fg:x="12517" fg:w="172"/><text x="49.0644%" y="238.50"></text></g><g><title>game_encoder_encode_game_state (game_encoder.pyx:56) (1,880 samples, 7.33%)</title><rect x="42.1574%" y="196" width="7.3317%" height="15" fill="rgb(226,210,39)" fg:x="10810" fg:w="1880"/><text x="42.4074%" y="206.50">game_encod..</text></g><g><title>PyArray_CheckFromAny_int (numpy/_core/_multiarray_umath.cpython-312-x86_64-linux-gnu.so) (52 samples, 0.20%)</title><rect x="49.9103%" y="244" width="0.2028%" height="15" fill="rgb(208,219,16)" fg:x="12798" fg:w="52"/><text x="50.1603%" y="254.50"></text></g><g><title>PyArray_FromAny_int (numpy/_core/_multiarray_umath.cpython-312-x86_64-linux-gnu.so) (52 samples, 0.20%)</title><rect x="49.9103%" y="260" width="0.2028%" height="15" fill="rgb(216,158,51)" fg:x="12798" fg:w="52"/><text x="50.1603%" y="270.50"></text></g><g><title>game_encoder_encode_squad_entity_features (game_encoder.pyx:285) (119 samples, 0.46%)</title><rect x="49.6802%" y="212" width="0.4641%" height="15" fill="rgb(233,14,44)" fg:x="12739" fg:w="119"/><text x="49.9302%" y="222.50"></text></g><g><title>array_array (numpy/_core/_multiarray_umath.cpython-312-x86_64-linux-gnu.so) (65 samples, 0.25%)</title><rect x="49.8908%" y="228" width="0.2535%" height="15" fill="rgb(237,97,39)" fg:x="12793" fg:w="65"/><text x="50.1408%" y="238.50"></text></g><g><title>PyArray_AssignFromCache_Recursive (numpy/_core/_multiarray_umath.cpython-312-x86_64-linux-gnu.so) (47 samples, 0.18%)</title><rect x="50.3588%" y="276" width="0.1833%" height="15" fill="rgb(218,198,43)" fg:x="12913" fg:w="47"/><text x="50.6088%" y="286.50"></text></g><g><title>PyArray_Pack (numpy/_core/_multiarray_umath.cpython-312-x86_64-linux-gnu.so) (45 samples, 0.18%)</title><rect x="50.3666%" y="292" width="0.1755%" height="15" fill="rgb(231,104,20)" fg:x="12915" fg:w="45"/><text x="50.6166%" y="302.50"></text></g><g><title>PyArray_CheckFromAny_int (numpy/_core/_multiarray_umath.cpython-312-x86_64-linux-gnu.so) (75 samples, 0.29%)</title><rect x="50.3549%" y="244" width="0.2925%" height="15" fill="rgb(254,36,13)" fg:x="12912" fg:w="75"/><text x="50.6049%" y="254.50"></text></g><g><title>PyArray_FromAny_int (numpy/_core/_multiarray_umath.cpython-312-x86_64-linux-gnu.so) (75 samples, 0.29%)</title><rect x="50.3549%" y="260" width="0.2925%" height="15" fill="rgb(248,14,50)" fg:x="12912" fg:w="75"/><text x="50.6049%" y="270.50"></text></g><g><title>game_encoder_encode_squad_entity_features (game_encoder.pyx:297) (116 samples, 0.45%)</title><rect x="50.2262%" y="212" width="0.4524%" height="15" fill="rgb(217,107,29)" fg:x="12879" fg:w="116"/><text x="50.4762%" y="222.50"></text></g><g><title>array_array (numpy/_core/_multiarray_umath.cpython-312-x86_64-linux-gnu.so) (86 samples, 0.34%)</title><rect x="50.3432%" y="228" width="0.3354%" height="15" fill="rgb(251,169,33)" fg:x="12909" fg:w="86"/><text x="50.5932%" y="238.50"></text></g><g><title>game_encoder_encode_squad_entity_features (game_encoder.pyx:302) (31 samples, 0.12%)</title><rect x="50.7176%" y="212" width="0.1209%" height="15" fill="rgb(217,108,32)" fg:x="13005" fg:w="31"/><text x="50.9676%" y="222.50"></text></g><g><title>game_encoder_encode_squad_entity_features (game_encoder.pyx:307) (76 samples, 0.30%)</title><rect x="50.9243%" y="212" width="0.2964%" height="15" fill="rgb(219,66,42)" fg:x="13058" fg:w="76"/><text x="51.1743%" y="222.50"></text></g><g><title>game_encoder_encode_squad_entity_features (game_encoder.pyx:312) (43 samples, 0.17%)</title><rect x="51.2597%" y="212" width="0.1677%" height="15" fill="rgb(206,180,7)" fg:x="13144" fg:w="43"/><text x="51.5097%" y="222.50"></text></g><g><title>PyArray_CheckFromAny_int (numpy/_core/_multiarray_umath.cpython-312-x86_64-linux-gnu.so) (33 samples, 0.13%)</title><rect x="51.5911%" y="244" width="0.1287%" height="15" fill="rgb(208,226,31)" fg:x="13229" fg:w="33"/><text x="51.8411%" y="254.50"></text></g><g><title>PyArray_FromAny_int (numpy/_core/_multiarray_umath.cpython-312-x86_64-linux-gnu.so) (33 samples, 0.13%)</title><rect x="51.5911%" y="260" width="0.1287%" height="15" fill="rgb(218,26,49)" fg:x="13229" fg:w="33"/><text x="51.8411%" y="270.50"></text></g><g><title>array_array (numpy/_core/_multiarray_umath.cpython-312-x86_64-linux-gnu.so) (42 samples, 0.16%)</title><rect x="51.5794%" y="228" width="0.1638%" height="15" fill="rgb(233,197,48)" fg:x="13226" fg:w="42"/><text x="51.8294%" y="238.50"></text></g><g><title>array_assign_subscript (numpy/_core/_multiarray_umath.cpython-312-x86_64-linux-gnu.so) (27 samples, 0.11%)</title><rect x="51.7432%" y="228" width="0.1053%" height="15" fill="rgb(252,181,51)" fg:x="13268" fg:w="27"/><text x="51.9932%" y="238.50"></text></g><g><title>game_encoder_encode_squad_entity_features (game_encoder.pyx:313) (239 samples, 0.93%)</title><rect x="51.4273%" y="212" width="0.9321%" height="15" fill="rgb(253,90,19)" fg:x="13187" fg:w="239"/><text x="51.6773%" y="222.50"></text></g><g><title>array_true_divide (numpy/_core/_multiarray_umath.cpython-312-x86_64-linux-gnu.so) (126 samples, 0.49%)</title><rect x="51.8680%" y="228" width="0.4914%" height="15" fill="rgb(215,171,30)" fg:x="13300" fg:w="126"/><text x="52.1180%" y="238.50"></text></g><g><title>ufunc_generic_fastcall (numpy/_core/_multiarray_umath.cpython-312-x86_64-linux-gnu.so) (114 samples, 0.44%)</title><rect x="51.9148%" y="244" width="0.4446%" height="15" fill="rgb(214,222,9)" fg:x="13312" fg:w="114"/><text x="52.1648%" y="254.50"></text></g><g><title>PyArray_CheckFromAny_int (numpy/_core/_multiarray_umath.cpython-312-x86_64-linux-gnu.so) (32 samples, 0.12%)</title><rect x="52.5505%" y="244" width="0.1248%" height="15" fill="rgb(223,3,22)" fg:x="13475" fg:w="32"/><text x="52.8005%" y="254.50"></text></g><g><title>PyArray_FromAny_int (numpy/_core/_multiarray_umath.cpython-312-x86_64-linux-gnu.so) (32 samples, 0.12%)</title><rect x="52.5505%" y="260" width="0.1248%" height="15" fill="rgb(225,196,46)" fg:x="13475" fg:w="32"/><text x="52.8005%" y="270.50"></text></g><g><title>array_array (numpy/_core/_multiarray_umath.cpython-312-x86_64-linux-gnu.so) (40 samples, 0.16%)</title><rect x="52.5388%" y="228" width="0.1560%" height="15" fill="rgb(209,110,37)" fg:x="13472" fg:w="40"/><text x="52.7888%" y="238.50"></text></g><g><title>game_encoder_encode_squad_entity_features (game_encoder.pyx:314) (192 samples, 0.75%)</title><rect x="52.3594%" y="212" width="0.7488%" height="15" fill="rgb(249,89,12)" fg:x="13426" fg:w="192"/><text x="52.6094%" y="222.50"></text></g><g><title>array_true_divide (numpy/_core/_multiarray_umath.cpython-312-x86_64-linux-gnu.so) (88 samples, 0.34%)</title><rect x="52.7650%" y="228" width="0.3432%" height="15" fill="rgb(226,27,33)" fg:x="13530" fg:w="88"/><text x="53.0150%" y="238.50"></text></g><g><title>ufunc_generic_fastcall (numpy/_core/_multiarray_umath.cpython-312-x86_64-linux-gnu.so) (78 samples, 0.30%)</title><rect x="52.8040%" y="244" width="0.3042%" height="15" fill="rgb(213,82,22)" fg:x="13540" fg:w="78"/><text x="53.0540%" y="254.50"></text></g><g><title>game_encoder_encode_squad_entity_features (game_encoder.pyx:317) (68 samples, 0.27%)</title><rect x="53.1082%" y="212" width="0.2652%" height="15" fill="rgb(248,140,0)" fg:x="13618" fg:w="68"/><text x="53.3582%" y="222.50"></text></g><g><title>game_encoder_encode_squad_entity_features (game_encoder.pyx:325) (53 samples, 0.21%)</title><rect x="53.4241%" y="212" width="0.2067%" height="15" fill="rgb(228,106,3)" fg:x="13699" fg:w="53"/><text x="53.6741%" y="222.50"></text></g><g><title>__Pyx_SetItemInt_Fast (game_encoder.pyx:1) (30 samples, 0.12%)</title><rect x="53.7400%" y="228" width="0.1170%" height="15" fill="rgb(209,23,37)" fg:x="13780" fg:w="30"/><text x="53.9900%" y="238.50"></text></g><g><title>Py_DECREF (object.h:700) (30 samples, 0.12%)</title><rect x="53.7400%" y="244" width="0.1170%" height="15" fill="rgb(241,93,50)" fg:x="13780" fg:w="30"/><text x="53.9900%" y="254.50"></text></g><g><title>_Py_IsImmortal (object.h:242) (30 samples, 0.12%)</title><rect x="53.7400%" y="260" width="0.1170%" height="15" fill="rgb(253,46,43)" fg:x="13780" fg:w="30"/><text x="53.9900%" y="270.50"></text></g><g><title>array_assign_subscript (numpy/_core/_multiarray_umath.cpython-312-x86_64-linux-gnu.so) (30 samples, 0.12%)</title><rect x="53.7400%" y="276" width="0.1170%" height="15" fill="rgb(226,206,43)" fg:x="13780" fg:w="30"/><text x="53.9900%" y="286.50"></text></g><g><title>game_encoder_encode_squad_entity_features (game_encoder.pyx:337) (44 samples, 0.17%)</title><rect x="53.6893%" y="212" width="0.1716%" height="15" fill="rgb(217,54,7)" fg:x="13767" fg:w="44"/><text x="53.9393%" y="222.50"></text></g><g><title>PyArray_AssignArray (numpy/_core/_multiarray_umath.cpython-312-x86_64-linux-gnu.so) (50 samples, 0.19%)</title><rect x="54.0519%" y="292" width="0.1950%" height="15" fill="rgb(223,5,52)" fg:x="13860" fg:w="50"/><text x="54.3019%" y="302.50"></text></g><g><title>raw_array_assign_array (numpy/_core/_multiarray_umath.cpython-312-x86_64-linux-gnu.so) (35 samples, 0.14%)</title><rect x="54.1104%" y="308" width="0.1365%" height="15" fill="rgb(206,52,46)" fg:x="13875" fg:w="35"/><text x="54.3604%" y="318.50"></text></g><g><title>PyArray_ConcatenateArrays (numpy/_core/_multiarray_umath.cpython-312-x86_64-linux-gnu.so) (86 samples, 0.34%)</title><rect x="54.0246%" y="276" width="0.3354%" height="15" fill="rgb(253,136,11)" fg:x="13853" fg:w="86"/><text x="54.2746%" y="286.50"></text></g><g><title>PyArray_FromAny (numpy/_core/_multiarray_umath.cpython-312-x86_64-linux-gnu.so) (29 samples, 0.11%)</title><rect x="54.3600%" y="276" width="0.1131%" height="15" fill="rgb(208,106,33)" fg:x="13939" fg:w="29"/><text x="54.6100%" y="286.50"></text></g><g><title>PyArray_FromAny_int (numpy/_core/_multiarray_umath.cpython-312-x86_64-linux-gnu.so) (27 samples, 0.11%)</title><rect x="54.3678%" y="292" width="0.1053%" height="15" fill="rgb(206,54,4)" fg:x="13941" fg:w="27"/><text x="54.6178%" y="302.50"></text></g><g><title>PyArray_ConcatenateInto (numpy/_core/_multiarray_umath.cpython-312-x86_64-linux-gnu.so) (133 samples, 0.52%)</title><rect x="53.9700%" y="260" width="0.5187%" height="15" fill="rgb(213,3,15)" fg:x="13839" fg:w="133"/><text x="54.2200%" y="270.50"></text></g><g><title>array_concatenate (numpy/_core/_multiarray_umath.cpython-312-x86_64-linux-gnu.so) (137 samples, 0.53%)</title><rect x="53.9622%" y="244" width="0.5343%" height="15" fill="rgb(252,211,39)" fg:x="13837" fg:w="137"/><text x="54.2122%" y="254.50"></text></g><g><title>game_encoder_encode_game_state (game_encoder.pyx:57) (1,287 samples, 5.02%)</title><rect x="49.4891%" y="196" width="5.0191%" height="15" fill="rgb(223,6,36)" fg:x="12690" fg:w="1287"/><text x="49.7391%" y="206.50">game_e..</text></g><g><title>game_encoder_encode_squad_entity_features (game_encoder.pyx:338) (166 samples, 0.65%)</title><rect x="53.8609%" y="212" width="0.6474%" height="15" fill="rgb(252,169,45)" fg:x="13811" fg:w="166"/><text x="54.1109%" y="222.50"></text></g><g><title>dispatcher_vectorcall (numpy/_core/_multiarray_umath.cpython-312-x86_64-linux-gnu.so) (159 samples, 0.62%)</title><rect x="53.8882%" y="228" width="0.6201%" height="15" fill="rgb(212,48,26)" fg:x="13818" fg:w="159"/><text x="54.1382%" y="238.50"></text></g><g><title>PyArray_Zeros_int (numpy/_core/_multiarray_umath.cpython-312-x86_64-linux-gnu.so) (27 samples, 0.11%)</title><rect x="54.5628%" y="244" width="0.1053%" height="15" fill="rgb(251,102,48)" fg:x="13991" fg:w="27"/><text x="54.8128%" y="254.50"></text></g><g><title>PyArray_NewFromDescr_int (numpy/_core/_multiarray_umath.cpython-312-x86_64-linux-gnu.so) (27 samples, 0.11%)</title><rect x="54.5628%" y="260" width="0.1053%" height="15" fill="rgb(243,208,16)" fg:x="13991" fg:w="27"/><text x="54.8128%" y="270.50"></text></g><g><title>PyDataMem_UserNEW_ZEROED (numpy/_core/_multiarray_umath.cpython-312-x86_64-linux-gnu.so) (26 samples, 0.10%)</title><rect x="54.5667%" y="276" width="0.1014%" height="15" fill="rgb(219,96,24)" fg:x="13992" fg:w="26"/><text x="54.8167%" y="286.50"></text></g><g><title>game_encoder_encode_spatial_features (game_encoder.pyx:351) (38 samples, 0.15%)</title><rect x="54.5277%" y="212" width="0.1482%" height="15" fill="rgb(219,33,29)" fg:x="13982" fg:w="38"/><text x="54.7777%" y="222.50"></text></g><g><title>array_zeros (numpy/_core/_multiarray_umath.cpython-312-x86_64-linux-gnu.so) (29 samples, 0.11%)</title><rect x="54.5628%" y="228" width="0.1131%" height="15" fill="rgb(223,176,5)" fg:x="13991" fg:w="29"/><text x="54.8128%" y="238.50"></text></g><g><title>PyArray_AssignArray (numpy/_core/_multiarray_umath.cpython-312-x86_64-linux-gnu.so) (26 samples, 0.10%)</title><rect x="54.7149%" y="308" width="0.1014%" height="15" fill="rgb(228,140,14)" fg:x="14030" fg:w="26"/><text x="54.9649%" y="318.50"></text></g><g><title>PyArray_CopyObject (numpy/_core/_multiarray_umath.cpython-312-x86_64-linux-gnu.so) (33 samples, 0.13%)</title><rect x="54.7149%" y="292" width="0.1287%" height="15" fill="rgb(217,179,31)" fg:x="14030" fg:w="33"/><text x="54.9649%" y="302.50"></text></g><g><title>__Pyx_SetItemInt_Fast (game_encoder.pyx:1) (40 samples, 0.16%)</title><rect x="54.7071%" y="228" width="0.1560%" height="15" fill="rgb(230,9,30)" fg:x="14028" fg:w="40"/><text x="54.9571%" y="238.50"></text></g><g><title>Py_DECREF (object.h:700) (39 samples, 0.15%)</title><rect x="54.7110%" y="244" width="0.1521%" height="15" fill="rgb(230,136,20)" fg:x="14029" fg:w="39"/><text x="54.9610%" y="254.50"></text></g><g><title>_Py_IsImmortal (object.h:242) (39 samples, 0.15%)</title><rect x="54.7110%" y="260" width="0.1521%" height="15" fill="rgb(215,210,22)" fg:x="14029" fg:w="39"/><text x="54.9610%" y="270.50"></text></g><g><title>array_assign_subscript (numpy/_core/_multiarray_umath.cpython-312-x86_64-linux-gnu.so) (39 samples, 0.15%)</title><rect x="54.7110%" y="276" width="0.1521%" height="15" fill="rgb(218,43,5)" fg:x="14029" fg:w="39"/><text x="54.9610%" y="286.50"></text></g><g><title>game_encoder_encode_spatial_features (game_encoder.pyx:365) (46 samples, 0.18%)</title><rect x="54.6915%" y="212" width="0.1794%" height="15" fill="rgb(216,11,5)" fg:x="14024" fg:w="46"/><text x="54.9415%" y="222.50"></text></g><g><title>game_encoder_encode_spatial_features (game_encoder.pyx:366) (98 samples, 0.38%)</title><rect x="54.8709%" y="212" width="0.3822%" height="15" fill="rgb(209,82,29)" fg:x="14070" fg:w="98"/><text x="55.1209%" y="222.50"></text></g><g><title>_aligned_contig_cast_half_to_float (numpy/_core/_multiarray_umath.cpython-312-x86_64-linux-gnu.so) (61 samples, 0.24%)</title><rect x="55.3233%" y="340" width="0.2379%" height="15" fill="rgb(244,115,12)" fg:x="14186" fg:w="61"/><text x="55.5733%" y="350.50"></text></g><g><title>PyArray_AssignArray (numpy/_core/_multiarray_umath.cpython-312-x86_64-linux-gnu.so) (77 samples, 0.30%)</title><rect x="55.2726%" y="308" width="0.3003%" height="15" fill="rgb(222,82,18)" fg:x="14173" fg:w="77"/><text x="55.5226%" y="318.50"></text></g><g><title>raw_array_assign_array (numpy/_core/_multiarray_umath.cpython-312-x86_64-linux-gnu.so) (71 samples, 0.28%)</title><rect x="55.2960%" y="324" width="0.2769%" height="15" fill="rgb(249,227,8)" fg:x="14179" fg:w="71"/><text x="55.5460%" y="334.50"></text></g><g><title>PyArray_CopyObject (numpy/_core/_multiarray_umath.cpython-312-x86_64-linux-gnu.so) (87 samples, 0.34%)</title><rect x="55.2726%" y="292" width="0.3393%" height="15" fill="rgb(253,141,45)" fg:x="14173" fg:w="87"/><text x="55.5226%" y="302.50"></text></g><g><title>__Pyx_SetItemInt_Fast (game_encoder.pyx:1) (98 samples, 0.38%)</title><rect x="55.2531%" y="228" width="0.3822%" height="15" fill="rgb(234,184,4)" fg:x="14168" fg:w="98"/><text x="55.5031%" y="238.50"></text></g><g><title>Py_DECREF (object.h:700) (96 samples, 0.37%)</title><rect x="55.2609%" y="244" width="0.3744%" height="15" fill="rgb(218,194,23)" fg:x="14170" fg:w="96"/><text x="55.5109%" y="254.50"></text></g><g><title>_Py_IsImmortal (object.h:242) (96 samples, 0.37%)</title><rect x="55.2609%" y="260" width="0.3744%" height="15" fill="rgb(235,66,41)" fg:x="14170" fg:w="96"/><text x="55.5109%" y="270.50"></text></g><g><title>array_assign_subscript (numpy/_core/_multiarray_umath.cpython-312-x86_64-linux-gnu.so) (96 samples, 0.37%)</title><rect x="55.2609%" y="276" width="0.3744%" height="15" fill="rgb(245,217,1)" fg:x="14170" fg:w="96"/><text x="55.5109%" y="286.50"></text></g><g><title>game_encoder_encode_spatial_features (game_encoder.pyx:368) (102 samples, 0.40%)</title><rect x="55.2531%" y="212" width="0.3978%" height="15" fill="rgb(229,91,1)" fg:x="14168" fg:w="102"/><text x="55.5031%" y="222.50"></text></g><g><title>draw_threat_zone (cache_function.py:288) (46 samples, 0.18%)</title><rect x="55.9044%" y="244" width="0.1794%" height="15" fill="rgb(207,101,30)" fg:x="14335" fg:w="46"/><text x="56.1544%" y="254.50"></text></g><g><title>polygon (skimage/draw/draw.py:522) (45 samples, 0.18%)</title><rect x="55.9083%" y="260" width="0.1755%" height="15" fill="rgb(223,82,49)" fg:x="14336" fg:w="45"/><text x="56.1583%" y="270.50"></text></g><g><title>_polygon (skimage/draw/_draw.cpython-312-x86_64-linux-gnu.so) (44 samples, 0.17%)</title><rect x="55.9122%" y="276" width="0.1716%" height="15" fill="rgb(218,167,17)" fg:x="14337" fg:w="44"/><text x="56.1622%" y="286.50"></text></g><g><title>_polygon.constprop.0 (skimage/draw/_draw.cpython-312-x86_64-linux-gnu.so) (44 samples, 0.17%)</title><rect x="55.9122%" y="292" width="0.1716%" height="15" fill="rgb(208,103,14)" fg:x="14337" fg:w="44"/><text x="56.1622%" y="302.50"></text></g><g><title>_threat_plane (cache_function.py:293) (52 samples, 0.20%)</title><rect x="55.8927%" y="228" width="0.2028%" height="15" fill="rgb(238,20,8)" fg:x="14332" fg:w="52"/><text x="56.1427%" y="238.50"></text></g><g><title>_threat_plane (cache_function.py:294) (28 samples, 0.11%)</title><rect x="56.0955%" y="228" width="0.1092%" height="15" fill="rgb(218,80,54)" fg:x="14384" fg:w="28"/><text x="56.3455%" y="238.50"></text></g><g><title>game_encoder_encode_spatial_features (game_encoder.pyx:369) (195 samples, 0.76%)</title><rect x="55.6509%" y="212" width="0.7605%" height="15" fill="rgb(240,144,17)" fg:x="14270" fg:w="195"/><text x="55.9009%" y="222.50"></text></g><g><title>Squad_get_squad_hash_state (squad.pyx:110) (31 samples, 0.12%)</title><rect x="56.4660%" y="228" width="0.1209%" height="15" fill="rgb(245,27,50)" fg:x="14479" fg:w="31"/><text x="56.7160%" y="238.50"></text></g><g><title>game_encoder_encode_spatial_features (game_encoder.pyx:378) (41 samples, 0.16%)</title><rect x="56.4660%" y="212" width="0.1599%" height="15" fill="rgb(251,51,7)" fg:x="14479" fg:w="41"/><text x="56.7160%" y="222.50"></text></g><g><title>game_encoder_encode_spatial_features (game_encoder.pyx:380) (109 samples, 0.43%)</title><rect x="56.6336%" y="212" width="0.4251%" height="15" fill="rgb(245,217,29)" fg:x="14522" fg:w="109"/><text x="56.8836%" y="222.50"></text></g><g><title>game_encoder_encode_spatial_features (game_encoder.pyx:385) (49 samples, 0.19%)</title><rect x="57.0626%" y="212" width="0.1911%" height="15" fill="rgb(221,176,29)" fg:x="14632" fg:w="49"/><text x="57.3126%" y="222.50"></text></g><g><title>game_encoder_encode_game_state (game_encoder.pyx:58) (767 samples, 2.99%)</title><rect x="54.5082%" y="196" width="2.9912%" height="15" fill="rgb(212,180,24)" fg:x="13977" fg:w="767"/><text x="54.7582%" y="206.50">gam..</text></g><g><title>game_encoder_encode_spatial_features (game_encoder.pyx:387) (63 samples, 0.25%)</title><rect x="57.2537%" y="212" width="0.2457%" height="15" fill="rgb(254,24,2)" fg:x="14681" fg:w="63"/><text x="57.5037%" y="222.50"></text></g><g><title>ufunc_generic_fastcall (numpy/_core/_multiarray_umath.cpython-312-x86_64-linux-gnu.so) (40 samples, 0.16%)</title><rect x="57.3434%" y="228" width="0.1560%" height="15" fill="rgb(230,100,2)" fg:x="14704" fg:w="40"/><text x="57.5934%" y="238.50"></text></g><g><title>game_encoder_encode_relation_matrix (game_encoder.pyx:395) (38 samples, 0.15%)</title><rect x="57.5189%" y="212" width="0.1482%" height="15" fill="rgb(219,142,25)" fg:x="14749" fg:w="38"/><text x="57.7689%" y="222.50"></text></g><g><title>Ship_get_ship_hash_state (ship.pyx:745) (33 samples, 0.13%)</title><rect x="58.4744%" y="228" width="0.1287%" height="15" fill="rgb(240,73,43)" fg:x="14994" fg:w="33"/><text x="58.7244%" y="238.50"></text></g><g><title>attack_range_s2s (cache_function.py:91) (26 samples, 0.10%)</title><rect x="59.1062%" y="228" width="0.1014%" height="15" fill="rgb(214,114,15)" fg:x="15156" fg:w="26"/><text x="59.3562%" y="238.50"></text></g><g><title>game_encoder_encode_relation_matrix (game_encoder.pyx:409) (372 samples, 1.45%)</title><rect x="57.7607%" y="212" width="1.4507%" height="15" fill="rgb(207,130,4)" fg:x="14811" fg:w="372"/><text x="58.0107%" y="222.50"></text></g><g><title>Py_DECREF (object.h:700) (145 samples, 0.57%)</title><rect x="59.3284%" y="244" width="0.5655%" height="15" fill="rgb(221,25,40)" fg:x="15213" fg:w="145"/><text x="59.5784%" y="254.50"></text></g><g><title>_Py_IsImmortal (object.h:242) (145 samples, 0.57%)</title><rect x="59.3284%" y="260" width="0.5655%" height="15" fill="rgb(241,184,7)" fg:x="15213" fg:w="145"/><text x="59.5784%" y="270.50"></text></g><g><title>__Pyx_GetItemInt_Fast (game_encoder.pyx:1) (153 samples, 0.60%)</title><rect x="59.3011%" y="228" width="0.5967%" height="15" fill="rgb(235,159,4)" fg:x="15206" fg:w="153"/><text x="59.5511%" y="238.50"></text></g><g><title>__Pyx_PyDict_GetItem (game_encoder.pyx:1) (169 samples, 0.66%)</title><rect x="59.8978%" y="228" width="0.6591%" height="15" fill="rgb(214,87,48)" fg:x="15359" fg:w="169"/><text x="60.1478%" y="238.50"></text></g><g><title>game_encoder_encode_relation_matrix (game_encoder.pyx:417) (340 samples, 1.33%)</title><rect x="59.2465%" y="212" width="1.3259%" height="15" fill="rgb(246,198,24)" fg:x="15192" fg:w="340"/><text x="59.4965%" y="222.50"></text></g><g><title>MCTS_para_search (para_mcts.pyx:202) (5,192 samples, 20.25%)</title><rect x="40.4064%" y="180" width="20.2480%" height="15" fill="rgb(209,66,40)" fg:x="10361" fg:w="5192"/><text x="40.6564%" y="190.50">MCTS_para_search (para_mcts.pyx:..</text></g><g><title>game_encoder_encode_game_state (game_encoder.pyx:59) (809 samples, 3.15%)</title><rect x="57.4994%" y="196" width="3.1550%" height="15" fill="rgb(233,147,39)" fg:x="14744" fg:w="809"/><text x="57.7494%" y="206.50">gam..</text></g><g><title>get_valid_actions (armada.pyx:149) (85 samples, 0.33%)</title><rect x="61.0015%" y="196" width="0.3315%" height="15" fill="rgb(231,145,52)" fg:x="15642" fg:w="85"/><text x="61.2515%" y="206.50"></text></g><g><title>get_valid_actions (armada.pyx:314) (27 samples, 0.11%)</title><rect x="62.0622%" y="196" width="0.1053%" height="15" fill="rgb(206,20,26)" fg:x="15914" fg:w="27"/><text x="62.3122%" y="206.50"></text></g><g><title>__call__ (enum.py:720) (26 samples, 0.10%)</title><rect x="62.0661%" y="212" width="0.1014%" height="15" fill="rgb(238,220,4)" fg:x="15915" fg:w="26"/><text x="62.3161%" y="222.50"></text></g><g><title>is_engaged (squad.pyx:123) (34 samples, 0.13%)</title><rect x="62.3781%" y="228" width="0.1326%" height="15" fill="rgb(252,195,42)" fg:x="15995" fg:w="34"/><text x="62.6281%" y="238.50"></text></g><g><title>get_valid_actions (armada.pyx:385) (51 samples, 0.20%)</title><rect x="62.3274%" y="196" width="0.1989%" height="15" fill="rgb(209,10,6)" fg:x="15982" fg:w="51"/><text x="62.5774%" y="206.50"></text></g><g><title>is_engaged (squad.pyx:114) (43 samples, 0.17%)</title><rect x="62.3586%" y="212" width="0.1677%" height="15" fill="rgb(229,3,52)" fg:x="15990" fg:w="43"/><text x="62.6086%" y="222.50"></text></g><g><title>get_valid_target (squad.pyx:142) (30 samples, 0.12%)</title><rect x="62.5809%" y="228" width="0.1170%" height="15" fill="rgb(253,49,37)" fg:x="16047" fg:w="30"/><text x="62.8309%" y="238.50"></text></g><g><title>get_valid_target (squad.pyx:146) (31 samples, 0.12%)</title><rect x="62.7018%" y="228" width="0.1209%" height="15" fill="rgb(240,103,49)" fg:x="16078" fg:w="31"/><text x="62.9518%" y="238.50"></text></g><g><title>is_engaged (squad.pyx:114) (29 samples, 0.11%)</title><rect x="62.7096%" y="244" width="0.1131%" height="15" fill="rgb(250,182,30)" fg:x="16080" fg:w="29"/><text x="62.9596%" y="254.50"></text></g><g><title>get_valid_actions (armada.pyx:386) (131 samples, 0.51%)</title><rect x="62.5263%" y="196" width="0.5109%" height="15" fill="rgb(248,8,30)" fg:x="16033" fg:w="131"/><text x="62.7763%" y="206.50"></text></g><g><title>get_valid_target (squad.pyx:131) (124 samples, 0.48%)</title><rect x="62.5536%" y="212" width="0.4836%" height="15" fill="rgb(237,120,30)" fg:x="16040" fg:w="124"/><text x="62.8036%" y="222.50"></text></g><g><title>get_valid_target (squad.pyx:153) (48 samples, 0.19%)</title><rect x="62.8500%" y="228" width="0.1872%" height="15" fill="rgb(221,146,34)" fg:x="16116" fg:w="48"/><text x="63.1000%" y="238.50"></text></g><g><title>move (squad.pyx:201) (68 samples, 0.27%)</title><rect x="63.3453%" y="308" width="0.2652%" height="15" fill="rgb(242,55,13)" fg:x="16243" fg:w="68"/><text x="63.5953%" y="318.50"></text></g><g><title>ufunc_generic_fastcall (numpy/_core/_multiarray_umath.cpython-312-x86_64-linux-gnu.so) (57 samples, 0.22%)</title><rect x="63.3882%" y="324" width="0.2223%" height="15" fill="rgb(242,112,31)" fg:x="16254" fg:w="57"/><text x="63.6382%" y="334.50"></text></g><g><title>Py_XDECREF (object.h:798) (169 samples, 0.66%)</title><rect x="63.3180%" y="244" width="0.6591%" height="15" fill="rgb(249,192,27)" fg:x="16236" fg:w="169"/><text x="63.5680%" y="254.50"></text></g><g><title>Py_DECREF (object.h:700) (169 samples, 0.66%)</title><rect x="63.3180%" y="260" width="0.6591%" height="15" fill="rgb(208,204,44)" fg:x="16236" fg:w="169"/><text x="63.5680%" y="270.50"></text></g><g><title>_Py_IsImmortal (object.h:242) (169 samples, 0.66%)</title><rect x="63.3180%" y="276" width="0.6591%" height="15" fill="rgb(208,93,54)" fg:x="16236" fg:w="169"/><text x="63.5680%" y="286.50"></text></g><g><title>move (squad.pyx:194) (167 samples, 0.65%)</title><rect x="63.3258%" y="292" width="0.6513%" height="15" fill="rgb(242,1,31)" fg:x="16238" fg:w="167"/><text x="63.5758%" y="302.50"></text></g><g><title>move (squad.pyx:202) (94 samples, 0.37%)</title><rect x="63.6105%" y="308" width="0.3666%" height="15" fill="rgb(241,83,25)" fg:x="16311" fg:w="94"/><text x="63.8605%" y="318.50"></text></g><g><title>ufunc_generic_fastcall (numpy/_core/_multiarray_umath.cpython-312-x86_64-linux-gnu.so) (72 samples, 0.28%)</title><rect x="63.6963%" y="324" width="0.2808%" height="15" fill="rgb(205,169,50)" fg:x="16333" fg:w="72"/><text x="63.9463%" y="334.50"></text></g><g><title>get_valid_moves (squad.pyx:223) (174 samples, 0.68%)</title><rect x="63.3102%" y="228" width="0.6786%" height="15" fill="rgb(239,186,37)" fg:x="16234" fg:w="174"/><text x="63.5602%" y="238.50"></text></g><g><title>is_overlap (squad.pyx:240) (30 samples, 0.12%)</title><rect x="64.0278%" y="308" width="0.1170%" height="15" fill="rgb(205,221,10)" fg:x="16418" fg:w="30"/><text x="64.2778%" y="318.50"></text></g><g><title>PyArray_DiscoverDTypeAndShape (numpy/_core/_multiarray_umath.cpython-312-x86_64-linux-gnu.so) (26 samples, 0.10%)</title><rect x="64.7882%" y="372" width="0.1014%" height="15" fill="rgb(218,196,15)" fg:x="16613" fg:w="26"/><text x="65.0382%" y="382.50"></text></g><g><title>PyArray_NewFromDescr_int (numpy/_core/_multiarray_umath.cpython-312-x86_64-linux-gnu.so) (42 samples, 0.16%)</title><rect x="64.8896%" y="372" width="0.1638%" height="15" fill="rgb(218,196,35)" fg:x="16639" fg:w="42"/><text x="65.1396%" y="382.50"></text></g><g><title>PyArray_FromAny (numpy/_core/_multiarray_umath.cpython-312-x86_64-linux-gnu.so) (93 samples, 0.36%)</title><rect x="64.7336%" y="340" width="0.3627%" height="15" fill="rgb(233,63,24)" fg:x="16599" fg:w="93"/><text x="64.9836%" y="350.50"></text></g><g><title>PyArray_FromAny_int (numpy/_core/_multiarray_umath.cpython-312-x86_64-linux-gnu.so) (83 samples, 0.32%)</title><rect x="64.7726%" y="356" width="0.3237%" height="15" fill="rgb(225,8,4)" fg:x="16609" fg:w="83"/><text x="65.0226%" y="366.50"></text></g><g><title>array_dealloc (numpy/_core/_multiarray_umath.cpython-312-x86_64-linux-gnu.so) (33 samples, 0.13%)</title><rect x="65.1899%" y="340" width="0.1287%" height="15" fill="rgb(234,105,35)" fg:x="16716" fg:w="33"/><text x="65.4399%" y="350.50"></text></g><g><title>is_overlap (squad.pyx:242) (379 samples, 1.48%)</title><rect x="64.1448%" y="308" width="1.4780%" height="15" fill="rgb(236,21,32)" fg:x="16448" fg:w="379"/><text x="64.3948%" y="318.50"></text></g><g><title>ufunc_generic_fastcall (numpy/_core/_multiarray_umath.cpython-312-x86_64-linux-gnu.so) (299 samples, 1.17%)</title><rect x="64.4568%" y="324" width="1.1661%" height="15" fill="rgb(228,109,6)" fg:x="16528" fg:w="299"/><text x="64.7068%" y="334.50"></text></g><g><title>try_trivial_single_output_loop (numpy/_core/_multiarray_umath.cpython-312-x86_64-linux-gnu.so) (55 samples, 0.21%)</title><rect x="65.4083%" y="340" width="0.2145%" height="15" fill="rgb(229,215,31)" fg:x="16772" fg:w="55"/><text x="65.6583%" y="350.50"></text></g><g><title>Py_XDECREF (object.h:798) (37 samples, 0.14%)</title><rect x="66.2312%" y="324" width="0.1443%" height="15" fill="rgb(221,52,54)" fg:x="16983" fg:w="37"/><text x="66.4812%" y="334.50"></text></g><g><title>Py_DECREF (object.h:700) (37 samples, 0.14%)</title><rect x="66.2312%" y="340" width="0.1443%" height="15" fill="rgb(252,129,43)" fg:x="16983" fg:w="37"/><text x="66.4812%" y="350.50"></text></g><g><title>_Py_IsImmortal (object.h:242) (37 samples, 0.14%)</title><rect x="66.2312%" y="356" width="0.1443%" height="15" fill="rgb(248,183,27)" fg:x="16983" fg:w="37"/><text x="66.4812%" y="366.50"></text></g><g><title>get_ship_hash_state (ship.pyx:743) (35 samples, 0.14%)</title><rect x="66.2390%" y="372" width="0.1365%" height="15" fill="rgb(250,0,22)" fg:x="16985" fg:w="35"/><text x="66.4890%" y="382.50"></text></g><g><title>get_ship_hash_state (ship.pyx:743) (34 samples, 0.13%)</title><rect x="66.2429%" y="388" width="0.1326%" height="15" fill="rgb(213,166,10)" fg:x="16986" fg:w="34"/><text x="66.4929%" y="398.50"></text></g><g><title>is_overlap_s2q (cache_function.py:155) (29 samples, 0.11%)</title><rect x="66.5783%" y="324" width="0.1131%" height="15" fill="rgb(207,163,36)" fg:x="17072" fg:w="29"/><text x="66.8283%" y="334.50"></text></g><g><title>is_overlap_s2q (cache_function.py:158) (27 samples, 0.11%)</title><rect x="66.7031%" y="324" width="0.1053%" height="15" fill="rgb(208,122,22)" fg:x="17104" fg:w="27"/><text x="66.9531%" y="334.50"></text></g><g><title>is_overlap (squad.pyx:231) (729 samples, 2.84%)</title><rect x="64.0083%" y="292" width="2.8430%" height="15" fill="rgb(207,104,49)" fg:x="16413" fg:w="729"/><text x="64.2583%" y="302.50">is..</text></g><g><title>is_overlap (squad.pyx:249) (274 samples, 1.07%)</title><rect x="65.7827%" y="308" width="1.0686%" height="15" fill="rgb(248,211,50)" fg:x="16868" fg:w="274"/><text x="66.0327%" y="318.50"></text></g><g><title>Py_XDECREF (object.h:798) (753 samples, 2.94%)</title><rect x="64.0005%" y="244" width="2.9366%" height="15" fill="rgb(217,13,45)" fg:x="16411" fg:w="753"/><text x="64.2505%" y="254.50">Py..</text></g><g><title>Py_DECREF (object.h:700) (753 samples, 2.94%)</title><rect x="64.0005%" y="260" width="2.9366%" height="15" fill="rgb(211,216,49)" fg:x="16411" fg:w="753"/><text x="64.2505%" y="270.50">Py..</text></g><g><title>_Py_IsImmortal (object.h:242) (753 samples, 2.94%)</title><rect x="64.0005%" y="276" width="2.9366%" height="15" fill="rgb(221,58,53)" fg:x="16411" fg:w="753"/><text x="64.2505%" y="286.50">_P..</text></g><g><title>get_valid_moves (squad.pyx:225) (765 samples, 2.98%)</title><rect x="63.9888%" y="228" width="2.9834%" height="15" fill="rgb(220,112,41)" fg:x="16408" fg:w="765"/><text x="64.2388%" y="238.50">get..</text></g><g><title>get_valid_actions (armada.pyx:390) (1,012 samples, 3.95%)</title><rect x="63.0372%" y="196" width="3.9467%" height="15" fill="rgb(236,38,28)" fg:x="16164" fg:w="1012"/><text x="63.2872%" y="206.50">get_..</text></g><g><title>get_valid_moves (squad.pyx:205) (952 samples, 3.71%)</title><rect x="63.2712%" y="212" width="3.7127%" height="15" fill="rgb(227,195,22)" fg:x="16224" fg:w="952"/><text x="63.5212%" y="222.50">get_..</text></g><g><title>MCTS_para_search (para_mcts.pyx:220) (1,556 samples, 6.07%)</title><rect x="60.9274%" y="180" width="6.0682%" height="15" fill="rgb(214,55,33)" fg:x="15623" fg:w="1556"/><text x="61.1774%" y="190.50">MCTS_par..</text></g><g><title>MCTS__mask_policy (para_mcts.pyx:402) (40 samples, 0.16%)</title><rect x="66.9956%" y="196" width="0.1560%" height="15" fill="rgb(248,80,13)" fg:x="17179" fg:w="40"/><text x="67.2456%" y="206.50"></text></g><g><title>_zeros_like_dispatcher (numpy/_core/numeric.py:59) (1,723 samples, 6.72%)</title><rect x="67.3075%" y="228" width="6.7194%" height="15" fill="rgb(238,52,6)" fg:x="17259" fg:w="1723"/><text x="67.5575%" y="238.50">_zeros_li..</text></g><g><title>zeros_like (numpy/_core/numeric.py:134) (42 samples, 0.16%)</title><rect x="74.0426%" y="228" width="0.1638%" height="15" fill="rgb(224,198,47)" fg:x="18986" fg:w="42"/><text x="74.2926%" y="238.50"></text></g><g><title>dispatcher_vectorcall (numpy/_core/_multiarray_umath.cpython-312-x86_64-linux-gnu.so) (37 samples, 0.14%)</title><rect x="74.0621%" y="244" width="0.1443%" height="15" fill="rgb(233,171,20)" fg:x="18991" fg:w="37"/><text x="74.3121%" y="254.50"></text></g><g><title>array_empty_like (numpy/_core/_multiarray_umath.cpython-312-x86_64-linux-gnu.so) (32 samples, 0.12%)</title><rect x="74.0816%" y="260" width="0.1248%" height="15" fill="rgb(241,30,25)" fg:x="18996" fg:w="32"/><text x="74.3316%" y="270.50"></text></g><g><title>zeros_like (numpy/_core/numeric.py:139) (32 samples, 0.12%)</title><rect x="74.2727%" y="228" width="0.1248%" height="15" fill="rgb(207,171,38)" fg:x="19045" fg:w="32"/><text x="74.5227%" y="238.50"></text></g><g><title>MCTS__mask_policy (para_mcts.pyx:404) (1,859 samples, 7.25%)</title><rect x="67.1515%" y="196" width="7.2498%" height="15" fill="rgb(234,70,1)" fg:x="17219" fg:w="1859"/><text x="67.4015%" y="206.50">MCTS__mask..</text></g><g><title>dispatcher_vectorcall (numpy/_core/_multiarray_umath.cpython-312-x86_64-linux-gnu.so) (1,839 samples, 7.17%)</title><rect x="67.2295%" y="212" width="7.1718%" height="15" fill="rgb(232,178,18)" fg:x="17239" fg:w="1839"/><text x="67.4795%" y="222.50">dispatcher..</text></g><g><title>PyArray_CastToType (numpy/_core/_multiarray_umath.cpython-312-x86_64-linux-gnu.so) (35 samples, 0.14%)</title><rect x="74.5262%" y="228" width="0.1365%" height="15" fill="rgb(241,78,40)" fg:x="19110" fg:w="35"/><text x="74.7762%" y="238.50"></text></g><g><title>ufunc_generic_fastcall (numpy/_core/_multiarray_umath.cpython-312-x86_64-linux-gnu.so) (69 samples, 0.27%)</title><rect x="74.5067%" y="212" width="0.2691%" height="15" fill="rgb(222,35,25)" fg:x="19105" fg:w="69"/><text x="74.7567%" y="222.50"></text></g><g><title>MCTS__mask_policy (para_mcts.pyx:414) (79 samples, 0.31%)</title><rect x="74.4755%" y="196" width="0.3081%" height="15" fill="rgb(207,92,16)" fg:x="19097" fg:w="79"/><text x="74.7255%" y="206.50"></text></g><g><title>_wrapreduction (numpy/_core/fromnumeric.py:70) (45 samples, 0.18%)</title><rect x="74.9084%" y="244" width="0.1755%" height="15" fill="rgb(216,59,51)" fg:x="19208" fg:w="45"/><text x="75.1584%" y="254.50"></text></g><g><title>PyUFunc_ReduceWrapper (numpy/_core/_multiarray_umath.cpython-312-x86_64-linux-gnu.so) (41 samples, 0.16%)</title><rect x="75.1735%" y="276" width="0.1599%" height="15" fill="rgb(213,80,28)" fg:x="19276" fg:w="41"/><text x="75.4235%" y="286.50"></text></g><g><title>sum (numpy/_core/fromnumeric.py:2389) (133 samples, 0.52%)</title><rect x="74.8694%" y="228" width="0.5187%" height="15" fill="rgb(220,93,7)" fg:x="19198" fg:w="133"/><text x="75.1194%" y="238.50"></text></g><g><title>_wrapreduction (numpy/_core/fromnumeric.py:86) (73 samples, 0.28%)</title><rect x="75.1033%" y="244" width="0.2847%" height="15" fill="rgb(225,24,44)" fg:x="19258" fg:w="73"/><text x="75.3533%" y="254.50"></text></g><g><title>PyUFunc_GenericReduction (numpy/_core/_multiarray_umath.cpython-312-x86_64-linux-gnu.so) (63 samples, 0.25%)</title><rect x="75.1423%" y="260" width="0.2457%" height="15" fill="rgb(243,74,40)" fg:x="19268" fg:w="63"/><text x="75.3923%" y="270.50"></text></g><g><title>dispatcher_vectorcall (numpy/_core/_multiarray_umath.cpython-312-x86_64-linux-gnu.so) (151 samples, 0.59%)</title><rect x="74.8070%" y="212" width="0.5889%" height="15" fill="rgb(228,39,7)" fg:x="19182" fg:w="151"/><text x="75.0570%" y="222.50"></text></g><g><title>MCTS__mask_policy (para_mcts.pyx:417) (158 samples, 0.62%)</title><rect x="74.7836%" y="196" width="0.6162%" height="15" fill="rgb(227,79,8)" fg:x="19176" fg:w="158"/><text x="75.0336%" y="206.50"></text></g><g><title>MCTS__mask_policy (para_mcts.pyx:419) (31 samples, 0.12%)</title><rect x="75.3997%" y="196" width="0.1209%" height="15" fill="rgb(236,58,11)" fg:x="19334" fg:w="31"/><text x="75.6497%" y="206.50"></text></g><g><title>MCTS_para_search (para_mcts.pyx:222) (2,191 samples, 8.54%)</title><rect x="66.9956%" y="180" width="8.5446%" height="15" fill="rgb(249,63,35)" fg:x="17179" fg:w="2191"/><text x="67.2456%" y="190.50">MCTS_para_se..</text></g><g><title>apply_action (armada.pyx:407) (75 samples, 0.29%)</title><rect x="75.7468%" y="260" width="0.2925%" height="15" fill="rgb(252,114,16)" fg:x="19423" fg:w="75"/><text x="75.9968%" y="270.50"></text></g><g><title>apply_action (armada.pyx:516) (72 samples, 0.28%)</title><rect x="76.4137%" y="260" width="0.2808%" height="15" fill="rgb(254,151,24)" fg:x="19594" fg:w="72"/><text x="76.6637%" y="270.50"></text></g><g><title>apply_action (armada.pyx:528) (28 samples, 0.11%)</title><rect x="76.6945%" y="260" width="0.1092%" height="15" fill="rgb(253,54,39)" fg:x="19666" fg:w="28"/><text x="76.9445%" y="270.50"></text></g><g><title>apply_action (armada.pyx:579) (26 samples, 0.10%)</title><rect x="77.0689%" y="260" width="0.1014%" height="15" fill="rgb(243,25,45)" fg:x="19762" fg:w="26"/><text x="77.3189%" y="270.50"></text></g><g><title>apply_action (armada.pyx:596) (32 samples, 0.12%)</title><rect x="77.1859%" y="260" width="0.1248%" height="15" fill="rgb(234,134,9)" fg:x="19792" fg:w="32"/><text x="77.4359%" y="270.50"></text></g><g><title>apply_action (armada.pyx:649) (55 samples, 0.21%)</title><rect x="77.4823%" y="260" width="0.2145%" height="15" fill="rgb(227,166,31)" fg:x="19868" fg:w="55"/><text x="77.7323%" y="270.50"></text></g><g><title>apply_action (armada.pyx:738) (37 samples, 0.14%)</title><rect x="77.7981%" y="260" width="0.1443%" height="15" fill="rgb(245,143,41)" fg:x="19949" fg:w="37"/><text x="78.0481%" y="270.50"></text></g><g><title>PyArray_DiscoverDTypeAndShape (numpy/_core/_multiarray_umath.cpython-312-x86_64-linux-gnu.so) (304 samples, 1.19%)</title><rect x="78.1101%" y="436" width="1.1856%" height="15" fill="rgb(238,181,32)" fg:x="20029" fg:w="304"/><text x="78.3601%" y="446.50"></text></g><g><title>PyArray_DiscoverDTypeAndShape_Recursive (numpy/_core/_multiarray_umath.cpython-312-x86_64-linux-gnu.so) (304 samples, 1.19%)</title><rect x="78.1101%" y="452" width="1.1856%" height="15" fill="rgb(224,113,18)" fg:x="20029" fg:w="304"/><text x="78.3601%" y="462.50"></text></g><g><title>move_ship (ship.pyx:159) (320 samples, 1.25%)</title><rect x="78.0672%" y="372" width="1.2480%" height="15" fill="rgb(240,229,28)" fg:x="20018" fg:w="320"/><text x="78.3172%" y="382.50"></text></g><g><title>array_array (numpy/_core/_multiarray_umath.cpython-312-x86_64-linux-gnu.so) (313 samples, 1.22%)</title><rect x="78.0945%" y="388" width="1.2207%" height="15" fill="rgb(250,185,3)" fg:x="20025" fg:w="313"/><text x="78.3445%" y="398.50"></text></g><g><title>PyArray_CheckFromAny_int (numpy/_core/_multiarray_umath.cpython-312-x86_64-linux-gnu.so) (311 samples, 1.21%)</title><rect x="78.1023%" y="404" width="1.2129%" height="15" fill="rgb(212,59,25)" fg:x="20027" fg:w="311"/><text x="78.3523%" y="414.50"></text></g><g><title>PyArray_FromAny_int (numpy/_core/_multiarray_umath.cpython-312-x86_64-linux-gnu.so) (311 samples, 1.21%)</title><rect x="78.1023%" y="420" width="1.2129%" height="15" fill="rgb(221,87,20)" fg:x="20027" fg:w="311"/><text x="78.3523%" y="430.50"></text></g><g><title>PyArray_DiscoverDTypeAndShape (numpy/_core/_multiarray_umath.cpython-312-x86_64-linux-gnu.so) (38 samples, 0.15%)</title><rect x="79.4556%" y="436" width="0.1482%" height="15" fill="rgb(213,74,28)" fg:x="20374" fg:w="38"/><text x="79.7056%" y="446.50"></text></g><g><title>PyArray_DiscoverDTypeAndShape_Recursive (numpy/_core/_multiarray_umath.cpython-312-x86_64-linux-gnu.so) (38 samples, 0.15%)</title><rect x="79.4556%" y="452" width="0.1482%" height="15" fill="rgb(224,132,34)" fg:x="20374" fg:w="38"/><text x="79.7056%" y="462.50"></text></g><g><title>array_array (numpy/_core/_multiarray_umath.cpython-312-x86_64-linux-gnu.so) (43 samples, 0.17%)</title><rect x="79.4400%" y="388" width="0.1677%" height="15" fill="rgb(222,101,24)" fg:x="20370" fg:w="43"/><text x="79.6900%" y="398.50"></text></g><g><title>PyArray_CheckFromAny_int (numpy/_core/_multiarray_umath.cpython-312-x86_64-linux-gnu.so) (43 samples, 0.17%)</title><rect x="79.4400%" y="404" width="0.1677%" height="15" fill="rgb(254,142,4)" fg:x="20370" fg:w="43"/><text x="79.6900%" y="414.50"></text></g><g><title>PyArray_FromAny_int (numpy/_core/_multiarray_umath.cpython-312-x86_64-linux-gnu.so) (43 samples, 0.17%)</title><rect x="79.4400%" y="420" width="0.1677%" height="15" fill="rgb(230,229,49)" fg:x="20370" fg:w="43"/><text x="79.6900%" y="430.50"></text></g><g><title>move_ship (ship.pyx:166) (47 samples, 0.18%)</title><rect x="79.4283%" y="372" width="0.1833%" height="15" fill="rgb(238,70,47)" fg:x="20367" fg:w="47"/><text x="79.6783%" y="382.50"></text></g><g><title>move_ship (ship.pyx:168) (29 samples, 0.11%)</title><rect x="79.6116%" y="372" width="0.1131%" height="15" fill="rgb(231,160,17)" fg:x="20414" fg:w="29"/><text x="79.8616%" y="382.50"></text></g><g><title>ufunc_generic_fastcall (numpy/_core/_multiarray_umath.cpython-312-x86_64-linux-gnu.so) (26 samples, 0.10%)</title><rect x="79.6233%" y="388" width="0.1014%" height="15" fill="rgb(218,68,53)" fg:x="20417" fg:w="26"/><text x="79.8733%" y="398.50"></text></g><g><title>is_overlap_s2s (cache_function.py:149) (27 samples, 0.11%)</title><rect x="80.0406%" y="452" width="0.1053%" height="15" fill="rgb(236,111,10)" fg:x="20524" fg:w="27"/><text x="80.2906%" y="462.50"></text></g><g><title>Py_XDECREF (object.h:798) (104 samples, 0.41%)</title><rect x="79.8144%" y="388" width="0.4056%" height="15" fill="rgb(224,34,41)" fg:x="20466" fg:w="104"/><text x="80.0644%" y="398.50"></text></g><g><title>Py_DECREF (object.h:700) (104 samples, 0.41%)</title><rect x="79.8144%" y="404" width="0.4056%" height="15" fill="rgb(241,118,19)" fg:x="20466" fg:w="104"/><text x="80.0644%" y="414.50"></text></g><g><title>is_overlap (ship.pyx:483) (102 samples, 0.40%)</title><rect x="79.8222%" y="420" width="0.3978%" height="15" fill="rgb(238,129,25)" fg:x="20468" fg:w="102"/><text x="80.0722%" y="430.50"></text></g><g><title>is_overlap (ship.pyx:495) (90 samples, 0.35%)</title><rect x="79.8690%" y="436" width="0.3510%" height="15" fill="rgb(238,22,31)" fg:x="20480" fg:w="90"/><text x="80.1190%" y="446.50"></text></g><g><title>move_ship (ship.pyx:172) (108 samples, 0.42%)</title><rect x="79.8144%" y="372" width="0.4212%" height="15" fill="rgb(222,174,48)" fg:x="20466" fg:w="108"/><text x="80.0644%" y="382.50"></text></g><g><title>execute_maneuver (ship.pyx:145) (576 samples, 2.25%)</title><rect x="78.0438%" y="292" width="2.2463%" height="15" fill="rgb(206,152,40)" fg:x="20012" fg:w="576"/><text x="78.2938%" y="302.50">e..</text></g><g><title>Py_XDECREF (object.h:798) (574 samples, 2.24%)</title><rect x="78.0516%" y="308" width="2.2385%" height="15" fill="rgb(218,99,54)" fg:x="20014" fg:w="574"/><text x="78.3016%" y="318.50">P..</text></g><g><title>Py_DECREF (object.h:700) (574 samples, 2.24%)</title><rect x="78.0516%" y="324" width="2.2385%" height="15" fill="rgb(220,174,26)" fg:x="20014" fg:w="574"/><text x="78.3016%" y="334.50">P..</text></g><g><title>_Py_IsImmortal (object.h:242) (574 samples, 2.24%)</title><rect x="78.0516%" y="340" width="2.2385%" height="15" fill="rgb(245,116,9)" fg:x="20014" fg:w="574"/><text x="78.3016%" y="350.50">_..</text></g><g><title>move_ship (ship.pyx:153) (574 samples, 2.24%)</title><rect x="78.0516%" y="356" width="2.2385%" height="15" fill="rgb(209,72,35)" fg:x="20014" fg:w="574"/><text x="78.3016%" y="366.50">m..</text></g><g><title>out_of_board (ship.pyx:534) (32 samples, 0.12%)</title><rect x="80.3525%" y="324" width="0.1248%" height="15" fill="rgb(226,126,21)" fg:x="20604" fg:w="32"/><text x="80.6025%" y="334.50"></text></g><g><title>execute_maneuver (ship.pyx:147) (66 samples, 0.26%)</title><rect x="80.3135%" y="292" width="0.2574%" height="15" fill="rgb(227,192,1)" fg:x="20594" fg:w="66"/><text x="80.5635%" y="302.50"></text></g><g><title>out_of_board (ship.pyx:525) (65 samples, 0.25%)</title><rect x="80.3174%" y="308" width="0.2535%" height="15" fill="rgb(237,180,29)" fg:x="20595" fg:w="65"/><text x="80.5674%" y="318.50"></text></g><g><title>apply_action (armada.pyx:764) (656 samples, 2.56%)</title><rect x="78.0165%" y="260" width="2.5583%" height="15" fill="rgb(230,197,35)" fg:x="20005" fg:w="656"/><text x="78.2665%" y="270.50">ap..</text></g><g><title>execute_maneuver (ship.pyx:144) (650 samples, 2.53%)</title><rect x="78.0399%" y="276" width="2.5349%" height="15" fill="rgb(246,193,31)" fg:x="20011" fg:w="650"/><text x="78.2899%" y="286.50">ex..</text></g><g><title>apply_action (armada.pyx:767) (97 samples, 0.38%)</title><rect x="80.5748%" y="260" width="0.3783%" height="15" fill="rgb(241,36,4)" fg:x="20661" fg:w="97"/><text x="80.8248%" y="270.50"></text></g><g><title>is_overlap_squad (ship.pyx:183) (83 samples, 0.32%)</title><rect x="80.6294%" y="276" width="0.3237%" height="15" fill="rgb(241,130,17)" fg:x="20675" fg:w="83"/><text x="80.8794%" y="286.50"></text></g><g><title>is_overlap_squad (ship.pyx:195) (81 samples, 0.32%)</title><rect x="80.6372%" y="292" width="0.3159%" height="15" fill="rgb(206,137,32)" fg:x="20677" fg:w="81"/><text x="80.8872%" y="302.50"></text></g><g><title>move (squad.pyx:201) (55 samples, 0.21%)</title><rect x="81.1715%" y="292" width="0.2145%" height="15" fill="rgb(237,228,51)" fg:x="20814" fg:w="55"/><text x="81.4215%" y="302.50"></text></g><g><title>ufunc_generic_fastcall (numpy/_core/_multiarray_umath.cpython-312-x86_64-linux-gnu.so) (44 samples, 0.17%)</title><rect x="81.2144%" y="308" width="0.1716%" height="15" fill="rgb(243,6,42)" fg:x="20825" fg:w="44"/><text x="81.4644%" y="318.50"></text></g><g><title>apply_action (armada.pyx:858) (126 samples, 0.49%)</title><rect x="81.1091%" y="260" width="0.4914%" height="15" fill="rgb(251,74,28)" fg:x="20798" fg:w="126"/><text x="81.3591%" y="270.50"></text></g><g><title>move (squad.pyx:194) (115 samples, 0.45%)</title><rect x="81.1520%" y="276" width="0.4485%" height="15" fill="rgb(218,20,49)" fg:x="20809" fg:w="115"/><text x="81.4020%" y="286.50"></text></g><g><title>move (squad.pyx:202) (55 samples, 0.21%)</title><rect x="81.3860%" y="292" width="0.2145%" height="15" fill="rgb(238,28,14)" fg:x="20869" fg:w="55"/><text x="81.6360%" y="302.50"></text></g><g><title>ufunc_generic_fastcall (numpy/_core/_multiarray_umath.cpython-312-x86_64-linux-gnu.so) (33 samples, 0.13%)</title><rect x="81.4718%" y="308" width="0.1287%" height="15" fill="rgb(229,40,46)" fg:x="20891" fg:w="33"/><text x="81.7218%" y="318.50"></text></g><g><title>Armada_update_decision_player (armada.pyx:137) (45 samples, 0.18%)</title><rect x="82.0217%" y="276" width="0.1755%" height="15" fill="rgb(244,195,20)" fg:x="21032" fg:w="45"/><text x="82.2717%" y="286.50"></text></g><g><title>Py_XDECREF (object.h:798) (1,685 samples, 6.57%)</title><rect x="75.6688%" y="212" width="6.5713%" height="15" fill="rgb(253,56,35)" fg:x="19403" fg:w="1685"/><text x="75.9188%" y="222.50">Py_XDECRE..</text></g><g><title>Py_DECREF (object.h:700) (1,685 samples, 6.57%)</title><rect x="75.6688%" y="228" width="6.5713%" height="15" fill="rgb(210,149,44)" fg:x="19403" fg:w="1685"/><text x="75.9188%" y="238.50">Py_DECREF..</text></g><g><title>_Py_IsImmortal (object.h:242) (1,685 samples, 6.57%)</title><rect x="75.6688%" y="244" width="6.5713%" height="15" fill="rgb(240,135,12)" fg:x="19403" fg:w="1685"/><text x="75.9188%" y="254.50">_Py_IsImm..</text></g><g><title>apply_action (armada.pyx:919) (100 samples, 0.39%)</title><rect x="81.8501%" y="260" width="0.3900%" height="15" fill="rgb(251,24,50)" fg:x="20988" fg:w="100"/><text x="82.1001%" y="270.50"></text></g><g><title>MCTS__expand (para_mcts.pyx:443) (1,691 samples, 6.59%)</title><rect x="75.6649%" y="196" width="6.5946%" height="15" fill="rgb(243,200,47)" fg:x="19402" fg:w="1691"/><text x="75.9149%" y="206.50">MCTS__exp..</text></g><g><title>Node_add_child (para_mcts.pyx:65) (54 samples, 0.21%)</title><rect x="82.2635%" y="212" width="0.2106%" height="15" fill="rgb(224,166,26)" fg:x="21094" fg:w="54"/><text x="82.5135%" y="222.50"></text></g><g><title>Armada_get_snapshot (armada.pyx:1022) (50 samples, 0.19%)</title><rect x="82.6262%" y="260" width="0.1950%" height="15" fill="rgb(233,0,47)" fg:x="21187" fg:w="50"/><text x="82.8762%" y="270.50"></text></g><g><title>Ship_get_snapshot (ship.pyx:718) (71 samples, 0.28%)</title><rect x="82.9459%" y="276" width="0.2769%" height="15" fill="rgb(253,80,5)" fg:x="21269" fg:w="71"/><text x="83.1959%" y="286.50"></text></g><g><title>DefenseToken_get_snapshot (defense_token.pyx:50) (45 samples, 0.18%)</title><rect x="83.4880%" y="292" width="0.1755%" height="15" fill="rgb(214,133,25)" fg:x="21408" fg:w="45"/><text x="83.7380%" y="302.50"></text></g><g><title>Ship_get_snapshot (ship.pyx:724) (108 samples, 0.42%)</title><rect x="83.2579%" y="276" width="0.4212%" height="15" fill="rgb(209,27,14)" fg:x="21349" fg:w="108"/><text x="83.5079%" y="286.50"></text></g><g><title>__Pyx_dict_iter_next (ship.pyx:1) (26 samples, 0.10%)</title><rect x="83.6869%" y="292" width="0.1014%" height="15" fill="rgb(219,102,51)" fg:x="21459" fg:w="26"/><text x="83.9369%" y="302.50"></text></g><g><title>Armada_get_snapshot (armada.pyx:1031) (243 samples, 0.95%)</title><rect x="82.8485%" y="260" width="0.9477%" height="15" fill="rgb(237,18,16)" fg:x="21244" fg:w="243"/><text x="83.0985%" y="270.50"></text></g><g><title>Ship_get_snapshot (ship.pyx:725) (30 samples, 0.12%)</title><rect x="83.6791%" y="276" width="0.1170%" height="15" fill="rgb(241,85,17)" fg:x="21457" fg:w="30"/><text x="83.9291%" y="286.50"></text></g><g><title>Armada_get_snapshot (armada.pyx:1034) (76 samples, 0.30%)</title><rect x="83.8234%" y="260" width="0.2964%" height="15" fill="rgb(236,90,42)" fg:x="21494" fg:w="76"/><text x="84.0734%" y="270.50"></text></g><g><title>Py_XDECREF (object.h:798) (27 samples, 0.11%)</title><rect x="84.1705%" y="276" width="0.1053%" height="15" fill="rgb(249,57,21)" fg:x="21583" fg:w="27"/><text x="84.4205%" y="286.50"></text></g><g><title>Py_DECREF (object.h:700) (27 samples, 0.11%)</title><rect x="84.1705%" y="292" width="0.1053%" height="15" fill="rgb(243,12,36)" fg:x="21583" fg:w="27"/><text x="84.4205%" y="302.50"></text></g><g><title>Armada_get_snapshot (armada.pyx:1046) (29 samples, 0.11%)</title><rect x="84.1666%" y="260" width="0.1131%" height="15" fill="rgb(253,128,47)" fg:x="21582" fg:w="29"/><text x="84.4166%" y="270.50"></text></g><g><title>Node___init__ (para_mcts.pyx:51) (437 samples, 1.70%)</title><rect x="82.6145%" y="244" width="1.7042%" height="15" fill="rgb(207,33,20)" fg:x="21184" fg:w="437"/><text x="82.8645%" y="254.50"></text></g><g><title>__init__ (para_mcts.pyx:43) (465 samples, 1.81%)</title><rect x="82.5755%" y="228" width="1.8134%" height="15" fill="rgb(233,215,35)" fg:x="21174" fg:w="465"/><text x="82.8255%" y="238.50">_..</text></g><g><title>Node_add_child (para_mcts.pyx:72) (500 samples, 1.95%)</title><rect x="82.4741%" y="212" width="1.9499%" height="15" fill="rgb(249,188,52)" fg:x="21148" fg:w="500"/><text x="82.7241%" y="222.50">N..</text></g><g><title>MCTS__expand (para_mcts.pyx:444) (564 samples, 2.20%)</title><rect x="82.2596%" y="196" width="2.1995%" height="15" fill="rgb(225,12,32)" fg:x="21093" fg:w="564"/><text x="82.5096%" y="206.50">M..</text></g><g><title>__Pyx_dict_iter_next (ship.pyx:1) (35 samples, 0.14%)</title><rect x="84.8803%" y="244" width="0.1365%" height="15" fill="rgb(247,98,14)" fg:x="21765" fg:w="35"/><text x="85.1303%" y="254.50"></text></g><g><title>Ship_revert_snapshot (ship.pyx:740) (40 samples, 0.16%)</title><rect x="84.8764%" y="228" width="0.1560%" height="15" fill="rgb(247,219,48)" fg:x="21764" fg:w="40"/><text x="85.1264%" y="238.50"></text></g><g><title>Armada_revert_snapshot (armada.pyx:1062) (115 samples, 0.45%)</title><rect x="84.7009%" y="212" width="0.4485%" height="15" fill="rgb(253,60,48)" fg:x="21719" fg:w="115"/><text x="84.9509%" y="222.50"></text></g><g><title>MCTS__expand (para_mcts.pyx:445) (214 samples, 0.83%)</title><rect x="84.4591%" y="196" width="0.8346%" height="15" fill="rgb(245,15,52)" fg:x="21657" fg:w="214"/><text x="84.7091%" y="206.50"></text></g><g><title>Armada_revert_snapshot (armada.pyx:1064) (27 samples, 0.11%)</title><rect x="85.1884%" y="212" width="0.1053%" height="15" fill="rgb(220,133,28)" fg:x="21844" fg:w="27"/><text x="85.4384%" y="222.50"></text></g><g><title>Armada_revert_snapshot (armada.pyx:1062) (35 samples, 0.14%)</title><rect x="85.3366%" y="212" width="0.1365%" height="15" fill="rgb(217,180,4)" fg:x="21882" fg:w="35"/><text x="85.5866%" y="222.50"></text></g><g><title>MCTS__expand (para_mcts.pyx:446) (65 samples, 0.25%)</title><rect x="85.2937%" y="196" width="0.2535%" height="15" fill="rgb(251,24,1)" fg:x="21871" fg:w="65"/><text x="85.5437%" y="206.50"></text></g><g><title>MCTS_para_search (para_mcts.pyx:224) (2,567 samples, 10.01%)</title><rect x="75.5401%" y="180" width="10.0109%" height="15" fill="rgb(212,185,49)" fg:x="19370" fg:w="2567"/><text x="75.7901%" y="190.50">MCTS_para_sear..</text></g><g><title>para_self_play (self_play.py:53) (21,815 samples, 85.08%)</title><rect x="0.5733%" y="132" width="85.0753%" height="15" fill="rgb(215,175,22)" fg:x="147" fg:w="21815"/><text x="0.8233%" y="142.50">para_self_play (self_play.py:53)</text></g><g><title>para_search (para_mcts.pyx:150) (21,815 samples, 85.08%)</title><rect x="0.5733%" y="148" width="85.0753%" height="15" fill="rgb(250,205,14)" fg:x="147" fg:w="21815"/><text x="0.8233%" y="158.50">para_search (para_mcts.pyx:150)</text></g><g><title>para_search (para_mcts.pyx:150) (21,815 samples, 85.08%)</title><rect x="0.5733%" y="164" width="85.0753%" height="15" fill="rgb(225,211,22)" fg:x="147" fg:w="21815"/><text x="0.8233%" y="174.50">para_search (para_mcts.pyx:150)</text></g><g><title>game_encoder_encode_game_state (game_encoder.pyx:56) (28 samples, 0.11%)</title><rect x="85.6641%" y="180" width="0.1092%" height="15" fill="rgb(251,179,42)" fg:x="21966" fg:w="28"/><text x="85.9141%" y="190.50"></text></g><g><title>para_self_play (self_play.py:57) (67 samples, 0.26%)</title><rect x="85.6485%" y="132" width="0.2613%" height="15" fill="rgb(208,216,51)" fg:x="21962" fg:w="67"/><text x="85.8985%" y="142.50"></text></g><g><title>encode_game_state (game_encoder.pyx:52) (66 samples, 0.26%)</title><rect x="85.6524%" y="148" width="0.2574%" height="15" fill="rgb(235,36,11)" fg:x="21963" fg:w="66"/><text x="85.9024%" y="158.50"></text></g><g><title>encode_game_state (game_encoder.pyx:52) (66 samples, 0.26%)</title><rect x="85.6524%" y="164" width="0.2574%" height="15" fill="rgb(213,189,28)" fg:x="21963" fg:w="66"/><text x="85.9024%" y="174.50"></text></g><g><title>__pyx_tp_dealloc_9para_mcts_Node (para_mcts.pyx:139) (33 samples, 0.13%)</title><rect x="86.4675%" y="388" width="0.1287%" height="15" fill="rgb(227,203,42)" fg:x="22172" fg:w="33"/><text x="86.7175%" y="398.50"></text></g><g><title>Py_DECREF (object.h:705) (32 samples, 0.12%)</title><rect x="86.4714%" y="404" width="0.1248%" height="15" fill="rgb(244,72,36)" fg:x="22173" fg:w="32"/><text x="86.7214%" y="414.50"></text></g><g><title>__pyx_tp_dealloc_9para_mcts_Node (para_mcts.pyx:139) (45 samples, 0.18%)</title><rect x="86.4246%" y="356" width="0.1755%" height="15" fill="rgb(213,53,17)" fg:x="22161" fg:w="45"/><text x="86.6746%" y="366.50"></text></g><g><title>Py_DECREF (object.h:705) (44 samples, 0.17%)</title><rect x="86.4285%" y="372" width="0.1716%" height="15" fill="rgb(207,167,3)" fg:x="22162" fg:w="44"/><text x="86.6785%" y="382.50"></text></g><g><title>MCTS_advance_tree (para_mcts.pyx:272) (142 samples, 0.55%)</title><rect x="86.0502%" y="180" width="0.5538%" height="15" fill="rgb(216,98,30)" fg:x="22065" fg:w="142"/><text x="86.3002%" y="190.50"></text></g><g><title>Py_XDECREF (object.h:798) (141 samples, 0.55%)</title><rect x="86.0541%" y="196" width="0.5499%" height="15" fill="rgb(236,123,15)" fg:x="22066" fg:w="141"/><text x="86.3041%" y="206.50"></text></g><g><title>Py_DECREF (object.h:705) (141 samples, 0.55%)</title><rect x="86.0541%" y="212" width="0.5499%" height="15" fill="rgb(248,81,50)" fg:x="22066" fg:w="141"/><text x="86.3041%" y="222.50"></text></g><g><title>__pyx_tp_dealloc_9para_mcts_Node (para_mcts.pyx:139) (137 samples, 0.53%)</title><rect x="86.0697%" y="228" width="0.5343%" height="15" fill="rgb(214,120,4)" fg:x="22070" fg:w="137"/><text x="86.3197%" y="238.50"></text></g><g><title>Py_DECREF (object.h:705) (137 samples, 0.53%)</title><rect x="86.0697%" y="244" width="0.5343%" height="15" fill="rgb(208,179,34)" fg:x="22070" fg:w="137"/><text x="86.3197%" y="254.50"></text></g><g><title>__pyx_tp_dealloc_9para_mcts_Node (para_mcts.pyx:139) (136 samples, 0.53%)</title><rect x="86.0736%" y="260" width="0.5304%" height="15" fill="rgb(227,140,7)" fg:x="22071" fg:w="136"/><text x="86.3236%" y="270.50"></text></g><g><title>Py_DECREF (object.h:705) (136 samples, 0.53%)</title><rect x="86.0736%" y="276" width="0.5304%" height="15" fill="rgb(214,22,6)" fg:x="22071" fg:w="136"/><text x="86.3236%" y="286.50"></text></g><g><title>__pyx_tp_dealloc_9para_mcts_Node (para_mcts.pyx:139) (133 samples, 0.52%)</title><rect x="86.0853%" y="292" width="0.5187%" height="15" fill="rgb(207,137,27)" fg:x="22074" fg:w="133"/><text x="86.3353%" y="302.50"></text></g><g><title>Py_DECREF (object.h:705) (133 samples, 0.52%)</title><rect x="86.0853%" y="308" width="0.5187%" height="15" fill="rgb(210,8,46)" fg:x="22074" fg:w="133"/><text x="86.3353%" y="318.50"></text></g><g><title>__pyx_tp_dealloc_9para_mcts_Node (para_mcts.pyx:139) (112 samples, 0.44%)</title><rect x="86.1672%" y="324" width="0.4368%" height="15" fill="rgb(240,16,54)" fg:x="22095" fg:w="112"/><text x="86.4172%" y="334.50"></text></g><g><title>Py_DECREF (object.h:705) (112 samples, 0.44%)</title><rect x="86.1672%" y="340" width="0.4368%" height="15" fill="rgb(211,209,29)" fg:x="22095" fg:w="112"/><text x="86.4172%" y="350.50"></text></g><g><title>Py_XDECREF (object.h:798) (156 samples, 0.61%)</title><rect x="86.6235%" y="196" width="0.6084%" height="15" fill="rgb(226,228,24)" fg:x="22212" fg:w="156"/><text x="86.8735%" y="206.50"></text></g><g><title>Py_DECREF (object.h:705) (156 samples, 0.61%)</title><rect x="86.6235%" y="212" width="0.6084%" height="15" fill="rgb(222,84,9)" fg:x="22212" fg:w="156"/><text x="86.8735%" y="222.50"></text></g><g><title>__pyx_tp_dealloc_9para_mcts_Node (para_mcts.pyx:139) (153 samples, 0.60%)</title><rect x="86.6352%" y="228" width="0.5967%" height="15" fill="rgb(234,203,30)" fg:x="22215" fg:w="153"/><text x="86.8852%" y="238.50"></text></g><g><title>Py_DECREF (object.h:705) (153 samples, 0.60%)</title><rect x="86.6352%" y="244" width="0.5967%" height="15" fill="rgb(238,109,14)" fg:x="22215" fg:w="153"/><text x="86.8852%" y="254.50"></text></g><g><title>__pyx_tp_dealloc_9para_mcts_Node (para_mcts.pyx:139) (150 samples, 0.58%)</title><rect x="86.6469%" y="260" width="0.5850%" height="15" fill="rgb(233,206,34)" fg:x="22218" fg:w="150"/><text x="86.8969%" y="270.50"></text></g><g><title>Py_DECREF (object.h:705) (148 samples, 0.58%)</title><rect x="86.6547%" y="276" width="0.5772%" height="15" fill="rgb(220,167,47)" fg:x="22220" fg:w="148"/><text x="86.9047%" y="286.50"></text></g><g><title>__pyx_tp_dealloc_9para_mcts_Node (para_mcts.pyx:139) (138 samples, 0.54%)</title><rect x="86.6937%" y="292" width="0.5382%" height="15" fill="rgb(238,105,10)" fg:x="22230" fg:w="138"/><text x="86.9437%" y="302.50"></text></g><g><title>Py_DECREF (object.h:705) (134 samples, 0.52%)</title><rect x="86.7093%" y="308" width="0.5226%" height="15" fill="rgb(213,227,17)" fg:x="22234" fg:w="134"/><text x="86.9593%" y="318.50"></text></g><g><title>__pyx_tp_dealloc_9para_mcts_Node (para_mcts.pyx:139) (112 samples, 0.44%)</title><rect x="86.7951%" y="324" width="0.4368%" height="15" fill="rgb(217,132,38)" fg:x="22256" fg:w="112"/><text x="87.0451%" y="334.50"></text></g><g><title>Py_DECREF (object.h:705) (109 samples, 0.43%)</title><rect x="86.8068%" y="340" width="0.4251%" height="15" fill="rgb(242,146,4)" fg:x="22259" fg:w="109"/><text x="87.0568%" y="350.50"></text></g><g><title>__pyx_tp_dealloc_9para_mcts_Node (para_mcts.pyx:139) (56 samples, 0.22%)</title><rect x="87.0135%" y="356" width="0.2184%" height="15" fill="rgb(212,61,9)" fg:x="22312" fg:w="56"/><text x="87.2635%" y="366.50"></text></g><g><title>Py_DECREF (object.h:705) (53 samples, 0.21%)</title><rect x="87.0252%" y="372" width="0.2067%" height="15" fill="rgb(247,126,22)" fg:x="22315" fg:w="53"/><text x="87.2752%" y="382.50"></text></g><g><title>MCTS_advance_tree (para_mcts.pyx:291) (157 samples, 0.61%)</title><rect x="86.6235%" y="180" width="0.6123%" height="15" fill="rgb(220,196,2)" fg:x="22212" fg:w="157"/><text x="86.8735%" y="190.50"></text></g><g><title>advance_tree (para_mcts.pyx:272) (329 samples, 1.28%)</title><rect x="86.0502%" y="148" width="1.2831%" height="15" fill="rgb(208,46,4)" fg:x="22065" fg:w="329"/><text x="86.3002%" y="158.50"></text></g><g><title>advance_tree (para_mcts.pyx:272) (329 samples, 1.28%)</title><rect x="86.0502%" y="164" width="1.2831%" height="15" fill="rgb(252,104,46)" fg:x="22065" fg:w="329"/><text x="86.3002%" y="174.50"></text></g><g><title>para_self_play (self_play.py:83) (331 samples, 1.29%)</title><rect x="86.0502%" y="132" width="1.2909%" height="15" fill="rgb(237,152,48)" fg:x="22065" fg:w="331"/><text x="86.3002%" y="142.50"></text></g><g><title>learn (self_play.py:229) (22,253 samples, 86.78%)</title><rect x="0.5655%" y="116" width="86.7834%" height="15" fill="rgb(221,59,37)" fg:x="145" fg:w="22253"/><text x="0.8155%" y="126.50">learn (self_play.py:229)</text></g><g><title>THPVariable_subclass_dealloc (libtorch_python.so) (29 samples, 0.11%)</title><rect x="87.6648%" y="132" width="0.1131%" height="15" fill="rgb(209,202,51)" fg:x="22479" fg:w="29"/><text x="87.9148%" y="142.50"></text></g><g><title>THPVariable_subclass_clear (libtorch_python.so) (29 samples, 0.11%)</title><rect x="87.6648%" y="148" width="0.1131%" height="15" fill="rgb(228,81,30)" fg:x="22479" fg:w="29"/><text x="87.9148%" y="158.50"></text></g><g><title>c10::TensorImpl::~TensorImpl (libc10.so) (28 samples, 0.11%)</title><rect x="87.6687%" y="164" width="0.1092%" height="15" fill="rgb(227,42,39)" fg:x="22480" fg:w="28"/><text x="87.9187%" y="174.50"></text></g><g><title>c10::TensorImpl::~TensorImpl (libc10.so) (28 samples, 0.11%)</title><rect x="87.6687%" y="180" width="0.1092%" height="15" fill="rgb(221,26,2)" fg:x="22480" fg:w="28"/><text x="87.9187%" y="190.50"></text></g><g><title>torch::autograd::AutogradMeta::~AutogradMeta (libtorch_cpu.so) (28 samples, 0.11%)</title><rect x="87.6687%" y="196" width="0.1092%" height="15" fill="rgb(254,61,31)" fg:x="22480" fg:w="28"/><text x="87.9187%" y="206.50"></text></g><g><title>torch::autograd::AutogradMeta::~AutogradMeta (libtorch_cpu.so) (28 samples, 0.11%)</title><rect x="87.6687%" y="212" width="0.1092%" height="15" fill="rgb(222,173,38)" fg:x="22480" fg:w="28"/><text x="87.9187%" y="222.50"></text></g><g><title>std::_Sp_counted_base&lt;(__gnu_cxx::_Lock_policy)2&gt;::_M_release_last_use_cold (libtorch_cpu.so) (28 samples, 0.11%)</title><rect x="87.6687%" y="228" width="0.1092%" height="15" fill="rgb(218,50,12)" fg:x="22480" fg:w="28"/><text x="87.9187%" y="238.50"></text></g><g><title>std::_Sp_counted_deleter&lt;torch::autograd::generated::AddBackward0*, void (*)(torch::autograd::Node*), std::allocator&lt;void&gt;, (__gnu_cxx::_Lock_policy)2&gt;::_M_dispose (libtorch_cpu.so) (28 samples, 0.11%)</title><rect x="87.6687%" y="244" width="0.1092%" height="15" fill="rgb(223,88,40)" fg:x="22480" fg:w="28"/><text x="87.9187%" y="254.50"></text></g><g><title>torch::autograd::deleteNode (libtorch_cpu.so) (28 samples, 0.11%)</title><rect x="87.6687%" y="260" width="0.1092%" height="15" fill="rgb(237,54,19)" fg:x="22480" fg:w="28"/><text x="87.9187%" y="270.50"></text></g><g><title>_sa_block (torch/nn/modules/transformer.py:949) (47 samples, 0.18%)</title><rect x="87.8598%" y="292" width="0.1833%" height="15" fill="rgb(251,129,25)" fg:x="22529" fg:w="47"/><text x="88.1098%" y="302.50"></text></g><g><title>_wrapped_call_impl (torch/nn/modules/module.py:1773) (46 samples, 0.18%)</title><rect x="87.8637%" y="308" width="0.1794%" height="15" fill="rgb(238,97,19)" fg:x="22530" fg:w="46"/><text x="88.1137%" y="318.50"></text></g><g><title>_call_impl (torch/nn/modules/module.py:1784) (46 samples, 0.18%)</title><rect x="87.8637%" y="324" width="0.1794%" height="15" fill="rgb(240,169,18)" fg:x="22530" fg:w="46"/><text x="88.1137%" y="334.50"></text></g><g><title>forward (torch/nn/modules/activation.py:1380) (43 samples, 0.17%)</title><rect x="87.8754%" y="340" width="0.1677%" height="15" fill="rgb(230,187,49)" fg:x="22533" fg:w="43"/><text x="88.1254%" y="350.50"></text></g><g><title>forward (torch/nn/modules/transformer.py:935) (55 samples, 0.21%)</title><rect x="87.8598%" y="276" width="0.2145%" height="15" fill="rgb(209,44,26)" fg:x="22529" fg:w="55"/><text x="88.1098%" y="286.50"></text></g><g><title>forward (armada_net.py:156) (105 samples, 0.41%)</title><rect x="87.8013%" y="180" width="0.4095%" height="15" fill="rgb(244,0,6)" fg:x="22514" fg:w="105"/><text x="88.0513%" y="190.50"></text></g><g><title>_wrapped_call_impl (torch/nn/modules/module.py:1773) (105 samples, 0.41%)</title><rect x="87.8013%" y="196" width="0.4095%" height="15" fill="rgb(248,18,21)" fg:x="22514" fg:w="105"/><text x="88.0513%" y="206.50"></text></g><g><title>_call_impl (torch/nn/modules/module.py:1784) (105 samples, 0.41%)</title><rect x="87.8013%" y="212" width="0.4095%" height="15" fill="rgb(245,180,19)" fg:x="22514" fg:w="105"/><text x="88.0513%" y="222.50"></text></g><g><title>forward (torch/nn/modules/transformer.py:524) (103 samples, 0.40%)</title><rect x="87.8091%" y="228" width="0.4017%" height="15" fill="rgb(252,118,36)" fg:x="22516" fg:w="103"/><text x="88.0591%" y="238.50"></text></g><g><title>_wrapped_call_impl (torch/nn/modules/module.py:1773) (103 samples, 0.40%)</title><rect x="87.8091%" y="244" width="0.4017%" height="15" fill="rgb(210,224,19)" fg:x="22516" fg:w="103"/><text x="88.0591%" y="254.50"></text></g><g><title>_call_impl (torch/nn/modules/module.py:1784) (102 samples, 0.40%)</title><rect x="87.8130%" y="260" width="0.3978%" height="15" fill="rgb(218,30,24)" fg:x="22517" fg:w="102"/><text x="88.0630%" y="270.50"></text></g><g><title>forward (torch/nn/modules/transformer.py:937) (35 samples, 0.14%)</title><rect x="88.0743%" y="276" width="0.1365%" height="15" fill="rgb(219,75,50)" fg:x="22584" fg:w="35"/><text x="88.3243%" y="286.50"></text></g><g><title>_sa_block (torch/nn/modules/transformer.py:949) (52 samples, 0.20%)</title><rect x="88.2809%" y="292" width="0.2028%" height="15" fill="rgb(234,72,50)" fg:x="22637" fg:w="52"/><text x="88.5309%" y="302.50"></text></g><g><title>_wrapped_call_impl (torch/nn/modules/module.py:1773) (52 samples, 0.20%)</title><rect x="88.2809%" y="308" width="0.2028%" height="15" fill="rgb(219,100,48)" fg:x="22637" fg:w="52"/><text x="88.5309%" y="318.50"></text></g><g><title>_call_impl (torch/nn/modules/module.py:1784) (50 samples, 0.19%)</title><rect x="88.2887%" y="324" width="0.1950%" height="15" fill="rgb(253,5,41)" fg:x="22639" fg:w="50"/><text x="88.5387%" y="334.50"></text></g><g><title>forward (torch/nn/modules/activation.py:1380) (48 samples, 0.19%)</title><rect x="88.2965%" y="340" width="0.1872%" height="15" fill="rgb(247,181,11)" fg:x="22641" fg:w="48"/><text x="88.5465%" y="350.50"></text></g><g><title>forward (torch/nn/modules/transformer.py:935) (63 samples, 0.25%)</title><rect x="88.2770%" y="276" width="0.2457%" height="15" fill="rgb(222,223,25)" fg:x="22636" fg:w="63"/><text x="88.5270%" y="286.50"></text></g><g><title>forward (armada_net.py:161) (103 samples, 0.40%)</title><rect x="88.2419%" y="180" width="0.4017%" height="15" fill="rgb(214,198,28)" fg:x="22627" fg:w="103"/><text x="88.4919%" y="190.50"></text></g><g><title>_wrapped_call_impl (torch/nn/modules/module.py:1773) (103 samples, 0.40%)</title><rect x="88.2419%" y="196" width="0.4017%" height="15" fill="rgb(230,46,43)" fg:x="22627" fg:w="103"/><text x="88.4919%" y="206.50"></text></g><g><title>_call_impl (torch/nn/modules/module.py:1784) (103 samples, 0.40%)</title><rect x="88.2419%" y="212" width="0.4017%" height="15" fill="rgb(233,65,53)" fg:x="22627" fg:w="103"/><text x="88.4919%" y="222.50"></text></g><g><title>forward (torch/nn/modules/transformer.py:524) (103 samples, 0.40%)</title><rect x="88.2419%" y="228" width="0.4017%" height="15" fill="rgb(221,121,27)" fg:x="22627" fg:w="103"/><text x="88.4919%" y="238.50"></text></g><g><title>_wrapped_call_impl (torch/nn/modules/module.py:1773) (103 samples, 0.40%)</title><rect x="88.2419%" y="244" width="0.4017%" height="15" fill="rgb(247,70,47)" fg:x="22627" fg:w="103"/><text x="88.4919%" y="254.50"></text></g><g><title>_call_impl (torch/nn/modules/module.py:1784) (103 samples, 0.40%)</title><rect x="88.2419%" y="260" width="0.4017%" height="15" fill="rgb(228,85,35)" fg:x="22627" fg:w="103"/><text x="88.4919%" y="270.50"></text></g><g><title>forward (torch/nn/modules/transformer.py:937) (31 samples, 0.12%)</title><rect x="88.5227%" y="276" width="0.1209%" height="15" fill="rgb(209,50,18)" fg:x="22699" fg:w="31"/><text x="88.7727%" y="286.50"></text></g><g><title>forward (armada_net.py:167) (71 samples, 0.28%)</title><rect x="88.6475%" y="180" width="0.2769%" height="15" fill="rgb(250,19,35)" fg:x="22731" fg:w="71"/><text x="88.8975%" y="190.50"></text></g><g><title>_wrapped_call_impl (torch/nn/modules/module.py:1773) (71 samples, 0.28%)</title><rect x="88.6475%" y="196" width="0.2769%" height="15" fill="rgb(253,107,29)" fg:x="22731" fg:w="71"/><text x="88.8975%" y="206.50"></text></g><g><title>_call_impl (torch/nn/modules/module.py:1784) (71 samples, 0.28%)</title><rect x="88.6475%" y="212" width="0.2769%" height="15" fill="rgb(252,179,29)" fg:x="22731" fg:w="71"/><text x="88.8975%" y="222.50"></text></g><g><title>forward (torch/nn/modules/container.py:244) (70 samples, 0.27%)</title><rect x="88.6514%" y="228" width="0.2730%" height="15" fill="rgb(238,194,6)" fg:x="22732" fg:w="70"/><text x="88.9014%" y="238.50"></text></g><g><title>_wrapped_call_impl (torch/nn/modules/module.py:1773) (70 samples, 0.27%)</title><rect x="88.6514%" y="244" width="0.2730%" height="15" fill="rgb(238,164,29)" fg:x="22732" fg:w="70"/><text x="88.9014%" y="254.50"></text></g><g><title>_call_impl (torch/nn/modules/module.py:1784) (67 samples, 0.26%)</title><rect x="88.6631%" y="260" width="0.2613%" height="15" fill="rgb(224,25,9)" fg:x="22735" fg:w="67"/><text x="88.9131%" y="270.50"></text></g><g><title>forward (armada_net.py:202) (50 samples, 0.19%)</title><rect x="89.0648%" y="180" width="0.1950%" height="15" fill="rgb(244,153,23)" fg:x="22838" fg:w="50"/><text x="89.3148%" y="190.50"></text></g><g><title>torch::autograd::THPVariable_getitem (libtorch_python.so) (50 samples, 0.19%)</title><rect x="89.0648%" y="196" width="0.1950%" height="15" fill="rgb(212,203,14)" fg:x="22838" fg:w="50"/><text x="89.3148%" y="206.50"></text></g><g><title>torch::autograd::applySlicing (libtorch_python.so) (29 samples, 0.11%)</title><rect x="89.1467%" y="212" width="0.1131%" height="15" fill="rgb(220,164,20)" fg:x="22859" fg:w="29"/><text x="89.3967%" y="222.50"></text></g><g><title>torch::utils::indexing_tensor_from_data (libtorch_python.so) (29 samples, 0.11%)</title><rect x="89.1467%" y="228" width="0.1131%" height="15" fill="rgb(222,203,48)" fg:x="22859" fg:w="29"/><text x="89.3967%" y="238.50"></text></g><g><title>torch::utils::(anonymous namespace)::internal_new_from_data (libtorch_python.so) (27 samples, 0.11%)</title><rect x="89.1545%" y="244" width="0.1053%" height="15" fill="rgb(215,159,22)" fg:x="22861" fg:w="27"/><text x="89.4045%" y="254.50"></text></g><g><title>at::_ops::relu::call (libtorch_cpu.so) (29 samples, 0.11%)</title><rect x="89.3651%" y="324" width="0.1131%" height="15" fill="rgb(216,183,47)" fg:x="22915" fg:w="29"/><text x="89.6151%" y="334.50"></text></g><g><title>c10::impl::wrap_kernel_functor_unboxed_&lt;c10::impl::detail::WrapFunctionIntoFunctor_&lt;c10::CompileTimeFunctionPointer&lt;at::Tensor(c10::DispatchKeySet, at::Tensor const&amp;), &amp;torch::autograd::VariableType::(anonymous namespace)::relu(c10::DispatchKeySet, at::Tensor const&amp;)&gt;, at::Tensor, c10::guts::typelist::typelist&lt;c10::DispatchKeySet, at::Tensor const&amp;&gt; &gt;, at::Tensor(c10::DispatchKeySet, at::Tensor const&amp;)&gt;::call (libtorch_cpu.so) (29 samples, 0.11%)</title><rect x="89.3651%" y="340" width="0.1131%" height="15" fill="rgb(229,195,25)" fg:x="22915" fg:w="29"/><text x="89.6151%" y="350.50"></text></g><g><title>torch::autograd::VariableType::(anonymous namespace)::relu (libtorch_cpu.so) (29 samples, 0.11%)</title><rect x="89.3651%" y="356" width="0.1131%" height="15" fill="rgb(224,132,51)" fg:x="22915" fg:w="29"/><text x="89.6151%" y="366.50"></text></g><g><title>forward (torch/nn/modules/activation.py:135) (37 samples, 0.14%)</title><rect x="89.3495%" y="276" width="0.1443%" height="15" fill="rgb(240,63,7)" fg:x="22911" fg:w="37"/><text x="89.5995%" y="286.50"></text></g><g><title>relu (torch/nn/functional.py:1701) (34 samples, 0.13%)</title><rect x="89.3612%" y="292" width="0.1326%" height="15" fill="rgb(249,182,41)" fg:x="22914" fg:w="34"/><text x="89.6112%" y="302.50"></text></g><g><title>torch::autograd::THPVariable_relu (libtorch_python.so) (34 samples, 0.13%)</title><rect x="89.3612%" y="308" width="0.1326%" height="15" fill="rgb(243,47,26)" fg:x="22914" fg:w="34"/><text x="89.6112%" y="318.50"></text></g><g><title>at::cuda::blas::gemm_and_bias&lt;float, float&gt; (libtorch_cuda.so) (40 samples, 0.16%)</title><rect x="89.5484%" y="484" width="0.1560%" height="15" fill="rgb(233,48,2)" fg:x="22962" fg:w="40"/><text x="89.7984%" y="494.50"></text></g><g><title>at::_ops::addmm::redispatch (libtorch_cpu.so) (52 samples, 0.20%)</title><rect x="89.5094%" y="404" width="0.2028%" height="15" fill="rgb(244,165,34)" fg:x="22952" fg:w="52"/><text x="89.7594%" y="414.50"></text></g><g><title>c10::impl::wrap_kernel_functor_unboxed_&lt;c10::impl::detail::WrapFunctionIntoFunctor_&lt;c10::CompileTimeFunctionPointer&lt;at::Tensor(at::Tensor const&amp;, at::Tensor const&amp;, at::Tensor const&amp;, c10::Scalar const&amp;, c10::Scalar const&amp;), &amp;at::(anonymous namespace)::wrapper_CUDA_addmm(at::Tensor const&amp;, at::Tensor const&amp;, at::Tensor const&amp;, c10::Scalar const&amp;, c10::Scalar const&amp;)&gt;, at::Tensor, c10::guts::typelist::typelist&lt;at::Tensor const&amp;, at::Tensor const&amp;, at::Tensor const&amp;, c10::Scalar const&amp;, c10::Scalar const&amp;&gt; &gt;, at::Tensor(at::Tensor const&amp;, at::Tensor const&amp;, at::Tensor const&amp;, c10::Scalar const&amp;, c10::Scalar const&amp;)&gt;::call (libtorch_cuda.so) (52 samples, 0.20%)</title><rect x="89.5094%" y="420" width="0.2028%" height="15" fill="rgb(207,89,7)" fg:x="22952" fg:w="52"/><text x="89.7594%" y="430.50"></text></g><g><title>at::(anonymous namespace)::wrapper_CUDA_addmm (libtorch_cuda.so) (52 samples, 0.20%)</title><rect x="89.5094%" y="436" width="0.2028%" height="15" fill="rgb(244,117,36)" fg:x="22952" fg:w="52"/><text x="89.7594%" y="446.50"></text></g><g><title>at::native::structured_addmm_out_cuda::impl (libtorch_cuda.so) (43 samples, 0.17%)</title><rect x="89.5445%" y="452" width="0.1677%" height="15" fill="rgb(226,144,34)" fg:x="22961" fg:w="43"/><text x="89.7945%" y="462.50"></text></g><g><title>at::native::(anonymous namespace)::addmm_out_cuda_impl (libtorch_cuda.so) (43 samples, 0.17%)</title><rect x="89.5445%" y="468" width="0.1677%" height="15" fill="rgb(213,23,19)" fg:x="22961" fg:w="43"/><text x="89.7945%" y="478.50"></text></g><g><title>at::_ops::addmm::call (libtorch_cpu.so) (58 samples, 0.23%)</title><rect x="89.5094%" y="356" width="0.2262%" height="15" fill="rgb(217,75,12)" fg:x="22952" fg:w="58"/><text x="89.7594%" y="366.50"></text></g><g><title>c10::impl::wrap_kernel_functor_unboxed_&lt;c10::impl::detail::WrapFunctionIntoFunctor_&lt;c10::CompileTimeFunctionPointer&lt;at::Tensor(c10::DispatchKeySet, at::Tensor const&amp;, at::Tensor const&amp;, at::Tensor const&amp;, c10::Scalar const&amp;, c10::Scalar const&amp;), &amp;torch::autograd::VariableType::(anonymous namespace)::addmm(c10::DispatchKeySet, at::Tensor const&amp;, at::Tensor const&amp;, at::Tensor const&amp;, c10::Scalar const&amp;, c10::Scalar const&amp;)&gt;, at::Tensor, c10::guts::typelist::typelist&lt;c10::DispatchKeySet, at::Tensor const&amp;, at::Tensor const&amp;, at::Tensor const&amp;, c10::Scalar const&amp;, c10::Scalar const&amp;&gt; &gt;, at::Tensor(c10::DispatchKeySet, at::Tensor const&amp;, at::Tensor const&amp;, at::Tensor const&amp;, c10::Scalar const&amp;, c10::Scalar const&amp;)&gt;::call (libtorch_cpu.so) (58 samples, 0.23%)</title><rect x="89.5094%" y="372" width="0.2262%" height="15" fill="rgb(224,159,17)" fg:x="22952" fg:w="58"/><text x="89.7594%" y="382.50"></text></g><g><title>torch::autograd::VariableType::(anonymous namespace)::addmm (libtorch_cpu.so) (58 samples, 0.23%)</title><rect x="89.5094%" y="388" width="0.2262%" height="15" fill="rgb(217,118,1)" fg:x="22952" fg:w="58"/><text x="89.7594%" y="398.50"></text></g><g><title>at::_ops::linear::call (libtorch_cpu.so) (75 samples, 0.29%)</title><rect x="89.5055%" y="308" width="0.2925%" height="15" fill="rgb(232,180,48)" fg:x="22951" fg:w="75"/><text x="89.7555%" y="318.50"></text></g><g><title>c10::impl::wrap_kernel_functor_unboxed_&lt;c10::impl::detail::WrapFunctionIntoFunctor_&lt;c10::CompileTimeFunctionPointer&lt;at::Tensor(at::Tensor const&amp;, at::Tensor const&amp;, std::optional&lt;at::Tensor&gt; const&amp;), &amp;at::(anonymous namespace)::(anonymous namespace)::wrapper_CompositeImplicitAutograd__linear(at::Tensor const&amp;, at::Tensor const&amp;, std::optional&lt;at::Tensor&gt; const&amp;)&gt;, at::Tensor, c10::guts::typelist::typelist&lt;at::Tensor const&amp;, at::Tensor const&amp;, std::optional&lt;at::Tensor&gt; const&amp;&gt; &gt;, at::Tensor(at::Tensor const&amp;, at::Tensor const&amp;, std::optional&lt;at::Tensor&gt; const&amp;)&gt;::call (libtorch_cpu.so) (75 samples, 0.29%)</title><rect x="89.5055%" y="324" width="0.2925%" height="15" fill="rgb(230,27,33)" fg:x="22951" fg:w="75"/><text x="89.7555%" y="334.50"></text></g><g><title>at::native::linear (libtorch_cpu.so) (75 samples, 0.29%)</title><rect x="89.5055%" y="340" width="0.2925%" height="15" fill="rgb(205,31,21)" fg:x="22951" fg:w="75"/><text x="89.7555%" y="350.50"></text></g><g><title>forward (armada_net.py:205) (141 samples, 0.55%)</title><rect x="89.2598%" y="180" width="0.5499%" height="15" fill="rgb(253,59,4)" fg:x="22888" fg:w="141"/><text x="89.5098%" y="190.50"></text></g><g><title>_wrapped_call_impl (torch/nn/modules/module.py:1773) (138 samples, 0.54%)</title><rect x="89.2715%" y="196" width="0.5382%" height="15" fill="rgb(224,201,9)" fg:x="22891" fg:w="138"/><text x="89.5215%" y="206.50"></text></g><g><title>_call_impl (torch/nn/modules/module.py:1784) (136 samples, 0.53%)</title><rect x="89.2793%" y="212" width="0.5304%" height="15" fill="rgb(229,206,30)" fg:x="22893" fg:w="136"/><text x="89.5293%" y="222.50"></text></g><g><title>forward (torch/nn/modules/container.py:244) (136 samples, 0.53%)</title><rect x="89.2793%" y="228" width="0.5304%" height="15" fill="rgb(212,67,47)" fg:x="22893" fg:w="136"/><text x="89.5293%" y="238.50"></text></g><g><title>_wrapped_call_impl (torch/nn/modules/module.py:1773) (133 samples, 0.52%)</title><rect x="89.2910%" y="244" width="0.5187%" height="15" fill="rgb(211,96,50)" fg:x="22896" fg:w="133"/><text x="89.5410%" y="254.50"></text></g><g><title>_call_impl (torch/nn/modules/module.py:1784) (119 samples, 0.46%)</title><rect x="89.3456%" y="260" width="0.4641%" height="15" fill="rgb(252,114,18)" fg:x="22910" fg:w="119"/><text x="89.5956%" y="270.50"></text></g><g><title>forward (torch/nn/modules/linear.py:125) (81 samples, 0.32%)</title><rect x="89.4938%" y="276" width="0.3159%" height="15" fill="rgb(223,58,37)" fg:x="22948" fg:w="81"/><text x="89.7438%" y="286.50"></text></g><g><title>torch::autograd::THPVariable_linear (libtorch_python.so) (80 samples, 0.31%)</title><rect x="89.4977%" y="292" width="0.3120%" height="15" fill="rgb(237,70,4)" fg:x="22949" fg:w="80"/><text x="89.7477%" y="302.50"></text></g><g><title>at::_ops::index_put_::call (libtorch_cpu.so) (28 samples, 0.11%)</title><rect x="89.8214%" y="228" width="0.1092%" height="15" fill="rgb(244,85,46)" fg:x="23032" fg:w="28"/><text x="90.0714%" y="238.50"></text></g><g><title>torch::autograd::VariableType::(anonymous namespace)::index_put_ (libtorch_cpu.so) (26 samples, 0.10%)</title><rect x="89.8292%" y="244" width="0.1014%" height="15" fill="rgb(223,39,52)" fg:x="23034" fg:w="26"/><text x="90.0792%" y="254.50"></text></g><g><title>at::indexing::dispatch_index_put_ (libtorch_python.so) (29 samples, 0.11%)</title><rect x="89.8214%" y="212" width="0.1131%" height="15" fill="rgb(218,200,14)" fg:x="23032" fg:w="29"/><text x="90.0714%" y="222.50"></text></g><g><title>forward (armada_net.py:209) (61 samples, 0.24%)</title><rect x="89.8097%" y="180" width="0.2379%" height="15" fill="rgb(208,171,16)" fg:x="23029" fg:w="61"/><text x="90.0597%" y="190.50"></text></g><g><title>torch::autograd::THPVariable_setitem (libtorch_python.so) (59 samples, 0.23%)</title><rect x="89.8175%" y="196" width="0.2301%" height="15" fill="rgb(234,200,18)" fg:x="23031" fg:w="59"/><text x="90.0675%" y="206.50"></text></g><g><title>torch::autograd::applySlicing (libtorch_python.so) (28 samples, 0.11%)</title><rect x="89.9384%" y="212" width="0.1092%" height="15" fill="rgb(228,45,11)" fg:x="23062" fg:w="28"/><text x="90.1884%" y="222.50"></text></g><g><title>train (self_play.py:139) (606 samples, 2.36%)</title><rect x="87.7779%" y="132" width="2.3633%" height="15" fill="rgb(237,182,11)" fg:x="22508" fg:w="606"/><text x="88.0279%" y="142.50">tr..</text></g><g><title>_wrapped_call_impl (torch/nn/modules/module.py:1773) (606 samples, 2.36%)</title><rect x="87.7779%" y="148" width="2.3633%" height="15" fill="rgb(241,175,49)" fg:x="22508" fg:w="606"/><text x="88.0279%" y="158.50">_w..</text></g><g><title>_call_impl (torch/nn/modules/module.py:1784) (606 samples, 2.36%)</title><rect x="87.7779%" y="164" width="2.3633%" height="15" fill="rgb(247,38,35)" fg:x="22508" fg:w="606"/><text x="88.0279%" y="174.50">_c..</text></g><g><title>train (self_play.py:167) (39 samples, 0.15%)</title><rect x="90.1880%" y="132" width="0.1521%" height="15" fill="rgb(228,39,49)" fg:x="23126" fg:w="39"/><text x="90.4380%" y="142.50"></text></g><g><title>torch::autograd::THPVariable_getitem (libtorch_python.so) (39 samples, 0.15%)</title><rect x="90.1880%" y="148" width="0.1521%" height="15" fill="rgb(226,101,26)" fg:x="23126" fg:w="39"/><text x="90.4380%" y="158.50"></text></g><g><title>train (self_play.py:169) (35 samples, 0.14%)</title><rect x="90.3401%" y="132" width="0.1365%" height="15" fill="rgb(206,141,19)" fg:x="23165" fg:w="35"/><text x="90.5901%" y="142.50"></text></g><g><title>torch::autograd::THPVariable_getitem (libtorch_python.so) (35 samples, 0.14%)</title><rect x="90.3401%" y="148" width="0.1365%" height="15" fill="rgb(211,200,13)" fg:x="23165" fg:w="35"/><text x="90.5901%" y="158.50"></text></g><g><title>train (self_play.py:175) (57 samples, 0.22%)</title><rect x="90.5546%" y="132" width="0.2223%" height="15" fill="rgb(241,121,6)" fg:x="23220" fg:w="57"/><text x="90.8046%" y="142.50"></text></g><g><title>parameters (torch/nn/modules/module.py:2673) (34 samples, 0.13%)</title><rect x="90.8158%" y="148" width="0.1326%" height="15" fill="rgb(234,221,29)" fg:x="23287" fg:w="34"/><text x="91.0658%" y="158.50"></text></g><g><title>named_parameters (torch/nn/modules/module.py:2706) (34 samples, 0.13%)</title><rect x="90.8158%" y="164" width="0.1326%" height="15" fill="rgb(229,136,5)" fg:x="23287" fg:w="34"/><text x="91.0658%" y="174.50"></text></g><g><title>train (self_play.py:189) (36 samples, 0.14%)</title><rect x="90.8119%" y="132" width="0.1404%" height="15" fill="rgb(238,36,11)" fg:x="23286" fg:w="36"/><text x="91.0619%" y="142.50"></text></g><g><title>at::detail::empty_cuda (libtorch_cuda.so) (27 samples, 0.11%)</title><rect x="91.1239%" y="388" width="0.1053%" height="15" fill="rgb(251,55,41)" fg:x="23366" fg:w="27"/><text x="91.3739%" y="398.50"></text></g><g><title>at::(anonymous namespace)::create_out (libtorch_cuda.so) (29 samples, 0.11%)</title><rect x="91.1200%" y="340" width="0.1131%" height="15" fill="rgb(242,34,40)" fg:x="23365" fg:w="29"/><text x="91.3700%" y="350.50"></text></g><g><title>at::detail::empty_cuda (libtorch_cuda.so) (28 samples, 0.11%)</title><rect x="91.1239%" y="356" width="0.1092%" height="15" fill="rgb(215,42,17)" fg:x="23366" fg:w="28"/><text x="91.3739%" y="366.50"></text></g><g><title>at::detail::empty_cuda (libtorch_cuda.so) (28 samples, 0.11%)</title><rect x="91.1239%" y="372" width="0.1092%" height="15" fill="rgb(207,44,46)" fg:x="23366" fg:w="28"/><text x="91.3739%" y="382.50"></text></g><g><title>at::TensorIteratorBase::fast_set_up (libtorch_cpu.so) (32 samples, 0.12%)</title><rect x="91.1200%" y="308" width="0.1248%" height="15" fill="rgb(211,206,28)" fg:x="23365" fg:w="32"/><text x="91.3700%" y="318.50"></text></g><g><title>at::(anonymous namespace)::structured_pow_Tensor_Scalar_out_functional::set_output_raw_strided (libtorch_cuda.so) (32 samples, 0.12%)</title><rect x="91.1200%" y="324" width="0.1248%" height="15" fill="rgb(237,167,16)" fg:x="23365" fg:w="32"/><text x="91.3700%" y="334.50"></text></g><g><title>at::TensorIteratorBase::build_output_borrowing_argument_owning_unary_op (libtorch_cpu.so) (38 samples, 0.15%)</title><rect x="91.1083%" y="276" width="0.1482%" height="15" fill="rgb(233,66,6)" fg:x="23362" fg:w="38"/><text x="91.3583%" y="286.50"></text></g><g><title>at::TensorIteratorBase::build (libtorch_cpu.so) (37 samples, 0.14%)</title><rect x="91.1122%" y="292" width="0.1443%" height="15" fill="rgb(246,123,29)" fg:x="23363" fg:w="37"/><text x="91.3622%" y="302.50"></text></g><g><title>at::meta::structured_pow_Tensor_Scalar::meta (libtorch_cpu.so) (42 samples, 0.16%)</title><rect x="91.1044%" y="260" width="0.1638%" height="15" fill="rgb(209,62,40)" fg:x="23361" fg:w="42"/><text x="91.3544%" y="270.50"></text></g><g><title>at::native::gpu_kernel_impl_nocast&lt;__nv_hdl_wrapper_t&lt;false, false, false, __nv_dl_tag&lt;void (*)(at::TensorIteratorBase&amp;, float), &amp;at::native::(anonymous namespace)::pow_tensor_scalar_kernel_impl&lt;float, float&gt;(at::TensorIteratorBase&amp;, float), (unsigned int)1&gt;, float (float), &gt; &gt; (libtorch_cuda.so) (45 samples, 0.18%)</title><rect x="91.2799%" y="276" width="0.1755%" height="15" fill="rgb(218,4,25)" fg:x="23406" fg:w="45"/><text x="91.5299%" y="286.50"></text></g><g><title>cudaLaunchKernel (nvidia/cuda_runtime/lib/libcudart.so.12) (35 samples, 0.14%)</title><rect x="91.3189%" y="292" width="0.1365%" height="15" fill="rgb(253,91,49)" fg:x="23416" fg:w="35"/><text x="91.5689%" y="302.50"></text></g><g><title>0x7ac5be415aa8 (nvidia/cuda_runtime/lib/libcudart.so.12) (31 samples, 0.12%)</title><rect x="91.3345%" y="308" width="0.1209%" height="15" fill="rgb(228,155,29)" fg:x="23420" fg:w="31"/><text x="91.5845%" y="318.50"></text></g><g><title>0x7ac4e00ef270 (libcuda.so.550.54.15) (31 samples, 0.12%)</title><rect x="91.3345%" y="324" width="0.1209%" height="15" fill="rgb(243,57,37)" fg:x="23420" fg:w="31"/><text x="91.5845%" y="334.50"></text></g><g><title>0x7ac4dff32a6f (libcuda.so.550.54.15) (28 samples, 0.11%)</title><rect x="91.3462%" y="340" width="0.1092%" height="15" fill="rgb(244,167,17)" fg:x="23423" fg:w="28"/><text x="91.5962%" y="350.50"></text></g><g><title>at::native::(anonymous namespace)::pow_tensor_scalar_kernel_impl&lt;float, float&gt; (libtorch_cuda.so) (50 samples, 0.19%)</title><rect x="91.2682%" y="260" width="0.1950%" height="15" fill="rgb(207,181,38)" fg:x="23403" fg:w="50"/><text x="91.5182%" y="270.50"></text></g><g><title>at::_ops::pow_Tensor_Scalar::redispatch (libtorch_cpu.so) (101 samples, 0.39%)</title><rect x="91.0888%" y="212" width="0.3939%" height="15" fill="rgb(211,8,23)" fg:x="23357" fg:w="101"/><text x="91.3388%" y="222.50"></text></g><g><title>c10::impl::wrap_kernel_functor_unboxed_&lt;c10::impl::detail::WrapFunctionIntoFunctor_&lt;c10::CompileTimeFunctionPointer&lt;at::Tensor(at::Tensor const&amp;, c10::Scalar const&amp;), &amp;at::(anonymous namespace)::wrapper_CUDA_pow_Tensor_Scalar(at::Tensor const&amp;, c10::Scalar const&amp;)&gt;, at::Tensor, c10::guts::typelist::typelist&lt;at::Tensor const&amp;, c10::Scalar const&amp;&gt; &gt;, at::Tensor(at::Tensor const&amp;, c10::Scalar const&amp;)&gt;::call (libtorch_cuda.so) (99 samples, 0.39%)</title><rect x="91.0966%" y="228" width="0.3861%" height="15" fill="rgb(235,11,44)" fg:x="23359" fg:w="99"/><text x="91.3466%" y="238.50"></text></g><g><title>at::(anonymous namespace)::wrapper_CUDA_pow_Tensor_Scalar (libtorch_cuda.so) (99 samples, 0.39%)</title><rect x="91.0966%" y="244" width="0.3861%" height="15" fill="rgb(248,18,52)" fg:x="23359" fg:w="99"/><text x="91.3466%" y="254.50"></text></g><g><title>at::_ops::pow_Tensor_Scalar::call (libtorch_cpu.so) (120 samples, 0.47%)</title><rect x="91.0849%" y="164" width="0.4680%" height="15" fill="rgb(208,4,7)" fg:x="23356" fg:w="120"/><text x="91.3349%" y="174.50"></text></g><g><title>c10::impl::wrap_kernel_functor_unboxed_&lt;c10::impl::detail::WrapFunctionIntoFunctor_&lt;c10::CompileTimeFunctionPointer&lt;at::Tensor(c10::DispatchKeySet, at::Tensor const&amp;, c10::Scalar const&amp;), &amp;torch::autograd::VariableType::(anonymous namespace)::pow_Tensor_Scalar(c10::DispatchKeySet, at::Tensor const&amp;, c10::Scalar const&amp;)&gt;, at::Tensor, c10::guts::typelist::typelist&lt;c10::DispatchKeySet, at::Tensor const&amp;, c10::Scalar const&amp;&gt; &gt;, at::Tensor(c10::DispatchKeySet, at::Tensor const&amp;, c10::Scalar const&amp;)&gt;::call (libtorch_cpu.so) (120 samples, 0.47%)</title><rect x="91.0849%" y="180" width="0.4680%" height="15" fill="rgb(240,17,39)" fg:x="23356" fg:w="120"/><text x="91.3349%" y="190.50"></text></g><g><title>torch::autograd::VariableType::(anonymous namespace)::pow_Tensor_Scalar (libtorch_cpu.so) (120 samples, 0.47%)</title><rect x="91.0849%" y="196" width="0.4680%" height="15" fill="rgb(207,170,3)" fg:x="23356" fg:w="120"/><text x="91.3349%" y="206.50"></text></g><g><title>torch::autograd::THPVariable_pow (libtorch_python.so) (136 samples, 0.53%)</title><rect x="91.0693%" y="148" width="0.5304%" height="15" fill="rgb(236,100,52)" fg:x="23352" fg:w="136"/><text x="91.3193%" y="158.50"></text></g><g><title>0x7ac5be415aa8 (nvidia/cuda_runtime/lib/libcudart.so.12) (28 samples, 0.11%)</title><rect x="91.8376%" y="356" width="0.1092%" height="15" fill="rgb(246,78,51)" fg:x="23549" fg:w="28"/><text x="92.0876%" y="366.50"></text></g><g><title>0x7ac4e00ef270 (libcuda.so.550.54.15) (27 samples, 0.11%)</title><rect x="91.8415%" y="372" width="0.1053%" height="15" fill="rgb(211,17,15)" fg:x="23550" fg:w="27"/><text x="92.0915%" y="382.50"></text></g><g><title>cudaLaunchKernel (nvidia/cuda_runtime/lib/libcudart.so.12) (34 samples, 0.13%)</title><rect x="91.8220%" y="340" width="0.1326%" height="15" fill="rgb(209,59,46)" fg:x="23545" fg:w="34"/><text x="92.0720%" y="350.50"></text></g><g><title>at::native::gpu_reduce_kernel&lt;float, float, 4, 4, at::native::func_wrapper_t&lt;float, __nv_hdl_wrapper_t&lt;false, true, false, __nv_dl_tag&lt;void (at::native::sum_functor&lt;float, float, float&gt;::*)(at::TensorIterator&amp;), &amp;at::native::sum_functor&lt;float, float, float&gt;(at::TensorIterator&amp;)::operator(), (unsigned int)1&gt;, float (float, float), &gt; &gt;, double&gt; (libtorch_cuda.so) (44 samples, 0.17%)</title><rect x="91.7869%" y="324" width="0.1716%" height="15" fill="rgb(210,92,25)" fg:x="23536" fg:w="44"/><text x="92.0369%" y="334.50"></text></g><g><title>at::native::structured_sum_out::impl (libtorch_cpu.so) (64 samples, 0.25%)</title><rect x="91.7128%" y="308" width="0.2496%" height="15" fill="rgb(238,174,52)" fg:x="23517" fg:w="64"/><text x="91.9628%" y="318.50"></text></g><g><title>at::_ops::sum::redispatch (libtorch_cpu.so) (87 samples, 0.34%)</title><rect x="91.6309%" y="212" width="0.3393%" height="15" fill="rgb(230,73,7)" fg:x="23496" fg:w="87"/><text x="91.8809%" y="222.50"></text></g><g><title>c10::impl::wrap_kernel_functor_unboxed_&lt;c10::impl::detail::WrapFunctionIntoFunctor_&lt;c10::CompileTimeFunctionPointer&lt;at::Tensor(at::Tensor const&amp;, std::optional&lt;c10::ScalarType&gt;), &amp;at::(anonymous namespace)::(anonymous namespace)::wrapper_CompositeExplicitAutograd__sum(at::Tensor const&amp;, std::optional&lt;c10::ScalarType&gt;)&gt;, at::Tensor, c10::guts::typelist::typelist&lt;at::Tensor const&amp;, std::optional&lt;c10::ScalarType&gt; &gt; &gt;, at::Tensor(at::Tensor const&amp;, std::optional&lt;c10::ScalarType&gt;)&gt;::call (libtorch_cpu.so) (86 samples, 0.34%)</title><rect x="91.6348%" y="228" width="0.3354%" height="15" fill="rgb(243,124,40)" fg:x="23497" fg:w="86"/><text x="91.8848%" y="238.50"></text></g><g><title>at::native::sum (libtorch_cpu.so) (86 samples, 0.34%)</title><rect x="91.6348%" y="244" width="0.3354%" height="15" fill="rgb(244,170,11)" fg:x="23497" fg:w="86"/><text x="91.8848%" y="254.50"></text></g><g><title>at::_ops::sum_dim_IntList::call (libtorch_cpu.so) (86 samples, 0.34%)</title><rect x="91.6348%" y="260" width="0.3354%" height="15" fill="rgb(207,114,54)" fg:x="23497" fg:w="86"/><text x="91.8848%" y="270.50"></text></g><g><title>c10::impl::wrap_kernel_functor_unboxed_&lt;c10::impl::detail::WrapFunctionIntoFunctor_&lt;c10::CompileTimeFunctionPointer&lt;at::Tensor(at::Tensor const&amp;, c10::OptionalArrayRef&lt;long&gt;, bool, std::optional&lt;c10::ScalarType&gt;), &amp;at::(anonymous namespace)::wrapper_CUDA_sum_dim_IntList(at::Tensor const&amp;, c10::OptionalArrayRef&lt;long&gt;, bool, std::optional&lt;c10::ScalarType&gt;)&gt;, at::Tensor, c10::guts::typelist::typelist&lt;at::Tensor const&amp;, c10::OptionalArrayRef&lt;long&gt;, bool, std::optional&lt;c10::ScalarType&gt; &gt; &gt;, at::Tensor(at::Tensor const&amp;, c10::OptionalArrayRef&lt;long&gt;, bool, std::optional&lt;c10::ScalarType&gt;)&gt;::call (libtorch_cuda.so) (86 samples, 0.34%)</title><rect x="91.6348%" y="276" width="0.3354%" height="15" fill="rgb(205,42,20)" fg:x="23497" fg:w="86"/><text x="91.8848%" y="286.50"></text></g><g><title>at::(anonymous namespace)::wrapper_CUDA_sum_dim_IntList (libtorch_cuda.so) (86 samples, 0.34%)</title><rect x="91.6348%" y="292" width="0.3354%" height="15" fill="rgb(230,30,28)" fg:x="23497" fg:w="86"/><text x="91.8848%" y="302.50"></text></g><g><title>at::_ops::sum::call (libtorch_cpu.so) (101 samples, 0.39%)</title><rect x="91.6114%" y="164" width="0.3939%" height="15" fill="rgb(205,73,54)" fg:x="23491" fg:w="101"/><text x="91.8614%" y="174.50"></text></g><g><title>c10::impl::wrap_kernel_functor_unboxed_&lt;c10::impl::detail::WrapFunctionIntoFunctor_&lt;c10::CompileTimeFunctionPointer&lt;at::Tensor(c10::DispatchKeySet, at::Tensor const&amp;, std::optional&lt;c10::ScalarType&gt;), &amp;torch::autograd::VariableType::(anonymous namespace)::sum(c10::DispatchKeySet, at::Tensor const&amp;, std::optional&lt;c10::ScalarType&gt;)&gt;, at::Tensor, c10::guts::typelist::typelist&lt;c10::DispatchKeySet, at::Tensor const&amp;, std::optional&lt;c10::ScalarType&gt; &gt; &gt;, at::Tensor(c10::DispatchKeySet, at::Tensor const&amp;, std::optional&lt;c10::ScalarType&gt;)&gt;::call (libtorch_cpu.so) (97 samples, 0.38%)</title><rect x="91.6270%" y="180" width="0.3783%" height="15" fill="rgb(254,227,23)" fg:x="23495" fg:w="97"/><text x="91.8770%" y="190.50"></text></g><g><title>torch::autograd::VariableType::(anonymous namespace)::sum (libtorch_cpu.so) (97 samples, 0.38%)</title><rect x="91.6270%" y="196" width="0.3783%" height="15" fill="rgb(228,202,34)" fg:x="23495" fg:w="97"/><text x="91.8770%" y="206.50"></text></g><g><title>torch::autograd::THPVariable_sum (libtorch_python.so) (109 samples, 0.43%)</title><rect x="91.5997%" y="148" width="0.4251%" height="15" fill="rgb(222,225,37)" fg:x="23488" fg:w="109"/><text x="91.8497%" y="158.50"></text></g><g><title>at::native::add_kernel (libtorch_cuda.so) (36 samples, 0.14%)</title><rect x="92.0911%" y="244" width="0.1404%" height="15" fill="rgb(221,14,54)" fg:x="23614" fg:w="36"/><text x="92.3411%" y="254.50"></text></g><g><title>at::native::add_kernel(at::TensorIteratorBase&amp;, c10::Scalar const&amp;)::{lambda()#1}::operator() const (libtorch_cuda.so) (36 samples, 0.14%)</title><rect x="92.0911%" y="260" width="0.1404%" height="15" fill="rgb(254,102,2)" fg:x="23614" fg:w="36"/><text x="92.3411%" y="270.50"></text></g><g><title>at::native::gpu_kernel_impl_nocast&lt;at::native::CUDAFunctor_add&lt;float&gt; &gt; (libtorch_cuda.so) (33 samples, 0.13%)</title><rect x="92.1028%" y="276" width="0.1287%" height="15" fill="rgb(232,104,17)" fg:x="23617" fg:w="33"/><text x="92.3528%" y="286.50"></text></g><g><title>cudaLaunchKernel (nvidia/cuda_runtime/lib/libcudart.so.12) (28 samples, 0.11%)</title><rect x="92.1223%" y="292" width="0.1092%" height="15" fill="rgb(250,220,14)" fg:x="23622" fg:w="28"/><text x="92.3723%" y="302.50"></text></g><g><title>at::(anonymous namespace)::wrapper_CUDA_add__Tensor (libtorch_cuda.so) (48 samples, 0.19%)</title><rect x="92.0482%" y="228" width="0.1872%" height="15" fill="rgb(241,158,9)" fg:x="23603" fg:w="48"/><text x="92.2982%" y="238.50"></text></g><g><title>c10::impl::wrap_kernel_functor_unboxed_&lt;c10::impl::detail::WrapFunctionIntoFunctor_&lt;c10::CompileTimeFunctionPointer&lt;at::Tensor&amp; (c10::DispatchKeySet, at::Tensor&amp;, at::Tensor const&amp;, c10::Scalar const&amp;), &amp;torch::ADInplaceOrView::(anonymous namespace)::add__Tensor(c10::DispatchKeySet, at::Tensor&amp;, at::Tensor const&amp;, c10::Scalar const&amp;)&gt;, at::Tensor&amp;, c10::guts::typelist::typelist&lt;c10::DispatchKeySet, at::Tensor&amp;, at::Tensor const&amp;, c10::Scalar const&amp;&gt; &gt;, at::Tensor&amp; (c10::DispatchKeySet, at::Tensor&amp;, at::Tensor const&amp;, c10::Scalar const&amp;)&gt;::call (libtorch_cpu.so) (53 samples, 0.21%)</title><rect x="92.0443%" y="212" width="0.2067%" height="15" fill="rgb(246,9,43)" fg:x="23602" fg:w="53"/><text x="92.2943%" y="222.50"></text></g><g><title>at::_ops::add__Tensor::call (libtorch_cpu.so) (93 samples, 0.36%)</title><rect x="92.0248%" y="180" width="0.3627%" height="15" fill="rgb(206,73,33)" fg:x="23597" fg:w="93"/><text x="92.2748%" y="190.50"></text></g><g><title>torch::autograd::VariableType::(anonymous namespace)::add__Tensor (libtorch_cpu.so) (92 samples, 0.36%)</title><rect x="92.0287%" y="196" width="0.3588%" height="15" fill="rgb(222,79,8)" fg:x="23598" fg:w="92"/><text x="92.2787%" y="206.50"></text></g><g><title>train (self_play.py:190) (370 samples, 1.44%)</title><rect x="90.9523%" y="132" width="1.4429%" height="15" fill="rgb(234,8,54)" fg:x="23322" fg:w="370"/><text x="91.2023%" y="142.50"></text></g><g><title>torch::autograd::TypeError_to_NotImplemented_&lt;&amp;torch::autograd::THPVariable_add_(_object*, _object*, _object*)&gt; (libtorch_python.so) (95 samples, 0.37%)</title><rect x="92.0248%" y="148" width="0.3705%" height="15" fill="rgb(209,134,38)" fg:x="23597" fg:w="95"/><text x="92.2748%" y="158.50"></text></g><g><title>torch::autograd::THPVariable_add_ (libtorch_python.so) (95 samples, 0.37%)</title><rect x="92.0248%" y="164" width="0.3705%" height="15" fill="rgb(230,127,29)" fg:x="23597" fg:w="95"/><text x="92.2748%" y="174.50"></text></g><g><title>train (self_play.py:202) (32 samples, 0.12%)</title><rect x="92.4031%" y="132" width="0.1248%" height="15" fill="rgb(242,44,41)" fg:x="23694" fg:w="32"/><text x="92.6531%" y="142.50"></text></g><g><title>backward (torch/_tensor.py:647) (32 samples, 0.12%)</title><rect x="92.4031%" y="148" width="0.1248%" height="15" fill="rgb(222,56,43)" fg:x="23694" fg:w="32"/><text x="92.6531%" y="158.50"></text></g><g><title>backward (torch/autograd/__init__.py:354) (31 samples, 0.12%)</title><rect x="92.4070%" y="164" width="0.1209%" height="15" fill="rgb(238,39,47)" fg:x="23695" fg:w="31"/><text x="92.6570%" y="174.50"></text></g><g><title>_engine_run_backward (torch/autograd/graph.py:829) (30 samples, 0.12%)</title><rect x="92.4109%" y="180" width="0.1170%" height="15" fill="rgb(226,79,43)" fg:x="23696" fg:w="30"/><text x="92.6609%" y="190.50"></text></g><g><title>THPEngine_run_backward (libtorch_python.so) (29 samples, 0.11%)</title><rect x="92.4148%" y="196" width="0.1131%" height="15" fill="rgb(242,105,53)" fg:x="23697" fg:w="29"/><text x="92.6648%" y="206.50"></text></g><g><title>torch::autograd::python::PythonEngine::execute (libtorch_python.so) (29 samples, 0.11%)</title><rect x="92.4148%" y="212" width="0.1131%" height="15" fill="rgb(251,132,46)" fg:x="23697" fg:w="29"/><text x="92.6648%" y="222.50"></text></g><g><title>torch::autograd::Engine::execute (libtorch_cpu.so) (29 samples, 0.11%)</title><rect x="92.4148%" y="228" width="0.1131%" height="15" fill="rgb(231,77,14)" fg:x="23697" fg:w="29"/><text x="92.6648%" y="238.50"></text></g><g><title>step (torch/optim/adam.py:237) (30 samples, 0.12%)</title><rect x="92.5357%" y="180" width="0.1170%" height="15" fill="rgb(240,135,9)" fg:x="23728" fg:w="30"/><text x="92.7857%" y="190.50"></text></g><g><title>step (torch/optim/adam.py:247) (139 samples, 0.54%)</title><rect x="92.6527%" y="180" width="0.5421%" height="15" fill="rgb(248,109,14)" fg:x="23758" fg:w="139"/><text x="92.9027%" y="190.50"></text></g><g><title>maybe_fallback (torch/optim/optimizer.py:149) (139 samples, 0.54%)</title><rect x="92.6527%" y="196" width="0.5421%" height="15" fill="rgb(227,146,52)" fg:x="23758" fg:w="139"/><text x="92.9027%" y="206.50"></text></g><g><title>adam (torch/optim/adam.py:949) (125 samples, 0.49%)</title><rect x="92.7073%" y="212" width="0.4875%" height="15" fill="rgb(232,54,3)" fg:x="23772" fg:w="125"/><text x="92.9573%" y="222.50"></text></g><g><title>_use_grad (torch/optim/optimizer.py:81) (171 samples, 0.67%)</title><rect x="92.5357%" y="164" width="0.6669%" height="15" fill="rgb(229,201,43)" fg:x="23728" fg:w="171"/><text x="92.7857%" y="174.50"></text></g><g><title>wrapper (torch/optim/optimizer.py:516) (172 samples, 0.67%)</title><rect x="92.5357%" y="148" width="0.6708%" height="15" fill="rgb(252,161,33)" fg:x="23728" fg:w="172"/><text x="92.7857%" y="158.50"></text></g><g><title>train (self_play.py:203) (176 samples, 0.69%)</title><rect x="92.5279%" y="132" width="0.6864%" height="15" fill="rgb(226,146,40)" fg:x="23726" fg:w="176"/><text x="92.7779%" y="142.50"></text></g><g><title>learn (self_play.py:322) (1,431 samples, 5.58%)</title><rect x="87.6648%" y="116" width="5.5807%" height="15" fill="rgb(219,47,25)" fg:x="22479" fg:w="1431"/><text x="87.9148%" y="126.50">learn (..</text></g><g><title>&lt;module&gt; (self_play.py:377) (23,854 samples, 93.03%)</title><rect x="0.2340%" y="84" width="93.0271%" height="15" fill="rgb(250,135,13)" fg:x="60" fg:w="23854"/><text x="0.4840%" y="94.50">&lt;module&gt; (self_play.py:377)</text></g><g><title>main (self_play.py:374) (23,769 samples, 92.70%)</title><rect x="0.5655%" y="100" width="92.6956%" height="15" fill="rgb(219,229,18)" fg:x="145" fg:w="23769"/><text x="0.8155%" y="110.50">main (self_play.py:374)</text></g><g><title>&lt;module&gt; (self_play.py:8) (71 samples, 0.28%)</title><rect x="93.2611%" y="84" width="0.2769%" height="15" fill="rgb(217,152,27)" fg:x="23914" fg:w="71"/><text x="93.5111%" y="94.50"></text></g><g><title>_find_and_load (&lt;frozen importlib._bootstrap&gt;:1360) (71 samples, 0.28%)</title><rect x="93.2611%" y="100" width="0.2769%" height="15" fill="rgb(225,71,47)" fg:x="23914" fg:w="71"/><text x="93.5111%" y="110.50"></text></g><g><title>_find_and_load_unlocked (&lt;frozen importlib._bootstrap&gt;:1331) (71 samples, 0.28%)</title><rect x="93.2611%" y="116" width="0.2769%" height="15" fill="rgb(220,139,14)" fg:x="23914" fg:w="71"/><text x="93.5111%" y="126.50"></text></g><g><title>_load_unlocked (&lt;frozen importlib._bootstrap&gt;:935) (71 samples, 0.28%)</title><rect x="93.2611%" y="132" width="0.2769%" height="15" fill="rgb(247,54,32)" fg:x="23914" fg:w="71"/><text x="93.5111%" y="142.50"></text></g><g><title>exec_module (&lt;frozen importlib._bootstrap_external&gt;:999) (71 samples, 0.28%)</title><rect x="93.2611%" y="148" width="0.2769%" height="15" fill="rgb(252,131,39)" fg:x="23914" fg:w="71"/><text x="93.5111%" y="158.50"></text></g><g><title>_call_with_frames_removed (&lt;frozen importlib._bootstrap&gt;:488) (71 samples, 0.28%)</title><rect x="93.2611%" y="164" width="0.2769%" height="15" fill="rgb(210,108,39)" fg:x="23914" fg:w="71"/><text x="93.5111%" y="174.50"></text></g><g><title>&lt;module&gt; (torch/__init__.py:416) (30 samples, 0.12%)</title><rect x="93.4210%" y="180" width="0.1170%" height="15" fill="rgb(205,23,29)" fg:x="23955" fg:w="30"/><text x="93.6710%" y="190.50"></text></g><g><title>_find_and_load (&lt;frozen importlib._bootstrap&gt;:1360) (30 samples, 0.12%)</title><rect x="93.4210%" y="196" width="0.1170%" height="15" fill="rgb(246,139,46)" fg:x="23955" fg:w="30"/><text x="93.6710%" y="206.50"></text></g><g><title>_find_and_load_unlocked (&lt;frozen importlib._bootstrap&gt;:1331) (30 samples, 0.12%)</title><rect x="93.4210%" y="212" width="0.1170%" height="15" fill="rgb(250,81,26)" fg:x="23955" fg:w="30"/><text x="93.6710%" y="222.50"></text></g><g><title>_load_unlocked (&lt;frozen importlib._bootstrap&gt;:921) (30 samples, 0.12%)</title><rect x="93.4210%" y="228" width="0.1170%" height="15" fill="rgb(214,104,7)" fg:x="23955" fg:w="30"/><text x="93.6710%" y="238.50"></text></g><g><title>module_from_spec (&lt;frozen importlib._bootstrap&gt;:813) (30 samples, 0.12%)</title><rect x="93.4210%" y="244" width="0.1170%" height="15" fill="rgb(233,189,8)" fg:x="23955" fg:w="30"/><text x="93.6710%" y="254.50"></text></g><g><title>create_module (&lt;frozen importlib._bootstrap_external&gt;:1293) (30 samples, 0.12%)</title><rect x="93.4210%" y="260" width="0.1170%" height="15" fill="rgb(228,141,17)" fg:x="23955" fg:w="30"/><text x="93.6710%" y="270.50"></text></g><g><title>_call_with_frames_removed (&lt;frozen importlib._bootstrap&gt;:488) (30 samples, 0.12%)</title><rect x="93.4210%" y="276" width="0.1170%" height="15" fill="rgb(247,157,1)" fg:x="23955" fg:w="30"/><text x="93.6710%" y="286.50"></text></g><g><title>forward (armada_net.py:167) (31 samples, 0.12%)</title><rect x="93.7992%" y="244" width="0.1209%" height="15" fill="rgb(249,225,5)" fg:x="24052" fg:w="31"/><text x="94.0492%" y="254.50"></text></g><g><title>_wrapped_call_impl (torch/nn/modules/module.py:1773) (31 samples, 0.12%)</title><rect x="93.7992%" y="260" width="0.1209%" height="15" fill="rgb(242,55,13)" fg:x="24052" fg:w="31"/><text x="94.0492%" y="270.50"></text></g><g><title>_call_impl (torch/nn/modules/module.py:1784) (30 samples, 0.12%)</title><rect x="93.8031%" y="276" width="0.1170%" height="15" fill="rgb(230,49,50)" fg:x="24053" fg:w="30"/><text x="94.0531%" y="286.50"></text></g><g><title>forward (torch/nn/modules/container.py:244) (30 samples, 0.12%)</title><rect x="93.8031%" y="292" width="0.1170%" height="15" fill="rgb(241,111,38)" fg:x="24053" fg:w="30"/><text x="94.0531%" y="302.50"></text></g><g><title>_wrapped_call_impl (torch/nn/modules/module.py:1773) (29 samples, 0.11%)</title><rect x="93.8070%" y="308" width="0.1131%" height="15" fill="rgb(252,155,4)" fg:x="24054" fg:w="29"/><text x="94.0570%" y="318.50"></text></g><g><title>MCTS_para_search (para_mcts.pyx:201) (131 samples, 0.51%)</title><rect x="93.5730%" y="116" width="0.5109%" height="15" fill="rgb(212,69,32)" fg:x="23994" fg:w="131"/><text x="93.8230%" y="126.50"></text></g><g><title>MCTS__get_value_policy (para_mcts.pyx:389) (127 samples, 0.50%)</title><rect x="93.5886%" y="132" width="0.4953%" height="15" fill="rgb(243,107,47)" fg:x="23998" fg:w="127"/><text x="93.8386%" y="142.50"></text></g><g><title>&lt;module&gt; (self_play.py:377) (127 samples, 0.50%)</title><rect x="93.5886%" y="148" width="0.4953%" height="15" fill="rgb(247,130,12)" fg:x="23998" fg:w="127"/><text x="93.8386%" y="158.50"></text></g><g><title>main (self_play.py:374) (127 samples, 0.50%)</title><rect x="93.5886%" y="164" width="0.4953%" height="15" fill="rgb(233,74,16)" fg:x="23998" fg:w="127"/><text x="93.8386%" y="174.50"></text></g><g><title>learn (self_play.py:229) (127 samples, 0.50%)</title><rect x="93.5886%" y="180" width="0.4953%" height="15" fill="rgb(208,58,18)" fg:x="23998" fg:w="127"/><text x="93.8386%" y="190.50"></text></g><g><title>para_self_play (self_play.py:53) (127 samples, 0.50%)</title><rect x="93.5886%" y="196" width="0.4953%" height="15" fill="rgb(242,225,1)" fg:x="23998" fg:w="127"/><text x="93.8386%" y="206.50"></text></g><g><title>_wrapped_call_impl (torch/nn/modules/module.py:1773) (127 samples, 0.50%)</title><rect x="93.5886%" y="212" width="0.4953%" height="15" fill="rgb(249,39,40)" fg:x="23998" fg:w="127"/><text x="93.8386%" y="222.50"></text></g><g><title>_call_impl (torch/nn/modules/module.py:1784) (127 samples, 0.50%)</title><rect x="93.5886%" y="228" width="0.4953%" height="15" fill="rgb(207,72,44)" fg:x="23998" fg:w="127"/><text x="93.8386%" y="238.50"></text></g><g><title>0x7ac5bf39dd90 (libc.so.6) (24,154 samples, 94.20%)</title><rect x="0.0000%" y="68" width="94.1970%" height="15" fill="rgb(215,193,12)" fg:x="0" fg:w="24154"/><text x="0.2500%" y="78.50">0x7ac5bf39dd90 (libc.so.6)</text></g><g><title>para_search (para_mcts.pyx:150) (160 samples, 0.62%)</title><rect x="93.5730%" y="84" width="0.6240%" height="15" fill="rgb(248,41,39)" fg:x="23994" fg:w="160"/><text x="93.8230%" y="94.50"></text></g><g><title>para_search (para_mcts.pyx:150) (160 samples, 0.62%)</title><rect x="93.5730%" y="100" width="0.6240%" height="15" fill="rgb(253,85,4)" fg:x="23994" fg:w="160"/><text x="93.8230%" y="110.50"></text></g><g><title>at::ThreadLocalState::setThreadLocalState (libtorch_cpu.so) (45 samples, 0.18%)</title><rect x="94.2945%" y="164" width="0.1755%" height="15" fill="rgb(243,70,31)" fg:x="24179" fg:w="45"/><text x="94.5445%" y="174.50"></text></g><g><title>at::native::gpu_kernel_impl_nocast&lt;at::native::CUDAFunctor_add&lt;float&gt; &gt; (libtorch_cuda.so) (33 samples, 0.13%)</title><rect x="94.8639%" y="308" width="0.1287%" height="15" fill="rgb(253,195,26)" fg:x="24325" fg:w="33"/><text x="95.1139%" y="318.50"></text></g><g><title>cudaLaunchKernel (nvidia/cuda_runtime/lib/libcudart.so.12) (28 samples, 0.11%)</title><rect x="94.8834%" y="324" width="0.1092%" height="15" fill="rgb(243,42,11)" fg:x="24330" fg:w="28"/><text x="95.1334%" y="334.50"></text></g><g><title>at::native::add_kernel (libtorch_cuda.so) (40 samples, 0.16%)</title><rect x="94.8444%" y="276" width="0.1560%" height="15" fill="rgb(239,66,17)" fg:x="24320" fg:w="40"/><text x="95.0944%" y="286.50"></text></g><g><title>at::native::add_kernel(at::TensorIteratorBase&amp;, c10::Scalar const&amp;)::{lambda()#1}::operator() const (libtorch_cuda.so) (40 samples, 0.16%)</title><rect x="94.8444%" y="292" width="0.1560%" height="15" fill="rgb(217,132,21)" fg:x="24320" fg:w="40"/><text x="95.0944%" y="302.50"></text></g><g><title>c10::impl::wrap_kernel_functor_unboxed_&lt;c10::impl::detail::WrapFunctionIntoFunctor_&lt;c10::CompileTimeFunctionPointer&lt;at::Tensor&amp; (c10::DispatchKeySet, at::Tensor&amp;, at::Tensor const&amp;, c10::Scalar const&amp;), &amp;torch::ADInplaceOrView::(anonymous namespace)::add__Tensor(c10::DispatchKeySet, at::Tensor&amp;, at::Tensor const&amp;, c10::Scalar const&amp;)&gt;, at::Tensor&amp;, c10::guts::typelist::typelist&lt;c10::DispatchKeySet, at::Tensor&amp;, at::Tensor const&amp;, c10::Scalar const&amp;&gt; &gt;, at::Tensor&amp; (c10::DispatchKeySet, at::Tensor&amp;, at::Tensor const&amp;, c10::Scalar const&amp;)&gt;::call (libtorch_cpu.so) (55 samples, 0.21%)</title><rect x="94.7937%" y="244" width="0.2145%" height="15" fill="rgb(252,202,21)" fg:x="24307" fg:w="55"/><text x="95.0437%" y="254.50"></text></g><g><title>at::(anonymous namespace)::wrapper_CUDA_add__Tensor (libtorch_cuda.so) (54 samples, 0.21%)</title><rect x="94.7976%" y="260" width="0.2106%" height="15" fill="rgb(233,98,36)" fg:x="24308" fg:w="54"/><text x="95.0476%" y="270.50"></text></g><g><title>at::_ops::add__Tensor::call (libtorch_cpu.so) (61 samples, 0.24%)</title><rect x="94.7781%" y="212" width="0.2379%" height="15" fill="rgb(216,153,54)" fg:x="24303" fg:w="61"/><text x="95.0281%" y="222.50"></text></g><g><title>torch::autograd::VariableType::(anonymous namespace)::add__Tensor (libtorch_cpu.so) (60 samples, 0.23%)</title><rect x="94.7820%" y="228" width="0.2340%" height="15" fill="rgb(250,99,7)" fg:x="24304" fg:w="60"/><text x="95.0320%" y="238.50"></text></g><g><title>torch::autograd::InputBuffer::add (libtorch_cpu.so) (71 samples, 0.28%)</title><rect x="94.7469%" y="180" width="0.2769%" height="15" fill="rgb(207,56,50)" fg:x="24295" fg:w="71"/><text x="94.9969%" y="190.50"></text></g><g><title>torch::autograd::accumulate (libtorch_cpu.so) (64 samples, 0.25%)</title><rect x="94.7742%" y="196" width="0.2496%" height="15" fill="rgb(244,61,34)" fg:x="24302" fg:w="64"/><text x="95.0242%" y="206.50"></text></g><g><title>at::_ops::add__Tensor::call (libtorch_cpu.so) (29 samples, 0.11%)</title><rect x="95.1096%" y="244" width="0.1131%" height="15" fill="rgb(241,50,38)" fg:x="24388" fg:w="29"/><text x="95.3596%" y="254.50"></text></g><g><title>torch::autograd::VariableType::(anonymous namespace)::add__Tensor (libtorch_cpu.so) (28 samples, 0.11%)</title><rect x="95.1135%" y="260" width="0.1092%" height="15" fill="rgb(212,166,30)" fg:x="24389" fg:w="28"/><text x="95.3635%" y="270.50"></text></g><g><title>c10::impl::wrap_kernel_functor_unboxed_&lt;c10::impl::detail::WrapFunctionIntoFunctor_&lt;c10::CompileTimeFunctionPointer&lt;at::Tensor&amp; (c10::DispatchKeySet, at::Tensor&amp;, at::Tensor const&amp;, c10::Scalar const&amp;), &amp;torch::ADInplaceOrView::(anonymous namespace)::add__Tensor(c10::DispatchKeySet, at::Tensor&amp;, at::Tensor const&amp;, c10::Scalar const&amp;)&gt;, at::Tensor&amp;, c10::guts::typelist::typelist&lt;c10::DispatchKeySet, at::Tensor&amp;, at::Tensor const&amp;, c10::Scalar const&amp;&gt; &gt;, at::Tensor&amp; (c10::DispatchKeySet, at::Tensor&amp;, at::Tensor const&amp;, c10::Scalar const&amp;)&gt;::call (libtorch_cpu.so) (26 samples, 0.10%)</title><rect x="95.1213%" y="276" width="0.1014%" height="15" fill="rgb(249,127,32)" fg:x="24391" fg:w="26"/><text x="95.3713%" y="286.50"></text></g><g><title>at::(anonymous namespace)::wrapper_CUDA_add__Tensor (libtorch_cuda.so) (26 samples, 0.10%)</title><rect x="95.1213%" y="292" width="0.1014%" height="15" fill="rgb(209,103,0)" fg:x="24391" fg:w="26"/><text x="95.3713%" y="302.50"></text></g><g><title>torch::autograd::AccumulateGrad::apply (libtorch_cpu.so) (44 samples, 0.17%)</title><rect x="95.0628%" y="196" width="0.1716%" height="15" fill="rgb(238,209,51)" fg:x="24376" fg:w="44"/><text x="95.3128%" y="206.50"></text></g><g><title>torch::autograd::(anonymous namespace)::AccumulateGrad_apply_impl (libtorch_cpu.so) (43 samples, 0.17%)</title><rect x="95.0667%" y="212" width="0.1677%" height="15" fill="rgb(237,56,23)" fg:x="24377" fg:w="43"/><text x="95.3167%" y="222.50"></text></g><g><title>torch::autograd::AccumulateGrad::accumulateGrad&lt;std::function&lt;void (at::Tensor&amp;&amp;)&gt; &gt; (libtorch_cpu.so) (35 samples, 0.14%)</title><rect x="95.0979%" y="228" width="0.1365%" height="15" fill="rgb(215,153,46)" fg:x="24385" fg:w="35"/><text x="95.3479%" y="238.50"></text></g><g><title>torch::autograd::CopySlices::apply (libtorch_cpu.so) (38 samples, 0.15%)</title><rect x="95.2344%" y="196" width="0.1482%" height="15" fill="rgb(224,49,31)" fg:x="24420" fg:w="38"/><text x="95.4844%" y="206.50"></text></g><g><title>at::native::structured_mm_out_cuda::impl (libtorch_cuda.so) (36 samples, 0.14%)</title><rect x="95.4606%" y="340" width="0.1404%" height="15" fill="rgb(250,18,42)" fg:x="24478" fg:w="36"/><text x="95.7106%" y="350.50"></text></g><g><title>at::native::(anonymous namespace)::addmm_out_cuda_impl (libtorch_cuda.so) (36 samples, 0.14%)</title><rect x="95.4606%" y="356" width="0.1404%" height="15" fill="rgb(215,176,39)" fg:x="24478" fg:w="36"/><text x="95.7106%" y="366.50"></text></g><g><title>at::cuda::blas::gemm_internal_cublas&lt;float, float&gt; (libtorch_cuda.so) (34 samples, 0.13%)</title><rect x="95.4684%" y="372" width="0.1326%" height="15" fill="rgb(223,77,29)" fg:x="24480" fg:w="34"/><text x="95.7184%" y="382.50"></text></g><g><title>cublasSgemm_v2 (nvidia/cublas/lib/libcublas.so.12) (26 samples, 0.10%)</title><rect x="95.4996%" y="388" width="0.1014%" height="15" fill="rgb(234,94,52)" fg:x="24488" fg:w="26"/><text x="95.7496%" y="398.50"></text></g><g><title>at::_ops::mm::call (libtorch_cpu.so) (46 samples, 0.18%)</title><rect x="95.4294%" y="244" width="0.1794%" height="15" fill="rgb(220,154,50)" fg:x="24470" fg:w="46"/><text x="95.6794%" y="254.50"></text></g><g><title>c10::impl::wrap_kernel_functor_unboxed_&lt;c10::impl::detail::WrapFunctionIntoFunctor_&lt;c10::CompileTimeFunctionPointer&lt;at::Tensor(c10::DispatchKeySet, at::Tensor const&amp;, at::Tensor const&amp;), &amp;torch::autograd::VariableType::(anonymous namespace)::mm(c10::DispatchKeySet, at::Tensor const&amp;, at::Tensor const&amp;)&gt;, at::Tensor, c10::guts::typelist::typelist&lt;c10::DispatchKeySet, at::Tensor const&amp;, at::Tensor const&amp;&gt; &gt;, at::Tensor(c10::DispatchKeySet, at::Tensor const&amp;, at::Tensor const&amp;)&gt;::call (libtorch_cpu.so) (45 samples, 0.18%)</title><rect x="95.4333%" y="260" width="0.1755%" height="15" fill="rgb(212,11,10)" fg:x="24471" fg:w="45"/><text x="95.6833%" y="270.50"></text></g><g><title>torch::autograd::VariableType::(anonymous namespace)::mm (libtorch_cpu.so) (45 samples, 0.18%)</title><rect x="95.4333%" y="276" width="0.1755%" height="15" fill="rgb(205,166,19)" fg:x="24471" fg:w="45"/><text x="95.6833%" y="286.50"></text></g><g><title>at::_ops::mm::redispatch (libtorch_cpu.so) (44 samples, 0.17%)</title><rect x="95.4372%" y="292" width="0.1716%" height="15" fill="rgb(244,198,16)" fg:x="24472" fg:w="44"/><text x="95.6872%" y="302.50"></text></g><g><title>c10::impl::wrap_kernel_functor_unboxed_&lt;c10::impl::detail::WrapFunctionIntoFunctor_&lt;c10::CompileTimeFunctionPointer&lt;at::Tensor(at::Tensor const&amp;, at::Tensor const&amp;), &amp;at::(anonymous namespace)::wrapper_CUDA_mm(at::Tensor const&amp;, at::Tensor const&amp;)&gt;, at::Tensor, c10::guts::typelist::typelist&lt;at::Tensor const&amp;, at::Tensor const&amp;&gt; &gt;, at::Tensor(at::Tensor const&amp;, at::Tensor const&amp;)&gt;::call (libtorch_cuda.so) (43 samples, 0.17%)</title><rect x="95.4411%" y="308" width="0.1677%" height="15" fill="rgb(219,69,12)" fg:x="24473" fg:w="43"/><text x="95.6911%" y="318.50"></text></g><g><title>at::(anonymous namespace)::wrapper_CUDA_mm (libtorch_cuda.so) (43 samples, 0.17%)</title><rect x="95.4411%" y="324" width="0.1677%" height="15" fill="rgb(245,30,7)" fg:x="24473" fg:w="43"/><text x="95.6911%" y="334.50"></text></g><g><title>torch::autograd::generated::details::mm_mat1_backward (libtorch_cpu.so) (52 samples, 0.20%)</title><rect x="95.4294%" y="228" width="0.2028%" height="15" fill="rgb(218,221,48)" fg:x="24470" fg:w="52"/><text x="95.6794%" y="238.50"></text></g><g><title>torch::autograd::generated::AddmmBackward0::apply (libtorch_cpu.so) (97 samples, 0.38%)</title><rect x="95.4060%" y="196" width="0.3783%" height="15" fill="rgb(216,66,15)" fg:x="24464" fg:w="97"/><text x="95.6560%" y="206.50"></text></g><g><title>torch::autograd::generated::AddmmBackward0_apply_functional (libtorch_cpu.so) (92 samples, 0.36%)</title><rect x="95.4255%" y="212" width="0.3588%" height="15" fill="rgb(226,122,50)" fg:x="24469" fg:w="92"/><text x="95.6755%" y="222.50"></text></g><g><title>torch::autograd::generated::details::mm_mat2_backward (libtorch_cpu.so) (39 samples, 0.15%)</title><rect x="95.6322%" y="228" width="0.1521%" height="15" fill="rgb(239,156,16)" fg:x="24522" fg:w="39"/><text x="95.8822%" y="238.50"></text></g><g><title>torch::autograd::generated::IndexBackward0::apply (libtorch_cpu.so) (77 samples, 0.30%)</title><rect x="95.9208%" y="196" width="0.3003%" height="15" fill="rgb(224,27,38)" fg:x="24596" fg:w="77"/><text x="96.1708%" y="206.50"></text></g><g><title>torch::autograd::generated::IndexBackward0_apply_functional (libtorch_cpu.so) (77 samples, 0.30%)</title><rect x="95.9208%" y="212" width="0.3003%" height="15" fill="rgb(224,39,27)" fg:x="24596" fg:w="77"/><text x="96.1708%" y="222.50"></text></g><g><title>torch::autograd::generated::details::index_backward (libtorch_cpu.so) (67 samples, 0.26%)</title><rect x="95.9598%" y="228" width="0.2613%" height="15" fill="rgb(215,92,29)" fg:x="24606" fg:w="67"/><text x="96.2098%" y="238.50"></text></g><g><title>at::_ops::_index_put_impl_::call (libtorch_cpu.so) (67 samples, 0.26%)</title><rect x="95.9598%" y="244" width="0.2613%" height="15" fill="rgb(207,159,16)" fg:x="24606" fg:w="67"/><text x="96.2098%" y="254.50"></text></g><g><title>torch::autograd::VariableType::(anonymous namespace)::_index_put_impl_ (libtorch_cpu.so) (67 samples, 0.26%)</title><rect x="95.9598%" y="260" width="0.2613%" height="15" fill="rgb(238,163,47)" fg:x="24606" fg:w="67"/><text x="96.2098%" y="270.50"></text></g><g><title>at::_ops::_index_put_impl_::redispatch (libtorch_cpu.so) (67 samples, 0.26%)</title><rect x="95.9598%" y="276" width="0.2613%" height="15" fill="rgb(219,91,49)" fg:x="24606" fg:w="67"/><text x="96.2098%" y="286.50"></text></g><g><title>c10::impl::wrap_kernel_functor_unboxed_&lt;c10::impl::detail::WrapFunctionIntoFunctor_&lt;c10::CompileTimeFunctionPointer&lt;at::Tensor&amp; (c10::DispatchKeySet, at::Tensor&amp;, c10::List&lt;std::optional&lt;at::Tensor&gt; &gt; const&amp;, at::Tensor const&amp;, bool, bool), &amp;torch::ADInplaceOrView::(anonymous namespace)::_index_put_impl_(c10::DispatchKeySet, at::Tensor&amp;, c10::List&lt;std::optional&lt;at::Tensor&gt; &gt; const&amp;, at::Tensor const&amp;, bool, bool)&gt;, at::Tensor&amp;, c10::guts::typelist::typelist&lt;c10::DispatchKeySet, at::Tensor&amp;, c10::List&lt;std::optional&lt;at::Tensor&gt; &gt; const&amp;, at::Tensor const&amp;, bool, bool&gt; &gt;, at::Tensor&amp; (c10::DispatchKeySet, at::Tensor&amp;, c10::List&lt;std::optional&lt;at::Tensor&gt; &gt; const&amp;, at::Tensor const&amp;, bool, bool)&gt;::call (libtorch_cpu.so) (67 samples, 0.26%)</title><rect x="95.9598%" y="292" width="0.2613%" height="15" fill="rgb(227,167,31)" fg:x="24606" fg:w="67"/><text x="96.2098%" y="302.50"></text></g><g><title>at::_ops::_index_put_impl_::redispatch (libtorch_cpu.so) (67 samples, 0.26%)</title><rect x="95.9598%" y="308" width="0.2613%" height="15" fill="rgb(234,80,54)" fg:x="24606" fg:w="67"/><text x="96.2098%" y="318.50"></text></g><g><title>c10::impl::wrap_kernel_functor_unboxed_&lt;c10::impl::detail::WrapFunctionIntoFunctor_&lt;c10::CompileTimeFunctionPointer&lt;at::Tensor&amp; (at::Tensor&amp;, c10::List&lt;std::optional&lt;at::Tensor&gt; &gt; const&amp;, at::Tensor const&amp;, bool, bool), &amp;at::(anonymous namespace)::(anonymous namespace)::wrapper_CUDA___index_put_impl_(at::Tensor&amp;, c10::List&lt;std::optional&lt;at::Tensor&gt; &gt; const&amp;, at::Tensor const&amp;, bool, bool)&gt;, at::Tensor&amp;, c10::guts::typelist::typelist&lt;at::Tensor&amp;, c10::List&lt;std::optional&lt;at::Tensor&gt; &gt; const&amp;, at::Tensor const&amp;, bool, bool&gt; &gt;, at::Tensor&amp; (at::Tensor&amp;, c10::List&lt;std::optional&lt;at::Tensor&gt; &gt; const&amp;, at::Tensor const&amp;, bool, bool)&gt;::call (libtorch_cuda.so) (67 samples, 0.26%)</title><rect x="95.9598%" y="324" width="0.2613%" height="15" fill="rgb(212,114,2)" fg:x="24606" fg:w="67"/><text x="96.2098%" y="334.50"></text></g><g><title>at::native::_index_put_impl_ (libtorch_cpu.so) (67 samples, 0.26%)</title><rect x="95.9598%" y="340" width="0.2613%" height="15" fill="rgb(234,50,24)" fg:x="24606" fg:w="67"/><text x="96.2098%" y="350.50"></text></g><g><title>at::native::(anonymous namespace)::index_put_with_sort_kernel (libtorch_cuda.so) (67 samples, 0.26%)</title><rect x="95.9598%" y="356" width="0.2613%" height="15" fill="rgb(221,68,8)" fg:x="24606" fg:w="67"/><text x="96.2098%" y="366.50"></text></g><g><title>at::_ops::mul_Tensor::call (libtorch_cpu.so) (49 samples, 0.19%)</title><rect x="96.4433%" y="340" width="0.1911%" height="15" fill="rgb(254,180,31)" fg:x="24730" fg:w="49"/><text x="96.6933%" y="350.50"></text></g><g><title>c10::impl::wrap_kernel_functor_unboxed_&lt;c10::impl::detail::WrapFunctionIntoFunctor_&lt;c10::CompileTimeFunctionPointer&lt;at::Tensor(at::Tensor const&amp;, at::Tensor const&amp;), &amp;at::(anonymous namespace)::wrapper_CUDA_mul_Tensor(at::Tensor const&amp;, at::Tensor const&amp;)&gt;, at::Tensor, c10::guts::typelist::typelist&lt;at::Tensor const&amp;, at::Tensor const&amp;&gt; &gt;, at::Tensor(at::Tensor const&amp;, at::Tensor const&amp;)&gt;::call (libtorch_cuda.so) (49 samples, 0.19%)</title><rect x="96.4433%" y="356" width="0.1911%" height="15" fill="rgb(247,130,50)" fg:x="24730" fg:w="49"/><text x="96.6933%" y="366.50"></text></g><g><title>at::(anonymous namespace)::wrapper_CUDA_mul_Tensor (libtorch_cuda.so) (49 samples, 0.19%)</title><rect x="96.4433%" y="372" width="0.1911%" height="15" fill="rgb(211,109,4)" fg:x="24730" fg:w="49"/><text x="96.6933%" y="382.50"></text></g><g><title>at::_ops::mul_Scalar::redispatch (libtorch_cpu.so) (56 samples, 0.22%)</title><rect x="96.4355%" y="292" width="0.2184%" height="15" fill="rgb(238,50,21)" fg:x="24728" fg:w="56"/><text x="96.6855%" y="302.50"></text></g><g><title>c10::impl::wrap_kernel_functor_unboxed_&lt;c10::impl::detail::WrapFunctionIntoFunctor_&lt;c10::CompileTimeFunctionPointer&lt;at::Tensor(at::Tensor const&amp;, c10::Scalar const&amp;), &amp;at::(anonymous namespace)::(anonymous namespace)::wrapper_CompositeExplicitAutograd_Scalar_mul(at::Tensor const&amp;, c10::Scalar const&amp;)&gt;, at::Tensor, c10::guts::typelist::typelist&lt;at::Tensor const&amp;, c10::Scalar const&amp;&gt; &gt;, at::Tensor(at::Tensor const&amp;, c10::Scalar const&amp;)&gt;::call (libtorch_cpu.so) (56 samples, 0.22%)</title><rect x="96.4355%" y="308" width="0.2184%" height="15" fill="rgb(225,57,45)" fg:x="24728" fg:w="56"/><text x="96.6855%" y="318.50"></text></g><g><title>at::native::mul (libtorch_cpu.so) (55 samples, 0.21%)</title><rect x="96.4394%" y="324" width="0.2145%" height="15" fill="rgb(209,196,50)" fg:x="24729" fg:w="55"/><text x="96.6894%" y="334.50"></text></g><g><title>at::_ops::mul_Scalar::call (libtorch_cpu.so) (59 samples, 0.23%)</title><rect x="96.4277%" y="244" width="0.2301%" height="15" fill="rgb(242,140,13)" fg:x="24726" fg:w="59"/><text x="96.6777%" y="254.50"></text></g><g><title>c10::impl::wrap_kernel_functor_unboxed_&lt;c10::impl::detail::WrapFunctionIntoFunctor_&lt;c10::CompileTimeFunctionPointer&lt;at::Tensor(c10::DispatchKeySet, at::Tensor const&amp;, c10::Scalar const&amp;), &amp;torch::autograd::VariableType::(anonymous namespace)::mul_Scalar(c10::DispatchKeySet, at::Tensor const&amp;, c10::Scalar const&amp;)&gt;, at::Tensor, c10::guts::typelist::typelist&lt;c10::DispatchKeySet, at::Tensor const&amp;, c10::Scalar const&amp;&gt; &gt;, at::Tensor(c10::DispatchKeySet, at::Tensor const&amp;, c10::Scalar const&amp;)&gt;::call (libtorch_cpu.so) (57 samples, 0.22%)</title><rect x="96.4355%" y="260" width="0.2223%" height="15" fill="rgb(217,111,7)" fg:x="24728" fg:w="57"/><text x="96.6855%" y="270.50"></text></g><g><title>torch::autograd::VariableType::(anonymous namespace)::mul_Scalar (libtorch_cpu.so) (57 samples, 0.22%)</title><rect x="96.4355%" y="276" width="0.2223%" height="15" fill="rgb(253,193,51)" fg:x="24728" fg:w="57"/><text x="96.6855%" y="286.50"></text></g><g><title>at::_ops::mul_Tensor::redispatch (libtorch_cpu.so) (30 samples, 0.12%)</title><rect x="96.6617%" y="292" width="0.1170%" height="15" fill="rgb(252,70,29)" fg:x="24786" fg:w="30"/><text x="96.9117%" y="302.50"></text></g><g><title>c10::impl::wrap_kernel_functor_unboxed_&lt;c10::impl::detail::WrapFunctionIntoFunctor_&lt;c10::CompileTimeFunctionPointer&lt;at::Tensor(at::Tensor const&amp;, at::Tensor const&amp;), &amp;at::(anonymous namespace)::wrapper_CUDA_mul_Tensor(at::Tensor const&amp;, at::Tensor const&amp;)&gt;, at::Tensor, c10::guts::typelist::typelist&lt;at::Tensor const&amp;, at::Tensor const&amp;&gt; &gt;, at::Tensor(at::Tensor const&amp;, at::Tensor const&amp;)&gt;::call (libtorch_cuda.so) (29 samples, 0.11%)</title><rect x="96.6656%" y="308" width="0.1131%" height="15" fill="rgb(232,127,12)" fg:x="24787" fg:w="29"/><text x="96.9156%" y="318.50"></text></g><g><title>at::(anonymous namespace)::wrapper_CUDA_mul_Tensor (libtorch_cuda.so) (29 samples, 0.11%)</title><rect x="96.6656%" y="324" width="0.1131%" height="15" fill="rgb(211,180,21)" fg:x="24787" fg:w="29"/><text x="96.9156%" y="334.50"></text></g><g><title>at::_ops::mul_Tensor::call (libtorch_cpu.so) (33 samples, 0.13%)</title><rect x="96.6578%" y="244" width="0.1287%" height="15" fill="rgb(229,72,13)" fg:x="24785" fg:w="33"/><text x="96.9078%" y="254.50"></text></g><g><title>c10::impl::wrap_kernel_functor_unboxed_&lt;c10::impl::detail::WrapFunctionIntoFunctor_&lt;c10::CompileTimeFunctionPointer&lt;at::Tensor(c10::DispatchKeySet, at::Tensor const&amp;, at::Tensor const&amp;), &amp;torch::autograd::VariableType::(anonymous namespace)::mul_Tensor(c10::DispatchKeySet, at::Tensor const&amp;, at::Tensor const&amp;)&gt;, at::Tensor, c10::guts::typelist::typelist&lt;c10::DispatchKeySet, at::Tensor const&amp;, at::Tensor const&amp;&gt; &gt;, at::Tensor(c10::DispatchKeySet, at::Tensor const&amp;, at::Tensor const&amp;)&gt;::call (libtorch_cpu.so) (33 samples, 0.13%)</title><rect x="96.6578%" y="260" width="0.1287%" height="15" fill="rgb(240,211,49)" fg:x="24785" fg:w="33"/><text x="96.9078%" y="270.50"></text></g><g><title>torch::autograd::VariableType::(anonymous namespace)::mul_Tensor (libtorch_cpu.so) (33 samples, 0.13%)</title><rect x="96.6578%" y="276" width="0.1287%" height="15" fill="rgb(219,149,40)" fg:x="24785" fg:w="33"/><text x="96.9078%" y="286.50"></text></g><g><title>at::native::copy_ (libtorch_cpu.so) (42 samples, 0.16%)</title><rect x="96.8060%" y="356" width="0.1638%" height="15" fill="rgb(210,127,46)" fg:x="24823" fg:w="42"/><text x="97.0560%" y="366.50"></text></g><g><title>at::native::copy_impl (libtorch_cpu.so) (41 samples, 0.16%)</title><rect x="96.8099%" y="372" width="0.1599%" height="15" fill="rgb(220,106,7)" fg:x="24824" fg:w="41"/><text x="97.0599%" y="382.50"></text></g><g><title>at::native::copy_device_to_device (libtorch_cuda.so) (36 samples, 0.14%)</title><rect x="96.8294%" y="388" width="0.1404%" height="15" fill="rgb(249,31,22)" fg:x="24829" fg:w="36"/><text x="97.0794%" y="398.50"></text></g><g><title>cudaMemcpyAsync (nvidia/cuda_runtime/lib/libcudart.so.12) (33 samples, 0.13%)</title><rect x="96.8411%" y="404" width="0.1287%" height="15" fill="rgb(253,1,49)" fg:x="24832" fg:w="33"/><text x="97.0911%" y="414.50"></text></g><g><title>0x7ac5be418cb2 (nvidia/cuda_runtime/lib/libcudart.so.12) (31 samples, 0.12%)</title><rect x="96.8489%" y="420" width="0.1209%" height="15" fill="rgb(227,144,33)" fg:x="24834" fg:w="31"/><text x="97.0989%" y="430.50"></text></g><g><title>0x7ac5be448c71 (nvidia/cuda_runtime/lib/libcudart.so.12) (31 samples, 0.12%)</title><rect x="96.8489%" y="436" width="0.1209%" height="15" fill="rgb(249,163,44)" fg:x="24834" fg:w="31"/><text x="97.0989%" y="446.50"></text></g><g><title>0x7ac4e00e91a1 (libcuda.so.550.54.15) (31 samples, 0.12%)</title><rect x="96.8489%" y="452" width="0.1209%" height="15" fill="rgb(234,15,39)" fg:x="24834" fg:w="31"/><text x="97.0989%" y="462.50"></text></g><g><title>at::_ops::copy_::call (libtorch_cpu.so) (44 samples, 0.17%)</title><rect x="96.8021%" y="340" width="0.1716%" height="15" fill="rgb(207,66,16)" fg:x="24822" fg:w="44"/><text x="97.0521%" y="350.50"></text></g><g><title>at::_ops::pow_Tensor_Scalar::redispatch (libtorch_cpu.so) (60 samples, 0.23%)</title><rect x="96.7943%" y="292" width="0.2340%" height="15" fill="rgb(233,112,24)" fg:x="24820" fg:w="60"/><text x="97.0443%" y="302.50"></text></g><g><title>c10::impl::wrap_kernel_functor_unboxed_&lt;c10::impl::detail::WrapFunctionIntoFunctor_&lt;c10::CompileTimeFunctionPointer&lt;at::Tensor(at::Tensor const&amp;, c10::Scalar const&amp;), &amp;at::(anonymous namespace)::wrapper_CUDA_pow_Tensor_Scalar(at::Tensor const&amp;, c10::Scalar const&amp;)&gt;, at::Tensor, c10::guts::typelist::typelist&lt;at::Tensor const&amp;, c10::Scalar const&amp;&gt; &gt;, at::Tensor(at::Tensor const&amp;, c10::Scalar const&amp;)&gt;::call (libtorch_cuda.so) (60 samples, 0.23%)</title><rect x="96.7943%" y="308" width="0.2340%" height="15" fill="rgb(230,90,22)" fg:x="24820" fg:w="60"/><text x="97.0443%" y="318.50"></text></g><g><title>at::(anonymous namespace)::wrapper_CUDA_pow_Tensor_Scalar (libtorch_cuda.so) (60 samples, 0.23%)</title><rect x="96.7943%" y="324" width="0.2340%" height="15" fill="rgb(229,61,13)" fg:x="24820" fg:w="60"/><text x="97.0443%" y="334.50"></text></g><g><title>at::_ops::pow_Tensor_Scalar::call (libtorch_cpu.so) (64 samples, 0.25%)</title><rect x="96.7865%" y="244" width="0.2496%" height="15" fill="rgb(225,57,24)" fg:x="24818" fg:w="64"/><text x="97.0365%" y="254.50"></text></g><g><title>c10::impl::wrap_kernel_functor_unboxed_&lt;c10::impl::detail::WrapFunctionIntoFunctor_&lt;c10::CompileTimeFunctionPointer&lt;at::Tensor(c10::DispatchKeySet, at::Tensor const&amp;, c10::Scalar const&amp;), &amp;torch::autograd::VariableType::(anonymous namespace)::pow_Tensor_Scalar(c10::DispatchKeySet, at::Tensor const&amp;, c10::Scalar const&amp;)&gt;, at::Tensor, c10::guts::typelist::typelist&lt;c10::DispatchKeySet, at::Tensor const&amp;, c10::Scalar const&amp;&gt; &gt;, at::Tensor(c10::DispatchKeySet, at::Tensor const&amp;, c10::Scalar const&amp;)&gt;::call (libtorch_cpu.so) (62 samples, 0.24%)</title><rect x="96.7943%" y="260" width="0.2418%" height="15" fill="rgb(208,169,48)" fg:x="24820" fg:w="62"/><text x="97.0443%" y="270.50"></text></g><g><title>torch::autograd::VariableType::(anonymous namespace)::pow_Tensor_Scalar (libtorch_cpu.so) (62 samples, 0.24%)</title><rect x="96.7943%" y="276" width="0.2418%" height="15" fill="rgb(244,218,51)" fg:x="24820" fg:w="62"/><text x="97.0443%" y="286.50"></text></g><g><title>torch::autograd::generated::PowBackward0::apply (libtorch_cpu.so) (166 samples, 0.65%)</title><rect x="96.4082%" y="196" width="0.6474%" height="15" fill="rgb(214,148,10)" fg:x="24721" fg:w="166"/><text x="96.6582%" y="206.50"></text></g><g><title>torch::autograd::generated::PowBackward0_apply_functional (libtorch_cpu.so) (163 samples, 0.64%)</title><rect x="96.4199%" y="212" width="0.6357%" height="15" fill="rgb(225,174,27)" fg:x="24724" fg:w="163"/><text x="96.6699%" y="222.50"></text></g><g><title>torch::autograd::generated::details::pow_backward (libtorch_cpu.so) (162 samples, 0.63%)</title><rect x="96.4238%" y="228" width="0.6318%" height="15" fill="rgb(230,96,26)" fg:x="24725" fg:w="162"/><text x="96.6738%" y="238.50"></text></g><g><title>torch::autograd::Node::operator() (libtorch_cpu.so) (627 samples, 2.45%)</title><rect x="95.0238%" y="180" width="2.4452%" height="15" fill="rgb(232,10,30)" fg:x="24366" fg:w="627"/><text x="95.2738%" y="190.50">to..</text></g><g><title>at::_ops::sum_dim_IntList::redispatch (libtorch_cpu.so) (27 samples, 0.11%)</title><rect x="97.7186%" y="292" width="0.1053%" height="15" fill="rgb(222,8,50)" fg:x="25057" fg:w="27"/><text x="97.9686%" y="302.50"></text></g><g><title>c10::impl::wrap_kernel_functor_unboxed_&lt;c10::impl::detail::WrapFunctionIntoFunctor_&lt;c10::CompileTimeFunctionPointer&lt;at::Tensor(at::Tensor const&amp;, c10::OptionalArrayRef&lt;long&gt;, bool, std::optional&lt;c10::ScalarType&gt;), &amp;at::(anonymous namespace)::wrapper_CUDA_sum_dim_IntList(at::Tensor const&amp;, c10::OptionalArrayRef&lt;long&gt;, bool, std::optional&lt;c10::ScalarType&gt;)&gt;, at::Tensor, c10::guts::typelist::typelist&lt;at::Tensor const&amp;, c10::OptionalArrayRef&lt;long&gt;, bool, std::optional&lt;c10::ScalarType&gt; &gt; &gt;, at::Tensor(at::Tensor const&amp;, c10::OptionalArrayRef&lt;long&gt;, bool, std::optional&lt;c10::ScalarType&gt;)&gt;::call (libtorch_cuda.so) (27 samples, 0.11%)</title><rect x="97.7186%" y="308" width="0.1053%" height="15" fill="rgb(213,81,27)" fg:x="25057" fg:w="27"/><text x="97.9686%" y="318.50"></text></g><g><title>at::(anonymous namespace)::wrapper_CUDA_sum_dim_IntList (libtorch_cuda.so) (27 samples, 0.11%)</title><rect x="97.7186%" y="324" width="0.1053%" height="15" fill="rgb(245,50,10)" fg:x="25057" fg:w="27"/><text x="97.9686%" y="334.50"></text></g><g><title>at::_ops::sum_dim_IntList::call (libtorch_cpu.so) (28 samples, 0.11%)</title><rect x="97.7186%" y="244" width="0.1092%" height="15" fill="rgb(216,100,18)" fg:x="25057" fg:w="28"/><text x="97.9686%" y="254.50"></text></g><g><title>c10::impl::wrap_kernel_functor_unboxed_&lt;c10::impl::detail::WrapFunctionIntoFunctor_&lt;c10::CompileTimeFunctionPointer&lt;at::Tensor(c10::DispatchKeySet, at::Tensor const&amp;, c10::OptionalArrayRef&lt;long&gt;, bool, std::optional&lt;c10::ScalarType&gt;), &amp;torch::autograd::VariableType::(anonymous namespace)::sum_dim_IntList(c10::DispatchKeySet, at::Tensor const&amp;, c10::OptionalArrayRef&lt;long&gt;, bool, std::optional&lt;c10::ScalarType&gt;)&gt;, at::Tensor, c10::guts::typelist::typelist&lt;c10::DispatchKeySet, at::Tensor const&amp;, c10::OptionalArrayRef&lt;long&gt;, bool, std::optional&lt;c10::ScalarType&gt; &gt; &gt;, at::Tensor(c10::DispatchKeySet, at::Tensor const&amp;, c10::OptionalArrayRef&lt;long&gt;, bool, std::optional&lt;c10::ScalarType&gt;)&gt;::call (libtorch_cpu.so) (28 samples, 0.11%)</title><rect x="97.7186%" y="260" width="0.1092%" height="15" fill="rgb(236,147,54)" fg:x="25057" fg:w="28"/><text x="97.9686%" y="270.50"></text></g><g><title>torch::autograd::VariableType::(anonymous namespace)::sum_dim_IntList (libtorch_cpu.so) (28 samples, 0.11%)</title><rect x="97.7186%" y="276" width="0.1092%" height="15" fill="rgb(205,143,26)" fg:x="25057" fg:w="28"/><text x="97.9686%" y="286.50"></text></g><g><title>torch::autograd::InputMetadata::reduce_grad (libtorch_cpu.so) (34 samples, 0.13%)</title><rect x="97.7147%" y="212" width="0.1326%" height="15" fill="rgb(236,26,9)" fg:x="25056" fg:w="34"/><text x="97.9647%" y="222.50"></text></g><g><title>at::_sum_to&lt;c10::SymInt&gt; (libtorch_cpu.so) (34 samples, 0.13%)</title><rect x="97.7147%" y="228" width="0.1326%" height="15" fill="rgb(221,165,53)" fg:x="25056" fg:w="34"/><text x="97.9647%" y="238.50"></text></g><g><title>torch::autograd::Engine::evaluate_function (libtorch_cpu.so) (862 samples, 3.36%)</title><rect x="94.4934%" y="164" width="3.3617%" height="15" fill="rgb(214,110,17)" fg:x="24230" fg:w="862"/><text x="94.7434%" y="174.50">tor..</text></g><g><title>torch::autograd::validate_outputs_impl&lt;torch::autograd::Edge&gt; (libtorch_cpu.so) (48 samples, 0.19%)</title><rect x="97.6679%" y="180" width="0.1872%" height="15" fill="rgb(237,197,12)" fg:x="25044" fg:w="48"/><text x="97.9179%" y="190.50"></text></g><g><title>torch::autograd::InputMetadata::maybe_reduce (libtorch_cpu.so) (41 samples, 0.16%)</title><rect x="97.6952%" y="196" width="0.1599%" height="15" fill="rgb(205,84,17)" fg:x="25051" fg:w="41"/><text x="97.9452%" y="206.50"></text></g><g><title>std::condition_variable::wait (libstdc++.so.6.0.30) (402 samples, 1.57%)</title><rect x="97.9175%" y="180" width="1.5677%" height="15" fill="rgb(237,18,45)" fg:x="25108" fg:w="402"/><text x="98.1675%" y="190.50"></text></g><g><title>pthread_cond_wait (libc.so.6) (402 samples, 1.57%)</title><rect x="97.9175%" y="196" width="1.5677%" height="15" fill="rgb(221,87,14)" fg:x="25108" fg:w="402"/><text x="98.1675%" y="206.50"></text></g><g><title>0x7ac5bf405117 (libc.so.6) (402 samples, 1.57%)</title><rect x="97.9175%" y="212" width="1.5677%" height="15" fill="rgb(238,186,15)" fg:x="25108" fg:w="402"/><text x="98.1675%" y="222.50"></text></g><g><title>torch::autograd::ReadyQueue::pop (libtorch_cpu.so) (412 samples, 1.61%)</title><rect x="97.8863%" y="164" width="1.6067%" height="15" fill="rgb(208,115,11)" fg:x="25100" fg:w="412"/><text x="98.1363%" y="174.50"></text></g><g><title>0x7ac5bf49a850 (libc.so.6) (1,372 samples, 5.35%)</title><rect x="94.1970%" y="68" width="5.3506%" height="15" fill="rgb(254,175,0)" fg:x="24154" fg:w="1372"/><text x="94.4470%" y="78.50">0x7ac5b..</text></g><g><title>0x7ac5bf408ac3 (libc.so.6) (1,372 samples, 5.35%)</title><rect x="94.1970%" y="84" width="5.3506%" height="15" fill="rgb(227,24,42)" fg:x="24154" fg:w="1372"/><text x="94.4470%" y="94.50">0x7ac5b..</text></g><g><title>0x7ac54c668253 (libstdc++.so.6.0.30) (1,372 samples, 5.35%)</title><rect x="94.1970%" y="100" width="5.3506%" height="15" fill="rgb(223,211,37)" fg:x="24154" fg:w="1372"/><text x="94.4470%" y="110.50">0x7ac54..</text></g><g><title>torch::autograd::python::PythonEngine::thread_init (libtorch_python.so) (1,372 samples, 5.35%)</title><rect x="94.1970%" y="116" width="5.3506%" height="15" fill="rgb(235,49,27)" fg:x="24154" fg:w="1372"/><text x="94.4470%" y="126.50">torch::..</text></g><g><title>torch::autograd::Engine::thread_init (libtorch_cpu.so) (1,372 samples, 5.35%)</title><rect x="94.1970%" y="132" width="5.3506%" height="15" fill="rgb(254,97,51)" fg:x="24154" fg:w="1372"/><text x="94.4470%" y="142.50">torch::..</text></g><g><title>torch::autograd::Engine::thread_main (libtorch_cpu.so) (1,372 samples, 5.35%)</title><rect x="94.1970%" y="148" width="5.3506%" height="15" fill="rgb(249,51,40)" fg:x="24154" fg:w="1372"/><text x="94.4470%" y="158.50">torch::..</text></g><g><title>attack_range_s2s (cache_function.py:84) (59 samples, 0.23%)</title><rect x="99.6061%" y="132" width="0.2301%" height="15" fill="rgb(210,128,45)" fg:x="25541" fg:w="59"/><text x="99.8561%" y="142.50"></text></g><g><title>all (25,642 samples, 100%)</title><rect x="0.0000%" y="52" width="100.0000%" height="15" fill="rgb(224,137,50)" fg:x="0" fg:w="25642"/><text x="0.2500%" y="62.50"></text></g><g><title>&lt;module&gt; (self_play.py:377) (116 samples, 0.45%)</title><rect x="99.5476%" y="68" width="0.4524%" height="15" fill="rgb(242,15,9)" fg:x="25526" fg:w="116"/><text x="99.7976%" y="78.50"></text></g><g><title>main (self_play.py:374) (116 samples, 0.45%)</title><rect x="99.5476%" y="84" width="0.4524%" height="15" fill="rgb(233,187,41)" fg:x="25526" fg:w="116"/><text x="99.7976%" y="94.50"></text></g><g><title>learn (self_play.py:229) (116 samples, 0.45%)</title><rect x="99.5476%" y="100" width="0.4524%" height="15" fill="rgb(227,2,29)" fg:x="25526" fg:w="116"/><text x="99.7976%" y="110.50"></text></g><g><title>para_self_play (self_play.py:53) (116 samples, 0.45%)</title><rect x="99.5476%" y="116" width="0.4524%" height="15" fill="rgb(222,70,3)" fg:x="25526" fg:w="116"/><text x="99.7976%" y="126.50"></text></g></svg></svg>